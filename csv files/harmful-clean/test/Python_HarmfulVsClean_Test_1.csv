id,language,text,smell,tokens,metrics
124330,Python,"class BigtableDeleteInstanceOperator(BaseOperator, BigtableValidationMixin):
    """"""
    Deletes the Cloud Bigtable instance, including its clusters and all related tables.

    For more details about deleting instance have a look at the reference:
    https://googleapis.github.io/google-cloud-python/latest/bigtable/instance.html#google.cloud.bigtable.instance.Instance.delete

    .. seealso::
        For more information on how to use this operator, take a look at the guide:
        :ref:`howto/operator:BigtableDeleteInstanceOperator`

    :type instance_id: str
    :param instance_id: The ID of the Cloud Bigtable instance to delete.
    :param project_id: Optional, the ID of the Google Cloud project.  If set to None or missing,
            the default project_id from the Google Cloud connection is used.
    :type project_id: str
    :param gcp_conn_id: The connection ID to use to connect to Google Cloud.
    :type gcp_conn_id: str
    :param impersonation_chain: Optional service account to impersonate using short-term
        credentials, or chained list of accounts required to get the access_token
        of the last account in the list, which will be impersonated in the request.
        If set as a string, the account must grant the originating account
        the Service Account Token Creator IAM role.
        If set as a sequence, the identities from the list must grant
        Service Account Token Creator IAM role to the directly preceding identity, with first
        account from the list granting this role to the originating account (templated).
    :type impersonation_chain: Union[str, Sequence[str]]
    """"""

    REQUIRED_ATTRIBUTES = ('instance_id',)  # type: Iterable[str]
    template_fields = [
        'project_id',
        'instance_id',
        'impersonation_chain',
    ]  # type: Iterable[str]

    def __init__(
        self,
        *,
        instance_id: str,
        project_id: Optional[str] = None,
        gcp_conn_id: str = 'google_cloud_default',
        impersonation_chain: Optional[Union[str, Sequence[str]]] = None,
        **kwargs,
    ) -> None:
        self.project_id = project_id
        self.instance_id = instance_id
        self._validate_inputs()
        self.gcp_conn_id = gcp_conn_id
        self.impersonation_chain = impersonation_chain
        super().__init__(**kwargs)

    def execute(self, context) -> None:
        hook = BigtableHook(
            gcp_conn_id=self.gcp_conn_id,
            impersonation_chain=self.impersonation_chain,
        )
        try:
            hook.delete_instance(project_id=self.project_id, instance_id=self.instance_id)
        except google.api_core.exceptions.NotFound:
            self.log.info(
                ""The instance '%s' does not exist in project '%s'. Consider it as deleted"",
                self.instance_id,
                self.project_id,
            )
        except google.api_core.exceptions.GoogleAPICallError as e:
            self.log.error('An error occurred. Exiting.')
            raise e",0,587 2000 40 2001 44 2002 41 58 362 2003 61 40 362 44 41 330 2004 61 91 362 44 362 44 362 44 93 330 612 2005 40 2006 44 42 44 2007 58 813 44 2008 58 2009 91 813 93 61 470 44 2010 58 813 61 362 44 2011 58 2009 91 2012 91 813 44 2013 91 813 93 93 93 61 470 44 350 2014 44 41 354 470 58 2006 46 2008 61 2008 2006 46 2007 61 2007 2006 46 2015 40 41 2006 46 2010 61 2010 2006 46 2011 61 2011 818 40 41 46 2005 40 350 2014 41 612 2016 40 2006 44 2017 41 354 470 58 2018 61 2019 40 2010 61 2006 46 2010 44 2011 61 2006 46 2011 44 41 830 58 2018 46 2020 40 2008 61 2006 46 2008 44 2007 61 2006 46 2007 41 645 2021 46 2022 46 2023 46 2024 58 2006 46 2025 46 2026 40 362 44 2006 46 2007 44 2006 46 2008 44 41 645 2021 46 2022 46 2023 46 2027 552 2028 58 2006 46 2025 46 2029 40 362 41 778 2028 ,"{'AvgLine': 15, 'CountLine': 68, 'CountStmt': 19, 'MaxNesting': 1, 'AvgLineCode': 15, 'AvgEssential': 2, 'AvgLineBlank': 0, 'CountStmtExe': 16, 'MaxEssential': 3, 'SumEssential': 4, 'AvgCyclomatic': 2, 'CountLineCode': 38, 'CountStmtDecl': 10, 'MaxCyclomatic': 3, 'SumCyclomatic': 4, 'AvgLineComment': 0, 'CountClassBase': 2, 'CountLineBlank': 6, 'CountDeclMethod': 2, 'CountLineCodeExe': 27, 'CountLineComment': 26, 'CountClassCoupled': 3, 'CountClassDerived': 1, 'CountLineCodeDecl': 19, 'CountDeclMethodAll': 81, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '0.68', 'AvgCyclomaticStrict': 2, 'MaxCyclomaticStrict': 3, 'SumCyclomaticStrict': 4, 'AvgCyclomaticModified': 2, 'MaxCyclomaticModified': 3, 'SumCyclomaticModified': 4, 'CountDeclInstanceMethod': 2, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 4}"
124293,Python,"class HiveToMySqlOperator(BaseOperator):
    """"""
    Moves data from Hive to MySQL, note that for now the data is loaded
    into memory before being pushed to MySQL, so this operator should
    be used for smallish amount of data.

    :param sql: SQL query to execute against Hive server. (templated)
    :type sql: str
    :param mysql_table: target MySQL table, use dot notation to target a
        specific database. (templated)
    :type mysql_table: str
    :param mysql_conn_id: source mysql connection
    :type mysql_conn_id: str
    :param metastore_conn_id: Reference to the
        :ref:`metastore thrift service connection id <howto/connection:hive_metastore>`.
    :type metastore_conn_id: str
    :param mysql_preoperator: sql statement to run against mysql prior to
        import, typically use to truncate of delete in place
        of the data coming in, allowing the task to be idempotent (running
        the task twice won't double load data). (templated)
    :type mysql_preoperator: str
    :param mysql_postoperator: sql statement to run against mysql after the
        import, typically used to move data from staging to
        production and issue cleanup commands. (templated)
    :type mysql_postoperator: str
    :param bulk_load: flag to use bulk_load option.  This loads mysql directly
        from a tab-delimited text file using the LOAD DATA LOCAL INFILE command.
        This option requires an extra connection parameter for the
        destination MySQL connection: {'local_infile': true}.
    :type bulk_load: bool
    :param hive_conf:
    :type hive_conf: dict
    """"""

    template_fields = ('sql', 'mysql_table', 'mysql_preoperator', 'mysql_postoperator')
    template_ext = ('.sql',)
    ui_color = '#a0e08c'

    def __init__(
        self,
        *,
        sql: str,
        mysql_table: str,
        hiveserver2_conn_id: str = 'hiveserver2_default',
        mysql_conn_id: str = 'mysql_default',
        mysql_preoperator: Optional[str] = None,
        mysql_postoperator: Optional[str] = None,
        bulk_load: bool = False,
        hive_conf: Optional[Dict] = None,
        **kwargs,
    ) -> None:
        super().__init__(**kwargs)
        self.sql = sql
        self.mysql_table = mysql_table
        self.mysql_conn_id = mysql_conn_id
        self.mysql_preoperator = mysql_preoperator
        self.mysql_postoperator = mysql_postoperator
        self.hiveserver2_conn_id = hiveserver2_conn_id
        self.bulk_load = bulk_load
        self.hive_conf = hive_conf

    def execute(self, context):
        hive = HiveServer2Hook(hiveserver2_conn_id=self.hiveserver2_conn_id)

        self.log.info(""Extracting data from Hive: %s"", self.sql)
        hive_conf = context_to_airflow_vars(context)
        if self.hive_conf:
            hive_conf.update(self.hive_conf)
        if self.bulk_load:
            with NamedTemporaryFile() as tmp_file:
                hive.to_csv(
                    self.sql,
                    tmp_file.name,
                    delimiter='\t',
                    lineterminator='\n',
                    output_header=False,
                    hive_conf=hive_conf,
                )
                mysql = self._call_preoperator()
                mysql.bulk_load(table=self.mysql_table, tmp_file=tmp_file.name)
        else:
            hive_results = hive.get_records(self.sql, hive_conf=hive_conf)
            mysql = self._call_preoperator()
            mysql.insert_rows(table=self.mysql_table, rows=hive_results)

        if self.mysql_postoperator:
            self.log.info(""Running MySQL postoperator"")
            mysql.run(self.mysql_postoperator)

        self.log.info(""Done."")

    def _call_preoperator(self):
        mysql = MySqlHook(mysql_conn_id=self.mysql_conn_id)
        if self.mysql_preoperator:
            self.log.info(""Running MySQL preoperator"")
            mysql.run(self.mysql_preoperator)
        self.log.info(""Inserting rows into MySQL"")
        return mysql",0,587 2000 40 2001 41 58 362 2002 61 40 362 44 362 44 362 44 362 41 2003 61 40 362 44 41 2004 61 362 612 2005 40 2006 44 42 44 2007 58 813 44 2008 58 813 44 2009 58 813 61 362 44 2010 58 813 61 362 44 2011 58 2012 91 813 93 61 470 44 2013 58 2012 91 813 93 61 470 44 2014 58 569 61 443 44 2015 58 2012 91 2016 93 61 470 44 350 2017 44 41 354 470 58 818 40 41 46 2005 40 350 2017 41 2006 46 2007 61 2007 2006 46 2008 61 2008 2006 46 2010 61 2010 2006 46 2011 61 2011 2006 46 2013 61 2013 2006 46 2009 61 2009 2006 46 2014 61 2014 2006 46 2015 61 2015 612 2018 40 2006 44 2019 41 58 2020 61 2021 40 2009 61 2006 46 2009 41 2006 46 2022 46 2023 40 362 44 2006 46 2007 41 2015 61 2024 40 2019 41 688 2006 46 2015 58 2015 46 2025 40 2006 46 2015 41 688 2006 46 2014 58 871 2026 40 41 552 2027 58 2020 46 2028 40 2006 46 2007 44 2027 46 2029 44 2030 61 362 44 2031 61 362 44 2032 61 443 44 2015 61 2015 44 41 2033 61 2006 46 2034 40 41 2033 46 2014 40 2035 61 2006 46 2008 44 2027 61 2027 46 2029 41 630 58 2036 61 2020 46 2037 40 2006 46 2007 44 2015 61 2015 41 2033 61 2006 46 2034 40 41 2033 46 2038 40 2035 61 2006 46 2008 44 2039 61 2036 41 688 2006 46 2013 58 2006 46 2022 46 2023 40 362 41 2033 46 2040 40 2006 46 2013 41 2006 46 2022 46 2023 40 362 41 612 2034 40 2006 41 58 2033 61 2041 40 2010 61 2006 46 2010 41 688 2006 46 2011 58 2006 46 2022 46 2023 40 362 41 2033 46 2040 40 2006 46 2011 41 2006 46 2022 46 2023 40 362 41 792 2033 ,"{'AvgLine': 19, 'CountLine': 98, 'CountStmt': 39, 'MaxNesting': 2, 'AvgLineCode': 18, 'AvgEssential': 1, 'AvgLineBlank': 1, 'CountStmtExe': 35, 'MaxEssential': 1, 'SumEssential': 3, 'AvgCyclomatic': 2, 'CountLineCode': 59, 'CountStmtDecl': 20, 'MaxCyclomatic': 4, 'SumCyclomatic': 7, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 8, 'CountDeclMethod': 3, 'CountLineCodeExe': 43, 'CountLineComment': 32, 'CountClassCoupled': 5, 'CountClassDerived': 1, 'CountLineCodeDecl': 33, 'CountDeclMethodAll': 81, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '0.54', 'AvgCyclomaticStrict': 2, 'MaxCyclomaticStrict': 4, 'SumCyclomaticStrict': 7, 'AvgCyclomaticModified': 2, 'MaxCyclomaticModified': 4, 'SumCyclomaticModified': 7, 'CountDeclInstanceMethod': 3, 'CountClassCoupledModified': 2, 'CountDeclInstanceVariable': 8}"
124126,Python,"class TestFiles:
    def test_dist_folder_should_exists(self):
        run_bash_in_docker('[ -f /opt/airflow/airflow/www/static/dist/manifest.json ] || exit 1')",0,587 2000 58 612 2001 40 2002 41 58 2003 40 362 41 ,"{'AvgLine': 2, 'CountLine': 3, 'CountStmt': 3, 'MaxNesting': 0, 'AvgLineCode': 2, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 1, 'MaxEssential': 1, 'SumEssential': 1, 'AvgCyclomatic': 1, 'CountLineCode': 3, 'CountStmtDecl': 2, 'MaxCyclomatic': 1, 'SumCyclomatic': 1, 'AvgLineComment': 0, 'CountClassBase': 0, 'CountLineBlank': 0, 'CountDeclMethod': 1, 'CountLineCodeExe': 1, 'CountLineComment': 0, 'CountClassCoupled': 0, 'CountClassDerived': 0, 'CountLineCodeDecl': 2, 'CountDeclMethodAll': 1, 'MaxInheritanceTree': 0, 'RatioCommentToCode': '0.00', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 1, 'SumCyclomaticStrict': 1, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 1, 'SumCyclomaticModified': 1, 'CountDeclInstanceMethod': 1, 'CountClassCoupledModified': 0, 'CountDeclInstanceVariable': 0}"
124112,Python,"class CloudDataCatalogUpdateEntryOperator(BaseOperator):
    """"""
    Updates an existing entry.

    .. seealso::
        For more information on how to use this operator, take a look at the guide:
        :ref:`howto/operator:CloudDataCatalogUpdateEntryOperator`

    :param entry: Required. The updated entry. The ""name"" field must be set.

        If a dict is provided, it must be of the same form as the protobuf message
        :class:`~google.cloud.datacatalog_v1beta1.types.Entry`
    :type entry: Union[Dict, google.cloud.datacatalog_v1beta1.types.Entry]
    :param update_mask: The fields to update on the entry. If absent or empty, all modifiable fields are
        updated.

        If a dict is provided, it must be of the same form as the protobuf message
        :class:`~google.protobuf.field_mask_pb2.FieldMask`
    :type update_mask: Union[Dict, google.protobuf.field_mask_pb2.FieldMask]
    :param location: Required. The location of the entry to update.
    :type location: str
    :param entry_group: The entry group ID for the entry that is being updated.
    :type entry_group: str
    :param entry_id: The entry ID that is being updated.
    :type entry_id: str
    :param project_id: The ID of the Google Cloud project that owns the entry group.
        If set to ``None`` or missing, the default project_id from the Google Cloud connection is used.
    :type project_id: Optional[str]
    :param retry: A retry object used to retry requests. If ``None`` is specified, requests will be
        retried using a default configuration.
    :type retry: google.api_core.retry.Retry
    :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
        ``retry`` is specified, the timeout applies to each individual attempt.
    :type timeout: float
    :param metadata: Additional metadata that is provided to the method.
    :type metadata: Sequence[Tuple[str, str]]
    :param gcp_conn_id: Optional, The connection ID used to connect to Google Cloud.
        Defaults to 'google_cloud_default'.
    :type gcp_conn_id: str
    :param impersonation_chain: Optional service account to impersonate using short-term
        credentials, or chained list of accounts required to get the access_token
        of the last account in the list, which will be impersonated in the request.
        If set as a string, the account must grant the originating account
        the Service Account Token Creator IAM role.
        If set as a sequence, the identities from the list must grant
        Service Account Token Creator IAM role to the directly preceding identity, with first
        account from the list granting this role to the originating account (templated).
    :type impersonation_chain: Union[str, Sequence[str]]
    """"""

    template_fields = (
        ""entry"",
        ""update_mask"",
        ""location"",
        ""entry_group"",
        ""entry_id"",
        ""project_id"",
        ""retry"",
        ""timeout"",
        ""metadata"",
        ""gcp_conn_id"",
        ""impersonation_chain"",
    )

    def __init__(
        self,
        *,
        entry: Union[Dict, Entry],
        update_mask: Union[Dict, FieldMask],
        location: Optional[str] = None,
        entry_group: Optional[str] = None,
        entry_id: Optional[str] = None,
        project_id: Optional[str] = None,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
        gcp_conn_id: str = ""google_cloud_default"",
        impersonation_chain: Optional[Union[str, Sequence[str]]] = None,
        **kwargs,
    ) -> None:
        super().__init__(**kwargs)
        self.entry = entry
        self.update_mask = update_mask
        self.location = location
        self.entry_group = entry_group
        self.entry_id = entry_id
        self.project_id = project_id
        self.retry = retry
        self.timeout = timeout
        self.metadata = metadata
        self.gcp_conn_id = gcp_conn_id
        self.impersonation_chain = impersonation_chain

    def execute(self, context: dict) -> None:
        hook = CloudDataCatalogHook(
            gcp_conn_id=self.gcp_conn_id, impersonation_chain=self.impersonation_chain
        )
        hook.update_entry(
            entry=self.entry,
            update_mask=self.update_mask,
            location=self.location,
            entry_group=self.entry_group,
            entry_id=self.entry_id,
            project_id=self.project_id,
            retry=self.retry,
            timeout=self.timeout,
            metadata=self.metadata,
        )",0,587 2000 40 2001 41 58 362 2002 61 40 362 44 362 44 362 44 362 44 362 44 362 44 362 44 362 44 362 44 362 44 362 44 41 612 2003 40 2004 44 42 44 2005 58 2006 91 2007 44 2008 93 44 2009 58 2006 91 2007 44 2010 93 44 2011 58 2012 91 813 93 61 470 44 2013 58 2012 91 813 93 61 470 44 2014 58 2012 91 813 93 61 470 44 2015 58 2012 91 813 93 61 470 44 2016 58 2012 91 2017 93 61 470 44 2018 58 2012 91 660 93 61 470 44 2019 58 2020 91 2021 91 813 44 813 93 93 61 40 41 44 2022 58 813 61 362 44 2023 58 2012 91 2006 91 813 44 2020 91 813 93 93 93 61 470 44 350 2024 44 41 354 470 58 818 40 41 46 2003 40 350 2024 41 2004 46 2005 61 2005 2004 46 2009 61 2009 2004 46 2011 61 2011 2004 46 2013 61 2013 2004 46 2014 61 2014 2004 46 2015 61 2015 2004 46 2016 61 2016 2004 46 2018 61 2018 2004 46 2019 61 2019 2004 46 2022 61 2022 2004 46 2023 61 2023 612 2025 40 2004 44 2026 58 620 41 354 470 58 2027 61 2028 40 2022 61 2004 46 2022 44 2023 61 2004 46 2023 41 2027 46 2029 40 2005 61 2004 46 2005 44 2009 61 2004 46 2009 44 2011 61 2004 46 2011 44 2013 61 2004 46 2013 44 2014 61 2004 46 2014 44 2015 61 2004 46 2015 44 2016 61 2004 46 2016 44 2018 61 2004 46 2018 44 2019 61 2004 46 2019 44 41 ,"{'AvgLine': 21, 'CountLine': 108, 'CountStmt': 18, 'MaxNesting': 0, 'AvgLineCode': 21, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 15, 'MaxEssential': 1, 'SumEssential': 2, 'AvgCyclomatic': 1, 'CountLineCode': 57, 'CountStmtDecl': 16, 'MaxCyclomatic': 1, 'SumCyclomatic': 2, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 7, 'CountDeclMethod': 2, 'CountLineCodeExe': 39, 'CountLineComment': 44, 'CountClassCoupled': 5, 'CountClassDerived': 0, 'CountLineCodeDecl': 31, 'CountDeclMethodAll': 80, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '0.77', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 1, 'SumCyclomaticStrict': 2, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 1, 'SumCyclomaticModified': 2, 'CountDeclInstanceMethod': 2, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 11}"
124449,Python,"class CloudSQLExportInstanceOperator(CloudSQLBaseOperator):
    """"""
    Exports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL dump
    or CSV file.

    Note: This operator is idempotent. If executed multiple times with the same
    export file URI, the export file in GCS will simply be overridden.

    .. seealso::
        For more information on how to use this operator, take a look at the guide:
        :ref:`howto/operator:CloudSQLExportInstanceOperator`

    :param instance: Cloud SQL instance ID. This does not include the project ID.
    :type instance: str
    :param body: The request body, as described in
        https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/export#request-body
    :type body: dict
    :param project_id: Optional, Google Cloud Project ID. If set to None or missing,
            the default project_id from the Google Cloud connection is used.
    :type project_id: str
    :param gcp_conn_id: The connection ID used to connect to Google Cloud.
    :type gcp_conn_id: str
    :param api_version: API version used (e.g. v1beta4).
    :type api_version: str
    :param validate_body: Whether the body should be validated. Defaults to True.
    :type validate_body: bool
    :param impersonation_chain: Optional service account to impersonate using short-term
        credentials, or chained list of accounts required to get the access_token
        of the last account in the list, which will be impersonated in the request.
        If set as a string, the account must grant the originating account
        the Service Account Token Creator IAM role.
        If set as a sequence, the identities from the list must grant
        Service Account Token Creator IAM role to the directly preceding identity, with first
        account from the list granting this role to the originating account (templated).
    :type impersonation_chain: Union[str, Sequence[str]]
    """"""

    # [START gcp_sql_export_template_fields]
    template_fields = (
        'project_id',
        'instance',
        'body',
        'gcp_conn_id',
        'api_version',
        'impersonation_chain',
    )
    # [END gcp_sql_export_template_fields]

    def __init__(
        self,
        *,
        instance: str,
        body: dict,
        project_id: Optional[str] = None,
        gcp_conn_id: str = 'google_cloud_default',
        api_version: str = 'v1beta4',
        validate_body: bool = True,
        impersonation_chain: Optional[Union[str, Sequence[str]]] = None,
        **kwargs,
    ) -> None:
        self.body = body
        self.validate_body = validate_body
        super().__init__(
            project_id=project_id,
            instance=instance,
            gcp_conn_id=gcp_conn_id,
            api_version=api_version,
            impersonation_chain=impersonation_chain,
            **kwargs,
        )

    def _validate_inputs(self) -> None:
        super()._validate_inputs()
        if not self.body:
            raise AirflowException(""The required parameter 'body' is empty"")

    def _validate_body_fields(self) -> None:
        if self.validate_body:
            GcpBodyFieldValidator(CLOUD_SQL_EXPORT_VALIDATION, api_version=self.api_version).validate(
                self.body
            )

    def execute(self, context) -> None:
        self._validate_body_fields()
        hook = CloudSQLHook(
            gcp_conn_id=self.gcp_conn_id,
            api_version=self.api_version,
            impersonation_chain=self.impersonation_chain,
        )
        return hook.export_instance(project_id=self.project_id, instance=self.instance, body=self.body)",0,587 2000 40 2001 41 58 362 330 2002 61 40 362 44 362 44 362 44 362 44 362 44 362 44 41 330 612 2003 40 2004 44 42 44 2005 58 813 44 2006 58 620 44 2007 58 2008 91 813 93 61 470 44 2009 58 813 61 362 44 2010 58 813 61 362 44 2011 58 569 61 515 44 2012 58 2008 91 2013 91 813 44 2014 91 813 93 93 93 61 470 44 350 2015 44 41 354 470 58 2004 46 2006 61 2006 2004 46 2011 61 2011 818 40 41 46 2003 40 2007 61 2007 44 2005 61 2005 44 2009 61 2009 44 2010 61 2010 44 2012 61 2012 44 350 2015 44 41 612 2016 40 2004 41 354 470 58 818 40 41 46 2016 40 41 688 750 2004 46 2006 58 778 2017 40 362 41 612 2018 40 2004 41 354 470 58 688 2004 46 2011 58 2019 40 2020 44 2010 61 2004 46 2010 41 46 2021 40 2004 46 2006 41 612 2022 40 2004 44 2023 41 354 470 58 2004 46 2018 40 41 2024 61 2025 40 2009 61 2004 46 2009 44 2010 61 2004 46 2010 44 2012 61 2004 46 2012 44 41 792 2024 46 2026 40 2007 61 2004 46 2007 44 2005 61 2004 46 2005 44 2006 61 2004 46 2006 41 ,"{'AvgLine': 9, 'CountLine': 90, 'CountStmt': 17, 'MaxNesting': 1, 'AvgLineCode': 9, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 12, 'MaxEssential': 1, 'SumEssential': 4, 'AvgCyclomatic': 1, 'CountLineCode': 48, 'CountStmtDecl': 9, 'MaxCyclomatic': 2, 'SumCyclomatic': 6, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 8, 'CountDeclMethod': 4, 'CountLineCodeExe': 32, 'CountLineComment': 34, 'CountClassCoupled': 7, 'CountClassDerived': 1, 'CountLineCodeDecl': 23, 'CountDeclMethodAll': 88, 'MaxInheritanceTree': 4, 'RatioCommentToCode': '0.71', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 2, 'SumCyclomaticStrict': 6, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 2, 'SumCyclomaticModified': 6, 'CountDeclInstanceMethod': 4, 'CountClassCoupledModified': 3, 'CountDeclInstanceVariable': 6}"
124550,Python,"class AutoMLBatchPredictOperator(BaseOperator):
    """"""
    Perform a batch prediction on Google Cloud AutoML.

    .. seealso::
        For more information on how to use this operator, take a look at the guide:
        :ref:`howto/operator:AutoMLBatchPredictOperator`

    :param project_id: ID of the Google Cloud project where model will be created if None then
        default project_id is used.
    :type project_id: str
    :param location: The location of the project.
    :type location: str
    :param model_id: Name of the model_id requested to serve the batch prediction.
    :type model_id: str
    :param input_config: Required. The input configuration for batch prediction.
        If a dict is provided, it must be of the same form as the protobuf message
        `google.cloud.automl_v1beta1.types.BatchPredictInputConfig`
    :type input_config: Union[dict, ~google.cloud.automl_v1beta1.types.BatchPredictInputConfig]
    :param output_config: Required. The Configuration specifying where output predictions should be
        written. If a dict is provided, it must be of the same form as the protobuf message
        `google.cloud.automl_v1beta1.types.BatchPredictOutputConfig`
    :type output_config: Union[dict, ~google.cloud.automl_v1beta1.types.BatchPredictOutputConfig]
    :param prediction_params: Additional domain-specific parameters for the predictions,
        any string must be up to 25000 characters long.
    :type prediction_params: Optional[Dict[str, str]]
    :param project_id: ID of the Google Cloud project where model is located if None then
        default project_id is used.
    :type project_id: str
    :param location: The location of the project.
    :type location: str
    :param retry: A retry object used to retry requests. If `None` is specified, requests will not be
        retried.
    :type retry: Optional[google.api_core.retry.Retry]
    :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
        `retry` is specified, the timeout applies to each individual attempt.
    :type timeout: Optional[float]
    :param metadata: Additional metadata that is provided to the method.
    :type metadata: Optional[Sequence[Tuple[str, str]]]
    :param gcp_conn_id: The connection ID to use to connect to Google Cloud.
    :type gcp_conn_id: str
    :param impersonation_chain: Optional service account to impersonate using short-term
        credentials, or chained list of accounts required to get the access_token
        of the last account in the list, which will be impersonated in the request.
        If set as a string, the account must grant the originating account
        the Service Account Token Creator IAM role.
        If set as a sequence, the identities from the list must grant
        Service Account Token Creator IAM role to the directly preceding identity, with first
        account from the list granting this role to the originating account (templated).
    :type impersonation_chain: Union[str, Sequence[str]]
    """"""

    template_fields = (
        ""model_id"",
        ""input_config"",
        ""output_config"",
        ""location"",
        ""project_id"",
        ""impersonation_chain"",
    )

    def __init__(
        self,
        *,
        model_id: str,
        input_config: dict,
        output_config: dict,
        location: str,
        project_id: Optional[str] = None,
        prediction_params: Optional[Dict[str, str]] = None,
        metadata: MetaData = (),
        timeout: Optional[float] = None,
        retry: Optional[Retry] = None,
        gcp_conn_id: str = ""google_cloud_default"",
        impersonation_chain: Optional[Union[str, Sequence[str]]] = None,
        **kwargs,
    ) -> None:
        super().__init__(**kwargs)

        self.model_id = model_id
        self.location = location
        self.project_id = project_id
        self.prediction_params = prediction_params
        self.metadata = metadata
        self.timeout = timeout
        self.retry = retry
        self.gcp_conn_id = gcp_conn_id
        self.impersonation_chain = impersonation_chain
        self.input_config = input_config
        self.output_config = output_config

    def execute(self, context):
        hook = CloudAutoMLHook(
            gcp_conn_id=self.gcp_conn_id,
            impersonation_chain=self.impersonation_chain,
        )
        self.log.info(""Fetch batch prediction."")
        operation = hook.batch_predict(
            model_id=self.model_id,
            input_config=self.input_config,
            output_config=self.output_config,
            project_id=self.project_id,
            location=self.location,
            params=self.prediction_params,
            retry=self.retry,
            timeout=self.timeout,
            metadata=self.metadata,
        )
        result = BatchPredictResult.to_dict(operation.result())
        self.log.info(""Batch prediction ready."")
        return result",0,587 2000 40 2001 41 58 362 2002 61 40 362 44 362 44 362 44 362 44 362 44 362 44 41 612 2003 40 2004 44 42 44 2005 58 813 44 2006 58 620 44 2007 58 620 44 2008 58 813 44 2009 58 2010 91 813 93 61 470 44 2011 58 2010 91 2012 91 813 44 813 93 93 61 470 44 2013 58 2014 61 40 41 44 2015 58 2010 91 660 93 61 470 44 2016 58 2010 91 2017 93 61 470 44 2018 58 813 61 362 44 2019 58 2010 91 2020 91 813 44 2021 91 813 93 93 93 61 470 44 350 2022 44 41 354 470 58 818 40 41 46 2003 40 350 2022 41 2004 46 2005 61 2005 2004 46 2008 61 2008 2004 46 2009 61 2009 2004 46 2011 61 2011 2004 46 2013 61 2013 2004 46 2015 61 2015 2004 46 2016 61 2016 2004 46 2018 61 2018 2004 46 2019 61 2019 2004 46 2006 61 2006 2004 46 2007 61 2007 612 2023 40 2004 44 2024 41 58 2025 61 2026 40 2018 61 2004 46 2018 44 2019 61 2004 46 2019 44 41 2004 46 2027 46 2028 40 362 41 2029 61 2025 46 2030 40 2005 61 2004 46 2005 44 2006 61 2004 46 2006 44 2007 61 2004 46 2007 44 2009 61 2004 46 2009 44 2008 61 2004 46 2008 44 2031 61 2004 46 2011 44 2016 61 2004 46 2016 44 2015 61 2004 46 2015 44 2013 61 2004 46 2013 44 41 2032 61 2033 46 2034 40 2029 46 2032 40 41 41 2004 46 2027 46 2028 40 362 41 792 2032 ,"{'AvgLine': 24, 'CountLine': 111, 'CountStmt': 22, 'MaxNesting': 0, 'AvgLineCode': 24, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 19, 'MaxEssential': 1, 'SumEssential': 2, 'AvgCyclomatic': 1, 'CountLineCode': 57, 'CountStmtDecl': 18, 'MaxCyclomatic': 1, 'SumCyclomatic': 2, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 6, 'CountDeclMethod': 2, 'CountLineCodeExe': 39, 'CountLineComment': 48, 'CountClassCoupled': 5, 'CountClassDerived': 0, 'CountLineCodeDecl': 33, 'CountDeclMethodAll': 80, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '0.84', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 1, 'SumCyclomaticStrict': 2, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 1, 'SumCyclomaticModified': 2, 'CountDeclInstanceMethod': 2, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 11}"
124419,Python,"class SlackHook(BaseHook):
    """"""
    Creates a Slack connection to be used for calls.

    Takes both Slack API token directly and connection that has Slack API token. If both are
    supplied, Slack API token will be used. Also exposes the rest of slack.WebClient args.
    Examples:
    .. code-block:: python

        # Create hook
        slack_hook = SlackHook(token=""xxx"")  # or slack_hook = SlackHook(slack_conn_id=""slack"")

        # Call generic API with parameters (errors are handled by hook)
        #  For more details check https://api.slack.com/methods/chat.postMessage
        slack_hook.call(""chat.postMessage"", json={""channel"": ""#random"", ""text"": ""Hello world!""})

        # Call method from Slack SDK (you have to handle errors yourself)
        #  For more details check https://slack.dev/python-slack-sdk/web/index.html#messaging
        slack_hook.client.chat_postMessage(channel=""#random"", text=""Hello world!"")

    :param token: Slack API token
    :type token: str
    :param slack_conn_id: :ref:`Slack connection id <howto/connection:slack>`
        that has Slack API token in the password field.
    :type slack_conn_id: str
    :param use_session: A boolean specifying if the client should take advantage of
        connection pooling. Default is True.
    :type use_session: bool
    :param base_url: A string representing the Slack API base URL. Default is
        ``https://www.slack.com/api/``
    :type base_url: str
    :param timeout: The maximum number of seconds the client will wait
        to connect and receive a response from Slack. Default is 30 seconds.
    :type timeout: int
    """"""

    def __init__(
        self,
        token: Optional[str] = None,
        slack_conn_id: Optional[str] = None,
        **client_args: Any,
    ) -> None:
        super().__init__()
        self.token = self.__get_token(token, slack_conn_id)
        self.client = WebClient(self.token, **client_args)

    def __get_token(self, token: Any, slack_conn_id: Any) -> str:
        if token is not None:
            return token

        if slack_conn_id is not None:
            conn = self.get_connection(slack_conn_id)

            if not getattr(conn, 'password', None):
                raise AirflowException('Missing token(password) in Slack connection')
            return conn.password

        raise AirflowException('Cannot get token: No valid Slack token nor slack_conn_id supplied.')

    def call(self, api_method: str, **kwargs) -> None:
        """"""
        Calls Slack WebClient `WebClient.api_call` with given arguments.

        :param api_method: The target Slack API method. e.g. 'chat.postMessage'. Required.
        :type api_method: str
        :param http_verb: HTTP Verb. Optional (defaults to 'POST')
        :type http_verb: str
        :param files: Files to multipart upload. e.g. {imageORfile: file_objectORfile_path}
        :type files: dict
        :param data: The body to attach to the request. If a dictionary is provided,
            form-encoding will take place. Optional.
        :type data: dict or aiohttp.FormData
        :param params: The URL parameters to append to the URL. Optional.
        :type params: dict
        :param json: JSON for the body to attach to the request. Optional.
        :type json: dict
        """"""
        self.client.api_call(api_method, **kwargs)",0,587 2000 40 2001 41 58 362 612 2002 40 2003 44 2004 58 2005 91 813 93 61 470 44 2006 58 2005 91 813 93 61 470 44 350 2007 58 2008 44 41 354 470 58 818 40 41 46 2002 40 41 2003 46 2004 61 2003 46 2009 40 2004 44 2006 41 2003 46 2010 61 2011 40 2003 46 2004 44 350 2007 41 612 2009 40 2003 44 2004 58 2008 44 2006 58 2008 41 354 813 58 688 2004 712 750 470 58 792 2004 688 2006 712 750 470 58 2012 61 2003 46 2013 40 2006 41 688 750 673 40 2012 44 362 44 470 41 58 778 2014 40 362 41 792 2012 46 2015 778 2014 40 362 41 612 2016 40 2003 44 2017 58 813 44 350 2018 41 354 470 58 362 2003 46 2010 46 2019 40 2017 44 350 2018 41 ,"{'AvgLine': 13, 'CountLine': 78, 'CountStmt': 16, 'MaxNesting': 2, 'AvgLineCode': 6, 'AvgEssential': 2, 'AvgLineBlank': 1, 'CountStmtExe': 12, 'MaxEssential': 4, 'SumEssential': 6, 'AvgCyclomatic': 2, 'CountLineCode': 21, 'CountStmtDecl': 7, 'MaxCyclomatic': 4, 'SumCyclomatic': 6, 'AvgLineComment': 5, 'CountClassBase': 1, 'CountLineBlank': 12, 'CountDeclMethod': 3, 'CountLineCodeExe': 12, 'CountLineComment': 45, 'CountClassCoupled': 3, 'CountClassDerived': 0, 'CountLineCodeDecl': 12, 'CountDeclMethodAll': 10, 'MaxInheritanceTree': 2, 'RatioCommentToCode': '2.14', 'AvgCyclomaticStrict': 2, 'MaxCyclomaticStrict': 4, 'SumCyclomaticStrict': 6, 'AvgCyclomaticModified': 2, 'MaxCyclomaticModified': 4, 'SumCyclomaticModified': 6, 'CountDeclInstanceMethod': 3, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 2}"
124538,Python,"class TestCloudDLPListInspectTemplatesOperator(unittest.TestCase):
    @mock.patch(""airflow.providers.google.cloud.operators.dlp.CloudDLPHook"")
    def test_list_inspect_templates(self, mock_hook):
        mock_hook.return_value.list_inspect_templates.return_value = mock.MagicMock()
        operator = CloudDLPListInspectTemplatesOperator(organization_id=ORGANIZATION_ID, task_id=""id"")
        operator.execute(context=None)
        mock_hook.assert_called_once_with(
            gcp_conn_id=GCP_CONN_ID,
            impersonation_chain=None,
        )
        mock_hook.return_value.list_inspect_templates.assert_called_once_with(
            organization_id=ORGANIZATION_ID,
            project_id=None,
            page_size=None,
            order_by=None,
            retry=None,
            timeout=None,
            metadata=(),
        )",0,587 2000 40 2001 46 2002 41 58 64 2003 46 2004 40 362 41 612 2005 40 2006 44 2007 41 58 2007 46 2008 46 2009 46 2008 61 2003 46 2010 40 41 2011 61 2012 40 2013 61 2014 44 2015 61 362 41 2011 46 2016 40 2017 61 470 41 2007 46 2018 40 2019 61 2020 44 2021 61 470 44 41 2007 46 2008 46 2009 46 2018 40 2013 61 2014 44 2022 61 470 44 2023 61 470 44 2024 61 470 44 2025 61 470 44 2026 61 470 44 2027 61 40 41 44 41 ,"{'AvgLine': 17, 'CountLine': 19, 'CountStmt': 7, 'MaxNesting': 0, 'AvgLineCode': 17, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 5, 'MaxEssential': 1, 'SumEssential': 1, 'AvgCyclomatic': 1, 'CountLineCode': 19, 'CountStmtDecl': 3, 'MaxCyclomatic': 1, 'SumCyclomatic': 1, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 0, 'CountDeclMethod': 1, 'CountLineCodeExe': 16, 'CountLineComment': 0, 'CountClassCoupled': 1, 'CountClassDerived': 0, 'CountLineCodeDecl': 4, 'CountDeclMethodAll': 1, 'MaxInheritanceTree': 1, 'RatioCommentToCode': '0.00', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 1, 'SumCyclomaticStrict': 1, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 1, 'SumCyclomaticModified': 1, 'CountDeclInstanceMethod': 1, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 0}"
124642,Python,"class CloudMemorystoreScaleInstanceOperator(BaseOperator):
    """"""
    Updates the metadata and configuration of a specific Redis instance.

    .. seealso::
        For more information on how to use this operator, take a look at the guide:
        :ref:`howto/operator:CloudMemorystoreScaleInstanceOperator`

    :param memory_size_gb: Redis memory size in GiB.
    :type memory_size_gb: int
    :param location: The location of the Cloud Memorystore instance (for example europe-west1)
    :type location: str
    :param instance_id: The logical name of the Redis instance in the customer project.
    :type instance_id: str
    :param project_id: Project ID of the project that contains the instance. If set
        to None or missing, the default project_id from the Google Cloud connection is used.
    :type project_id: str
    :param retry: A retry object used to retry requests. If ``None`` is specified, requests will not be
        retried.
    :type retry: google.api_core.retry.Retry
    :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
        ``retry`` is specified, the timeout applies to each individual attempt.
    :type timeout: float
    :param metadata: Additional metadata that is provided to the method.
    :type metadata: Sequence[Tuple[str, str]]
    :param gcp_conn_id: The connection ID to use connecting to Google Cloud.
    :type gcp_conn_id: str
    :param impersonation_chain: Optional service account to impersonate using short-term
        credentials, or chained list of accounts required to get the access_token
        of the last account in the list, which will be impersonated in the request.
        If set as a string, the account must grant the originating account
        the Service Account Token Creator IAM role.
        If set as a sequence, the identities from the list must grant
        Service Account Token Creator IAM role to the directly preceding identity, with first
        account from the list granting this role to the originating account (templated).
    :type impersonation_chain: Union[str, Sequence[str]]
    """"""

    template_fields = (
        ""memory_size_gb"",
        ""location"",
        ""instance_id"",
        ""project_id"",
        ""retry"",
        ""timeout"",
        ""metadata"",
        ""gcp_conn_id"",
        ""impersonation_chain"",
    )

    def __init__(
        self,
        *,
        memory_size_gb: int,
        location: Optional[str] = None,
        instance_id: Optional[str] = None,
        project_id: Optional[str] = None,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
        gcp_conn_id: str = ""google_cloud_default"",
        impersonation_chain: Optional[Union[str, Sequence[str]]] = None,
        **kwargs,
    ) -> None:
        super().__init__(**kwargs)
        self.memory_size_gb = memory_size_gb
        self.location = location
        self.instance_id = instance_id
        self.project_id = project_id
        self.retry = retry
        self.timeout = timeout
        self.metadata = metadata
        self.gcp_conn_id = gcp_conn_id
        self.impersonation_chain = impersonation_chain

    def execute(self, context: dict) -> None:
        hook = CloudMemorystoreHook(
            gcp_conn_id=self.gcp_conn_id, impersonation_chain=self.impersonation_chain
        )

        hook.update_instance(
            update_mask={""paths"": [""memory_size_gb""]},
            instance={""memory_size_gb"": self.memory_size_gb},
            location=self.location,
            instance_id=self.instance_id,
            project_id=self.project_id,
            retry=self.retry,
            timeout=self.timeout,
            metadata=self.metadata,
        )",0,587 2000 40 2001 41 58 362 2002 61 40 362 44 362 44 362 44 362 44 362 44 362 44 362 44 362 44 362 44 41 612 2003 40 2004 44 42 44 2005 58 704 44 2006 58 2007 91 813 93 61 470 44 2008 58 2007 91 813 93 61 470 44 2009 58 2007 91 813 93 61 470 44 2010 58 2007 91 2011 93 61 470 44 2012 58 2007 91 660 93 61 470 44 2013 58 2014 91 2015 91 813 44 813 93 93 61 40 41 44 2016 58 813 61 362 44 2017 58 2007 91 2018 91 813 44 2014 91 813 93 93 93 61 470 44 350 2019 44 41 354 470 58 818 40 41 46 2003 40 350 2019 41 2004 46 2005 61 2005 2004 46 2006 61 2006 2004 46 2008 61 2008 2004 46 2009 61 2009 2004 46 2010 61 2010 2004 46 2012 61 2012 2004 46 2013 61 2013 2004 46 2016 61 2016 2004 46 2017 61 2017 612 2020 40 2004 44 2021 58 620 41 354 470 58 2022 61 2023 40 2016 61 2004 46 2016 44 2017 61 2004 46 2017 41 2022 46 2024 40 2025 61 123 362 58 91 362 93 125 44 2026 61 123 362 58 2004 46 2005 125 44 2006 61 2004 46 2006 44 2008 61 2004 46 2008 44 2009 61 2004 46 2009 44 2010 61 2004 46 2010 44 2012 61 2004 46 2012 44 2013 61 2004 46 2013 44 41 ,"{'AvgLine': 19, 'CountLine': 90, 'CountStmt': 16, 'MaxNesting': 0, 'AvgLineCode': 19, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 13, 'MaxEssential': 1, 'SumEssential': 2, 'AvgCyclomatic': 1, 'CountLineCode': 50, 'CountStmtDecl': 14, 'MaxCyclomatic': 1, 'SumCyclomatic': 2, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 6, 'CountDeclMethod': 2, 'CountLineCodeExe': 34, 'CountLineComment': 34, 'CountClassCoupled': 6, 'CountClassDerived': 0, 'CountLineCodeDecl': 27, 'CountDeclMethodAll': 80, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '0.68', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 1, 'SumCyclomaticStrict': 2, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 1, 'SumCyclomaticModified': 2, 'CountDeclInstanceMethod': 2, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 9}"
124071,Python,"class DataprocCreateWorkflowTemplateOperator(BaseOperator):
    """"""
    Creates new workflow template.

    :param project_id: Required. The ID of the Google Cloud project the cluster belongs to.
    :type project_id: str
    :param region: Required. The Cloud Dataproc region in which to handle the request.
    :type region: str
    :param location: (To be deprecated). The Cloud Dataproc region in which to handle the request.
    :type location: str
    :param template: The Dataproc workflow template to create. If a dict is provided,
        it must be of the same form as the protobuf message WorkflowTemplate.
    :type template: Union[dict, WorkflowTemplate]
    :param retry: A retry object used to retry requests. If ``None`` is specified, requests will not be
        retried.
    :type retry: google.api_core.retry.Retry
    :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
        ``retry`` is specified, the timeout applies to each individual attempt.
    :type timeout: float
    :param metadata: Additional metadata that is provided to the method.
    :type metadata: Sequence[Tuple[str, str]]
    """"""

    template_fields = (""region"", ""template"")
    template_fields_renderers = {""template"": ""json""}

    def __init__(
        self,
        *,
        template: Dict,
        project_id: str,
        region: Optional[str] = None,
        location: Optional[str] = None,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
        gcp_conn_id: str = ""google_cloud_default"",
        impersonation_chain: Optional[Union[str, Sequence[str]]] = None,
        **kwargs,
    ):
        if region is None:
            if location is not None:
                warnings.warn(
                    ""Parameter `location` will be deprecated. ""
                    ""Please provide value through `region` parameter instead."",
                    DeprecationWarning,
                    stacklevel=2,
                )
                region = location
            else:
                raise TypeError(""missing 1 required keyword argument: 'region'"")
        super().__init__(**kwargs)
        self.region = region
        self.template = template
        self.project_id = project_id
        self.retry = retry
        self.timeout = timeout
        self.metadata = metadata
        self.gcp_conn_id = gcp_conn_id
        self.impersonation_chain = impersonation_chain

    def execute(self, context):
        hook = DataprocHook(gcp_conn_id=self.gcp_conn_id, impersonation_chain=self.impersonation_chain)
        self.log.info(""Creating template"")
        try:
            workflow = hook.create_workflow_template(
                region=self.region,
                template=self.template,
                project_id=self.project_id,
                retry=self.retry,
                timeout=self.timeout,
                metadata=self.metadata,
            )
            self.log.info(""Workflow %s created"", workflow.name)
        except AlreadyExists:
            self.log.info(""Workflow with given id already exists"")",0,587 2000 40 2001 41 58 362 2002 61 40 362 44 362 41 2003 61 123 362 58 362 125 612 2004 40 2005 44 42 44 2006 58 2007 44 2008 58 813 44 2009 58 2010 91 813 93 61 470 44 2011 58 2010 91 813 93 61 470 44 2012 58 2010 91 2013 93 61 470 44 2014 58 2010 91 660 93 61 470 44 2015 58 2016 91 2017 91 813 44 813 93 93 61 40 41 44 2018 58 813 61 362 44 2019 58 2010 91 2020 91 813 44 2016 91 813 93 93 93 61 470 44 350 2021 44 41 58 688 2009 712 470 58 688 2011 712 750 470 58 2022 46 2023 40 362 362 44 2024 44 2025 61 1502 44 41 2009 61 2011 630 58 778 2026 40 362 41 818 40 41 46 2004 40 350 2021 41 2005 46 2009 61 2009 2005 46 2006 61 2006 2005 46 2008 61 2008 2005 46 2012 61 2012 2005 46 2014 61 2014 2005 46 2015 61 2015 2005 46 2018 61 2018 2005 46 2019 61 2019 612 2027 40 2005 44 2028 41 58 2029 61 2030 40 2018 61 2005 46 2018 44 2019 61 2005 46 2019 41 2005 46 2031 46 2032 40 362 41 830 58 2033 61 2029 46 2034 40 2009 61 2005 46 2009 44 2006 61 2005 46 2006 44 2008 61 2005 46 2008 44 2012 61 2005 46 2012 44 2014 61 2005 46 2014 44 2015 61 2005 46 2015 44 41 2005 46 2031 46 2032 40 362 44 2033 46 2035 41 645 2036 58 2005 46 2031 46 2032 40 362 41 ,"{'AvgLine': 24, 'CountLine': 76, 'CountStmt': 26, 'MaxNesting': 2, 'AvgLineCode': 24, 'AvgEssential': 2, 'AvgLineBlank': 0, 'CountStmtExe': 23, 'MaxEssential': 3, 'SumEssential': 4, 'AvgCyclomatic': 2, 'CountLineCode': 52, 'CountStmtDecl': 15, 'MaxCyclomatic': 3, 'SumCyclomatic': 5, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 4, 'CountDeclMethod': 2, 'CountLineCodeExe': 36, 'CountLineComment': 20, 'CountClassCoupled': 4, 'CountClassDerived': 0, 'CountLineCodeDecl': 28, 'CountDeclMethodAll': 80, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '0.38', 'AvgCyclomaticStrict': 2, 'MaxCyclomaticStrict': 3, 'SumCyclomaticStrict': 5, 'AvgCyclomaticModified': 2, 'MaxCyclomaticModified': 3, 'SumCyclomaticModified': 5, 'CountDeclInstanceMethod': 2, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 8}"
124658,Python,"class PubSubPullSensor(BaseSensorOperator):
    """"""Pulls messages from a PubSub subscription and passes them through XCom.
    Always waits for at least one message to be returned from the subscription.

    .. seealso::
        For more information on how to use this operator, take a look at the guide:
        :ref:`howto/operator:PubSubPullSensor`

    .. seealso::
        If you don't want to wait for at least one message to come, use Operator instead:
        :class:`~airflow.providers.google.cloud.operators.pubsub.PubSubPullOperator`

    This sensor operator will pull up to ``max_messages`` messages from the
    specified PubSub subscription. When the subscription returns messages,
    the poke method's criteria will be fulfilled and the messages will be
    returned from the operator and passed through XCom for downstream tasks.

    If ``ack_messages`` is set to True, messages will be immediately
    acknowledged before being returned, otherwise, downstream tasks will be
    responsible for acknowledging them.

    ``project`` and ``subscription`` are templated so you can use
    variables in them.

    :param project: the Google Cloud project ID for the subscription (templated)
    :type project: str
    :param subscription: the Pub/Sub subscription name. Do not include the
        full subscription path.
    :type subscription: str
    :param max_messages: The maximum number of messages to retrieve per
        PubSub pull request
    :type max_messages: int
    :param return_immediately:
        (Deprecated) This is an underlying PubSub API implementation detail.
        It has no real effect on Sensor behaviour other than some internal wait time before retrying
        on empty queue.
        The Sensor task will (by definition) always wait for a message, regardless of this argument value.

        If you want a non-blocking task that does not to wait for messages, please use
        :class:`~airflow.providers.google.cloud.operators.pubsub.PubSubPullOperator`
        instead.
    :type return_immediately: bool
    :param ack_messages: If True, each message will be acknowledged
        immediately rather than by any downstream tasks
    :type ack_messages: bool
    :param gcp_conn_id: The connection ID to use connecting to
        Google Cloud.
    :type gcp_conn_id: str
    :param delegate_to: The account to impersonate using domain-wide delegation of authority,
        if any. For this to work, the service account making the request must have
        domain-wide delegation enabled.
    :type delegate_to: str
    :param messages_callback: (Optional) Callback to process received messages.
        It's return value will be saved to XCom.
        If you are pulling large messages, you probably want to provide a custom callback.
        If not provided, the default implementation will convert `ReceivedMessage` objects
        into JSON-serializable dicts using `google.protobuf.json_format.MessageToDict` function.
    :type messages_callback: Optional[Callable[[List[ReceivedMessage], Dict[str, Any]], Any]]
    :param impersonation_chain: Optional service account to impersonate using short-term
        credentials, or chained list of accounts required to get the access_token
        of the last account in the list, which will be impersonated in the request.
        If set as a string, the account must grant the originating account
        the Service Account Token Creator IAM role.
        If set as a sequence, the identities from the list must grant
        Service Account Token Creator IAM role to the directly preceding identity, with first
        account from the list granting this role to the originating account (templated).
    :type impersonation_chain: Union[str, Sequence[str]]
    """"""

    template_fields = [
        'project_id',
        'subscription',
        'impersonation_chain',
    ]
    ui_color = '#ff7f50'

    def __init__(
        self,
        *,
        project_id: str,
        subscription: str,
        max_messages: int = 5,
        return_immediately: bool = True,
        ack_messages: bool = False,
        gcp_conn_id: str = 'google_cloud_default',
        messages_callback: Optional[Callable[[List[ReceivedMessage], Dict[str, Any]], Any]] = None,
        delegate_to: Optional[str] = None,
        project: Optional[str] = None,
        impersonation_chain: Optional[Union[str, Sequence[str]]] = None,
        **kwargs,
    ) -> None:
        # To preserve backward compatibility
        # TODO: remove one day
        if project:
            warnings.warn(
                ""The project parameter has been deprecated. You should pass the project_id parameter."",
                DeprecationWarning,
                stacklevel=2,
            )
            project_id = project

        if not return_immediately:
            warnings.warn(
                ""The return_immediately parameter is deprecated.\n""
                "" It exposes what is really just an implementation detail of underlying PubSub API.\n""
                "" It has no effect on PubSubPullSensor behaviour.\n""
                "" It should be left as default value of True.\n""
                "" If is here only because of backwards compatibility.\n""
                "" If may be removed in the future.\n"",
                DeprecationWarning,
                stacklevel=2,
            )

        super().__init__(**kwargs)
        self.gcp_conn_id = gcp_conn_id
        self.delegate_to = delegate_to
        self.project_id = project_id
        self.subscription = subscription
        self.max_messages = max_messages
        self.return_immediately = return_immediately
        self.ack_messages = ack_messages
        self.messages_callback = messages_callback
        self.impersonation_chain = impersonation_chain

        self._return_value = None

    def execute(self, context: dict):
        """"""Overridden to allow messages to be passed""""""
        super().execute(context)
        return self._return_value

    def poke(self, context: dict) -> bool:
        hook = PubSubHook(
            gcp_conn_id=self.gcp_conn_id,
            delegate_to=self.delegate_to,
            impersonation_chain=self.impersonation_chain,
        )

        pulled_messages = hook.pull(
            project_id=self.project_id,
            subscription=self.subscription,
            max_messages=self.max_messages,
            return_immediately=self.return_immediately,
        )

        handle_messages = self.messages_callback or self._default_message_callback

        self._return_value = handle_messages(pulled_messages, context)

        if pulled_messages and self.ack_messages:
            hook.acknowledge(
                project_id=self.project_id,
                subscription=self.subscription,
                messages=pulled_messages,
            )

        return bool(pulled_messages)

    def _default_message_callback(
        self,
        pulled_messages: List[ReceivedMessage],
        context: Dict[str, Any],
    ):
        """"""
        This method can be overridden by subclasses or by `messages_callback` constructor argument.
        This default implementation converts `ReceivedMessage` objects into JSON-serializable dicts.

        :param pulled_messages: messages received from the topic.
        :type pulled_messages: List[ReceivedMessage]
        :param context: same as in `execute`
        :return: value to be saved to XCom.
        """"""
        messages_json = [ReceivedMessage.to_dict(m) for m in pulled_messages]

        return messages_json",0,587 2000 40 2001 41 58 362 2002 61 91 362 44 362 44 362 44 93 2003 61 362 612 2004 40 2005 44 42 44 2006 58 813 44 2007 58 813 44 2008 58 704 61 1502 44 2009 58 569 61 515 44 2010 58 569 61 443 44 2011 58 813 61 362 44 2012 58 2013 91 2014 91 91 2015 91 2016 93 44 2017 91 813 44 2018 93 93 44 2018 93 93 61 470 44 2019 58 2013 91 813 93 61 470 44 2020 58 2013 91 813 93 61 470 44 2021 58 2013 91 2022 91 813 44 2023 91 813 93 93 93 61 470 44 350 2024 44 41 354 470 58 330 330 688 2020 58 2025 46 2026 40 362 44 2027 44 2028 61 1502 44 41 2006 61 2020 688 750 2009 58 2025 46 2026 40 362 362 362 362 362 362 44 2027 44 2028 61 1502 44 41 818 40 41 46 2004 40 350 2024 41 2005 46 2011 61 2011 2005 46 2019 61 2019 2005 46 2006 61 2006 2005 46 2007 61 2007 2005 46 2008 61 2008 2005 46 2009 61 2009 2005 46 2010 61 2010 2005 46 2012 61 2012 2005 46 2021 61 2021 2005 46 2029 61 470 612 2030 40 2005 44 2031 58 620 41 58 362 818 40 41 46 2030 40 2031 41 792 2005 46 2029 612 2032 40 2005 44 2031 58 620 41 354 569 58 2033 61 2034 40 2011 61 2005 46 2011 44 2019 61 2005 46 2019 44 2021 61 2005 46 2021 44 41 2035 61 2033 46 2036 40 2006 61 2005 46 2006 44 2007 61 2005 46 2007 44 2008 61 2005 46 2008 44 2009 61 2005 46 2009 44 41 2037 61 2005 46 2012 759 2005 46 2038 2005 46 2029 61 2037 40 2035 44 2031 41 688 2035 545 2005 46 2010 58 2033 46 2039 40 2006 61 2005 46 2006 44 2007 61 2005 46 2007 44 2040 61 2035 44 41 792 569 40 2035 41 612 2038 40 2005 44 2035 58 2015 91 2016 93 44 2031 58 2017 91 813 44 2018 93 44 41 58 362 2041 61 91 2016 46 2042 40 2043 41 664 2043 696 2035 93 792 2041 ,"{'AvgLine': 24, 'CountLine': 175, 'CountStmt': 34, 'MaxNesting': 1, 'AvgLineCode': 18, 'AvgEssential': 1, 'AvgLineBlank': 2, 'CountStmtExe': 29, 'MaxEssential': 1, 'SumEssential': 4, 'AvgCyclomatic': 1, 'CountLineCode': 82, 'CountStmtDecl': 21, 'MaxCyclomatic': 3, 'SumCyclomatic': 7, 'AvgLineComment': 2, 'CountClassBase': 1, 'CountLineBlank': 22, 'CountDeclMethod': 4, 'CountLineCodeExe': 59, 'CountLineComment': 72, 'CountClassCoupled': 6, 'CountClassDerived': 0, 'CountLineCodeDecl': 39, 'CountDeclMethodAll': 94, 'MaxInheritanceTree': 4, 'RatioCommentToCode': '0.88', 'AvgCyclomaticStrict': 2, 'MaxCyclomaticStrict': 4, 'SumCyclomaticStrict': 9, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 3, 'SumCyclomaticModified': 7, 'CountDeclInstanceMethod': 4, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 10}"
124552,Python,"class AutoMLDeleteDatasetOperator(BaseOperator):
    """"""
    Deletes a dataset and all of its contents.

    .. seealso::
        For more information on how to use this operator, take a look at the guide:
        :ref:`howto/operator:AutoMLDeleteDatasetOperator`

    :param dataset_id: Name of the dataset_id, list of dataset_id or string of dataset_id
        coma separated to be deleted.
    :type dataset_id: Union[str, List[str]]
    :param project_id: ID of the Google Cloud project where dataset is located if None then
        default project_id is used.
    :type project_id: str
    :param location: The location of the project.
    :type location: str
    :param retry: A retry object used to retry requests. If `None` is specified, requests will not be
        retried.
    :type retry: Optional[google.api_core.retry.Retry]
    :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
        `retry` is specified, the timeout applies to each individual attempt.
    :type timeout: Optional[float]
    :param metadata: Additional metadata that is provided to the method.
    :type metadata: Optional[Sequence[Tuple[str, str]]]
    :param gcp_conn_id: The connection ID to use to connect to Google Cloud.
    :type gcp_conn_id: str
    :param impersonation_chain: Optional service account to impersonate using short-term
        credentials, or chained list of accounts required to get the access_token
        of the last account in the list, which will be impersonated in the request.
        If set as a string, the account must grant the originating account
        the Service Account Token Creator IAM role.
        If set as a sequence, the identities from the list must grant
        Service Account Token Creator IAM role to the directly preceding identity, with first
        account from the list granting this role to the originating account (templated).
    :type impersonation_chain: Union[str, Sequence[str]]
    """"""

    template_fields = (
        ""dataset_id"",
        ""location"",
        ""project_id"",
        ""impersonation_chain"",
    )

    def __init__(
        self,
        *,
        dataset_id: Union[str, List[str]],
        location: str,
        project_id: Optional[str] = None,
        metadata: MetaData = (),
        timeout: Optional[float] = None,
        retry: Optional[Retry] = None,
        gcp_conn_id: str = ""google_cloud_default"",
        impersonation_chain: Optional[Union[str, Sequence[str]]] = None,
        **kwargs,
    ) -> None:
        super().__init__(**kwargs)

        self.dataset_id = dataset_id
        self.location = location
        self.project_id = project_id
        self.metadata = metadata
        self.timeout = timeout
        self.retry = retry
        self.gcp_conn_id = gcp_conn_id
        self.impersonation_chain = impersonation_chain

    @staticmethod
    def _parse_dataset_id(dataset_id: Union[str, List[str]]) -> List[str]:
        if not isinstance(dataset_id, str):
            return dataset_id
        try:
            return ast.literal_eval(dataset_id)
        except (SyntaxError, ValueError):
            return dataset_id.split("","")

    def execute(self, context):
        hook = CloudAutoMLHook(
            gcp_conn_id=self.gcp_conn_id,
            impersonation_chain=self.impersonation_chain,
        )
        dataset_id_list = self._parse_dataset_id(self.dataset_id)
        for dataset_id in dataset_id_list:
            self.log.info(""Deleting dataset %s"", dataset_id)
            hook.delete_dataset(
                dataset_id=dataset_id,
                location=self.location,
                project_id=self.project_id,
                retry=self.retry,
                timeout=self.timeout,
                metadata=self.metadata,
            )
            self.log.info(""Dataset deleted."")",0,587 2000 40 2001 41 58 362 2002 61 40 362 44 362 44 362 44 362 44 41 612 2003 40 2004 44 42 44 2005 58 2006 91 813 44 2007 91 813 93 93 44 2008 58 813 44 2009 58 2010 91 813 93 61 470 44 2011 58 2012 61 40 41 44 2013 58 2010 91 660 93 61 470 44 2014 58 2010 91 2015 93 61 470 44 2016 58 813 61 362 44 2017 58 2010 91 2006 91 813 44 2018 91 813 93 93 93 61 470 44 350 2019 44 41 354 470 58 818 40 41 46 2003 40 350 2019 41 2004 46 2005 61 2005 2004 46 2008 61 2008 2004 46 2009 61 2009 2004 46 2011 61 2011 2004 46 2013 61 2013 2004 46 2014 61 2014 2004 46 2016 61 2016 2004 46 2017 61 2017 64 812 612 2020 40 2005 58 2006 91 813 44 2007 91 813 93 93 41 354 2007 91 813 93 58 688 750 713 40 2005 44 813 41 58 792 2005 830 58 792 2021 46 2022 40 2005 41 645 40 2023 44 2024 41 58 792 2005 46 2025 40 362 41 612 2026 40 2004 44 2027 41 58 2028 61 2029 40 2016 61 2004 46 2016 44 2017 61 2004 46 2017 44 41 2030 61 2004 46 2020 40 2004 46 2005 41 664 2005 696 2030 58 2004 46 2031 46 2032 40 362 44 2005 41 2028 46 2033 40 2005 61 2005 44 2008 61 2004 46 2008 44 2009 61 2004 46 2009 44 2014 61 2004 46 2014 44 2013 61 2004 46 2013 44 2011 61 2004 46 2011 44 41 2004 46 2031 46 2032 40 362 41 ,"{'AvgLine': 15, 'CountLine': 94, 'CountStmt': 26, 'MaxNesting': 1, 'AvgLineCode': 15, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 22, 'MaxEssential': 3, 'SumEssential': 5, 'AvgCyclomatic': 2, 'CountLineCode': 54, 'CountStmtDecl': 16, 'MaxCyclomatic': 3, 'SumCyclomatic': 6, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 7, 'CountDeclMethod': 3, 'CountLineCodeExe': 37, 'CountLineComment': 33, 'CountClassCoupled': 4, 'CountClassDerived': 0, 'CountLineCodeDecl': 29, 'CountDeclMethodAll': 81, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '0.61', 'AvgCyclomaticStrict': 2, 'MaxCyclomaticStrict': 3, 'SumCyclomaticStrict': 6, 'AvgCyclomaticModified': 2, 'MaxCyclomaticModified': 3, 'SumCyclomaticModified': 6, 'CountDeclInstanceMethod': 2, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 8}"
124398,Python,"class TriggerDagRunLink(BaseOperatorLink):
    """"""
    Operator link for TriggerDagRunOperator. It allows users to access
    DAG triggered by task using TriggerDagRunOperator.
    """"""

    name = 'Triggered DAG'

    def get_link(self, operator, dttm):
        # Fetch the correct execution date for the triggerED dag which is
        # stored in xcom during execution of the triggerING task.
        trigger_execution_date_iso = XCom.get_one(
            execution_date=dttm, key=XCOM_EXECUTION_DATE_ISO, task_id=operator.task_id, dag_id=operator.dag_id
        )

        query = {""dag_id"": operator.trigger_dag_id, ""base_date"": trigger_execution_date_iso}
        return build_airflow_url_with_query(query)",0,587 2000 40 2001 41 58 362 2002 61 362 612 2003 40 2004 44 2005 44 2006 41 58 330 330 2007 61 2008 46 2009 40 2010 61 2006 44 2011 61 2012 44 2013 61 2005 46 2013 44 2014 61 2005 46 2014 41 2015 61 123 362 58 2005 46 2016 44 362 58 2007 125 792 2017 40 2015 41 ,"{'AvgLine': 9, 'CountLine': 17, 'CountStmt': 6, 'MaxNesting': 0, 'AvgLineCode': 6, 'AvgEssential': 1, 'AvgLineBlank': 1, 'CountStmtExe': 4, 'MaxEssential': 1, 'SumEssential': 1, 'AvgCyclomatic': 1, 'CountLineCode': 8, 'CountStmtDecl': 5, 'MaxCyclomatic': 1, 'SumCyclomatic': 1, 'AvgLineComment': 2, 'CountClassBase': 1, 'CountLineBlank': 3, 'CountDeclMethod': 1, 'CountLineCodeExe': 6, 'CountLineComment': 6, 'CountClassCoupled': 0, 'CountClassDerived': 0, 'CountLineCodeDecl': 5, 'CountDeclMethodAll': 3, 'MaxInheritanceTree': 2, 'RatioCommentToCode': '0.75', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 1, 'SumCyclomaticStrict': 1, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 1, 'SumCyclomaticModified': 1, 'CountDeclInstanceMethod': 1, 'CountClassCoupledModified': 0, 'CountDeclInstanceVariable': 0}"
124502,Python,"class TestCloudLanguageClassifyTextOperator(unittest.TestCase):
    @patch(""airflow.providers.google.cloud.operators.natural_language.CloudNaturalLanguageHook"")
    def test_minimal_green_path(self, hook_mock):
        hook_mock.return_value.classify_text.return_value = CLASSIFY_TEXT_RESPONSE
        op = CloudNaturalLanguageClassifyTextOperator(task_id=""task-id"", document=DOCUMENT)
        resp = op.execute({})
        assert resp == {}",0,587 2000 40 2001 46 2002 41 58 64 2003 40 362 41 612 2004 40 2005 44 2006 41 58 2006 46 2007 46 2008 46 2007 61 2009 2010 61 2011 40 2012 61 362 44 2013 61 2014 41 2015 61 2010 46 2016 40 123 125 41 555 2015 323 123 125 ,"{'AvgLine': 5, 'CountLine': 7, 'CountStmt': 6, 'MaxNesting': 0, 'AvgLineCode': 5, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 4, 'MaxEssential': 1, 'SumEssential': 1, 'AvgCyclomatic': 1, 'CountLineCode': 7, 'CountStmtDecl': 4, 'MaxCyclomatic': 1, 'SumCyclomatic': 1, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 0, 'CountDeclMethod': 1, 'CountLineCodeExe': 4, 'CountLineComment': 0, 'CountClassCoupled': 1, 'CountClassDerived': 0, 'CountLineCodeDecl': 5, 'CountDeclMethodAll': 1, 'MaxInheritanceTree': 1, 'RatioCommentToCode': '0.00', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 1, 'SumCyclomaticStrict': 1, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 1, 'SumCyclomaticModified': 1, 'CountDeclInstanceMethod': 1, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 0}"
124442,Python,"class CloudSqlInstancePatchOperator(CloudSQLInstancePatchOperator):
    """"""
    This class is deprecated. Please use `airflow.providers.google.cloud.operators
    .sql.CloudSQLInstancePatchOperator`.
    """"""

    def __init__(self, *args, **kwargs):
        warnings.warn(self.__doc__, DeprecationWarning, stacklevel=2)
        super().__init__(*args, **kwargs)",0,587 2000 40 2001 41 58 362 612 2002 40 2003 44 42 2004 44 350 2005 41 58 2006 46 2007 40 2003 46 2008 44 2009 44 2010 61 1502 41 818 40 41 46 2002 40 42 2004 44 350 2005 41 ,"{'AvgLine': 3, 'CountLine': 9, 'CountStmt': 4, 'MaxNesting': 0, 'AvgLineCode': 3, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 2, 'MaxEssential': 1, 'SumEssential': 1, 'AvgCyclomatic': 1, 'CountLineCode': 4, 'CountStmtDecl': 2, 'MaxCyclomatic': 1, 'SumCyclomatic': 1, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 1, 'CountDeclMethod': 1, 'CountLineCodeExe': 2, 'CountLineComment': 4, 'CountClassCoupled': 1, 'CountClassDerived': 0, 'CountLineCodeDecl': 3, 'CountDeclMethodAll': 88, 'MaxInheritanceTree': 5, 'RatioCommentToCode': '1.00', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 1, 'SumCyclomaticStrict': 1, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 1, 'SumCyclomaticModified': 1, 'CountDeclInstanceMethod': 1, 'CountClassCoupledModified': 0, 'CountDeclInstanceVariable': 1}"
124154,Python,"class PubSubDeleteTopicOperator(BaseOperator):
    """"""Delete a PubSub topic.

    .. seealso::
        For more information on how to use this operator, take a look at the guide:
        :ref:`howto/operator:PubSubDeleteTopicOperator`

    By default, if the topic does not exist, this operator will
    not cause the DAG to fail. ::

        with DAG('successful DAG') as dag:
            (
                PubSubTopicDeleteOperator(project='my-project',
                                             topic='non_existing_topic')
            )

    The operator can be configured to fail if the topic does not exist. ::

        with DAG('failing DAG') as dag:
            (
                PubSubTopicCreateOperator(project='my-project',
                                             topic='non_existing_topic',
                                             fail_if_not_exists=True)
            )

    Both ``project`` and ``topic`` are templated so you can use
    variables in them.

    :param project_id: Optional, the Google Cloud project ID in which to work (templated).
        If set to None or missing, the default project_id from the Google Cloud connection is used.
    :type project_id: str
    :param topic: the topic to delete. Do not include the
        full topic path. In other words, instead of
        ``projects/{project}/topics/{topic}``, provide only
        ``{topic}``. (templated)
    :type topic: str
    :param fail_if_not_exists: If True and the topic does not exist, fail
        the task
    :type fail_if_not_exists: bool
    :param gcp_conn_id: The connection ID to use connecting to
        Google Cloud.
    :type gcp_conn_id: str
    :param delegate_to: The account to impersonate using domain-wide delegation of authority,
        if any. For this to work, the service account making the request must have
        domain-wide delegation enabled.
    :type delegate_to: str
    :param retry: (Optional) A retry object used to retry requests.
        If None is specified, requests will not be retried.
    :type retry: google.api_core.retry.Retry
    :param timeout: (Optional) The amount of time, in seconds, to wait for the request
        to complete. Note that if retry is specified, the timeout applies to each
        individual attempt.
    :type timeout: float
    :param metadata: (Optional) Additional metadata that is provided to the method.
    :type metadata: Sequence[Tuple[str, str]]]
    :param project: (Deprecated) the Google Cloud project ID where the topic will be created
    :type project: str
    :param impersonation_chain: Optional service account to impersonate using short-term
        credentials, or chained list of accounts required to get the access_token
        of the last account in the list, which will be impersonated in the request.
        If set as a string, the account must grant the originating account
        the Service Account Token Creator IAM role.
        If set as a sequence, the identities from the list must grant
        Service Account Token Creator IAM role to the directly preceding identity, with first
        account from the list granting this role to the originating account (templated).
    :type impersonation_chain: Union[str, Sequence[str]]
    """"""

    template_fields = [
        'project_id',
        'topic',
        'impersonation_chain',
    ]
    ui_color = '#cb4335'

    def __init__(
        self,
        *,
        topic: str,
        project_id: Optional[str] = None,
        fail_if_not_exists: bool = False,
        gcp_conn_id: str = 'google_cloud_default',
        delegate_to: Optional[str] = None,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
        project: Optional[str] = None,
        impersonation_chain: Optional[Union[str, Sequence[str]]] = None,
        **kwargs,
    ) -> None:
        # To preserve backward compatibility
        # TODO: remove one day
        if project:
            warnings.warn(
                ""The project parameter has been deprecated. You should pass the project_id parameter."",
                DeprecationWarning,
                stacklevel=2,
            )
            project_id = project

        super().__init__(**kwargs)
        self.project_id = project_id
        self.topic = topic
        self.fail_if_not_exists = fail_if_not_exists
        self.gcp_conn_id = gcp_conn_id
        self.delegate_to = delegate_to
        self.retry = retry
        self.timeout = timeout
        self.metadata = metadata
        self.impersonation_chain = impersonation_chain

    def execute(self, context) -> None:
        hook = PubSubHook(
            gcp_conn_id=self.gcp_conn_id,
            delegate_to=self.delegate_to,
            impersonation_chain=self.impersonation_chain,
        )

        self.log.info(""Deleting topic %s"", self.topic)
        hook.delete_topic(
            project_id=self.project_id,
            topic=self.topic,
            fail_if_not_exists=self.fail_if_not_exists,
            retry=self.retry,
            timeout=self.timeout,
            metadata=self.metadata,
        )
        self.log.info(""Deleted topic %s"", self.topic)",0,587 2000 40 2001 41 58 362 2002 61 91 362 44 362 44 362 44 93 2003 61 362 612 2004 40 2005 44 42 44 2006 58 813 44 2007 58 2008 91 813 93 61 470 44 2009 58 569 61 443 44 2010 58 813 61 362 44 2011 58 2008 91 813 93 61 470 44 2012 58 2008 91 2013 93 61 470 44 2014 58 2008 91 660 93 61 470 44 2015 58 2016 91 2017 91 813 44 813 93 93 61 40 41 44 2018 58 2008 91 813 93 61 470 44 2019 58 2008 91 2020 91 813 44 2016 91 813 93 93 93 61 470 44 350 2021 44 41 354 470 58 330 330 688 2018 58 2022 46 2023 40 362 44 2024 44 2025 61 1502 44 41 2007 61 2018 818 40 41 46 2004 40 350 2021 41 2005 46 2007 61 2007 2005 46 2006 61 2006 2005 46 2009 61 2009 2005 46 2010 61 2010 2005 46 2011 61 2011 2005 46 2012 61 2012 2005 46 2014 61 2014 2005 46 2015 61 2015 2005 46 2019 61 2019 612 2026 40 2005 44 2027 41 354 470 58 2028 61 2029 40 2010 61 2005 46 2010 44 2011 61 2005 46 2011 44 2019 61 2005 46 2019 44 41 2005 46 2030 46 2031 40 362 44 2005 46 2006 41 2028 46 2032 40 2007 61 2005 46 2007 44 2006 61 2005 46 2006 44 2009 61 2005 46 2009 44 2012 61 2005 46 2012 44 2014 61 2005 46 2014 44 2015 61 2005 46 2015 44 41 2005 46 2030 46 2031 40 362 44 2005 46 2006 41 ,"{'AvgLine': 26, 'CountLine': 128, 'CountStmt': 22, 'MaxNesting': 1, 'AvgLineCode': 24, 'AvgEssential': 1, 'AvgLineBlank': 1, 'CountStmtExe': 19, 'MaxEssential': 1, 'SumEssential': 2, 'AvgCyclomatic': 1, 'CountLineCode': 55, 'CountStmtDecl': 15, 'MaxCyclomatic': 2, 'SumCyclomatic': 3, 'AvgLineComment': 1, 'CountClassBase': 1, 'CountLineBlank': 12, 'CountDeclMethod': 2, 'CountLineCodeExe': 38, 'CountLineComment': 62, 'CountClassCoupled': 5, 'CountClassDerived': 1, 'CountLineCodeDecl': 29, 'CountDeclMethodAll': 80, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '1.13', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 2, 'SumCyclomaticStrict': 3, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 2, 'SumCyclomaticModified': 3, 'CountDeclInstanceMethod': 2, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 9}"
124612,Python,"class PubSubTopicCreateOperator(PubSubCreateTopicOperator):
    """"""This class is deprecated.

    Please use `airflow.providers.google.cloud.operators.pubsub.PubSubCreateTopicOperator`.
    """"""

    def __init__(self, *args, **kwargs):
        warnings.warn(
            """"""This class is deprecated.
            Please use `airflow.providers.google.cloud.operators.pubsub.PubSubCreateTopicOperator`."""""",
            DeprecationWarning,
            stacklevel=2,
        )
        super().__init__(*args, **kwargs)",0,587 2000 40 2001 41 58 362 612 2002 40 2003 44 42 2004 44 350 2005 41 58 2006 46 2007 40 362 44 2008 44 2009 61 1502 44 41 818 40 41 46 2002 40 42 2004 44 350 2005 41 ,"{'AvgLine': 8, 'CountLine': 14, 'CountStmt': 4, 'MaxNesting': 0, 'AvgLineCode': 8, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 2, 'MaxEssential': 1, 'SumEssential': 1, 'AvgCyclomatic': 1, 'CountLineCode': 9, 'CountStmtDecl': 2, 'MaxCyclomatic': 1, 'SumCyclomatic': 1, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 2, 'CountDeclMethod': 1, 'CountLineCodeExe': 7, 'CountLineComment': 3, 'CountClassCoupled': 1, 'CountClassDerived': 0, 'CountLineCodeDecl': 2, 'CountDeclMethodAll': 81, 'MaxInheritanceTree': 4, 'RatioCommentToCode': '0.33', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 1, 'SumCyclomaticStrict': 1, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 1, 'SumCyclomaticModified': 1, 'CountDeclInstanceMethod': 1, 'CountClassCoupledModified': 0, 'CountDeclInstanceVariable': 0}"
124299,Python,"class CloudDataTransferServiceJobStatusSensor(BaseSensorOperator):
    """"""
    Waits for at least one operation belonging to the job to have the
    expected status.

    .. seealso::
        For more information on how to use this operator, take a look at the guide:
        :ref:`howto/operator:CloudDataTransferServiceJobStatusSensor`

    :param job_name: The name of the transfer job
    :type job_name: str
    :param expected_statuses: The expected state of the operation.
        See:
        https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferOperations#Status
    :type expected_statuses: set[str] or string
    :param project_id: (Optional) the ID of the project that owns the Transfer
        Job. If set to None or missing, the default project_id from the Google Cloud
        connection is used.
    :type project_id: str
    :param gcp_conn_id: The connection ID used to connect to Google Cloud.
    :type gcp_conn_id: str
    :param impersonation_chain: Optional service account to impersonate using short-term
        credentials, or chained list of accounts required to get the access_token
        of the last account in the list, which will be impersonated in the request.
        If set as a string, the account must grant the originating account
        the Service Account Token Creator IAM role.
        If set as a sequence, the identities from the list must grant
        Service Account Token Creator IAM role to the directly preceding identity, with first
        account from the list granting this role to the originating account (templated).
    :type impersonation_chain: Union[str, Sequence[str]]
    """"""

    # [START gcp_transfer_job_sensor_template_fields]
    template_fields = (
        'job_name',
        'impersonation_chain',
    )
    # [END gcp_transfer_job_sensor_template_fields]

    def __init__(
        self,
        *,
        job_name: str,
        expected_statuses: Union[Set[str], str],
        project_id: Optional[str] = None,
        gcp_conn_id: str = 'google_cloud_default',
        impersonation_chain: Optional[Union[str, Sequence[str]]] = None,
        **kwargs,
    ) -> None:
        super().__init__(**kwargs)
        self.job_name = job_name
        self.expected_statuses = (
            {expected_statuses} if isinstance(expected_statuses, str) else expected_statuses
        )
        self.project_id = project_id
        self.gcp_cloud_conn_id = gcp_conn_id
        self.impersonation_chain = impersonation_chain

    def poke(self, context: dict) -> bool:
        hook = CloudDataTransferServiceHook(
            gcp_conn_id=self.gcp_cloud_conn_id,
            impersonation_chain=self.impersonation_chain,
        )
        operations = hook.list_transfer_operations(
            request_filter={'project_id': self.project_id, 'job_names': [self.job_name]}
        )

        for operation in operations:
            self.log.info(""Progress for operation %s: %s"", operation[NAME], operation[METADATA][COUNTERS])

        check = CloudDataTransferServiceHook.operations_contain_expected_statuses(
            operations=operations, expected_statuses=self.expected_statuses
        )
        if check:
            self.xcom_push(key=""sensed_operations"", value=operations, context=context)

        return check",0,587 2000 40 2001 41 58 362 330 2002 61 40 362 44 362 44 41 330 612 2003 40 2004 44 42 44 2005 58 813 44 2006 58 2007 91 2008 91 813 93 44 813 93 44 2009 58 2010 91 813 93 61 470 44 2011 58 813 61 362 44 2012 58 2010 91 2007 91 813 44 2013 91 813 93 93 93 61 470 44 350 2014 44 41 354 470 58 818 40 41 46 2003 40 350 2014 41 2004 46 2005 61 2005 2004 46 2006 61 40 123 2006 125 688 713 40 2006 44 813 41 630 2006 41 2004 46 2009 61 2009 2004 46 2015 61 2011 2004 46 2012 61 2012 612 2016 40 2004 44 2017 58 620 41 354 569 58 2018 61 2019 40 2011 61 2004 46 2015 44 2012 61 2004 46 2012 44 41 2020 61 2018 46 2021 40 2022 61 123 362 58 2004 46 2009 44 362 58 91 2004 46 2005 93 125 41 664 2023 696 2020 58 2004 46 2024 46 2025 40 362 44 2023 91 2026 93 44 2023 91 2027 93 91 2028 93 41 2029 61 2019 46 2030 40 2020 61 2020 44 2006 61 2004 46 2006 41 688 2029 58 2004 46 2031 40 2032 61 362 44 2033 61 2020 44 2017 61 2017 41 792 2029 ,"{'AvgLine': 18, 'CountLine': 77, 'CountStmt': 18, 'MaxNesting': 1, 'AvgLineCode': 17, 'AvgEssential': 1, 'AvgLineBlank': 1, 'CountStmtExe': 15, 'MaxEssential': 1, 'SumEssential': 2, 'AvgCyclomatic': 2, 'CountLineCode': 39, 'CountStmtDecl': 13, 'MaxCyclomatic': 3, 'SumCyclomatic': 5, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 8, 'CountDeclMethod': 2, 'CountLineCodeExe': 27, 'CountLineComment': 30, 'CountClassCoupled': 5, 'CountClassDerived': 1, 'CountLineCodeDecl': 22, 'CountDeclMethodAll': 92, 'MaxInheritanceTree': 4, 'RatioCommentToCode': '0.77', 'AvgCyclomaticStrict': 2, 'MaxCyclomaticStrict': 3, 'SumCyclomaticStrict': 5, 'AvgCyclomaticModified': 2, 'MaxCyclomaticModified': 3, 'SumCyclomaticModified': 5, 'CountDeclInstanceMethod': 2, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 5}"
124104,Python,"class CloudDataCatalogDeleteTagTemplateOperator(BaseOperator):
    """"""
    Deletes a tag template and all tags using the template.

    .. seealso::
        For more information on how to use this operator, take a look at the guide:
        :ref:`howto/operator:CloudDataCatalogDeleteTagTemplateOperator`

    :param location: Required. The location of the tag template to delete.
    :type location: str
    :param tag_template: ID for tag template that is deleted.
    :type tag_template: str
    :param project_id: The ID of the Google Cloud project that owns the entry group.
        If set to ``None`` or missing, the default project_id from the Google Cloud connection is used.
    :type project_id: Optional[str]
    :param force: Required. Currently, this field must always be set to ``true``. This confirms the
        deletion of any possible tags using this template. ``force = false`` will be supported in the
        future.
    :type force: bool
    :param retry: A retry object used to retry requests. If ``None`` is specified, requests will be
        retried using a default configuration.
    :type retry: google.api_core.retry.Retry
    :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
        ``retry`` is specified, the timeout applies to each individual attempt.
    :type timeout: float
    :param metadata: Additional metadata that is provided to the method.
    :type metadata: Sequence[Tuple[str, str]]
    :param gcp_conn_id: Optional, The connection ID used to connect to Google Cloud.
        Defaults to 'google_cloud_default'.
    :type gcp_conn_id: str
    :param impersonation_chain: Optional service account to impersonate using short-term
        credentials, or chained list of accounts required to get the access_token
        of the last account in the list, which will be impersonated in the request.
        If set as a string, the account must grant the originating account
        the Service Account Token Creator IAM role.
        If set as a sequence, the identities from the list must grant
        Service Account Token Creator IAM role to the directly preceding identity, with first
        account from the list granting this role to the originating account (templated).
    :type impersonation_chain: Union[str, Sequence[str]]
    """"""

    template_fields = (
        ""location"",
        ""tag_template"",
        ""force"",
        ""project_id"",
        ""retry"",
        ""timeout"",
        ""metadata"",
        ""gcp_conn_id"",
        ""impersonation_chain"",
    )

    def __init__(
        self,
        *,
        location: str,
        tag_template: str,
        force: bool,
        project_id: Optional[str] = None,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
        gcp_conn_id: str = ""google_cloud_default"",
        impersonation_chain: Optional[Union[str, Sequence[str]]] = None,
        **kwargs,
    ) -> None:
        super().__init__(**kwargs)
        self.location = location
        self.tag_template = tag_template
        self.force = force
        self.project_id = project_id
        self.retry = retry
        self.timeout = timeout
        self.metadata = metadata
        self.gcp_conn_id = gcp_conn_id
        self.impersonation_chain = impersonation_chain

    def execute(self, context: dict) -> None:
        hook = CloudDataCatalogHook(
            gcp_conn_id=self.gcp_conn_id, impersonation_chain=self.impersonation_chain
        )
        try:
            hook.delete_tag_template(
                location=self.location,
                tag_template=self.tag_template,
                force=self.force,
                project_id=self.project_id,
                retry=self.retry,
                timeout=self.timeout,
                metadata=self.metadata,
            )
        except NotFound:
            self.log.info(""Tag Template doesn't exists. skipping"")",0,587 2000 40 2001 41 58 362 2002 61 40 362 44 362 44 362 44 362 44 362 44 362 44 362 44 362 44 362 44 41 612 2003 40 2004 44 42 44 2005 58 813 44 2006 58 813 44 2007 58 569 44 2008 58 2009 91 813 93 61 470 44 2010 58 2009 91 2011 93 61 470 44 2012 58 2009 91 660 93 61 470 44 2013 58 2014 91 2015 91 813 44 813 93 93 61 40 41 44 2016 58 813 61 362 44 2017 58 2009 91 2018 91 813 44 2014 91 813 93 93 93 61 470 44 350 2019 44 41 354 470 58 818 40 41 46 2003 40 350 2019 41 2004 46 2005 61 2005 2004 46 2006 61 2006 2004 46 2007 61 2007 2004 46 2008 61 2008 2004 46 2010 61 2010 2004 46 2012 61 2012 2004 46 2013 61 2013 2004 46 2016 61 2016 2004 46 2017 61 2017 612 2020 40 2004 44 2021 58 620 41 354 470 58 2022 61 2023 40 2016 61 2004 46 2016 44 2017 61 2004 46 2017 41 830 58 2022 46 2024 40 2005 61 2004 46 2005 44 2006 61 2004 46 2006 44 2007 61 2004 46 2007 44 2008 61 2004 46 2008 44 2010 61 2004 46 2010 44 2012 61 2004 46 2012 44 2013 61 2004 46 2013 44 41 645 2025 58 2004 46 2026 46 2027 40 362 41 ,"{'AvgLine': 20, 'CountLine': 94, 'CountStmt': 19, 'MaxNesting': 1, 'AvgLineCode': 20, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 16, 'MaxEssential': 1, 'SumEssential': 2, 'AvgCyclomatic': 1, 'CountLineCode': 52, 'CountStmtDecl': 14, 'MaxCyclomatic': 2, 'SumCyclomatic': 3, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 5, 'CountDeclMethod': 2, 'CountLineCodeExe': 36, 'CountLineComment': 37, 'CountClassCoupled': 6, 'CountClassDerived': 0, 'CountLineCodeDecl': 27, 'CountDeclMethodAll': 80, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '0.71', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 2, 'SumCyclomaticStrict': 3, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 2, 'SumCyclomaticModified': 3, 'CountDeclInstanceMethod': 2, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 9}"
124648,Python,"class LocalFilesystemToGCSOperator(BaseOperator):
    """"""
    Uploads a file or list of files to Google Cloud Storage.
    Optionally can compress the file for upload.

    .. seealso::
        For more information on how to use this operator, take a look at the guide:
        :ref:`howto/operator:LocalFilesystemToGCSOperator`

    :param src: Path to the local file, or list of local files. Path can be either absolute
        (e.g. /path/to/file.ext) or relative (e.g. ../../foo/*/*.csv). (templated)
    :type src: str or list
    :param dst: Destination path within the specified bucket on GCS (e.g. /path/to/file.ext).
        If multiple files are being uploaded, specify object prefix with trailing backslash
        (e.g. /path/to/directory/) (templated)
    :type dst: str
    :param bucket: The bucket to upload to. (templated)
    :type bucket: str
    :param gcp_conn_id: (Optional) The connection ID used to connect to Google Cloud.
    :type gcp_conn_id: str
    :param google_cloud_storage_conn_id: (Deprecated) The connection ID used to connect to Google Cloud.
        This parameter has been deprecated. You should pass the gcp_conn_id parameter instead.
    :type google_cloud_storage_conn_id: str
    :param mime_type: The mime-type string
    :type mime_type: str
    :param delegate_to: The account to impersonate, if any
    :type delegate_to: str
    :param gzip: Allows for file to be compressed and uploaded as gzip
    :type gzip: bool
    :param impersonation_chain: Optional service account to impersonate using short-term
        credentials, or chained list of accounts required to get the access_token
        of the last account in the list, which will be impersonated in the request.
        If set as a string, the account must grant the originating account
        the Service Account Token Creator IAM role.
        If set as a sequence, the identities from the list must grant
        Service Account Token Creator IAM role to the directly preceding identity, with first
        account from the list granting this role to the originating account (templated).
    :type impersonation_chain: Union[str, Sequence[str]]
    """"""

    template_fields = (
        'src',
        'dst',
        'bucket',
        'impersonation_chain',
    )

    def __init__(
        self,
        *,
        src,
        dst,
        bucket,
        gcp_conn_id='google_cloud_default',
        google_cloud_storage_conn_id=None,
        mime_type='application/octet-stream',
        delegate_to=None,
        gzip=False,
        impersonation_chain: Optional[Union[str, Sequence[str]]] = None,
        **kwargs,
    ):
        super().__init__(**kwargs)

        if google_cloud_storage_conn_id:
            warnings.warn(
                ""The google_cloud_storage_conn_id parameter has been deprecated. You should pass ""
                ""the gcp_conn_id parameter."",
                DeprecationWarning,
                stacklevel=3,
            )
            gcp_conn_id = google_cloud_storage_conn_id

        self.src = src
        self.dst = dst
        self.bucket = bucket
        self.gcp_conn_id = gcp_conn_id
        self.mime_type = mime_type
        self.delegate_to = delegate_to
        self.gzip = gzip
        self.impersonation_chain = impersonation_chain

    def execute(self, context):
        """"""Uploads a file or list of files to Google Cloud Storage""""""
        hook = GCSHook(
            gcp_conn_id=self.gcp_conn_id,
            delegate_to=self.delegate_to,
            impersonation_chain=self.impersonation_chain,
        )

        filepaths = self.src if isinstance(self.src, list) else glob(self.src)
        if os.path.basename(self.dst):  # path to a file
            if len(filepaths) > 1:  # multiple file upload
                raise ValueError(
                    ""'dst' parameter references filepath. Please specify ""
                    ""directory (with trailing backslash) to upload multiple ""
                    ""files. e.g. /path/to/directory/""
                )
            object_paths = [self.dst]
        else:  # directory is provided
            object_paths = [os.path.join(self.dst, os.path.basename(filepath)) for filepath in filepaths]

        for filepath, object_path in zip(filepaths, object_paths):
            hook.upload(
                bucket_name=self.bucket,
                object_name=object_path,
                mime_type=self.mime_type,
                filename=filepath,
                gzip=self.gzip,
            )",0,587 2000 40 2001 41 58 362 2002 61 40 362 44 362 44 362 44 362 44 41 612 2003 40 2004 44 42 44 2005 44 2006 44 2007 44 2008 61 362 44 2009 61 470 44 2010 61 362 44 2011 61 470 44 2012 61 443 44 2013 58 2014 91 2015 91 813 44 2016 91 813 93 93 93 61 470 44 350 2017 44 41 58 818 40 41 46 2003 40 350 2017 41 688 2009 58 2018 46 2019 40 362 362 44 2020 44 2021 61 1502 44 41 2008 61 2009 2004 46 2005 61 2005 2004 46 2006 61 2006 2004 46 2007 61 2007 2004 46 2008 61 2008 2004 46 2010 61 2010 2004 46 2011 61 2011 2004 46 2012 61 2012 2004 46 2013 61 2013 612 2022 40 2004 44 2023 41 58 362 2024 61 2025 40 2008 61 2004 46 2008 44 2011 61 2004 46 2011 44 2013 61 2004 46 2013 44 41 2026 61 2004 46 2005 688 713 40 2004 46 2005 44 723 41 630 2027 40 2004 46 2005 41 688 2028 46 2029 46 2030 40 2004 46 2006 41 58 330 688 720 40 2026 41 62 1501 58 330 778 2031 40 362 362 362 41 2032 61 91 2004 46 2006 93 630 58 330 2032 61 91 2028 46 2029 46 2033 40 2004 46 2006 44 2028 46 2029 46 2030 40 2034 41 41 664 2034 696 2026 93 664 2034 44 2035 696 875 40 2026 44 2032 41 58 2024 46 2036 40 2037 61 2004 46 2007 44 2038 61 2035 44 2010 61 2004 46 2010 44 2039 61 2034 44 2012 61 2004 46 2012 44 41 ,"{'AvgLine': 30, 'CountLine': 109, 'CountStmt': 25, 'MaxNesting': 2, 'AvgLineCode': 28, 'AvgEssential': 2, 'AvgLineBlank': 2, 'CountStmtExe': 22, 'MaxEssential': 3, 'SumEssential': 4, 'AvgCyclomatic': 3, 'CountLineCode': 63, 'CountStmtDecl': 16, 'MaxCyclomatic': 5, 'SumCyclomatic': 7, 'AvgLineComment': 2, 'CountClassBase': 1, 'CountLineBlank': 9, 'CountDeclMethod': 2, 'CountLineCodeExe': 47, 'CountLineComment': 40, 'CountClassCoupled': 4, 'CountClassDerived': 1, 'CountLineCodeDecl': 29, 'CountDeclMethodAll': 80, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '0.63', 'AvgCyclomaticStrict': 3, 'MaxCyclomaticStrict': 5, 'SumCyclomaticStrict': 7, 'AvgCyclomaticModified': 3, 'MaxCyclomaticModified': 5, 'SumCyclomaticModified': 7, 'CountDeclInstanceMethod': 2, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 8}"
124156,Python,"class PubSubPullOperator(BaseOperator):
    """"""Pulls messages from a PubSub subscription and passes them through XCom.
    If the queue is empty, returns empty list - never waits for messages.
    If you do need to wait, please use :class:`airflow.providers.google.cloud.sensors.PubSubPullSensor`
    instead.

    .. seealso::
        For more information on how to use this operator, take a look at the guide:
        :ref:`howto/operator:PubSubPullSensor`

    This sensor operator will pull up to ``max_messages`` messages from the
    specified PubSub subscription. When the subscription returns messages,
    the poke method's criteria will be fulfilled and the messages will be
    returned from the operator and passed through XCom for downstream tasks.

    If ``ack_messages`` is set to True, messages will be immediately
    acknowledged before being returned, otherwise, downstream tasks will be
    responsible for acknowledging them.

    ``project`` and ``subscription`` are templated so you can use
    variables in them.

    :param project: the Google Cloud project ID for the subscription (templated)
    :type project: str
    :param subscription: the Pub/Sub subscription name. Do not include the
        full subscription path.
    :type subscription: str
    :param max_messages: The maximum number of messages to retrieve per
        PubSub pull request
    :type max_messages: int
    :param ack_messages: If True, each message will be acknowledged
        immediately rather than by any downstream tasks
    :type ack_messages: bool
    :param gcp_conn_id: The connection ID to use connecting to
        Google Cloud.
    :type gcp_conn_id: str
    :param delegate_to: The account to impersonate using domain-wide delegation of authority,
        if any. For this to work, the service account making the request must have
        domain-wide delegation enabled.
    :type delegate_to: str
    :param messages_callback: (Optional) Callback to process received messages.
        It's return value will be saved to XCom.
        If you are pulling large messages, you probably want to provide a custom callback.
        If not provided, the default implementation will convert `ReceivedMessage` objects
        into JSON-serializable dicts using `google.protobuf.json_format.MessageToDict` function.
    :type messages_callback: Optional[Callable[[List[ReceivedMessage], Dict[str, Any]], Any]]
    :param impersonation_chain: Optional service account to impersonate using short-term
        credentials, or chained list of accounts required to get the access_token
        of the last account in the list, which will be impersonated in the request.
        If set as a string, the account must grant the originating account
        the Service Account Token Creator IAM role.
        If set as a sequence, the identities from the list must grant
        Service Account Token Creator IAM role to the directly preceding identity, with first
        account from the list granting this role to the originating account (templated).
    :type impersonation_chain: Union[str, Sequence[str]]
    """"""

    template_fields = [
        'project_id',
        'subscription',
        'impersonation_chain',
    ]

    def __init__(
        self,
        *,
        project_id: str,
        subscription: str,
        max_messages: int = 5,
        ack_messages: bool = False,
        messages_callback: Optional[Callable[[List[ReceivedMessage], Dict[str, Any]], Any]] = None,
        gcp_conn_id: str = 'google_cloud_default',
        delegate_to: Optional[str] = None,
        impersonation_chain: Optional[Union[str, Sequence[str]]] = None,
        **kwargs,
    ) -> None:
        super().__init__(**kwargs)
        self.gcp_conn_id = gcp_conn_id
        self.delegate_to = delegate_to
        self.project_id = project_id
        self.subscription = subscription
        self.max_messages = max_messages
        self.ack_messages = ack_messages
        self.messages_callback = messages_callback
        self.impersonation_chain = impersonation_chain

    def execute(self, context) -> list:
        hook = PubSubHook(
            gcp_conn_id=self.gcp_conn_id,
            delegate_to=self.delegate_to,
            impersonation_chain=self.impersonation_chain,
        )

        pulled_messages = hook.pull(
            project_id=self.project_id,
            subscription=self.subscription,
            max_messages=self.max_messages,
            return_immediately=True,
        )

        handle_messages = self.messages_callback or self._default_message_callback

        ret = handle_messages(pulled_messages, context)

        if pulled_messages and self.ack_messages:
            hook.acknowledge(
                project_id=self.project_id,
                subscription=self.subscription,
                messages=pulled_messages,
            )

        return ret

    def _default_message_callback(
        self,
        pulled_messages: List[ReceivedMessage],
        context: Dict[str, Any],
    ) -> list:
        """"""
        This method can be overridden by subclasses or by `messages_callback` constructor argument.
        This default implementation converts `ReceivedMessage` objects into JSON-serializable dicts.

        :param pulled_messages: messages received from the topic.
        :type pulled_messages: List[ReceivedMessage]
        :param context: same as in `execute`
        :return: value to be saved to XCom.
        """"""
        messages_json = [ReceivedMessage.to_dict(m) for m in pulled_messages]

        return messages_json",0,587 2000 40 2001 41 58 362 2002 61 91 362 44 362 44 362 44 93 612 2003 40 2004 44 42 44 2005 58 813 44 2006 58 813 44 2007 58 704 61 1502 44 2008 58 569 61 443 44 2009 58 2010 91 2011 91 91 2012 91 2013 93 44 2014 91 813 44 2015 93 93 44 2015 93 93 61 470 44 2016 58 813 61 362 44 2017 58 2010 91 813 93 61 470 44 2018 58 2010 91 2019 91 813 44 2020 91 813 93 93 93 61 470 44 350 2021 44 41 354 470 58 818 40 41 46 2003 40 350 2021 41 2004 46 2016 61 2016 2004 46 2017 61 2017 2004 46 2005 61 2005 2004 46 2006 61 2006 2004 46 2007 61 2007 2004 46 2008 61 2008 2004 46 2009 61 2009 2004 46 2018 61 2018 612 2022 40 2004 44 2023 41 354 723 58 2024 61 2025 40 2016 61 2004 46 2016 44 2017 61 2004 46 2017 44 2018 61 2004 46 2018 44 41 2026 61 2024 46 2027 40 2005 61 2004 46 2005 44 2006 61 2004 46 2006 44 2007 61 2004 46 2007 44 2028 61 515 44 41 2029 61 2004 46 2009 759 2004 46 2030 2031 61 2029 40 2026 44 2023 41 688 2026 545 2004 46 2008 58 2024 46 2032 40 2005 61 2004 46 2005 44 2006 61 2004 46 2006 44 2033 61 2026 44 41 792 2031 612 2030 40 2004 44 2026 58 2012 91 2013 93 44 2023 58 2014 91 813 44 2015 93 44 41 354 723 58 362 2034 61 91 2013 46 2035 40 2036 41 664 2036 696 2026 93 792 2034 ,"{'AvgLine': 21, 'CountLine': 130, 'CountStmt': 23, 'MaxNesting': 1, 'AvgLineCode': 16, 'AvgEssential': 1, 'AvgLineBlank': 2, 'CountStmtExe': 19, 'MaxEssential': 1, 'SumEssential': 3, 'AvgCyclomatic': 1, 'CountLineCode': 56, 'CountStmtDecl': 18, 'MaxCyclomatic': 2, 'SumCyclomatic': 4, 'AvgLineComment': 2, 'CountClassBase': 1, 'CountLineBlank': 16, 'CountDeclMethod': 3, 'CountLineCodeExe': 36, 'CountLineComment': 58, 'CountClassCoupled': 6, 'CountClassDerived': 0, 'CountLineCodeDecl': 34, 'CountDeclMethodAll': 81, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '1.04', 'AvgCyclomaticStrict': 2, 'MaxCyclomaticStrict': 4, 'SumCyclomaticStrict': 6, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 2, 'SumCyclomaticModified': 4, 'CountDeclInstanceMethod': 3, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 8}"
124039,Python,"class TestCloudDataFusionStartPipelineOperator:
    @mock.patch(HOOK_STR)
    def test_execute(self, mock_hook):
        PIPELINE_ID = ""test_pipeline_id""
        mock_hook.return_value.get_instance.return_value = {""apiEndpoint"": INSTANCE_URL}
        mock_hook.return_value.start_pipeline.return_value = PIPELINE_ID

        op = CloudDataFusionStartPipelineOperator(
            task_id=""test_task"",
            pipeline_name=PIPELINE_NAME,
            instance_name=INSTANCE_NAME,
            namespace=NAMESPACE,
            location=LOCATION,
            project_id=PROJECT_ID,
            runtime_args=RUNTIME_ARGS,
        )
        op.dag = mock.MagicMock(spec=DAG, task_dict={}, dag_id=""test"")

        op.execute({})
        mock_hook.return_value.get_instance.assert_called_once_with(
            instance_name=INSTANCE_NAME, location=LOCATION, project_id=PROJECT_ID
        )

        mock_hook.return_value.start_pipeline.assert_called_once_with(
            instance_url=INSTANCE_URL,
            pipeline_name=PIPELINE_NAME,
            namespace=NAMESPACE,
            runtime_args=RUNTIME_ARGS,
        )

        mock_hook.return_value.wait_for_pipeline_state.assert_called_once_with(
            success_states=SUCCESS_STATES + [PipelineStates.RUNNING],
            pipeline_id=PIPELINE_ID,
            pipeline_name=PIPELINE_NAME,
            namespace=NAMESPACE,
            instance_url=INSTANCE_URL,
            timeout=300,
        )

    @mock.patch(HOOK_STR)
    def test_execute_async(self, mock_hook):
        PIPELINE_ID = ""test_pipeline_id""
        mock_hook.return_value.get_instance.return_value = {""apiEndpoint"": INSTANCE_URL}
        mock_hook.return_value.start_pipeline.return_value = PIPELINE_ID

        op = CloudDataFusionStartPipelineOperator(
            task_id=""test_task"",
            pipeline_name=PIPELINE_NAME,
            instance_name=INSTANCE_NAME,
            namespace=NAMESPACE,
            location=LOCATION,
            project_id=PROJECT_ID,
            runtime_args=RUNTIME_ARGS,
            asynchronous=True,
        )
        op.dag = mock.MagicMock(spec=DAG, task_dict={}, dag_id=""test"")

        op.execute({})
        mock_hook.return_value.get_instance.assert_called_once_with(
            instance_name=INSTANCE_NAME, location=LOCATION, project_id=PROJECT_ID
        )

        mock_hook.return_value.start_pipeline.assert_called_once_with(
            instance_url=INSTANCE_URL,
            pipeline_name=PIPELINE_NAME,
            namespace=NAMESPACE,
            runtime_args=RUNTIME_ARGS,
        )

        mock_hook.return_value.wait_for_pipeline_state.assert_not_called()",0,587 2000 58 64 2001 46 2002 40 2003 41 612 2004 40 2005 44 2006 41 58 2007 61 362 2006 46 2008 46 2009 46 2008 61 123 362 58 2010 125 2006 46 2008 46 2011 46 2008 61 2007 2012 61 2013 40 2014 61 362 44 2015 61 2016 44 2017 61 2018 44 2019 61 2020 44 2021 61 2022 44 2023 61 2024 44 2025 61 2026 44 41 2012 46 2027 61 2001 46 2028 40 2029 61 2030 44 2031 61 123 125 44 2032 61 362 41 2012 46 2033 40 123 125 41 2006 46 2008 46 2009 46 2034 40 2017 61 2018 44 2021 61 2022 44 2023 61 2024 41 2006 46 2008 46 2011 46 2034 40 2035 61 2010 44 2015 61 2016 44 2019 61 2020 44 2025 61 2026 44 41 2006 46 2008 46 2036 46 2034 40 2037 61 2038 43 91 2039 46 2040 93 44 2041 61 2007 44 2015 61 2016 44 2019 61 2020 44 2035 61 2010 44 2042 61 1504 44 41 64 2001 46 2002 40 2003 41 612 2043 40 2005 44 2006 41 58 2007 61 362 2006 46 2008 46 2009 46 2008 61 123 362 58 2010 125 2006 46 2008 46 2011 46 2008 61 2007 2012 61 2013 40 2014 61 362 44 2015 61 2016 44 2017 61 2018 44 2019 61 2020 44 2021 61 2022 44 2023 61 2024 44 2025 61 2026 44 2044 61 515 44 41 2012 46 2027 61 2001 46 2028 40 2029 61 2030 44 2031 61 123 125 44 2032 61 362 41 2012 46 2033 40 123 125 41 2006 46 2008 46 2009 46 2034 40 2017 61 2018 44 2021 61 2022 44 2023 61 2024 41 2006 46 2008 46 2011 46 2034 40 2035 61 2010 44 2015 61 2016 44 2019 61 2020 44 2025 61 2026 44 41 2006 46 2008 46 2036 46 2045 40 41 ,"{'AvgLine': 33, 'CountLine': 70, 'CountStmt': 21, 'MaxNesting': 0, 'AvgLineCode': 29, 'AvgEssential': 1, 'AvgLineBlank': 4, 'CountStmtExe': 18, 'MaxEssential': 1, 'SumEssential': 2, 'AvgCyclomatic': 1, 'CountLineCode': 61, 'CountStmtDecl': 7, 'MaxCyclomatic': 1, 'SumCyclomatic': 2, 'AvgLineComment': 0, 'CountClassBase': 0, 'CountLineBlank': 9, 'CountDeclMethod': 2, 'CountLineCodeExe': 56, 'CountLineComment': 0, 'CountClassCoupled': 2, 'CountClassDerived': 0, 'CountLineCodeDecl': 9, 'CountDeclMethodAll': 2, 'MaxInheritanceTree': 0, 'RatioCommentToCode': '0.00', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 1, 'SumCyclomaticStrict': 2, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 1, 'SumCyclomaticModified': 2, 'CountDeclInstanceMethod': 2, 'CountClassCoupledModified': 2, 'CountDeclInstanceVariable': 0}"
123951,Python,"class SQLIntervalCheckOperator(BaseSQLOperator):
    """"""
    Checks that the values of metrics given as SQL expressions are within
    a certain tolerance of the ones from days_back before.

    :param table: the table name
    :type table: str
    :param conn_id: the connection ID used to connect to the database.
    :type conn_id: str
    :param database: name of database which will overwrite the defined one in connection
    :type database: Optional[str]
    :param days_back: number of days between ds and the ds we want to check
        against. Defaults to 7 days
    :type days_back: Optional[int]
    :param date_filter_column: The column name for the dates to filter on. Defaults to 'ds'
    :type date_filter_column: Optional[str]
    :param ratio_formula: which formula to use to compute the ratio between
        the two metrics. Assuming cur is the metric of today and ref is
        the metric to today - days_back.

        max_over_min: computes max(cur, ref) / min(cur, ref)
        relative_diff: computes abs(cur-ref) / ref

        Default: 'max_over_min'
    :type ratio_formula: str
    :param ignore_zero: whether we should ignore zero metrics
    :type ignore_zero: bool
    :param metrics_thresholds: a dictionary of ratios indexed by metrics
    :type metrics_thresholds: dict
    """"""

    __mapper_args__ = {""polymorphic_identity"": ""SQLIntervalCheckOperator""}
    template_fields: Iterable[str] = (""sql1"", ""sql2"")
    template_ext: Iterable[str] = (
        "".hql"",
        "".sql"",
    )
    template_fields_renderers = {""sql1"": ""sql"", ""sql2"": ""sql""}
    ui_color = ""#fff7e6""

    ratio_formulas = {
        ""max_over_min"": lambda cur, ref: float(max(cur, ref)) / min(cur, ref),
        ""relative_diff"": lambda cur, ref: float(abs(cur - ref)) / ref,
    }

    def __init__(
        self,
        *,
        table: str,
        metrics_thresholds: Dict[str, int],
        date_filter_column: Optional[str] = ""ds"",
        days_back: SupportsAbs[int] = -7,
        ratio_formula: Optional[str] = ""max_over_min"",
        ignore_zero: bool = True,
        conn_id: Optional[str] = None,
        database: Optional[str] = None,
        **kwargs,
    ):
        super().__init__(conn_id=conn_id, database=database, **kwargs)
        if ratio_formula not in self.ratio_formulas:
            msg_template = ""Invalid diff_method: {diff_method}. Supported diff methods are: {diff_methods}""

            raise AirflowException(
                msg_template.format(diff_method=ratio_formula, diff_methods=self.ratio_formulas)
            )
        self.ratio_formula = ratio_formula
        self.ignore_zero = ignore_zero
        self.table = table
        self.metrics_thresholds = metrics_thresholds
        self.metrics_sorted = sorted(metrics_thresholds.keys())
        self.date_filter_column = date_filter_column
        self.days_back = -abs(days_back)
        sqlexp = "", "".join(self.metrics_sorted)
        sqlt = f""SELECT {sqlexp} FROM {table} WHERE {date_filter_column}=""

        self.sql1 = sqlt + ""'{{ ds }}'""
        self.sql2 = sqlt + ""'{{ macros.ds_add(ds, "" + str(self.days_back) + "") }}'""

    def execute(self, context=None):
        hook = self.get_db_hook()
        self.log.info(""Using ratio formula: %s"", self.ratio_formula)
        self.log.info(""Executing SQL check: %s"", self.sql2)
        row2 = hook.get_first(self.sql2)
        self.log.info(""Executing SQL check: %s"", self.sql1)
        row1 = hook.get_first(self.sql1)

        if not row2:
            raise AirflowException(f""The query {self.sql2} returned None"")
        if not row1:
            raise AirflowException(f""The query {self.sql1} returned None"")

        current = dict(zip(self.metrics_sorted, row1))
        reference = dict(zip(self.metrics_sorted, row2))

        ratios = {}
        test_results = {}

        for metric in self.metrics_sorted:
            cur = current[metric]
            ref = reference[metric]
            threshold = self.metrics_thresholds[metric]
            if cur == 0 or ref == 0:
                ratios[metric] = None
                test_results[metric] = self.ignore_zero
            else:
                ratios[metric] = self.ratio_formulas[self.ratio_formula](current[metric], reference[metric])
                test_results[metric] = ratios[metric] < threshold

            self.log.info(
                (
                    ""Current metric for %s: %s\n""
                    ""Past metric for %s: %s\n""
                    ""Ratio for %s: %s\n""
                    ""Threshold: %s\n""
                ),
                metric,
                cur,
                metric,
                ref,
                metric,
                ratios[metric],
                threshold,
            )

        if not all(test_results.values()):
            failed_tests = [it[0] for it in test_results.items() if not it[1]]
            self.log.warning(
                ""The following %s tests out of %s failed:"",
                len(failed_tests),
                len(self.metrics_sorted),
            )
            for k in failed_tests:
                self.log.warning(
                    ""'%s' check failed. %s is above %s"",
                    k,
                    ratios[k],
                    self.metrics_thresholds[k],
                )
            raise AirflowException(f""The following tests have failed:\n {', '.join(sorted(failed_tests))}"")

        self.log.info(""All tests have passed"")",0,587 2000 40 2001 41 58 362 2002 61 123 362 58 362 125 2003 58 2004 91 813 93 61 40 362 44 362 41 2005 58 2004 91 813 93 61 40 362 44 362 44 41 2006 61 123 362 58 362 44 362 58 362 125 2007 61 362 2008 61 123 362 58 719 2009 44 2010 58 660 40 733 40 2009 44 2010 41 41 47 735 40 2009 44 2010 41 44 362 58 719 2009 44 2010 58 660 40 538 40 2009 45 2010 41 41 47 2010 44 125 612 2011 40 2012 44 42 44 2013 58 813 44 2014 58 2015 91 813 44 704 93 44 2016 58 2017 91 813 93 61 362 44 2018 58 2019 91 704 93 61 45 1502 44 2020 58 2017 91 813 93 61 362 44 2021 58 569 61 515 44 2022 58 2017 91 813 93 61 470 44 2023 58 2017 91 813 93 61 470 44 350 2024 44 41 58 818 40 41 46 2011 40 2022 61 2022 44 2023 61 2023 44 350 2024 41 688 2020 750 696 2012 46 2008 58 2025 61 362 778 2026 40 2025 46 666 40 2027 61 2020 44 2028 61 2012 46 2008 41 41 2012 46 2020 61 2020 2012 46 2021 61 2021 2012 46 2013 61 2013 2012 46 2014 61 2014 2012 46 2029 61 807 40 2014 46 2030 40 41 41 2012 46 2016 61 2016 2012 46 2018 61 45 538 40 2018 41 2031 61 362 46 2032 40 2012 46 2029 41 2033 61 362 2012 46 2034 61 2033 43 362 2012 46 2035 61 2033 43 362 43 813 40 2012 46 2018 41 43 362 612 2036 40 2012 44 2037 61 470 41 58 2038 61 2012 46 2039 40 41 2012 46 2040 46 2041 40 362 44 2012 46 2020 41 2012 46 2040 46 2041 40 362 44 2012 46 2035 41 2042 61 2038 46 2043 40 2012 46 2035 41 2012 46 2040 46 2041 40 362 44 2012 46 2034 41 2044 61 2038 46 2043 40 2012 46 2034 41 688 750 2042 58 778 2026 40 362 41 688 750 2044 58 778 2026 40 362 41 2045 61 620 40 875 40 2012 46 2029 44 2044 41 41 2046 61 620 40 875 40 2012 46 2029 44 2042 41 41 2047 61 123 125 2048 61 123 125 664 2049 696 2012 46 2029 58 2009 61 2045 91 2049 93 2010 61 2046 91 2049 93 2050 61 2012 46 2014 91 2049 93 688 2009 323 1500 759 2010 323 1500 58 2047 91 2049 93 61 470 2048 91 2049 93 61 2012 46 2021 630 58 2047 91 2049 93 61 2012 46 2008 91 2012 46 2020 93 40 2045 91 2049 93 44 2046 91 2049 93 41 2048 91 2049 93 61 2047 91 2049 93 60 2050 2012 46 2040 46 2041 40 40 362 362 362 362 41 44 2049 44 2009 44 2049 44 2010 44 2049 44 2047 91 2049 93 44 2050 44 41 688 750 544 40 2048 46 2051 40 41 41 58 2052 61 91 2053 91 1500 93 664 2053 696 2048 46 2054 40 41 688 750 2053 91 1501 93 93 2012 46 2040 46 2055 40 362 44 720 40 2052 41 44 720 40 2012 46 2029 41 44 41 664 2056 696 2052 58 2012 46 2040 46 2055 40 362 44 2056 44 2047 91 2056 93 44 2012 46 2014 91 2056 93 44 41 778 2026 40 362 41 2012 46 2040 46 2041 40 362 41 ,"{'AvgLine': 47, 'CountLine': 141, 'CountStmt': 55, 'MaxNesting': 2, 'AvgLineCode': 43, 'AvgEssential': 2, 'AvgLineBlank': 4, 'CountStmtExe': 52, 'MaxEssential': 4, 'SumEssential': 5, 'AvgCyclomatic': 4, 'CountLineCode': 99, 'CountStmtDecl': 34, 'MaxCyclomatic': 7, 'SumCyclomatic': 9, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 16, 'CountDeclMethod': 2, 'CountLineCodeExe': 84, 'CountLineComment': 27, 'CountClassCoupled': 7, 'CountClassDerived': 4, 'CountLineCodeDecl': 46, 'CountDeclMethodAll': 83, 'MaxInheritanceTree': 4, 'RatioCommentToCode': '0.27', 'AvgCyclomaticStrict': 5, 'MaxCyclomaticStrict': 8, 'SumCyclomaticStrict': 10, 'AvgCyclomaticModified': 4, 'MaxCyclomaticModified': 7, 'SumCyclomaticModified': 9, 'CountDeclInstanceMethod': 2, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 9}"
123924,Python,"class CloudAutoMLHook(GoogleBaseHook):
    """"""
    Google Cloud AutoML hook.

    All the methods in the hook where project_id is used must be called with
    keyword arguments rather than positional.
    """"""

    def __init__(
        self,
        gcp_conn_id: str = ""google_cloud_default"",
        delegate_to: Optional[str] = None,
        impersonation_chain: Optional[Union[str, Sequence[str]]] = None,
    ) -> None:
        super().__init__(
            gcp_conn_id=gcp_conn_id,
            delegate_to=delegate_to,
            impersonation_chain=impersonation_chain,
        )
        self._client = None  # type: Optional[AutoMlClient]

    @staticmethod
    def extract_object_id(obj: Dict) -> str:
        """"""Returns unique id of the object.""""""
        return obj[""name""].rpartition(""/"")[-1]

    def get_conn(self) -> AutoMlClient:
        """"""
        Retrieves connection to AutoML.

        :return: Google Cloud AutoML client object.
        :rtype: google.cloud.automl_v1beta1.AutoMlClient
        """"""
        if self._client is None:
            self._client = AutoMlClient(credentials=self._get_credentials(), client_info=self.client_info)
        return self._client

    @cached_property
    def prediction_client(self) -> PredictionServiceClient:
        """"""
        Creates PredictionServiceClient.

        :return: Google Cloud AutoML PredictionServiceClient client object.
        :rtype: google.cloud.automl_v1beta1.PredictionServiceClient
        """"""
        return PredictionServiceClient(credentials=self._get_credentials(), client_info=self.client_info)

    @GoogleBaseHook.fallback_to_default_project_id
    def create_model(
        self,
        model: Union[dict, Model],
        location: str,
        project_id: str = PROVIDE_PROJECT_ID,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
        retry: Optional[Retry] = None,
    ) -> Operation:
        """"""
        Creates a model_id. Returns a Model in the `response` field when it
        completes. When you create a model, several model evaluations are
        created for it: a global evaluation, and one evaluation for each
        annotation spec.

        :param model: The model_id to create. If a dict is provided, it must be of the same form
            as the protobuf message `google.cloud.automl_v1beta1.types.Model`
        :type model: Union[dict, google.cloud.automl_v1beta1.types.Model]
        :param project_id: ID of the Google Cloud project where model will be created if None then
            default project_id is used.
        :type project_id: str
        :param location: The location of the project.
        :type location: str
        :param retry: A retry object used  to retry requests. If `None` is specified, requests
            will not be retried.
        :type retry: Optional[google.api_core.retry.Retry]
        :param timeout: The amount of time, in seconds, to wait for the request to complete.
            Note that if `retry` is specified, the timeout applies to each individual attempt.
        :type timeout: Optional[float]
        :param metadata: Additional metadata that is provided to the method.
        :type metadata: Optional[Sequence[Tuple[str, str]]]

        :return: `google.cloud.automl_v1beta1.types._OperationFuture` instance
        """"""
        client = self.get_conn()
        parent = f""projects/{project_id}/locations/{location}""
        return client.create_model(
            request={'parent': parent, 'model': model},
            retry=retry,
            timeout=timeout,
            metadata=metadata,
        )

    @GoogleBaseHook.fallback_to_default_project_id
    def batch_predict(
        self,
        model_id: str,
        input_config: Union[dict, BatchPredictInputConfig],
        output_config: Union[dict, BatchPredictOutputConfig],
        location: str,
        project_id: str = PROVIDE_PROJECT_ID,
        params: Optional[Dict[str, str]] = None,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> Operation:
        """"""
        Perform a batch prediction. Unlike the online `Predict`, batch
        prediction result won't be immediately available in the response.
        Instead, a long running operation object is returned.

        :param model_id: Name of the model_id requested to serve the batch prediction.
        :type model_id: str
        :param input_config: Required. The input configuration for batch prediction.
            If a dict is provided, it must be of the same form as the protobuf message
            `google.cloud.automl_v1beta1.types.BatchPredictInputConfig`
        :type input_config: Union[dict, google.cloud.automl_v1beta1.types.BatchPredictInputConfig]
        :param output_config: Required. The Configuration specifying where output predictions should be
            written. If a dict is provided, it must be of the same form as the protobuf message
            `google.cloud.automl_v1beta1.types.BatchPredictOutputConfig`
        :type output_config: Union[dict, google.cloud.automl_v1beta1.types.BatchPredictOutputConfig]
        :param params: Additional domain-specific parameters for the predictions, any string must be up to
            25000 characters long.
        :type params: Optional[Dict[str, str]]
        :param project_id: ID of the Google Cloud project where model is located if None then
            default project_id is used.
        :type project_id: str
        :param location: The location of the project.
        :type location: str
        :param retry: A retry object used to retry requests. If `None` is specified, requests will not be
            retried.
        :type retry: Optional[google.api_core.retry.Retry]
        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
            `retry` is specified, the timeout applies to each individual attempt.
        :type timeout: Optional[float]
        :param metadata: Additional metadata that is provided to the method.
        :type metadata: Optional[Sequence[Tuple[str, str]]]

        :return: `google.cloud.automl_v1beta1.types._OperationFuture` instance
        """"""
        client = self.prediction_client
        name = f""projects/{project_id}/locations/{location}/models/{model_id}""
        result = client.batch_predict(
            request={
                'name': name,
                'input_config': input_config,
                'output_config': output_config,
                'params': params,
            },
            retry=retry,
            timeout=timeout,
            metadata=metadata,
        )
        return result

    @GoogleBaseHook.fallback_to_default_project_id
    def predict(
        self,
        model_id: str,
        payload: Union[dict, ExamplePayload],
        location: str,
        project_id: str = PROVIDE_PROJECT_ID,
        params: Optional[Dict[str, str]] = None,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> PredictResponse:
        """"""
        Perform an online prediction. The prediction result will be directly
        returned in the response.

        :param model_id: Name of the model_id requested to serve the prediction.
        :type model_id: str
        :param payload: Required. Payload to perform a prediction on. The payload must match the problem type
            that the model_id was trained to solve. If a dict is provided, it must be of
            the same form as the protobuf message `google.cloud.automl_v1beta1.types.ExamplePayload`
        :type payload: Union[dict, google.cloud.automl_v1beta1.types.ExamplePayload]
        :param params: Additional domain-specific parameters, any string must be up to 25000 characters long.
        :type params: Optional[Dict[str, str]]
        :param project_id: ID of the Google Cloud project where model is located if None then
            default project_id is used.
        :type project_id: str
        :param location: The location of the project.
        :type location: str
        :param retry: A retry object used to retry requests. If `None` is specified, requests will not be
            retried.
        :type retry: Optional[google.api_core.retry.Retry]
        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
            `retry` is specified, the timeout applies to each individual attempt.
        :type timeout: Optional[float]
        :param metadata: Additional metadata that is provided to the method.
        :type metadata: Optional[Sequence[Tuple[str, str]]]

        :return: `google.cloud.automl_v1beta1.types.PredictResponse` instance
        """"""
        client = self.prediction_client
        name = f""projects/{project_id}/locations/{location}/models/{model_id}""
        result = client.predict(
            request={'name': name, 'payload': payload, 'params': params},
            retry=retry,
            timeout=timeout,
            metadata=metadata,
        )
        return result

    @GoogleBaseHook.fallback_to_default_project_id
    def create_dataset(
        self,
        dataset: Union[dict, Dataset],
        location: str,
        project_id: str = PROVIDE_PROJECT_ID,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> Dataset:
        """"""
        Creates a dataset.

        :param dataset: The dataset to create. If a dict is provided, it must be of the
            same form as the protobuf message Dataset.
        :type dataset: Union[dict, Dataset]
        :param project_id: ID of the Google Cloud project where dataset is located if None then
            default project_id is used.
        :type project_id: str
        :param location: The location of the project.
        :type location: str
        :param retry: A retry object used to retry requests. If `None` is specified, requests will not be
            retried.
        :type retry: Optional[google.api_core.retry.Retry]
        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
            `retry` is specified, the timeout applies to each individual attempt.
        :type timeout: Optional[float]
        :param metadata: Additional metadata that is provided to the method.
        :type metadata: Optional[Sequence[Tuple[str, str]]]

        :return: `google.cloud.automl_v1beta1.types.Dataset` instance.
        """"""
        client = self.get_conn()
        parent = f""projects/{project_id}/locations/{location}""
        result = client.create_dataset(
            request={'parent': parent, 'dataset': dataset},
            retry=retry,
            timeout=timeout,
            metadata=metadata,
        )
        return result

    @GoogleBaseHook.fallback_to_default_project_id
    def import_data(
        self,
        dataset_id: str,
        location: str,
        input_config: Union[dict, InputConfig],
        project_id: str = PROVIDE_PROJECT_ID,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> Operation:
        """"""
        Imports data into a dataset. For Tables this method can only be called on an empty Dataset.

        :param dataset_id: Name of the AutoML dataset.
        :type dataset_id: str
        :param input_config: The desired input location and its domain specific semantics, if any.
            If a dict is provided, it must be of the same form as the protobuf message InputConfig.
        :type input_config: Union[dict, InputConfig]
        :param project_id: ID of the Google Cloud project where dataset is located if None then
            default project_id is used.
        :type project_id: str
        :param location: The location of the project.
        :type location: str
        :param retry: A retry object used to retry requests. If `None` is specified, requests will not be
            retried.
        :type retry: Optional[google.api_core.retry.Retry]
        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
            `retry` is specified, the timeout applies to each individual attempt.
        :type timeout: Optional[float]
        :param metadata: Additional metadata that is provided to the method.
        :type metadata: Optional[Sequence[Tuple[str, str]]]

        :return: `google.cloud.automl_v1beta1.types._OperationFuture` instance
        """"""
        client = self.get_conn()
        name = f""projects/{project_id}/locations/{location}/datasets/{dataset_id}""
        result = client.import_data(
            request={'name': name, 'input_config': input_config},
            retry=retry,
            timeout=timeout,
            metadata=metadata,
        )
        return result

    @GoogleBaseHook.fallback_to_default_project_id
    def list_column_specs(
        self,
        dataset_id: str,
        table_spec_id: str,
        location: str,
        project_id: str = PROVIDE_PROJECT_ID,
        field_mask: Optional[Union[dict, FieldMask]] = None,
        filter_: Optional[str] = None,
        page_size: Optional[int] = None,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> ListColumnSpecsPager:
        """"""
        Lists column specs in a table spec.

        :param dataset_id: Name of the AutoML dataset.
        :type dataset_id: str
        :param table_spec_id: table_spec_id for path builder.
        :type table_spec_id: str
        :param field_mask: Mask specifying which fields to read. If a dict is provided, it must be of the same
            form as the protobuf message `google.cloud.automl_v1beta1.types.FieldMask`
        :type field_mask: Union[dict, google.cloud.automl_v1beta1.types.FieldMask]
        :param filter_: Filter expression, see go/filtering.
        :type filter_: str
        :param page_size: The maximum number of resources contained in the
            underlying API response. If page streaming is performed per
            resource, this parameter does not affect the return value. If page
            streaming is performed per-page, this determines the maximum number
            of resources in a page.
        :type page_size: int
        :param project_id: ID of the Google Cloud project where dataset is located if None then
            default project_id is used.
        :type project_id: str
        :param location: The location of the project.
        :type location: str
        :param retry: A retry object used to retry requests. If `None` is specified, requests will not be
            retried.
        :type retry: Optional[google.api_core.retry.Retry]
        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
            `retry` is specified, the timeout applies to each individual attempt.
        :type timeout: Optional[float]
        :param metadata: Additional metadata that is provided to the method.
        :type metadata: Optional[Sequence[Tuple[str, str]]]

        :return: `google.cloud.automl_v1beta1.types.ColumnSpec` instance.
        """"""
        client = self.get_conn()
        parent = client.table_spec_path(
            project=project_id,
            location=location,
            dataset=dataset_id,
            table_spec=table_spec_id,
        )
        result = client.list_column_specs(
            request={'parent': parent, 'field_mask': field_mask, 'filter': filter_, 'page_size': page_size},
            retry=retry,
            timeout=timeout,
            metadata=metadata,
        )
        return result

    @GoogleBaseHook.fallback_to_default_project_id
    def get_model(
        self,
        model_id: str,
        location: str,
        project_id: str = PROVIDE_PROJECT_ID,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> Model:
        """"""
        Gets a AutoML model.

        :param model_id: Name of the model.
        :type model_id: str
        :param project_id: ID of the Google Cloud project where model is located if None then
            default project_id is used.
        :type project_id: str
        :param location: The location of the project.
        :type location: str
        :param retry: A retry object used to retry requests. If `None` is specified, requests will not be
            retried.
        :type retry: Optional[google.api_core.retry.Retry]
        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
            `retry` is specified, the timeout applies to each individual attempt.
        :type timeout: Optional[float]
        :param metadata: Additional metadata that is provided to the method.
        :type metadata: Optional[Sequence[Tuple[str, str]]]

        :return: `google.cloud.automl_v1beta1.types.Model` instance.
        """"""
        client = self.get_conn()
        name = f""projects/{project_id}/locations/{location}/models/{model_id}""
        result = client.get_model(
            request={'name': name},
            retry=retry,
            timeout=timeout,
            metadata=metadata,
        )
        return result

    @GoogleBaseHook.fallback_to_default_project_id
    def delete_model(
        self,
        model_id: str,
        location: str,
        project_id: str = PROVIDE_PROJECT_ID,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> Model:
        """"""
        Deletes a AutoML model.

        :param model_id: Name of the model.
        :type model_id: str
        :param project_id: ID of the Google Cloud project where model is located if None then
            default project_id is used.
        :type project_id: str
        :param location: The location of the project.
        :type location: str
        :param retry: A retry object used to retry requests. If `None` is specified, requests will not be
            retried.
        :type retry: Optional[google.api_core.retry.Retry]
        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
            `retry` is specified, the timeout applies to each individual attempt.
        :type timeout: Optional[float]
        :param metadata: Additional metadata that is provided to the method.
        :type metadata: Optional[Sequence[Tuple[str, str]]]

        :return: `google.cloud.automl_v1beta1.types._OperationFuture` instance.
        """"""
        client = self.get_conn()
        name = f""projects/{project_id}/locations/{location}/models/{model_id}""
        result = client.delete_model(
            request={'name': name},
            retry=retry,
            timeout=timeout,
            metadata=metadata,
        )
        return result

    def update_dataset(
        self,
        dataset: Union[dict, Dataset],
        update_mask: Optional[Union[dict, FieldMask]] = None,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> Dataset:
        """"""
        Updates a dataset.

        :param dataset: The dataset which replaces the resource on the server.
            If a dict is provided, it must be of the same form as the protobuf message Dataset.
        :type dataset: Union[dict, Dataset]
        :param update_mask: The update mask applies to the resource.  If a dict is provided, it must
            be of the same form as the protobuf message FieldMask.
        :type update_mask: Union[dict, FieldMask]
        :param retry: A retry object used to retry requests. If `None` is specified, requests will not be
            retried.
        :type retry: Optional[google.api_core.retry.Retry]
        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
            `retry` is specified, the timeout applies to each individual attempt.
        :type timeout: Optional[float]
        :param metadata: Additional metadata that is provided to the method.
        :type metadata: Optional[Sequence[Tuple[str, str]]]

        :return: `google.cloud.automl_v1beta1.types.Dataset` instance..
        """"""
        client = self.get_conn()
        result = client.update_dataset(
            request={'dataset': dataset, 'update_mask': update_mask},
            retry=retry,
            timeout=timeout,
            metadata=metadata,
        )
        return result

    @GoogleBaseHook.fallback_to_default_project_id
    def deploy_model(
        self,
        model_id: str,
        location: str,
        project_id: str = PROVIDE_PROJECT_ID,
        image_detection_metadata: Optional[Union[ImageObjectDetectionModelDeploymentMetadata, dict]] = None,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> Operation:
        """"""
        Deploys a model. If a model is already deployed, deploying it with the same parameters
        has no effect. Deploying with different parameters (as e.g. changing node_number) will
        reset the deployment state without pausing the model_id’s availability.

        Only applicable for Text Classification, Image Object Detection and Tables; all other
        domains manage deployment automatically.

        :param model_id: Name of the model requested to serve the prediction.
        :type model_id: str
        :param image_detection_metadata: Model deployment metadata specific to Image Object Detection.
            If a dict is provided, it must be of the same form as the protobuf message
            ImageObjectDetectionModelDeploymentMetadata
        :type image_detection_metadata: Union[ImageObjectDetectionModelDeploymentMetadata, dict]
        :param project_id: ID of the Google Cloud project where model will be created if None then
            default project_id is used.
        :type project_id: str
        :param location: The location of the project.
        :type location: str
        :param retry: A retry object used to retry requests. If `None` is specified, requests will not be
            retried.
        :type retry: Optional[google.api_core.retry.Retry]
        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
            `retry` is specified, the timeout applies to each individual attempt.
        :type timeout: Optional[float]
        :param metadata: Additional metadata that is provided to the method.
        :type metadata: Optional[Sequence[Tuple[str, str]]]

        :return: `google.cloud.automl_v1beta1.types._OperationFuture` instance.
        """"""
        client = self.get_conn()
        name = f""projects/{project_id}/locations/{location}/models/{model_id}""
        result = client.deploy_model(
            request={
                'name': name,
                'image_object_detection_model_deployment_metadata': image_detection_metadata,
            },
            retry=retry,
            timeout=timeout,
            metadata=metadata,
        )
        return result

    def list_table_specs(
        self,
        dataset_id: str,
        location: str,
        project_id: Optional[str] = None,
        filter_: Optional[str] = None,
        page_size: Optional[int] = None,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> ListTableSpecsPager:
        """"""
        Lists table specs in a dataset_id.

        :param dataset_id: Name of the dataset.
        :type dataset_id: str
        :param filter_: Filter expression, see go/filtering.
        :type filter_: str
        :param page_size: The maximum number of resources contained in the
            underlying API response. If page streaming is performed per
            resource, this parameter does not affect the return value. If page
            streaming is performed per-page, this determines the maximum number
            of resources in a page.
        :type page_size: int
        :param project_id: ID of the Google Cloud project where dataset is located if None then
            default project_id is used.
        :type project_id: str
        :param location: The location of the project.
        :type location: str
        :param retry: A retry object used to retry requests. If `None` is specified, requests will not be
            retried.
        :type retry: Optional[google.api_core.retry.Retry]
        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
            `retry` is specified, the timeout applies to each individual attempt.
        :type timeout: Optional[float]
        :param metadata: Additional metadata that is provided to the method.
        :type metadata: Optional[Sequence[Tuple[str, str]]]

        :return: A `google.gax.PageIterator` instance. By default, this
            is an iterable of `google.cloud.automl_v1beta1.types.TableSpec` instances.
            This object can also be configured to iterate over the pages
            of the response through the `options` parameter.
        """"""
        client = self.get_conn()
        parent = f""projects/{project_id}/locations/{location}/datasets/{dataset_id}""
        result = client.list_table_specs(
            request={'parent': parent, 'filter': filter_, 'page_size': page_size},
            retry=retry,
            timeout=timeout,
            metadata=metadata,
        )
        return result

    @GoogleBaseHook.fallback_to_default_project_id
    def list_datasets(
        self,
        location: str,
        project_id: str,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> ListDatasetsPager:
        """"""
        Lists datasets in a project.

        :param project_id: ID of the Google Cloud project where dataset is located if None then
            default project_id is used.
        :type project_id: str
        :param location: The location of the project.
        :type location: str
        :param retry: A retry object used to retry requests. If `None` is specified, requests will not be
            retried.
        :type retry: Optional[google.api_core.retry.Retry]
        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
            `retry` is specified, the timeout applies to each individual attempt.
        :type timeout: Optional[float]
        :param metadata: Additional metadata that is provided to the method.
        :type metadata: Optional[Sequence[Tuple[str, str]]]

        :return: A `google.gax.PageIterator` instance. By default, this
            is an iterable of `google.cloud.automl_v1beta1.types.Dataset` instances.
            This object can also be configured to iterate over the pages
            of the response through the `options` parameter.
        """"""
        client = self.get_conn()
        parent = f""projects/{project_id}/locations/{location}""
        result = client.list_datasets(
            request={'parent': parent},
            retry=retry,
            timeout=timeout,
            metadata=metadata,
        )
        return result

    @GoogleBaseHook.fallback_to_default_project_id
    def delete_dataset(
        self,
        dataset_id: str,
        location: str,
        project_id: str,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> Operation:
        """"""
        Deletes a dataset and all of its contents.

        :param dataset_id: ID of dataset to be deleted.
        :type dataset_id: str
        :param project_id: ID of the Google Cloud project where dataset is located if None then
            default project_id is used.
        :type project_id: str
        :param location: The location of the project.
        :type location: str
        :param retry: A retry object used to retry requests. If `None` is specified, requests will not be
            retried.
        :type retry: Optional[google.api_core.retry.Retry]
        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
            `retry` is specified, the timeout applies to each individual attempt.
        :type timeout: Optional[float]
        :param metadata: Additional metadata that is provided to the method.
        :type metadata: Optional[Sequence[Tuple[str, str]]]

        :return: `google.cloud.automl_v1beta1.types._OperationFuture` instance
        """"""
        client = self.get_conn()
        name = f""projects/{project_id}/locations/{location}/datasets/{dataset_id}""
        result = client.delete_dataset(
            request={'name': name},
            retry=retry,
            timeout=timeout,
            metadata=metadata,
        )
        return result",0,587 2000 40 2001 41 58 362 612 2002 40 2003 44 2004 58 813 61 362 44 2005 58 2006 91 813 93 61 470 44 2007 58 2006 91 2008 91 813 44 2009 91 813 93 93 93 61 470 44 41 354 470 58 818 40 41 46 2002 40 2004 61 2004 44 2005 61 2005 44 2007 61 2007 44 41 2003 46 2010 61 470 330 64 812 612 2011 40 2012 58 2013 41 354 813 58 362 792 2012 91 362 93 46 2014 40 362 41 91 45 1501 93 612 2015 40 2003 41 354 2016 58 362 688 2003 46 2010 712 470 58 2003 46 2010 61 2016 40 2017 61 2003 46 2018 40 41 44 2019 61 2003 46 2019 41 792 2003 46 2010 64 2020 612 2021 40 2003 41 354 2022 58 362 792 2022 40 2017 61 2003 46 2018 40 41 44 2019 61 2003 46 2019 41 64 2001 46 2023 612 2024 40 2003 44 2025 58 2008 91 620 44 2026 93 44 2027 58 813 44 2028 58 813 61 2029 44 2030 58 2006 91 660 93 61 470 44 2031 58 2009 91 2032 91 813 44 813 93 93 61 40 41 44 2033 58 2006 91 2034 93 61 470 44 41 354 2035 58 362 2036 61 2003 46 2015 40 41 2037 61 362 792 2036 46 2024 40 2038 61 123 362 58 2037 44 362 58 2025 125 44 2033 61 2033 44 2030 61 2030 44 2031 61 2031 44 41 64 2001 46 2023 612 2039 40 2003 44 2040 58 813 44 2041 58 2008 91 620 44 2042 93 44 2043 58 2008 91 620 44 2044 93 44 2027 58 813 44 2028 58 813 61 2029 44 2045 58 2006 91 2013 91 813 44 813 93 93 61 470 44 2033 58 2006 91 2034 93 61 470 44 2030 58 2006 91 660 93 61 470 44 2031 58 2009 91 2032 91 813 44 813 93 93 61 40 41 44 41 354 2035 58 362 2036 61 2003 46 2021 2046 61 362 2047 61 2036 46 2039 40 2038 61 123 362 58 2046 44 362 58 2041 44 362 58 2043 44 362 58 2045 44 125 44 2033 61 2033 44 2030 61 2030 44 2031 61 2031 44 41 792 2047 64 2001 46 2023 612 2048 40 2003 44 2040 58 813 44 2049 58 2008 91 620 44 2050 93 44 2027 58 813 44 2028 58 813 61 2029 44 2045 58 2006 91 2013 91 813 44 813 93 93 61 470 44 2033 58 2006 91 2034 93 61 470 44 2030 58 2006 91 660 93 61 470 44 2031 58 2009 91 2032 91 813 44 813 93 93 61 40 41 44 41 354 2051 58 362 2036 61 2003 46 2021 2046 61 362 2047 61 2036 46 2048 40 2038 61 123 362 58 2046 44 362 58 2049 44 362 58 2045 125 44 2033 61 2033 44 2030 61 2030 44 2031 61 2031 44 41 792 2047 64 2001 46 2023 612 2052 40 2003 44 2053 58 2008 91 620 44 2054 93 44 2027 58 813 44 2028 58 813 61 2029 44 2033 58 2006 91 2034 93 61 470 44 2030 58 2006 91 660 93 61 470 44 2031 58 2009 91 2032 91 813 44 813 93 93 61 40 41 44 41 354 2054 58 362 2036 61 2003 46 2015 40 41 2037 61 362 2047 61 2036 46 2052 40 2038 61 123 362 58 2037 44 362 58 2053 125 44 2033 61 2033 44 2030 61 2030 44 2031 61 2031 44 41 792 2047 64 2001 46 2023 612 2055 40 2003 44 2056 58 813 44 2027 58 813 44 2041 58 2008 91 620 44 2057 93 44 2028 58 813 61 2029 44 2033 58 2006 91 2034 93 61 470 44 2030 58 2006 91 660 93 61 470 44 2031 58 2009 91 2032 91 813 44 813 93 93 61 40 41 44 41 354 2035 58 362 2036 61 2003 46 2015 40 41 2046 61 362 2047 61 2036 46 2055 40 2038 61 123 362 58 2046 44 362 58 2041 125 44 2033 61 2033 44 2030 61 2030 44 2031 61 2031 44 41 792 2047 64 2001 46 2023 612 2058 40 2003 44 2056 58 813 44 2059 58 813 44 2027 58 813 44 2028 58 813 61 2029 44 2060 58 2006 91 2008 91 620 44 2061 93 93 61 470 44 2062 58 2006 91 813 93 61 470 44 2063 58 2006 91 704 93 61 470 44 2033 58 2006 91 2034 93 61 470 44 2030 58 2006 91 660 93 61 470 44 2031 58 2009 91 2032 91 813 44 813 93 93 61 40 41 44 41 354 2064 58 362 2036 61 2003 46 2015 40 41 2037 61 2036 46 2065 40 2066 61 2028 44 2027 61 2027 44 2053 61 2056 44 2067 61 2059 44 41 2047 61 2036 46 2058 40 2038 61 123 362 58 2037 44 362 58 2060 44 362 58 2062 44 362 58 2063 125 44 2033 61 2033 44 2030 61 2030 44 2031 61 2031 44 41 792 2047 64 2001 46 2023 612 2068 40 2003 44 2040 58 813 44 2027 58 813 44 2028 58 813 61 2029 44 2033 58 2006 91 2034 93 61 470 44 2030 58 2006 91 660 93 61 470 44 2031 58 2009 91 2032 91 813 44 813 93 93 61 40 41 44 41 354 2026 58 362 2036 61 2003 46 2015 40 41 2046 61 362 2047 61 2036 46 2068 40 2038 61 123 362 58 2046 125 44 2033 61 2033 44 2030 61 2030 44 2031 61 2031 44 41 792 2047 64 2001 46 2023 612 2069 40 2003 44 2040 58 813 44 2027 58 813 44 2028 58 813 61 2029 44 2033 58 2006 91 2034 93 61 470 44 2030 58 2006 91 660 93 61 470 44 2031 58 2009 91 2032 91 813 44 813 93 93 61 40 41 44 41 354 2026 58 362 2036 61 2003 46 2015 40 41 2046 61 362 2047 61 2036 46 2069 40 2038 61 123 362 58 2046 125 44 2033 61 2033 44 2030 61 2030 44 2031 61 2031 44 41 792 2047 612 2070 40 2003 44 2053 58 2008 91 620 44 2054 93 44 2071 58 2006 91 2008 91 620 44 2061 93 93 61 470 44 2033 58 2006 91 2034 93 61 470 44 2030 58 2006 91 660 93 61 470 44 2031 58 2009 91 2032 91 813 44 813 93 93 61 40 41 44 41 354 2054 58 362 2036 61 2003 46 2015 40 41 2047 61 2036 46 2070 40 2038 61 123 362 58 2053 44 362 58 2071 125 44 2033 61 2033 44 2030 61 2030 44 2031 61 2031 44 41 792 2047 64 2001 46 2023 612 2072 40 2003 44 2040 58 813 44 2027 58 813 44 2028 58 813 61 2029 44 2073 58 2006 91 2008 91 2074 44 620 93 93 61 470 44 2033 58 2006 91 2034 93 61 470 44 2030 58 2006 91 660 93 61 470 44 2031 58 2009 91 2032 91 813 44 813 93 93 61 40 41 44 41 354 2035 58 362 2036 61 2003 46 2015 40 41 2046 61 362 2047 61 2036 46 2072 40 2038 61 123 362 58 2046 44 362 58 2073 44 125 44 2033 61 2033 44 2030 61 2030 44 2031 61 2031 44 41 792 2047 612 2075 40 2003 44 2056 58 813 44 2027 58 813 44 2028 58 2006 91 813 93 61 470 44 2062 58 2006 91 813 93 61 470 44 2063 58 2006 91 704 93 61 470 44 2033 58 2006 91 2034 93 61 470 44 2030 58 2006 91 660 93 61 470 44 2031 58 2009 91 2032 91 813 44 813 93 93 61 40 41 44 41 354 2076 58 362 2036 61 2003 46 2015 40 41 2037 61 362 2047 61 2036 46 2075 40 2038 61 123 362 58 2037 44 362 58 2062 44 362 58 2063 125 44 2033 61 2033 44 2030 61 2030 44 2031 61 2031 44 41 792 2047 64 2001 46 2023 612 2077 40 2003 44 2027 58 813 44 2028 58 813 44 2033 58 2006 91 2034 93 61 470 44 2030 58 2006 91 660 93 61 470 44 2031 58 2009 91 2032 91 813 44 813 93 93 61 40 41 44 41 354 2078 58 362 2036 61 2003 46 2015 40 41 2037 61 362 2047 61 2036 46 2077 40 2038 61 123 362 58 2037 125 44 2033 61 2033 44 2030 61 2030 44 2031 61 2031 44 41 792 2047 64 2001 46 2023 612 2079 40 2003 44 2056 58 813 44 2027 58 813 44 2028 58 813 44 2033 58 2006 91 2034 93 61 470 44 2030 58 2006 91 660 93 61 470 44 2031 58 2009 91 2032 91 813 44 813 93 93 61 40 41 44 41 354 2035 58 362 2036 61 2003 46 2015 40 41 2046 61 362 2047 61 2036 46 2079 40 2038 61 123 362 58 2046 125 44 2033 61 2033 44 2030 61 2030 44 2031 61 2031 44 41 792 2047 ,"{'AvgLine': 36, 'CountLine': 660, 'CountStmt': 75, 'MaxNesting': 1, 'AvgLineCode': 16, 'AvgEssential': 1, 'AvgLineBlank': 1, 'CountStmtExe': 57, 'MaxEssential': 1, 'SumEssential': 17, 'AvgCyclomatic': 1, 'CountLineCode': 290, 'CountStmtDecl': 56, 'MaxCyclomatic': 2, 'SumCyclomatic': 18, 'AvgLineComment': 18, 'CountClassBase': 1, 'CountLineBlank': 47, 'CountDeclMethod': 17, 'CountLineCodeExe': 139, 'CountLineComment': 324, 'CountClassCoupled': 5, 'CountClassDerived': 0, 'CountLineCodeDecl': 189, 'CountDeclMethodAll': 44, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '1.12', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 2, 'SumCyclomaticStrict': 18, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 2, 'SumCyclomaticModified': 18, 'CountDeclInstanceMethod': 16, 'CountClassCoupledModified': 0, 'CountDeclInstanceVariable': 1}"
123950,Python,"class SQLCheckOperator(BaseSQLOperator):
    """"""
    Performs checks against a db. The ``SQLCheckOperator`` expects
    a sql query that will return a single row. Each value on that
    first row is evaluated using python ``bool`` casting. If any of the
    values return ``False`` the check is failed and errors out.

    Note that Python bool casting evals the following as ``False``:

    * ``False``
    * ``0``
    * Empty string (``""""``)
    * Empty list (``[]``)
    * Empty dictionary or set (``{}``)

    Given a query like ``SELECT COUNT(*) FROM foo``, it will fail only if
    the count ``== 0``. You can craft much more complex query that could,
    for instance, check that the table has the same number of rows as
    the source table upstream, or that the count of today's partition is
    greater than yesterday's partition, or that a set of metrics are less
    than 3 standard deviation for the 7 day average.

    This operator can be used as a data quality check in your pipeline, and
    depending on where you put it in your DAG, you have the choice to
    stop the critical path, preventing from
    publishing dubious data, or on the side and receive email alerts
    without stopping the progress of the DAG.

    :param sql: the sql to be executed. (templated)
    :type sql: str
    :param conn_id: the connection ID used to connect to the database.
    :type conn_id: str
    :param database: name of database which overwrite the defined one in connection
    :type database: str
    """"""

    template_fields: Iterable[str] = (""sql"",)
    template_ext: Iterable[str] = (
        "".hql"",
        "".sql"",
    )
    ui_color = ""#fff7e6""

    def __init__(
        self, *, sql: str, conn_id: Optional[str] = None, database: Optional[str] = None, **kwargs
    ) -> None:
        super().__init__(conn_id=conn_id, database=database, **kwargs)
        self.sql = sql

    def execute(self, context: Context):
        self.log.info(""Executing SQL check: %s"", self.sql)
        records = self.get_db_hook().get_first(self.sql)

        self.log.info(""Record: %s"", records)
        if not records:
            raise AirflowException(""The query returned None"")
        elif not all(bool(r) for r in records):
            raise AirflowException(f""Test failed.\nQuery:\n{self.sql}\nResults:\n{records!s}"")

        self.log.info(""Success."")",0,587 2000 40 2001 41 58 362 2002 58 2003 91 813 93 61 40 362 44 41 2004 58 2003 91 813 93 61 40 362 44 362 44 41 2005 61 362 612 2006 40 2007 44 42 44 2008 58 813 44 2009 58 2010 91 813 93 61 470 44 2011 58 2010 91 813 93 61 470 44 350 2012 41 354 470 58 818 40 41 46 2006 40 2009 61 2009 44 2011 61 2011 44 350 2012 41 2007 46 2008 61 2008 612 2013 40 2007 44 2014 58 2015 41 58 2007 46 2016 46 2017 40 362 44 2007 46 2008 41 2018 61 2007 46 2019 40 41 46 2020 40 2007 46 2008 41 2007 46 2016 46 2017 40 362 44 2018 41 688 750 2018 58 778 2021 40 362 41 629 750 544 40 569 40 2022 41 664 2022 696 2018 41 58 778 2021 40 362 41 2007 46 2016 46 2017 40 362 41 ,"{'AvgLine': 8, 'CountLine': 60, 'CountStmt': 15, 'MaxNesting': 1, 'AvgLineCode': 7, 'AvgEssential': 2, 'AvgLineBlank': 1, 'CountStmtExe': 12, 'MaxEssential': 3, 'SumEssential': 4, 'AvgCyclomatic': 2, 'CountLineCode': 21, 'CountStmtDecl': 8, 'MaxCyclomatic': 3, 'SumCyclomatic': 4, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 10, 'CountDeclMethod': 2, 'CountLineCodeExe': 16, 'CountLineComment': 30, 'CountClassCoupled': 5, 'CountClassDerived': 6, 'CountLineCodeDecl': 10, 'CountDeclMethodAll': 83, 'MaxInheritanceTree': 4, 'RatioCommentToCode': '1.43', 'AvgCyclomaticStrict': 2, 'MaxCyclomaticStrict': 3, 'SumCyclomaticStrict': 4, 'AvgCyclomaticModified': 2, 'MaxCyclomaticModified': 3, 'SumCyclomaticModified': 4, 'CountDeclInstanceMethod': 2, 'CountClassCoupledModified': 2, 'CountDeclInstanceVariable': 1}"
126267,Python,"class TestCloudDLPHook(unittest.TestCase):
    def setUp(self):
        with mock.patch(
            ""airflow.providers.google.common.hooks.base_google.GoogleBaseHook.__init__"",
            new=mock_base_gcp_hook_no_default_project_id,
        ):
            self.hook = CloudDLPHook(gcp_conn_id=""test"")

    @mock.patch(
        ""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.client_info"", new_callable=mock.PropertyMock
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook._get_credentials"")
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.DlpServiceClient"")
    def test_dlp_service_client_creation(self, mock_client, mock_get_creds, mock_client_info):
        result = self.hook.get_conn()
        mock_client.assert_called_once_with(
            credentials=mock_get_creds.return_value, client_info=mock_client_info.return_value
        )
        assert mock_client.return_value == result
        assert self.hook._client == result

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_cancel_dlp_job(self, get_conn):
        self.hook.cancel_dlp_job(dlp_job_id=DLP_JOB_ID, project_id=PROJECT_ID)

        get_conn.return_value.cancel_dlp_job.assert_called_once_with(
            name=DLP_JOB_PATH, retry=None, timeout=None, metadata=()
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_cancel_dlp_job_without_dlp_job_id(self, _):
        with pytest.raises(AirflowException):
            self.hook.cancel_dlp_job(dlp_job_id=None, project_id=PROJECT_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_cancel_dlp_job_without_parent(self, _, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.cancel_dlp_job(dlp_job_id=DLP_JOB_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_create_deidentify_template_with_org_id(self, get_conn, mock_project_id):
        get_conn.return_value.create_deidentify_template.return_value = API_RESPONSE
        result = self.hook.create_deidentify_template(organization_id=ORGANIZATION_ID)

        assert result is API_RESPONSE
        get_conn.return_value.create_deidentify_template.assert_called_once_with(
            parent=ORGANIZATION_PATH,
            deidentify_template=None,
            template_id=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_create_deidentify_template_with_project_id(self, get_conn):
        get_conn.return_value.create_deidentify_template.return_value = API_RESPONSE
        result = self.hook.create_deidentify_template(project_id=PROJECT_ID)

        assert result is API_RESPONSE
        get_conn.return_value.create_deidentify_template.assert_called_once_with(
            parent=PROJECT_PATH,
            deidentify_template=None,
            template_id=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_create_deidentify_template_without_parent(self, _, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.create_deidentify_template()

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_create_dlp_job(self, get_conn):
        get_conn.return_value.create_dlp_job.return_value = API_RESPONSE
        result = self.hook.create_dlp_job(project_id=PROJECT_ID, wait_until_finished=False)

        assert result is API_RESPONSE
        get_conn.return_value.create_dlp_job.assert_called_once_with(
            parent=PROJECT_PATH,
            inspect_job=None,
            risk_job=None,
            job_id=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_create_dlp_job_without_project_id(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.create_dlp_job()

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_create_dlp_job_with_wait_until_finished(self, get_conn):
        job_for_create = DlpJob(name=DLP_JOB_PATH, state=DlpJob.JobState.PENDING)
        get_conn.return_value.create_dlp_job.return_value = job_for_create
        job_for_get = DlpJob(name=DLP_JOB_PATH, state=DlpJob.JobState.DONE)
        get_conn.return_value.get_dlp_job.return_value = job_for_get

        self.hook.create_dlp_job(project_id=PROJECT_ID)

        get_conn.return_value.get_dlp_job.assert_called_once_with(
            name=DLP_JOB_PATH, retry=None, timeout=None, metadata=()
        )

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_create_inspect_template_with_org_id(self, get_conn, mock_project_id):
        get_conn.return_value.create_inspect_template.return_value = API_RESPONSE
        result = self.hook.create_inspect_template(organization_id=ORGANIZATION_ID)

        assert result is API_RESPONSE
        get_conn.return_value.create_inspect_template.assert_called_once_with(
            parent=ORGANIZATION_PATH,
            inspect_template=None,
            template_id=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_create_inspect_template_with_project_id(self, get_conn):
        get_conn.return_value.create_inspect_template.return_value = API_RESPONSE
        result = self.hook.create_inspect_template(project_id=PROJECT_ID)

        assert result is API_RESPONSE
        get_conn.return_value.create_inspect_template.assert_called_once_with(
            parent=PROJECT_PATH,
            inspect_template=None,
            template_id=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_create_inspect_template_without_parent(self, _, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.create_inspect_template()

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_create_job_trigger(self, get_conn):
        get_conn.return_value.create_job_trigger.return_value = API_RESPONSE
        result = self.hook.create_job_trigger(project_id=PROJECT_ID)

        assert result is API_RESPONSE
        get_conn.return_value.create_job_trigger.assert_called_once_with(
            parent=PROJECT_PATH,
            job_trigger=None,
            trigger_id=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_create_job_trigger_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.create_job_trigger()

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_create_stored_info_type_with_org_id(self, get_conn, mock_project_id):
        get_conn.return_value.create_stored_info_type.return_value = API_RESPONSE
        result = self.hook.create_stored_info_type(organization_id=ORGANIZATION_ID)

        assert result is API_RESPONSE
        get_conn.return_value.create_stored_info_type.assert_called_once_with(
            parent=ORGANIZATION_PATH,
            config=None,
            stored_info_type_id=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_create_stored_info_type_with_project_id(self, get_conn):
        get_conn.return_value.create_stored_info_type.return_value = API_RESPONSE
        result = self.hook.create_stored_info_type(project_id=PROJECT_ID)

        assert result is API_RESPONSE
        get_conn.return_value.create_stored_info_type.assert_called_once_with(
            parent=PROJECT_PATH,
            config=None,
            stored_info_type_id=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_create_stored_info_type_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.create_stored_info_type()

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_deidentify_content(self, get_conn):
        get_conn.return_value.deidentify_content.return_value = API_RESPONSE
        result = self.hook.deidentify_content(project_id=PROJECT_ID)

        assert result is API_RESPONSE
        get_conn.return_value.deidentify_content.assert_called_once_with(
            parent=PROJECT_PATH,
            deidentify_config=None,
            inspect_config=None,
            item=None,
            inspect_template_name=None,
            deidentify_template_name=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_deidentify_content_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.deidentify_content()

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_deidentify_template_with_org_id(self, get_conn, mock_project_id):
        self.hook.delete_deidentify_template(template_id=TEMPLATE_ID, organization_id=ORGANIZATION_ID)

        get_conn.return_value.delete_deidentify_template.assert_called_once_with(
            name=DEIDENTIFY_TEMPLATE_ORGANIZATION_PATH,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_deidentify_template_with_project_id(self, get_conn):
        self.hook.delete_deidentify_template(template_id=TEMPLATE_ID, project_id=PROJECT_ID)

        get_conn.return_value.delete_deidentify_template.assert_called_once_with(
            name=DEIDENTIFY_TEMPLATE_PROJECT_PATH,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_deidentify_template_without_template_id(self, _):
        with pytest.raises(AirflowException):
            self.hook.delete_deidentify_template(template_id=None)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_deidentify_template_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.delete_deidentify_template(template_id=TEMPLATE_ID)

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_dlp_job(self, get_conn):
        self.hook.delete_dlp_job(dlp_job_id=DLP_JOB_ID, project_id=PROJECT_ID)

        get_conn.return_value.delete_dlp_job.assert_called_once_with(
            name=DLP_JOB_PATH, retry=None, timeout=None, metadata=()
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_dlp_job_without_dlp_job_id(self, _):
        with pytest.raises(AirflowException):
            self.hook.delete_dlp_job(dlp_job_id=None, project_id=PROJECT_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_dlp_job_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.delete_dlp_job(dlp_job_id=DLP_JOB_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_inspect_template_with_org_id(self, get_conn, mock_project_id):
        self.hook.delete_inspect_template(template_id=TEMPLATE_ID, organization_id=ORGANIZATION_ID)

        get_conn.return_value.delete_inspect_template.assert_called_once_with(
            name=INSPECT_TEMPLATE_ORGANIZATION_PATH,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_inspect_template_with_project_id(self, get_conn):
        self.hook.delete_inspect_template(template_id=TEMPLATE_ID, project_id=PROJECT_ID)

        get_conn.return_value.delete_inspect_template.assert_called_once_with(
            name=INSPECT_TEMPLATE_PROJECT_PATH,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_inspect_template_without_template_id(self, _):
        with pytest.raises(AirflowException):
            self.hook.delete_inspect_template(template_id=None)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_inspect_template_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.delete_inspect_template(template_id=TEMPLATE_ID)

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_job_trigger(self, get_conn):
        self.hook.delete_job_trigger(job_trigger_id=TRIGGER_ID, project_id=PROJECT_ID)

        get_conn.return_value.delete_job_trigger.assert_called_once_with(
            name=JOB_TRIGGER_PATH, retry=None, timeout=None, metadata=()
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_job_trigger_without_trigger_id(self, _):
        with pytest.raises(AirflowException):
            self.hook.delete_job_trigger(job_trigger_id=None, project_id=PROJECT_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_job_trigger_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.delete_job_trigger(job_trigger_id=TRIGGER_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_stored_info_type_with_org_id(self, get_conn, mock_project_id):
        self.hook.delete_stored_info_type(
            stored_info_type_id=STORED_INFO_TYPE_ID, organization_id=ORGANIZATION_ID
        )

        get_conn.return_value.delete_stored_info_type.assert_called_once_with(
            name=STORED_INFO_TYPE_ORGANIZATION_PATH,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_stored_info_type_with_project_id(self, get_conn):
        self.hook.delete_stored_info_type(stored_info_type_id=STORED_INFO_TYPE_ID, project_id=PROJECT_ID)

        get_conn.return_value.delete_stored_info_type.assert_called_once_with(
            name=STORED_INFO_TYPE_PROJECT_PATH,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_stored_info_type_without_stored_info_type_id(self, _):
        with pytest.raises(AirflowException):
            self.hook.delete_stored_info_type(stored_info_type_id=None)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_delete_stored_info_type_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.delete_stored_info_type(stored_info_type_id=STORED_INFO_TYPE_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_deidentify_template_with_org_id(self, get_conn, mock_project_id):
        get_conn.return_value.get_deidentify_template.return_value = API_RESPONSE
        result = self.hook.get_deidentify_template(template_id=TEMPLATE_ID, organization_id=ORGANIZATION_ID)

        assert result is API_RESPONSE
        get_conn.return_value.get_deidentify_template.assert_called_once_with(
            name=DEIDENTIFY_TEMPLATE_ORGANIZATION_PATH,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_deidentify_template_with_project_id(self, get_conn):
        get_conn.return_value.get_deidentify_template.return_value = API_RESPONSE
        result = self.hook.get_deidentify_template(template_id=TEMPLATE_ID, project_id=PROJECT_ID)

        assert result is API_RESPONSE
        get_conn.return_value.get_deidentify_template.assert_called_once_with(
            name=DEIDENTIFY_TEMPLATE_PROJECT_PATH,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_deidentify_template_without_template_id(self, _):
        with pytest.raises(AirflowException):
            self.hook.get_deidentify_template(template_id=None)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_deidentify_template_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.get_deidentify_template(template_id=TEMPLATE_ID)

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_dlp_job(self, get_conn):
        get_conn.return_value.get_dlp_job.return_value = API_RESPONSE
        result = self.hook.get_dlp_job(dlp_job_id=DLP_JOB_ID, project_id=PROJECT_ID)

        assert result is API_RESPONSE
        get_conn.return_value.get_dlp_job.assert_called_once_with(
            name=DLP_JOB_PATH, retry=None, timeout=None, metadata=()
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_dlp_job_without_dlp_job_id(self, _):
        with pytest.raises(AirflowException):
            self.hook.get_dlp_job(dlp_job_id=None, project_id=PROJECT_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_dlp_job_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.get_dlp_job(dlp_job_id=DLP_JOB_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_inspect_template_with_org_id(self, get_conn, mock_project_id):
        get_conn.return_value.get_inspect_template.return_value = API_RESPONSE
        result = self.hook.get_inspect_template(template_id=TEMPLATE_ID, organization_id=ORGANIZATION_ID)

        assert result is API_RESPONSE
        get_conn.return_value.get_inspect_template.assert_called_once_with(
            name=INSPECT_TEMPLATE_ORGANIZATION_PATH,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_inspect_template_with_project_id(self, get_conn):
        get_conn.return_value.get_inspect_template.return_value = API_RESPONSE
        result = self.hook.get_inspect_template(template_id=TEMPLATE_ID, project_id=PROJECT_ID)

        assert result is API_RESPONSE
        get_conn.return_value.get_inspect_template.assert_called_once_with(
            name=INSPECT_TEMPLATE_PROJECT_PATH,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_inspect_template_without_template_id(self, _):
        with pytest.raises(AirflowException):
            self.hook.get_inspect_template(template_id=None)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_inspect_template_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.get_inspect_template(template_id=TEMPLATE_ID)

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_job_trigger(self, get_conn):
        get_conn.return_value.get_job_trigger.return_value = API_RESPONSE
        result = self.hook.get_job_trigger(job_trigger_id=TRIGGER_ID, project_id=PROJECT_ID)

        assert result is API_RESPONSE
        get_conn.return_value.get_job_trigger.assert_called_once_with(
            name=JOB_TRIGGER_PATH, retry=None, timeout=None, metadata=()
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_job_trigger_without_trigger_id(self, _):
        with pytest.raises(AirflowException):
            self.hook.get_job_trigger(job_trigger_id=None, project_id=PROJECT_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_job_trigger_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.get_job_trigger(job_trigger_id=TRIGGER_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_stored_info_type_with_org_id(self, get_conn, mock_project_id):
        get_conn.return_value.get_stored_info_type.return_value = API_RESPONSE
        result = self.hook.get_stored_info_type(
            stored_info_type_id=STORED_INFO_TYPE_ID, organization_id=ORGANIZATION_ID
        )

        assert result is API_RESPONSE
        get_conn.return_value.get_stored_info_type.assert_called_once_with(
            name=STORED_INFO_TYPE_ORGANIZATION_PATH,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_stored_info_type_with_project_id(self, get_conn):
        get_conn.return_value.get_stored_info_type.return_value = API_RESPONSE
        result = self.hook.get_stored_info_type(
            stored_info_type_id=STORED_INFO_TYPE_ID, project_id=PROJECT_ID
        )

        assert result is API_RESPONSE
        get_conn.return_value.get_stored_info_type.assert_called_once_with(
            name=STORED_INFO_TYPE_PROJECT_PATH,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_stored_info_type_without_stored_info_type_id(self, _):
        with pytest.raises(AirflowException):
            self.hook.get_stored_info_type(stored_info_type_id=None)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_get_stored_info_type_without_parent(self, mock_get_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.get_stored_info_type(stored_info_type_id=STORED_INFO_TYPE_ID)

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_inspect_content(self, get_conn):
        get_conn.return_value.inspect_content.return_value = API_RESPONSE
        result = self.hook.inspect_content(project_id=PROJECT_ID)

        assert result is API_RESPONSE
        get_conn.return_value.inspect_content.assert_called_once_with(
            parent=PROJECT_PATH,
            inspect_config=None,
            item=None,
            inspect_template_name=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_inspect_content_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.inspect_content()

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_list_deidentify_templates_with_org_id(self, get_conn, mock_project_id):
        result = self.hook.list_deidentify_templates(organization_id=ORGANIZATION_ID)

        assert isinstance(result, list)
        get_conn.return_value.list_deidentify_templates.assert_called_once_with(
            parent=ORGANIZATION_PATH,
            page_size=None,
            order_by=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_list_deidentify_templates_with_project_id(self, get_conn):
        result = self.hook.list_deidentify_templates(project_id=PROJECT_ID)

        assert isinstance(result, list)
        get_conn.return_value.list_deidentify_templates.assert_called_once_with(
            parent=PROJECT_PATH,
            page_size=None,
            order_by=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_list_deidentify_templates_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.list_deidentify_templates()

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_list_dlp_jobs(self, get_conn):
        result = self.hook.list_dlp_jobs(project_id=PROJECT_ID)

        assert isinstance(result, list)
        get_conn.return_value.list_dlp_jobs.assert_called_once_with(
            parent=PROJECT_PATH,
            filter_=None,
            page_size=None,
            type_=None,
            order_by=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_list_dlp_jobs_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.list_dlp_jobs()

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_list_info_types(self, get_conn):
        get_conn.return_value.list_info_types.return_value = API_RESPONSE
        result = self.hook.list_info_types()

        assert result is API_RESPONSE
        get_conn.return_value.list_info_types.assert_called_once_with(
            language_code=None, filter_=None, retry=None, timeout=None, metadata=()
        )

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_list_inspect_templates_with_org_id(self, get_conn, mock_project_id):
        result = self.hook.list_inspect_templates(organization_id=ORGANIZATION_ID)

        assert isinstance(result, list)
        get_conn.return_value.list_inspect_templates.assert_called_once_with(
            parent=ORGANIZATION_PATH,
            page_size=None,
            order_by=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_list_inspect_templates_with_project_id(self, get_conn):
        result = self.hook.list_inspect_templates(project_id=PROJECT_ID)

        assert isinstance(result, list)
        get_conn.return_value.list_inspect_templates.assert_called_once_with(
            parent=PROJECT_PATH,
            page_size=None,
            order_by=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_list_inspect_templates_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.list_inspect_templates()

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_list_job_triggers(self, get_conn):
        result = self.hook.list_job_triggers(project_id=PROJECT_ID)

        assert isinstance(result, list)
        get_conn.return_value.list_job_triggers.assert_called_once_with(
            parent=PROJECT_PATH,
            page_size=None,
            order_by=None,
            filter_=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_list_job_triggers_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.list_job_triggers()

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_list_stored_info_types_with_org_id(self, get_conn, mock_project_id):
        result = self.hook.list_stored_info_types(organization_id=ORGANIZATION_ID)

        assert isinstance(result, list)
        get_conn.return_value.list_stored_info_types.assert_called_once_with(
            parent=ORGANIZATION_PATH,
            page_size=None,
            order_by=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_list_stored_info_types_with_project_id(self, get_conn):
        result = self.hook.list_stored_info_types(project_id=PROJECT_ID)

        assert isinstance(result, list)
        get_conn.return_value.list_stored_info_types.assert_called_once_with(
            parent=PROJECT_PATH,
            page_size=None,
            order_by=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_list_stored_info_types_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.list_stored_info_types()

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_redact_image(self, get_conn):
        get_conn.return_value.redact_image.return_value = API_RESPONSE
        result = self.hook.redact_image(project_id=PROJECT_ID)

        assert result is API_RESPONSE
        get_conn.return_value.redact_image.assert_called_once_with(
            parent=PROJECT_PATH,
            inspect_config=None,
            image_redaction_configs=None,
            include_findings=None,
            byte_item=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_redact_image_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.redact_image()

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_reidentify_content(self, get_conn):
        get_conn.return_value.reidentify_content.return_value = API_RESPONSE
        result = self.hook.reidentify_content(project_id=PROJECT_ID)

        assert result is API_RESPONSE
        get_conn.return_value.reidentify_content.assert_called_once_with(
            parent=PROJECT_PATH,
            reidentify_config=None,
            inspect_config=None,
            item=None,
            inspect_template_name=None,
            reidentify_template_name=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_reidentify_content_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.reidentify_content()

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_update_deidentify_template_with_org_id(self, get_conn, mock_project_id):
        get_conn.return_value.update_deidentify_template.return_value = API_RESPONSE
        result = self.hook.update_deidentify_template(
            template_id=TEMPLATE_ID, organization_id=ORGANIZATION_ID
        )

        assert result is API_RESPONSE
        get_conn.return_value.update_deidentify_template.assert_called_once_with(
            name=DEIDENTIFY_TEMPLATE_ORGANIZATION_PATH,
            deidentify_template=None,
            update_mask=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_update_deidentify_template_with_project_id(self, get_conn):
        get_conn.return_value.update_deidentify_template.return_value = API_RESPONSE
        result = self.hook.update_deidentify_template(template_id=TEMPLATE_ID, project_id=PROJECT_ID)

        assert result is API_RESPONSE
        get_conn.return_value.update_deidentify_template.assert_called_once_with(
            name=DEIDENTIFY_TEMPLATE_PROJECT_PATH,
            deidentify_template=None,
            update_mask=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_update_deidentify_template_without_template_id(self, _):
        with pytest.raises(AirflowException):
            self.hook.update_deidentify_template(template_id=None, organization_id=ORGANIZATION_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_update_deidentify_template_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.update_deidentify_template(template_id=TEMPLATE_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_update_inspect_template_with_org_id(self, get_conn, mock_project_id):
        get_conn.return_value.update_inspect_template.return_value = API_RESPONSE
        result = self.hook.update_inspect_template(template_id=TEMPLATE_ID, organization_id=ORGANIZATION_ID)

        assert result is API_RESPONSE
        get_conn.return_value.update_inspect_template.assert_called_once_with(
            name=INSPECT_TEMPLATE_ORGANIZATION_PATH,
            inspect_template=None,
            update_mask=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_update_inspect_template_with_project_id(self, get_conn):
        get_conn.return_value.update_inspect_template.return_value = API_RESPONSE
        result = self.hook.update_inspect_template(template_id=TEMPLATE_ID, project_id=PROJECT_ID)

        assert result is API_RESPONSE
        get_conn.return_value.update_inspect_template.assert_called_once_with(
            name=INSPECT_TEMPLATE_PROJECT_PATH,
            inspect_template=None,
            update_mask=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_update_inspect_template_without_template_id(self, _):
        with pytest.raises(AirflowException):
            self.hook.update_inspect_template(template_id=None, organization_id=ORGANIZATION_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_update_inspect_template_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.update_inspect_template(template_id=TEMPLATE_ID)

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_update_job_trigger(self, get_conn):
        get_conn.return_value.update_job_trigger.return_value = API_RESPONSE
        result = self.hook.update_job_trigger(job_trigger_id=TRIGGER_ID, project_id=PROJECT_ID)

        assert result is API_RESPONSE
        get_conn.return_value.update_job_trigger.assert_called_once_with(
            name=JOB_TRIGGER_PATH,
            job_trigger=None,
            update_mask=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_update_job_trigger_without_job_trigger_id(self, _):
        with pytest.raises(AirflowException):
            self.hook.update_job_trigger(job_trigger_id=None, project_id=PROJECT_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_update_job_trigger_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.update_job_trigger(job_trigger_id=TRIGGER_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_update_stored_info_type_with_org_id(self, get_conn, mock_project_id):
        get_conn.return_value.update_stored_info_type.return_value = API_RESPONSE
        result = self.hook.update_stored_info_type(
            stored_info_type_id=STORED_INFO_TYPE_ID, organization_id=ORGANIZATION_ID
        )

        assert result is API_RESPONSE
        get_conn.return_value.update_stored_info_type.assert_called_once_with(
            name=STORED_INFO_TYPE_ORGANIZATION_PATH,
            config=None,
            update_mask=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_update_stored_info_type_with_project_id(self, get_conn):
        get_conn.return_value.update_stored_info_type.return_value = API_RESPONSE
        result = self.hook.update_stored_info_type(
            stored_info_type_id=STORED_INFO_TYPE_ID, project_id=PROJECT_ID
        )

        assert result is API_RESPONSE
        get_conn.return_value.update_stored_info_type.assert_called_once_with(
            name=STORED_INFO_TYPE_PROJECT_PATH,
            config=None,
            update_mask=None,
            retry=None,
            timeout=None,
            metadata=(),
        )

    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_update_stored_info_type_without_stored_info_type_id(self, _):
        with pytest.raises(AirflowException):
            self.hook.update_stored_info_type(stored_info_type_id=None, organization_id=ORGANIZATION_ID)

    @mock.patch(
        'airflow.providers.google.common.hooks.base_google.GoogleBaseHook.project_id',
        new_callable=PropertyMock,
        return_value=None,
    )
    @mock.patch(""airflow.providers.google.cloud.hooks.dlp.CloudDLPHook.get_conn"")
    def test_update_stored_info_type_without_parent(self, mock_get_conn, mock_project_id):
        with pytest.raises(AirflowException):
            self.hook.update_stored_info_type(stored_info_type_id=STORED_INFO_TYPE_ID)",1,587 2000 40 2001 46 2002 41 58 612 2003 40 2004 41 58 871 2005 46 2006 40 362 44 2007 61 2008 44 41 58 2004 46 2009 61 2010 40 2011 61 362 41 64 2005 46 2006 40 362 44 2012 61 2005 46 2013 41 64 2005 46 2006 40 362 41 64 2005 46 2006 40 362 41 612 2014 40 2004 44 2015 44 2016 44 2017 41 58 2018 61 2004 46 2009 46 2019 40 41 2015 46 2020 40 2021 61 2016 46 2022 44 2023 61 2017 46 2022 41 555 2015 46 2022 323 2018 555 2004 46 2009 46 2024 323 2018 64 2005 46 2006 40 362 41 612 2025 40 2004 44 2019 41 58 2004 46 2009 46 2026 40 2027 61 2028 44 2029 61 2030 41 2019 46 2022 46 2026 46 2020 40 2031 61 2032 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 41 64 2005 46 2006 40 362 41 612 2036 40 2004 44 2037 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2026 40 2027 61 470 44 2029 61 2030 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2041 40 2004 44 2037 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2026 40 2027 61 2028 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2043 40 2004 44 2019 44 2042 41 58 2019 46 2022 46 2044 46 2022 61 2045 2018 61 2004 46 2009 46 2044 40 2046 61 2047 41 555 2018 712 2045 2019 46 2022 46 2044 46 2020 40 2048 61 2049 44 2050 61 470 44 2051 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2052 40 2004 44 2019 41 58 2019 46 2022 46 2044 46 2022 61 2045 2018 61 2004 46 2009 46 2044 40 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2044 46 2020 40 2048 61 2053 44 2050 61 470 44 2051 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2054 40 2004 44 2037 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2044 40 41 64 2005 46 2006 40 362 41 612 2055 40 2004 44 2019 41 58 2019 46 2022 46 2056 46 2022 61 2045 2018 61 2004 46 2009 46 2056 40 2029 61 2030 44 2057 61 443 41 555 2018 712 2045 2019 46 2022 46 2056 46 2020 40 2048 61 2053 44 2058 61 470 44 2059 61 470 44 2060 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2061 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2056 40 41 64 2005 46 2006 40 362 41 612 2063 40 2004 44 2019 41 58 2064 61 2065 40 2031 61 2032 44 2066 61 2065 46 2067 46 2068 41 2019 46 2022 46 2056 46 2022 61 2064 2069 61 2065 40 2031 61 2032 44 2066 61 2065 46 2067 46 2070 41 2019 46 2022 46 2071 46 2022 61 2069 2004 46 2009 46 2056 40 2029 61 2030 41 2019 46 2022 46 2071 46 2020 40 2031 61 2032 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2072 40 2004 44 2019 44 2042 41 58 2019 46 2022 46 2073 46 2022 61 2045 2018 61 2004 46 2009 46 2073 40 2046 61 2047 41 555 2018 712 2045 2019 46 2022 46 2073 46 2020 40 2048 61 2049 44 2074 61 470 44 2051 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2075 40 2004 44 2019 41 58 2019 46 2022 46 2073 46 2022 61 2045 2018 61 2004 46 2009 46 2073 40 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2073 46 2020 40 2048 61 2053 44 2074 61 470 44 2051 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2076 40 2004 44 2037 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2073 40 41 64 2005 46 2006 40 362 41 612 2077 40 2004 44 2019 41 58 2019 46 2022 46 2078 46 2022 61 2045 2018 61 2004 46 2009 46 2078 40 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2078 46 2020 40 2048 61 2053 44 2079 61 470 44 2080 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2081 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2078 40 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2082 40 2004 44 2019 44 2042 41 58 2019 46 2022 46 2083 46 2022 61 2045 2018 61 2004 46 2009 46 2083 40 2046 61 2047 41 555 2018 712 2045 2019 46 2022 46 2083 46 2020 40 2048 61 2049 44 2084 61 470 44 2085 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2086 40 2004 44 2019 41 58 2019 46 2022 46 2083 46 2022 61 2045 2018 61 2004 46 2009 46 2083 40 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2083 46 2020 40 2048 61 2053 44 2084 61 470 44 2085 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2087 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2083 40 41 64 2005 46 2006 40 362 41 612 2088 40 2004 44 2019 41 58 2019 46 2022 46 2089 46 2022 61 2045 2018 61 2004 46 2009 46 2089 40 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2089 46 2020 40 2048 61 2053 44 2090 61 470 44 2091 61 470 44 2092 61 470 44 2093 61 470 44 2094 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2095 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2089 40 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2096 40 2004 44 2019 44 2042 41 58 2004 46 2009 46 2097 40 2051 61 2098 44 2046 61 2047 41 2019 46 2022 46 2097 46 2020 40 2031 61 2099 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2100 40 2004 44 2019 41 58 2004 46 2009 46 2097 40 2051 61 2098 44 2029 61 2030 41 2019 46 2022 46 2097 46 2020 40 2031 61 2101 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2102 40 2004 44 2037 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2097 40 2051 61 470 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2103 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2097 40 2051 61 2098 41 64 2005 46 2006 40 362 41 612 2104 40 2004 44 2019 41 58 2004 46 2009 46 2105 40 2027 61 2028 44 2029 61 2030 41 2019 46 2022 46 2105 46 2020 40 2031 61 2032 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 41 64 2005 46 2006 40 362 41 612 2106 40 2004 44 2037 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2105 40 2027 61 470 44 2029 61 2030 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2107 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2105 40 2027 61 2028 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2108 40 2004 44 2019 44 2042 41 58 2004 46 2009 46 2109 40 2051 61 2098 44 2046 61 2047 41 2019 46 2022 46 2109 46 2020 40 2031 61 2110 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2111 40 2004 44 2019 41 58 2004 46 2009 46 2109 40 2051 61 2098 44 2029 61 2030 41 2019 46 2022 46 2109 46 2020 40 2031 61 2112 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2113 40 2004 44 2037 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2109 40 2051 61 470 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2114 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2109 40 2051 61 2098 41 64 2005 46 2006 40 362 41 612 2115 40 2004 44 2019 41 58 2004 46 2009 46 2116 40 2117 61 2118 44 2029 61 2030 41 2019 46 2022 46 2116 46 2020 40 2031 61 2119 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 41 64 2005 46 2006 40 362 41 612 2120 40 2004 44 2037 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2116 40 2117 61 470 44 2029 61 2030 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2121 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2116 40 2117 61 2118 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2122 40 2004 44 2019 44 2042 41 58 2004 46 2009 46 2123 40 2085 61 2124 44 2046 61 2047 41 2019 46 2022 46 2123 46 2020 40 2031 61 2125 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2126 40 2004 44 2019 41 58 2004 46 2009 46 2123 40 2085 61 2124 44 2029 61 2030 41 2019 46 2022 46 2123 46 2020 40 2031 61 2127 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2128 40 2004 44 2037 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2123 40 2085 61 470 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2129 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2123 40 2085 61 2124 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2130 40 2004 44 2019 44 2042 41 58 2019 46 2022 46 2131 46 2022 61 2045 2018 61 2004 46 2009 46 2131 40 2051 61 2098 44 2046 61 2047 41 555 2018 712 2045 2019 46 2022 46 2131 46 2020 40 2031 61 2099 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2132 40 2004 44 2019 41 58 2019 46 2022 46 2131 46 2022 61 2045 2018 61 2004 46 2009 46 2131 40 2051 61 2098 44 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2131 46 2020 40 2031 61 2101 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2133 40 2004 44 2037 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2131 40 2051 61 470 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2134 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2131 40 2051 61 2098 41 64 2005 46 2006 40 362 41 612 2135 40 2004 44 2019 41 58 2019 46 2022 46 2071 46 2022 61 2045 2018 61 2004 46 2009 46 2071 40 2027 61 2028 44 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2071 46 2020 40 2031 61 2032 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 41 64 2005 46 2006 40 362 41 612 2136 40 2004 44 2037 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2071 40 2027 61 470 44 2029 61 2030 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2137 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2071 40 2027 61 2028 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2138 40 2004 44 2019 44 2042 41 58 2019 46 2022 46 2139 46 2022 61 2045 2018 61 2004 46 2009 46 2139 40 2051 61 2098 44 2046 61 2047 41 555 2018 712 2045 2019 46 2022 46 2139 46 2020 40 2031 61 2110 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2140 40 2004 44 2019 41 58 2019 46 2022 46 2139 46 2022 61 2045 2018 61 2004 46 2009 46 2139 40 2051 61 2098 44 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2139 46 2020 40 2031 61 2112 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2141 40 2004 44 2037 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2139 40 2051 61 470 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2142 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2139 40 2051 61 2098 41 64 2005 46 2006 40 362 41 612 2143 40 2004 44 2019 41 58 2019 46 2022 46 2144 46 2022 61 2045 2018 61 2004 46 2009 46 2144 40 2117 61 2118 44 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2144 46 2020 40 2031 61 2119 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 41 64 2005 46 2006 40 362 41 612 2145 40 2004 44 2037 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2144 40 2117 61 470 44 2029 61 2030 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2146 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2144 40 2117 61 2118 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2147 40 2004 44 2019 44 2042 41 58 2019 46 2022 46 2148 46 2022 61 2045 2018 61 2004 46 2009 46 2148 40 2085 61 2124 44 2046 61 2047 41 555 2018 712 2045 2019 46 2022 46 2148 46 2020 40 2031 61 2125 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2149 40 2004 44 2019 41 58 2019 46 2022 46 2148 46 2022 61 2045 2018 61 2004 46 2009 46 2148 40 2085 61 2124 44 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2148 46 2020 40 2031 61 2127 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2150 40 2004 44 2037 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2148 40 2085 61 470 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2151 40 2004 44 2152 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2148 40 2085 61 2124 41 64 2005 46 2006 40 362 41 612 2153 40 2004 44 2019 41 58 2019 46 2022 46 2154 46 2022 61 2045 2018 61 2004 46 2009 46 2154 40 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2154 46 2020 40 2048 61 2053 44 2091 61 470 44 2092 61 470 44 2093 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2155 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2154 40 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2156 40 2004 44 2019 44 2042 41 58 2018 61 2004 46 2009 46 2157 40 2046 61 2047 41 555 713 40 2018 44 723 41 2019 46 2022 46 2157 46 2020 40 2048 61 2049 44 2158 61 470 44 2159 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2160 40 2004 44 2019 41 58 2018 61 2004 46 2009 46 2157 40 2029 61 2030 41 555 713 40 2018 44 723 41 2019 46 2022 46 2157 46 2020 40 2048 61 2053 44 2158 61 470 44 2159 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2161 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2157 40 41 64 2005 46 2006 40 362 41 612 2162 40 2004 44 2019 41 58 2018 61 2004 46 2009 46 2163 40 2029 61 2030 41 555 713 40 2018 44 723 41 2019 46 2022 46 2163 46 2020 40 2048 61 2053 44 2164 61 470 44 2158 61 470 44 2165 61 470 44 2159 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2166 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2163 40 41 64 2005 46 2006 40 362 41 612 2167 40 2004 44 2019 41 58 2019 46 2022 46 2168 46 2022 61 2045 2018 61 2004 46 2009 46 2168 40 41 555 2018 712 2045 2019 46 2022 46 2168 46 2020 40 2169 61 470 44 2164 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2170 40 2004 44 2019 44 2042 41 58 2018 61 2004 46 2009 46 2171 40 2046 61 2047 41 555 713 40 2018 44 723 41 2019 46 2022 46 2171 46 2020 40 2048 61 2049 44 2158 61 470 44 2159 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2172 40 2004 44 2019 41 58 2018 61 2004 46 2009 46 2171 40 2029 61 2030 41 555 713 40 2018 44 723 41 2019 46 2022 46 2171 46 2020 40 2048 61 2053 44 2158 61 470 44 2159 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2173 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2171 40 41 64 2005 46 2006 40 362 41 612 2174 40 2004 44 2019 41 58 2018 61 2004 46 2009 46 2175 40 2029 61 2030 41 555 713 40 2018 44 723 41 2019 46 2022 46 2175 46 2020 40 2048 61 2053 44 2158 61 470 44 2159 61 470 44 2164 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2176 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2175 40 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2177 40 2004 44 2019 44 2042 41 58 2018 61 2004 46 2009 46 2178 40 2046 61 2047 41 555 713 40 2018 44 723 41 2019 46 2022 46 2178 46 2020 40 2048 61 2049 44 2158 61 470 44 2159 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2179 40 2004 44 2019 41 58 2018 61 2004 46 2009 46 2178 40 2029 61 2030 41 555 713 40 2018 44 723 41 2019 46 2022 46 2178 46 2020 40 2048 61 2053 44 2158 61 470 44 2159 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2180 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2178 40 41 64 2005 46 2006 40 362 41 612 2181 40 2004 44 2019 41 58 2019 46 2022 46 2182 46 2022 61 2045 2018 61 2004 46 2009 46 2182 40 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2182 46 2020 40 2048 61 2053 44 2091 61 470 44 2183 61 470 44 2184 61 470 44 2185 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2186 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2182 40 41 64 2005 46 2006 40 362 41 612 2187 40 2004 44 2019 41 58 2019 46 2022 46 2188 46 2022 61 2045 2018 61 2004 46 2009 46 2188 40 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2188 46 2020 40 2048 61 2053 44 2189 61 470 44 2091 61 470 44 2092 61 470 44 2093 61 470 44 2190 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2191 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2188 40 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2192 40 2004 44 2019 44 2042 41 58 2019 46 2022 46 2193 46 2022 61 2045 2018 61 2004 46 2009 46 2193 40 2051 61 2098 44 2046 61 2047 41 555 2018 712 2045 2019 46 2022 46 2193 46 2020 40 2031 61 2099 44 2050 61 470 44 2194 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2195 40 2004 44 2019 41 58 2019 46 2022 46 2193 46 2022 61 2045 2018 61 2004 46 2009 46 2193 40 2051 61 2098 44 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2193 46 2020 40 2031 61 2101 44 2050 61 470 44 2194 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2196 40 2004 44 2037 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2193 40 2051 61 470 44 2046 61 2047 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2197 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2193 40 2051 61 2098 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2198 40 2004 44 2019 44 2042 41 58 2019 46 2022 46 2199 46 2022 61 2045 2018 61 2004 46 2009 46 2199 40 2051 61 2098 44 2046 61 2047 41 555 2018 712 2045 2019 46 2022 46 2199 46 2020 40 2031 61 2110 44 2074 61 470 44 2194 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2200 40 2004 44 2019 41 58 2019 46 2022 46 2199 46 2022 61 2045 2018 61 2004 46 2009 46 2199 40 2051 61 2098 44 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2199 46 2020 40 2031 61 2112 44 2074 61 470 44 2194 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2201 40 2004 44 2037 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2199 40 2051 61 470 44 2046 61 2047 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2202 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2199 40 2051 61 2098 41 64 2005 46 2006 40 362 41 612 2203 40 2004 44 2019 41 58 2019 46 2022 46 2204 46 2022 61 2045 2018 61 2004 46 2009 46 2204 40 2117 61 2118 44 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2204 46 2020 40 2031 61 2119 44 2079 61 470 44 2194 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2205 40 2004 44 2037 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2204 40 2117 61 470 44 2029 61 2030 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2206 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2204 40 2117 61 2118 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2207 40 2004 44 2019 44 2042 41 58 2019 46 2022 46 2208 46 2022 61 2045 2018 61 2004 46 2009 46 2208 40 2085 61 2124 44 2046 61 2047 41 555 2018 712 2045 2019 46 2022 46 2208 46 2020 40 2031 61 2125 44 2084 61 470 44 2194 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2209 40 2004 44 2019 41 58 2019 46 2022 46 2208 46 2022 61 2045 2018 61 2004 46 2009 46 2208 40 2085 61 2124 44 2029 61 2030 41 555 2018 712 2045 2019 46 2022 46 2208 46 2020 40 2031 61 2127 44 2084 61 470 44 2194 61 470 44 2033 61 470 44 2034 61 470 44 2035 61 40 41 44 41 64 2005 46 2006 40 362 41 612 2210 40 2004 44 2037 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2208 40 2085 61 470 44 2046 61 2047 41 64 2005 46 2006 40 362 44 2012 61 2013 44 2022 61 470 44 41 64 2005 46 2006 40 362 41 612 2211 40 2004 44 2062 44 2042 41 58 871 2038 46 2039 40 2040 41 58 2004 46 2009 46 2208 40 2085 61 2124 41 ,"{'AvgLine': 7, 'CountLine': 1093, 'CountStmt': 347, 'MaxNesting': 1, 'AvgLineCode': 6, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 254, 'MaxEssential': 1, 'SumEssential': 92, 'AvgCyclomatic': 1, 'CountLineCode': 955, 'CountStmtDecl': 133, 'MaxCyclomatic': 1, 'SumCyclomatic': 92, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 138, 'CountDeclMethod': 92, 'CountLineCodeExe': 547, 'CountLineComment': 0, 'CountClassCoupled': 3, 'CountClassDerived': 0, 'CountLineCodeDecl': 402, 'CountDeclMethodAll': 92, 'MaxInheritanceTree': 1, 'RatioCommentToCode': '0.00', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 1, 'SumCyclomaticStrict': 92, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 1, 'SumCyclomaticModified': 92, 'CountDeclInstanceMethod': 92, 'CountClassCoupledModified': 2, 'CountDeclInstanceVariable': 1}"
132418,Python,"class TestFormField(PostgreSQLSimpleTestCase):

    def test_valid_integer(self):
        field = pg_forms.IntegerRangeField()
        value = field.clean(['1', '2'])
        self.assertEqual(value, NumericRange(1, 2))

    def test_valid_decimal(self):
        field = pg_forms.DecimalRangeField()
        value = field.clean(['1.12345', '2.001'])
        self.assertEqual(value, NumericRange(Decimal('1.12345'), Decimal('2.001')))

    def test_valid_timestamps(self):
        field = pg_forms.DateTimeRangeField()
        value = field.clean(['01/01/2014 00:00:00', '02/02/2014 12:12:12'])
        lower = datetime.datetime(2014, 1, 1, 0, 0, 0)
        upper = datetime.datetime(2014, 2, 2, 12, 12, 12)
        self.assertEqual(value, DateTimeTZRange(lower, upper))

    def test_valid_dates(self):
        field = pg_forms.DateRangeField()
        value = field.clean(['01/01/2014', '02/02/2014'])
        lower = datetime.date(2014, 1, 1)
        upper = datetime.date(2014, 2, 2)
        self.assertEqual(value, DateRange(lower, upper))

    def test_using_split_datetime_widget(self):
        class SplitDateTimeRangeField(pg_forms.DateTimeRangeField):
            base_field = forms.SplitDateTimeField

        class SplitForm(forms.Form):
            field = SplitDateTimeRangeField()

        form = SplitForm()
        self.assertHTMLEqual(str(form), '''
            <tr>
                <th>
                <label>Field:</label>
                </th>
                <td>
                    <input id=""id_field_0_0"" name=""field_0_0"" type=""text"">
                    <input id=""id_field_0_1"" name=""field_0_1"" type=""text"">
                    <input id=""id_field_1_0"" name=""field_1_0"" type=""text"">
                    <input id=""id_field_1_1"" name=""field_1_1"" type=""text"">
                </td>
            </tr>
        ''')
        form = SplitForm({
            'field_0_0': '01/01/2014',
            'field_0_1': '00:00:00',
            'field_1_0': '02/02/2014',
            'field_1_1': '12:12:12',
        })
        self.assertTrue(form.is_valid())
        lower = datetime.datetime(2014, 1, 1, 0, 0, 0)
        upper = datetime.datetime(2014, 2, 2, 12, 12, 12)
        self.assertEqual(form.cleaned_data['field'], DateTimeTZRange(lower, upper))

    def test_none(self):
        field = pg_forms.IntegerRangeField(required=False)
        value = field.clean(['', ''])
        self.assertIsNone(value)

    def test_datetime_form_as_table(self):
        class DateTimeRangeForm(forms.Form):
            datetime_field = pg_forms.DateTimeRangeField(show_hidden_initial=True)

        form = DateTimeRangeForm()
        self.assertHTMLEqual(
            form.as_table(),
            """"""
            <tr><th>
            <label>Datetime field:</label>
            </th><td>
            <input type=""text"" name=""datetime_field_0"" id=""id_datetime_field_0"">
            <input type=""text"" name=""datetime_field_1"" id=""id_datetime_field_1"">
            <input type=""hidden"" name=""initial-datetime_field_0"" id=""initial-id_datetime_field_0"">
            <input type=""hidden"" name=""initial-datetime_field_1"" id=""initial-id_datetime_field_1"">
            </td></tr>
            """"""
        )
        form = DateTimeRangeForm({
            'datetime_field_0': '2010-01-01 11:13:00',
            'datetime_field_1': '2020-12-12 16:59:00',
        })
        self.assertHTMLEqual(
            form.as_table(),
            """"""
            <tr><th>
            <label>Datetime field:</label>
            </th><td>
            <input type=""text"" name=""datetime_field_0""
            value=""2010-01-01 11:13:00"" id=""id_datetime_field_0"">
            <input type=""text"" name=""datetime_field_1""
            value=""2020-12-12 16:59:00"" id=""id_datetime_field_1"">
            <input type=""hidden"" name=""initial-datetime_field_0"" value=""2010-01-01 11:13:00""
            id=""initial-id_datetime_field_0"">
            <input type=""hidden"" name=""initial-datetime_field_1"" value=""2020-12-12 16:59:00""
            id=""initial-id_datetime_field_1""></td></tr>
            """"""
        )

    def test_datetime_form_initial_data(self):
        class DateTimeRangeForm(forms.Form):
            datetime_field = pg_forms.DateTimeRangeField(show_hidden_initial=True)

        data = QueryDict(mutable=True)
        data.update({
            'datetime_field_0': '2010-01-01 11:13:00',
            'datetime_field_1': '',
            'initial-datetime_field_0': '2010-01-01 10:12:00',
            'initial-datetime_field_1': '',
        })
        form = DateTimeRangeForm(data=data)
        self.assertTrue(form.has_changed())

        data['initial-datetime_field_0'] = '2010-01-01 11:13:00'
        form = DateTimeRangeForm(data=data)
        self.assertFalse(form.has_changed())

    def test_rendering(self):
        class RangeForm(forms.Form):
            ints = pg_forms.IntegerRangeField()

        self.assertHTMLEqual(str(RangeForm()), '''
        <tr>
            <th><label>Ints:</label></th>
            <td>
                <input id=""id_ints_0"" name=""ints_0"" type=""number"">
                <input id=""id_ints_1"" name=""ints_1"" type=""number"">
            </td>
        </tr>
        ''')

    def test_integer_lower_bound_higher(self):
        field = pg_forms.IntegerRangeField()
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean(['10', '2'])
        self.assertEqual(cm.exception.messages[0], 'The start of the range must not exceed the end of the range.')
        self.assertEqual(cm.exception.code, 'bound_ordering')

    def test_integer_open(self):
        field = pg_forms.IntegerRangeField()
        value = field.clean(['', '0'])
        self.assertEqual(value, NumericRange(None, 0))

    def test_integer_incorrect_data_type(self):
        field = pg_forms.IntegerRangeField()
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean('1')
        self.assertEqual(cm.exception.messages[0], 'Enter two whole numbers.')
        self.assertEqual(cm.exception.code, 'invalid')

    def test_integer_invalid_lower(self):
        field = pg_forms.IntegerRangeField()
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean(['a', '2'])
        self.assertEqual(cm.exception.messages[0], 'Enter a whole number.')

    def test_integer_invalid_upper(self):
        field = pg_forms.IntegerRangeField()
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean(['1', 'b'])
        self.assertEqual(cm.exception.messages[0], 'Enter a whole number.')

    def test_integer_required(self):
        field = pg_forms.IntegerRangeField(required=True)
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean(['', ''])
        self.assertEqual(cm.exception.messages[0], 'This field is required.')
        value = field.clean([1, ''])
        self.assertEqual(value, NumericRange(1, None))

    def test_decimal_lower_bound_higher(self):
        field = pg_forms.DecimalRangeField()
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean(['1.8', '1.6'])
        self.assertEqual(cm.exception.messages[0], 'The start of the range must not exceed the end of the range.')
        self.assertEqual(cm.exception.code, 'bound_ordering')

    def test_decimal_open(self):
        field = pg_forms.DecimalRangeField()
        value = field.clean(['', '3.1415926'])
        self.assertEqual(value, NumericRange(None, Decimal('3.1415926')))

    def test_decimal_incorrect_data_type(self):
        field = pg_forms.DecimalRangeField()
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean('1.6')
        self.assertEqual(cm.exception.messages[0], 'Enter two numbers.')
        self.assertEqual(cm.exception.code, 'invalid')

    def test_decimal_invalid_lower(self):
        field = pg_forms.DecimalRangeField()
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean(['a', '3.1415926'])
        self.assertEqual(cm.exception.messages[0], 'Enter a number.')

    def test_decimal_invalid_upper(self):
        field = pg_forms.DecimalRangeField()
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean(['1.61803399', 'b'])
        self.assertEqual(cm.exception.messages[0], 'Enter a number.')

    def test_decimal_required(self):
        field = pg_forms.DecimalRangeField(required=True)
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean(['', ''])
        self.assertEqual(cm.exception.messages[0], 'This field is required.')
        value = field.clean(['1.61803399', ''])
        self.assertEqual(value, NumericRange(Decimal('1.61803399'), None))

    def test_date_lower_bound_higher(self):
        field = pg_forms.DateRangeField()
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean(['2013-04-09', '1976-04-16'])
        self.assertEqual(cm.exception.messages[0], 'The start of the range must not exceed the end of the range.')
        self.assertEqual(cm.exception.code, 'bound_ordering')

    def test_date_open(self):
        field = pg_forms.DateRangeField()
        value = field.clean(['', '2013-04-09'])
        self.assertEqual(value, DateRange(None, datetime.date(2013, 4, 9)))

    def test_date_incorrect_data_type(self):
        field = pg_forms.DateRangeField()
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean('1')
        self.assertEqual(cm.exception.messages[0], 'Enter two valid dates.')
        self.assertEqual(cm.exception.code, 'invalid')

    def test_date_invalid_lower(self):
        field = pg_forms.DateRangeField()
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean(['a', '2013-04-09'])
        self.assertEqual(cm.exception.messages[0], 'Enter a valid date.')

    def test_date_invalid_upper(self):
        field = pg_forms.DateRangeField()
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean(['2013-04-09', 'b'])
        self.assertEqual(cm.exception.messages[0], 'Enter a valid date.')

    def test_date_required(self):
        field = pg_forms.DateRangeField(required=True)
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean(['', ''])
        self.assertEqual(cm.exception.messages[0], 'This field is required.')
        value = field.clean(['1976-04-16', ''])
        self.assertEqual(value, DateRange(datetime.date(1976, 4, 16), None))

    def test_date_has_changed_first(self):
        self.assertTrue(pg_forms.DateRangeField().has_changed(
            ['2010-01-01', '2020-12-12'],
            ['2010-01-31', '2020-12-12'],
        ))

    def test_date_has_changed_last(self):
        self.assertTrue(pg_forms.DateRangeField().has_changed(
            ['2010-01-01', '2020-12-12'],
            ['2010-01-01', '2020-12-31'],
        ))

    def test_datetime_lower_bound_higher(self):
        field = pg_forms.DateTimeRangeField()
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean(['2006-10-25 14:59', '2006-10-25 14:58'])
        self.assertEqual(cm.exception.messages[0], 'The start of the range must not exceed the end of the range.')
        self.assertEqual(cm.exception.code, 'bound_ordering')

    def test_datetime_open(self):
        field = pg_forms.DateTimeRangeField()
        value = field.clean(['', '2013-04-09 11:45'])
        self.assertEqual(value, DateTimeTZRange(None, datetime.datetime(2013, 4, 9, 11, 45)))

    def test_datetime_incorrect_data_type(self):
        field = pg_forms.DateTimeRangeField()
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean('2013-04-09 11:45')
        self.assertEqual(cm.exception.messages[0], 'Enter two valid date/times.')
        self.assertEqual(cm.exception.code, 'invalid')

    def test_datetime_invalid_lower(self):
        field = pg_forms.DateTimeRangeField()
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean(['45', '2013-04-09 11:45'])
        self.assertEqual(cm.exception.messages[0], 'Enter a valid date/time.')

    def test_datetime_invalid_upper(self):
        field = pg_forms.DateTimeRangeField()
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean(['2013-04-09 11:45', 'sweet pickles'])
        self.assertEqual(cm.exception.messages[0], 'Enter a valid date/time.')

    def test_datetime_required(self):
        field = pg_forms.DateTimeRangeField(required=True)
        with self.assertRaises(exceptions.ValidationError) as cm:
            field.clean(['', ''])
        self.assertEqual(cm.exception.messages[0], 'This field is required.')
        value = field.clean(['2013-04-09 11:45', ''])
        self.assertEqual(value, DateTimeTZRange(datetime.datetime(2013, 4, 9, 11, 45), None))

    @override_settings(USE_TZ=True, TIME_ZONE='Africa/Johannesburg')
    def test_datetime_prepare_value(self):
        field = pg_forms.DateTimeRangeField()
        value = field.prepare_value(
            DateTimeTZRange(datetime.datetime(2015, 5, 22, 16, 6, 33, tzinfo=timezone.utc), None)
        )
        self.assertEqual(value, [datetime.datetime(2015, 5, 22, 18, 6, 33), None])

    def test_datetime_has_changed_first(self):
        self.assertTrue(pg_forms.DateTimeRangeField().has_changed(
            ['2010-01-01 00:00', '2020-12-12 00:00'],
            ['2010-01-31 23:00', '2020-12-12 00:00'],
        ))

    def test_datetime_has_changed_last(self):
        self.assertTrue(pg_forms.DateTimeRangeField().has_changed(
            ['2010-01-01 00:00', '2020-12-12 00:00'],
            ['2010-01-01 00:00', '2020-12-31 23:00'],
        ))

    def test_model_field_formfield_integer(self):
        model_field = pg_fields.IntegerRangeField()
        form_field = model_field.formfield()
        self.assertIsInstance(form_field, pg_forms.IntegerRangeField)
        self.assertEqual(form_field.range_kwargs, {})

    def test_model_field_formfield_biginteger(self):
        model_field = pg_fields.BigIntegerRangeField()
        form_field = model_field.formfield()
        self.assertIsInstance(form_field, pg_forms.IntegerRangeField)
        self.assertEqual(form_field.range_kwargs, {})

    def test_model_field_formfield_float(self):
        model_field = pg_fields.DecimalRangeField(default_bounds='()')
        form_field = model_field.formfield()
        self.assertIsInstance(form_field, pg_forms.DecimalRangeField)
        self.assertEqual(form_field.range_kwargs, {'bounds': '()'})

    def test_model_field_formfield_date(self):
        model_field = pg_fields.DateRangeField()
        form_field = model_field.formfield()
        self.assertIsInstance(form_field, pg_forms.DateRangeField)
        self.assertEqual(form_field.range_kwargs, {})

    def test_model_field_formfield_datetime(self):
        model_field = pg_fields.DateTimeRangeField()
        form_field = model_field.formfield()
        self.assertIsInstance(form_field, pg_forms.DateTimeRangeField)
        self.assertEqual(
            form_field.range_kwargs,
            {'bounds': pg_fields.ranges.CANONICAL_RANGE_BOUNDS},
        )

    def test_model_field_formfield_datetime_default_bounds(self):
        model_field = pg_fields.DateTimeRangeField(default_bounds='[]')
        form_field = model_field.formfield()
        self.assertIsInstance(form_field, pg_forms.DateTimeRangeField)
        self.assertEqual(form_field.range_kwargs, {'bounds': '[]'})

    def test_model_field_with_default_bounds(self):
        field = pg_forms.DateTimeRangeField(default_bounds='[]')
        value = field.clean(['2014-01-01 00:00:00', '2014-02-03 12:13:14'])
        lower = datetime.datetime(2014, 1, 1, 0, 0, 0)
        upper = datetime.datetime(2014, 2, 3, 12, 13, 14)
        self.assertEqual(value, DateTimeTZRange(lower, upper, '[]'))

    def test_has_changed(self):
        for field, value in (
            (pg_forms.DateRangeField(), ['2010-01-01', '2020-12-12']),
            (pg_forms.DateTimeRangeField(), ['2010-01-01 11:13', '2020-12-12 14:52']),
            (pg_forms.IntegerRangeField(), [1, 2]),
            (pg_forms.DecimalRangeField(), ['1.12345', '2.001']),
        ):
            with self.subTest(field=field.__class__.__name__):
                self.assertTrue(field.has_changed(None, value))
                self.assertTrue(field.has_changed([value[0], ''], value))
                self.assertTrue(field.has_changed(['', value[1]], value))
                self.assertFalse(field.has_changed(value, value))",1,587 2000 40 2001 41 58 612 2002 40 2003 41 58 2004 61 2005 46 2006 40 41 2007 61 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2007 44 2010 40 1501 44 1502 41 41 612 2011 40 2003 41 58 2004 61 2005 46 2012 40 41 2007 61 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2007 44 2010 40 2013 40 362 41 44 2013 40 362 41 41 41 612 2014 40 2003 41 58 2004 61 2005 46 2015 40 41 2007 61 2004 46 2008 40 91 362 44 362 93 41 2016 61 2017 46 2017 40 1505 44 1501 44 1501 44 1500 44 1500 44 1500 41 2018 61 2017 46 2017 40 1505 44 1502 44 1502 44 1503 44 1503 44 1503 41 2003 46 2009 40 2007 44 2019 40 2016 44 2018 41 41 612 2020 40 2003 41 58 2004 61 2005 46 2021 40 41 2007 61 2004 46 2008 40 91 362 44 362 93 41 2016 61 2017 46 2022 40 1505 44 1501 44 1501 41 2018 61 2017 46 2022 40 1505 44 1502 44 1502 41 2003 46 2009 40 2007 44 2023 40 2016 44 2018 41 41 612 2024 40 2003 41 58 587 2025 40 2005 46 2015 41 58 2026 61 2027 46 2028 587 2029 40 2027 46 2030 41 58 2004 61 2025 40 41 2031 61 2029 40 41 2003 46 2032 40 813 40 2031 41 44 362 41 2031 61 2029 40 123 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 125 41 2003 46 2033 40 2031 46 2034 40 41 41 2016 61 2017 46 2017 40 1505 44 1501 44 1501 44 1500 44 1500 44 1500 41 2018 61 2017 46 2017 40 1505 44 1502 44 1502 44 1503 44 1503 44 1503 41 2003 46 2009 40 2031 46 2035 91 362 93 44 2019 40 2016 44 2018 41 41 612 2036 40 2003 41 58 2004 61 2005 46 2006 40 2037 61 443 41 2007 61 2004 46 2008 40 91 362 44 362 93 41 2003 46 2038 40 2007 41 612 2039 40 2003 41 58 587 2040 40 2027 46 2030 41 58 2041 61 2005 46 2015 40 2042 61 515 41 2031 61 2040 40 41 2003 46 2032 40 2031 46 2043 40 41 44 362 41 2031 61 2040 40 123 362 58 362 44 362 58 362 44 125 41 2003 46 2032 40 2031 46 2043 40 41 44 362 41 612 2044 40 2003 41 58 587 2040 40 2027 46 2030 41 58 2041 61 2005 46 2015 40 2042 61 515 41 2045 61 2046 40 2047 61 515 41 2045 46 2048 40 123 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 125 41 2031 61 2040 40 2045 61 2045 41 2003 46 2033 40 2031 46 2049 40 41 41 2045 91 362 93 61 362 2031 61 2040 40 2045 61 2045 41 2003 46 2050 40 2031 46 2049 40 41 41 612 2051 40 2003 41 58 587 2052 40 2027 46 2030 41 58 2053 61 2005 46 2006 40 41 2003 46 2032 40 813 40 2052 40 41 41 44 362 41 612 2054 40 2003 41 58 2004 61 2005 46 2006 40 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 2003 46 2009 40 2058 46 2059 46 2061 44 362 41 612 2062 40 2003 41 58 2004 61 2005 46 2006 40 41 2007 61 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2007 44 2010 40 470 44 1500 41 41 612 2063 40 2003 41 58 2004 61 2005 46 2006 40 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 362 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 2003 46 2009 40 2058 46 2059 46 2061 44 362 41 612 2064 40 2003 41 58 2004 61 2005 46 2006 40 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 612 2065 40 2003 41 58 2004 61 2005 46 2006 40 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 612 2066 40 2003 41 58 2004 61 2005 46 2006 40 2037 61 515 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 2007 61 2004 46 2008 40 91 1501 44 362 93 41 2003 46 2009 40 2007 44 2010 40 1501 44 470 41 41 612 2067 40 2003 41 58 2004 61 2005 46 2012 40 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 2003 46 2009 40 2058 46 2059 46 2061 44 362 41 612 2068 40 2003 41 58 2004 61 2005 46 2012 40 41 2007 61 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2007 44 2010 40 470 44 2013 40 362 41 41 41 612 2069 40 2003 41 58 2004 61 2005 46 2012 40 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 362 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 2003 46 2009 40 2058 46 2059 46 2061 44 362 41 612 2070 40 2003 41 58 2004 61 2005 46 2012 40 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 612 2071 40 2003 41 58 2004 61 2005 46 2012 40 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 612 2072 40 2003 41 58 2004 61 2005 46 2012 40 2037 61 515 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 2007 61 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2007 44 2010 40 2013 40 362 41 44 470 41 41 612 2073 40 2003 41 58 2004 61 2005 46 2021 40 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 2003 46 2009 40 2058 46 2059 46 2061 44 362 41 612 2074 40 2003 41 58 2004 61 2005 46 2021 40 41 2007 61 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2007 44 2023 40 470 44 2017 46 2022 40 1505 44 1502 44 1502 41 41 41 612 2075 40 2003 41 58 2004 61 2005 46 2021 40 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 362 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 2003 46 2009 40 2058 46 2059 46 2061 44 362 41 612 2076 40 2003 41 58 2004 61 2005 46 2021 40 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 612 2077 40 2003 41 58 2004 61 2005 46 2021 40 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 612 2078 40 2003 41 58 2004 61 2005 46 2021 40 2037 61 515 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 2007 61 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2007 44 2023 40 2017 46 2022 40 1505 44 1502 44 1503 41 44 470 41 41 612 2079 40 2003 41 58 2003 46 2033 40 2005 46 2021 40 41 46 2049 40 91 362 44 362 93 44 91 362 44 362 93 44 41 41 612 2080 40 2003 41 58 2003 46 2033 40 2005 46 2021 40 41 46 2049 40 91 362 44 362 93 44 91 362 44 362 93 44 41 41 612 2081 40 2003 41 58 2004 61 2005 46 2015 40 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 2003 46 2009 40 2058 46 2059 46 2061 44 362 41 612 2082 40 2003 41 58 2004 61 2005 46 2015 40 41 2007 61 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2007 44 2019 40 470 44 2017 46 2017 40 1505 44 1502 44 1502 44 1503 44 1503 41 41 41 612 2083 40 2003 41 58 2004 61 2005 46 2015 40 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 362 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 2003 46 2009 40 2058 46 2059 46 2061 44 362 41 612 2084 40 2003 41 58 2004 61 2005 46 2015 40 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 612 2085 40 2003 41 58 2004 61 2005 46 2015 40 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 612 2086 40 2003 41 58 2004 61 2005 46 2015 40 2037 61 515 41 871 2003 46 2055 40 2056 46 2057 41 552 2058 58 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2058 46 2059 46 2060 91 1500 93 44 362 41 2007 61 2004 46 2008 40 91 362 44 362 93 41 2003 46 2009 40 2007 44 2019 40 2017 46 2017 40 1505 44 1502 44 1502 44 1503 44 1503 41 44 470 41 41 64 2087 40 2088 61 515 44 2089 61 362 41 612 2090 40 2003 41 58 2004 61 2005 46 2015 40 41 2007 61 2004 46 2091 40 2019 40 2017 46 2017 40 1505 44 1502 44 1503 44 1503 44 1502 44 1503 44 2092 61 2093 46 2094 41 44 470 41 41 2003 46 2009 40 2007 44 91 2017 46 2017 40 1505 44 1502 44 1503 44 1503 44 1502 44 1503 41 44 470 93 41 612 2095 40 2003 41 58 2003 46 2033 40 2005 46 2015 40 41 46 2049 40 91 362 44 362 93 44 91 362 44 362 93 44 41 41 612 2096 40 2003 41 58 2003 46 2033 40 2005 46 2015 40 41 46 2049 40 91 362 44 362 93 44 91 362 44 362 93 44 41 41 612 2097 40 2003 41 58 2098 61 2099 46 2006 40 41 2100 61 2098 46 2101 40 41 2003 46 2102 40 2100 44 2005 46 2006 41 2003 46 2009 40 2100 46 2103 44 123 125 41 612 2104 40 2003 41 58 2098 61 2099 46 2105 40 41 2100 61 2098 46 2101 40 41 2003 46 2102 40 2100 44 2005 46 2006 41 2003 46 2009 40 2100 46 2103 44 123 125 41 612 2106 40 2003 41 58 2098 61 2099 46 2012 40 2107 61 362 41 2100 61 2098 46 2101 40 41 2003 46 2102 40 2100 44 2005 46 2012 41 2003 46 2009 40 2100 46 2103 44 123 362 58 362 125 41 612 2108 40 2003 41 58 2098 61 2099 46 2021 40 41 2100 61 2098 46 2101 40 41 2003 46 2102 40 2100 44 2005 46 2021 41 2003 46 2009 40 2100 46 2103 44 123 125 41 612 2109 40 2003 41 58 2098 61 2099 46 2015 40 41 2100 61 2098 46 2101 40 41 2003 46 2102 40 2100 44 2005 46 2015 41 2003 46 2009 40 2100 46 2103 44 123 362 58 2099 46 2110 46 2111 125 44 41 612 2112 40 2003 41 58 2098 61 2099 46 2015 40 2107 61 362 41 2100 61 2098 46 2101 40 41 2003 46 2102 40 2100 44 2005 46 2015 41 2003 46 2009 40 2100 46 2103 44 123 362 58 362 125 41 612 2113 40 2003 41 58 2004 61 2005 46 2015 40 2107 61 362 41 2007 61 2004 46 2008 40 91 362 44 362 93 41 2016 61 2017 46 2017 40 1505 44 1501 44 1501 44 1500 44 1500 44 1500 41 2018 61 2017 46 2017 40 1505 44 1502 44 1502 44 1503 44 1503 44 1503 41 2003 46 2009 40 2007 44 2019 40 2016 44 2018 44 362 41 41 612 2114 40 2003 41 58 664 2004 44 2007 696 40 40 2005 46 2021 40 41 44 91 362 44 362 93 41 44 40 2005 46 2015 40 41 44 91 362 44 362 93 41 44 40 2005 46 2006 40 41 44 91 1501 44 1502 93 41 44 40 2005 46 2012 40 41 44 91 362 44 362 93 41 44 41 58 871 2003 46 2115 40 2004 61 2004 46 2116 46 2117 41 58 2003 46 2033 40 2004 46 2049 40 470 44 2007 41 41 2003 46 2033 40 2004 46 2049 40 91 2007 91 1500 93 44 362 93 44 2007 41 41 2003 46 2033 40 2004 46 2049 40 91 362 44 2007 91 1501 93 93 44 2007 41 41 2003 46 2050 40 2004 46 2049 40 2007 44 2007 41 41 ,"{'AvgLine': 7, 'CountLine': 380, 'CountStmt': 245, 'MaxNesting': 2, 'AvgLineCode': 7, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 193, 'MaxEssential': 1, 'SumEssential': 46, 'AvgCyclomatic': 1, 'CountLineCode': 328, 'CountStmtDecl': 128, 'MaxCyclomatic': 2, 'SumCyclomatic': 47, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 52, 'CountDeclMethod': 46, 'CountLineCodeExe': 275, 'CountLineComment': 0, 'CountClassCoupled': 9, 'CountClassDerived': 0, 'CountLineCodeDecl': 149, 'CountDeclMethodAll': 81, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '0.00', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 2, 'SumCyclomaticStrict': 47, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 2, 'SumCyclomaticModified': 47, 'CountDeclInstanceMethod': 46, 'CountClassCoupledModified': 6, 'CountDeclInstanceVariable': 0}"
124262,Python,"class PubSubHook(GoogleBaseHook):
    """"""
    Hook for accessing Google Pub/Sub.

    The Google Cloud project against which actions are applied is determined by
    the project embedded in the Connection referenced by gcp_conn_id.
    """"""

    def __init__(
        self,
        gcp_conn_id: str = ""google_cloud_default"",
        delegate_to: Optional[str] = None,
        impersonation_chain: Optional[Union[str, Sequence[str]]] = None,
    ) -> None:
        super().__init__(
            gcp_conn_id=gcp_conn_id,
            delegate_to=delegate_to,
            impersonation_chain=impersonation_chain,
        )
        self._client = None

    def get_conn(self) -> PublisherClient:
        """"""
        Retrieves connection to Google Cloud Pub/Sub.

        :return: Google Cloud Pub/Sub client object.
        :rtype: google.cloud.pubsub_v1.PublisherClient
        """"""
        if not self._client:
            self._client = PublisherClient(credentials=self._get_credentials(), client_info=self.client_info)
        return self._client

    @cached_property
    def subscriber_client(self) -> SubscriberClient:
        """"""
        Creates SubscriberClient.

        :return: Google Cloud Pub/Sub client object.
        :rtype: google.cloud.pubsub_v1.SubscriberClient
        """"""
        return SubscriberClient(credentials=self._get_credentials(), client_info=self.client_info)

    @GoogleBaseHook.fallback_to_default_project_id
    def publish(
        self,
        topic: str,
        messages: List[dict],
        project_id: str = PROVIDE_PROJECT_ID,
    ) -> None:
        """"""
        Publishes messages to a Pub/Sub topic.

        :param topic: the Pub/Sub topic to which to publish; do not
            include the ``projects/{project}/topics/`` prefix.
        :type topic: str
        :param messages: messages to publish; if the data field in a
            message is set, it should be a bytestring (utf-8 encoded)
        :type messages: list of PubSub messages; see
            http://cloud.google.com/pubsub/docs/reference/rest/v1/PubsubMessage
        :param project_id: Optional, the Google Cloud project ID in which to publish.
            If set to None or missing, the default project_id from the Google Cloud connection is used.
        :type project_id: str
        """"""
        self._validate_messages(messages)

        publisher = self.get_conn()
        topic_path = f""projects/{project_id}/topics/{topic}""

        self.log.info(""Publish %d messages to topic (path) %s"", len(messages), topic_path)
        try:
            for message in messages:
                future = publisher.publish(
                    topic=topic_path, data=message.get(""data"", b''), **message.get('attributes', {})
                )
                future.result()
        except GoogleAPICallError as e:
            raise PubSubException(f'Error publishing to topic {topic_path}', e)

        self.log.info(""Published %d messages to topic (path) %s"", len(messages), topic_path)

    @staticmethod
    def _validate_messages(messages) -> None:
        for message in messages:
            # To warn about broken backward compatibility
            # TODO: remove one day
            if ""data"" in message and isinstance(message[""data""], str):
                try:
                    b64decode(message[""data""])
                    warnings.warn(
                        ""The base 64 encoded string as 'data' field has been deprecated. ""
                        ""You should pass bytestring (utf-8 encoded)."",
                        DeprecationWarning,
                        stacklevel=4,
                    )
                except ValueError:
                    pass

            if not isinstance(message, dict):
                raise PubSubException(""Wrong message type. Must be a dictionary."")
            if ""data"" not in message and ""attributes"" not in message:
                raise PubSubException(""Wrong message. Dictionary must contain 'data' or 'attributes'."")
            if ""data"" in message and not isinstance(message[""data""], bytes):
                raise PubSubException(""Wrong message. 'data' must be send as a bytestring"")
            if (""data"" not in message and ""attributes"" in message and not message[""attributes""]) or (
                ""attributes"" in message and not isinstance(message[""attributes""], dict)
            ):
                raise PubSubException(
                    ""Wrong message. If 'data' is not provided 'attributes' must be a non empty dictionary.""
                )

    @GoogleBaseHook.fallback_to_default_project_id
    def create_topic(
        self,
        topic: str,
        project_id: str = PROVIDE_PROJECT_ID,
        fail_if_exists: bool = False,
        labels: Optional[Dict[str, str]] = None,
        message_storage_policy: Union[Dict, MessageStoragePolicy] = None,
        kms_key_name: Optional[str] = None,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> None:
        """"""
        Creates a Pub/Sub topic, if it does not already exist.

        :param topic: the Pub/Sub topic name to create; do not
            include the ``projects/{project}/topics/`` prefix.
        :type topic: str
        :param project_id: Optional, the Google Cloud project ID in which to create the topic
            If set to None or missing, the default project_id from the Google Cloud connection is used.
        :type project_id: str
        :param fail_if_exists: if set, raise an exception if the topic
            already exists
        :type fail_if_exists: bool
        :param labels: Client-assigned labels; see
            https://cloud.google.com/pubsub/docs/labels
        :type labels: Dict[str, str]
        :param message_storage_policy: Policy constraining the set
            of Google Cloud regions where messages published to
            the topic may be stored. If not present, then no constraints
            are in effect.
        :type message_storage_policy:
            Union[Dict, google.cloud.pubsub_v1.types.MessageStoragePolicy]
        :param kms_key_name: The resource name of the Cloud KMS CryptoKey
            to be used to protect access to messages published on this topic.
            The expected format is
            ``projects/*/locations/*/keyRings/*/cryptoKeys/*``.
        :type kms_key_name: str
        :param retry: (Optional) A retry object used to retry requests.
            If None is specified, requests will not be retried.
        :type retry: google.api_core.retry.Retry
        :param timeout: (Optional) The amount of time, in seconds, to wait for the request
            to complete. Note that if retry is specified, the timeout applies to each
            individual attempt.
        :type timeout: float
        :param metadata: (Optional) Additional metadata that is provided to the method.
        :type metadata: Sequence[Tuple[str, str]]]
        """"""
        publisher = self.get_conn()
        topic_path = f""projects/{project_id}/topics/{topic}""

        # Add airflow-version label to the topic
        labels = labels or {}
        labels['airflow-version'] = 'v' + version.replace('.', '-').replace('+', '-')

        self.log.info(""Creating topic (path) %s"", topic_path)
        try:

            publisher.create_topic(
                request={
                    ""name"": topic_path,
                    ""labels"": labels,
                    ""message_storage_policy"": message_storage_policy,
                    ""kms_key_name"": kms_key_name,
                },
                retry=retry,
                timeout=timeout,
                metadata=metadata,
            )
        except AlreadyExists:
            self.log.warning('Topic already exists: %s', topic)
            if fail_if_exists:
                raise PubSubException(f'Topic already exists: {topic}')
        except GoogleAPICallError as e:
            raise PubSubException(f'Error creating topic {topic}', e)

        self.log.info(""Created topic (path) %s"", topic_path)

    @GoogleBaseHook.fallback_to_default_project_id
    def delete_topic(
        self,
        topic: str,
        project_id: str = PROVIDE_PROJECT_ID,
        fail_if_not_exists: bool = False,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> None:
        """"""
        Deletes a Pub/Sub topic if it exists.

        :param topic: the Pub/Sub topic name to delete; do not
            include the ``projects/{project}/topics/`` prefix.
        :type topic: str
        :param project_id: Optional, the Google Cloud project ID in which to delete the topic.
            If set to None or missing, the default project_id from the Google Cloud connection is used.
        :type project_id: str
        :param fail_if_not_exists: if set, raise an exception if the topic
            does not exist
        :type fail_if_not_exists: bool
        :param retry: (Optional) A retry object used to retry requests.
            If None is specified, requests will not be retried.
        :type retry: google.api_core.retry.Retry
        :param timeout: (Optional) The amount of time, in seconds, to wait for the request
            to complete. Note that if retry is specified, the timeout applies to each
            individual attempt.
        :type timeout: float
        :param metadata: (Optional) Additional metadata that is provided to the method.
        :type metadata: Sequence[Tuple[str, str]]]
        """"""
        publisher = self.get_conn()
        topic_path = f""projects/{project_id}/topics/{topic}""

        self.log.info(""Deleting topic (path) %s"", topic_path)
        try:

            publisher.delete_topic(
                request={""topic"": topic_path}, retry=retry, timeout=timeout, metadata=metadata or ()
            )
        except NotFound:
            self.log.warning('Topic does not exist: %s', topic_path)
            if fail_if_not_exists:
                raise PubSubException(f'Topic does not exist: {topic_path}')
        except GoogleAPICallError as e:
            raise PubSubException(f'Error deleting topic {topic}', e)
        self.log.info(""Deleted topic (path) %s"", topic_path)

    @GoogleBaseHook.fallback_to_default_project_id
    def create_subscription(
        self,
        topic: str,
        project_id: str = PROVIDE_PROJECT_ID,
        subscription: Optional[str] = None,
        subscription_project_id: Optional[str] = None,
        ack_deadline_secs: int = 10,
        fail_if_exists: bool = False,
        push_config: Optional[Union[dict, PushConfig]] = None,
        retain_acked_messages: Optional[bool] = None,
        message_retention_duration: Optional[Union[dict, Duration]] = None,
        labels: Optional[Dict[str, str]] = None,
        enable_message_ordering: bool = False,
        expiration_policy: Optional[Union[dict, ExpirationPolicy]] = None,
        filter_: Optional[str] = None,
        dead_letter_policy: Optional[Union[dict, DeadLetterPolicy]] = None,
        retry_policy: Optional[Union[dict, RetryPolicy]] = None,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> str:
        """"""
        Creates a Pub/Sub subscription, if it does not already exist.

        :param topic: the Pub/Sub topic name that the subscription will be bound
            to create; do not include the ``projects/{project}/subscriptions/`` prefix.
        :type topic: str
        :param project_id: Optional, the Google Cloud project ID of the topic that the subscription will be
            bound to. If set to None or missing, the default project_id from the Google Cloud connection
            is used.
        :type project_id: str
        :param subscription: the Pub/Sub subscription name. If empty, a random
            name will be generated using the uuid module
        :type subscription: str
        :param subscription_project_id: the Google Cloud project ID where the subscription
            will be created. If unspecified, ``project_id`` will be used.
        :type subscription_project_id: str
        :param ack_deadline_secs: Number of seconds that a subscriber has to
            acknowledge each message pulled from the subscription
        :type ack_deadline_secs: int
        :param fail_if_exists: if set, raise an exception if the topic
            already exists
        :type fail_if_exists: bool
        :param push_config: If push delivery is used with this subscription,
            this field is used to configure it. An empty ``pushConfig`` signifies
            that the subscriber will pull and ack messages using API methods.
        :type push_config: Union[Dict, google.cloud.pubsub_v1.types.PushConfig]
        :param retain_acked_messages: Indicates whether to retain acknowledged
            messages. If true, then messages are not expunged from the subscription's
            backlog, even if they are acknowledged, until they fall out of the
            ``message_retention_duration`` window. This must be true if you would
            like to Seek to a timestamp.
        :type retain_acked_messages: bool
        :param message_retention_duration: How long to retain unacknowledged messages
            in the subscription's backlog, from the moment a message is published. If
            ``retain_acked_messages`` is true, then this also configures the
            retention of acknowledged messages, and thus configures how far back in
            time a ``Seek`` can be done. Defaults to 7 days. Cannot be more than 7
            days or less than 10 minutes.
        :type message_retention_duration: Union[Dict, google.cloud.pubsub_v1.types.Duration]
        :param labels: Client-assigned labels; see
            https://cloud.google.com/pubsub/docs/labels
        :type labels: Dict[str, str]
        :param enable_message_ordering: If true, messages published with the same
            ordering_key in PubsubMessage will be delivered to the subscribers in the order
            in which they are received by the Pub/Sub system. Otherwise, they may be
            delivered in any order.
        :type enable_message_ordering: bool
        :param expiration_policy: A policy that specifies the conditions for this
            subscription’s expiration. A subscription is considered active as long as any
            connected subscriber is successfully consuming messages from the subscription or
            is issuing operations on the subscription. If expiration_policy is not set,
            a default policy with ttl of 31 days will be used. The minimum allowed value for
            expiration_policy.ttl is 1 day.
        :type expiration_policy: Union[Dict, google.cloud.pubsub_v1.types.ExpirationPolicy`]
        :param filter_: An expression written in the Cloud Pub/Sub filter language. If
            non-empty, then only PubsubMessages whose attributes field matches the filter are
            delivered on this subscription. If empty, then no messages are filtered out.
        :type filter_: str
        :param dead_letter_policy: A policy that specifies the conditions for dead lettering
            messages in this subscription. If dead_letter_policy is not set, dead lettering is
            disabled.
        :type dead_letter_policy: Union[Dict, google.cloud.pubsub_v1.types.DeadLetterPolicy]
        :param retry_policy: A policy that specifies how Pub/Sub retries message delivery
            for this subscription. If not set, the default retry policy is applied. This
            generally implies that messages will be retried as soon as possible for healthy
            subscribers. RetryPolicy will be triggered on NACKs or acknowledgement deadline
            exceeded events for a given message.
        :type retry_policy: Union[Dict, google.cloud.pubsub_v1.types.RetryPolicy]
        :param retry: (Optional) A retry object used to retry requests.
            If None is specified, requests will not be retried.
        :type retry: google.api_core.retry.Retry
        :param timeout: (Optional) The amount of time, in seconds, to wait for the request
            to complete. Note that if retry is specified, the timeout applies to each
            individual attempt.
        :type timeout: float
        :param metadata: (Optional) Additional metadata that is provided to the method.
        :type metadata: Sequence[Tuple[str, str]]]
        :return: subscription name which will be the system-generated value if
            the ``subscription`` parameter is not supplied
        :rtype: str
        """"""
        subscriber = self.subscriber_client

        if not subscription:
            subscription = f'sub-{uuid4()}'
        if not subscription_project_id:
            subscription_project_id = project_id

        # Add airflow-version label to the subscription
        labels = labels or {}
        labels['airflow-version'] = 'v' + version.replace('.', '-').replace('+', '-')

        subscription_path = f""projects/{subscription_project_id}/subscriptions/{subscription}""
        topic_path = f""projects/{project_id}/topics/{topic}""

        self.log.info(""Creating subscription (path) %s for topic (path) %a"", subscription_path, topic_path)
        try:
            subscriber.create_subscription(
                request={
                    ""name"": subscription_path,
                    ""topic"": topic_path,
                    ""push_config"": push_config,
                    ""ack_deadline_seconds"": ack_deadline_secs,
                    ""retain_acked_messages"": retain_acked_messages,
                    ""message_retention_duration"": message_retention_duration,
                    ""labels"": labels,
                    ""enable_message_ordering"": enable_message_ordering,
                    ""expiration_policy"": expiration_policy,
                    ""filter"": filter_,
                    ""dead_letter_policy"": dead_letter_policy,
                    ""retry_policy"": retry_policy,
                },
                retry=retry,
                timeout=timeout,
                metadata=metadata,
            )
        except AlreadyExists:
            self.log.warning('Subscription already exists: %s', subscription_path)
            if fail_if_exists:
                raise PubSubException(f'Subscription already exists: {subscription_path}')
        except GoogleAPICallError as e:
            raise PubSubException(f'Error creating subscription {subscription_path}', e)

        self.log.info(""Created subscription (path) %s for topic (path) %s"", subscription_path, topic_path)
        return subscription

    @GoogleBaseHook.fallback_to_default_project_id
    def delete_subscription(
        self,
        subscription: str,
        project_id: str = PROVIDE_PROJECT_ID,
        fail_if_not_exists: bool = False,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> None:
        """"""
        Deletes a Pub/Sub subscription, if it exists.

        :param subscription: the Pub/Sub subscription name to delete; do not
            include the ``projects/{project}/subscriptions/`` prefix.
        :param project_id: Optional, the Google Cloud project ID where the subscription exists
            If set to None or missing, the default project_id from the Google Cloud connection is used.
        :type project_id: str
        :type subscription: str
        :param fail_if_not_exists: if set, raise an exception if the topic does not exist
        :type fail_if_not_exists: bool
        :param retry: (Optional) A retry object used to retry requests.
            If None is specified, requests will not be retried.
        :type retry: google.api_core.retry.Retry
        :param timeout: (Optional) The amount of time, in seconds, to wait for the request
            to complete. Note that if retry is specified, the timeout applies to each
            individual attempt.
        :type timeout: float
        :param metadata: (Optional) Additional metadata that is provided to the method.
        :type metadata: Sequence[Tuple[str, str]]]
        """"""
        subscriber = self.subscriber_client
        # E501
        subscription_path = f""projects/{project_id}/subscriptions/{subscription}""

        self.log.info(""Deleting subscription (path) %s"", subscription_path)
        try:

            subscriber.delete_subscription(
                request={""subscription"": subscription_path},
                retry=retry,
                timeout=timeout,
                metadata=metadata,
            )

        except NotFound:
            self.log.warning('Subscription does not exist: %s', subscription_path)
            if fail_if_not_exists:
                raise PubSubException(f'Subscription does not exist: {subscription_path}')
        except GoogleAPICallError as e:
            raise PubSubException(f'Error deleting subscription {subscription_path}', e)

        self.log.info(""Deleted subscription (path) %s"", subscription_path)

    @GoogleBaseHook.fallback_to_default_project_id
    def pull(
        self,
        subscription: str,
        max_messages: int,
        project_id: str = PROVIDE_PROJECT_ID,
        return_immediately: bool = False,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> List[ReceivedMessage]:
        """"""
        Pulls up to ``max_messages`` messages from Pub/Sub subscription.

        :param subscription: the Pub/Sub subscription name to pull from; do not
            include the 'projects/{project}/topics/' prefix.
        :type subscription: str
        :param max_messages: The maximum number of messages to return from
            the Pub/Sub API.
        :type max_messages: int
        :param project_id: Optional, the Google Cloud project ID where the subscription exists.
            If set to None or missing, the default project_id from the Google Cloud connection is used.
        :type project_id: str
        :param return_immediately: If set, the Pub/Sub API will immediately
            return if no messages are available. Otherwise, the request will
            block for an undisclosed, but bounded period of time
        :type return_immediately: bool
        :param retry: (Optional) A retry object used to retry requests.
            If None is specified, requests will not be retried.
        :type retry: google.api_core.retry.Retry
        :param timeout: (Optional) The amount of time, in seconds, to wait for the request
            to complete. Note that if retry is specified, the timeout applies to each
            individual attempt.
        :type timeout: float
        :param metadata: (Optional) Additional metadata that is provided to the method.
        :type metadata: Sequence[Tuple[str, str]]]
        :return: A list of Pub/Sub ReceivedMessage objects each containing
            an ``ackId`` property and a ``message`` property, which includes
            the base64-encoded message content. See
            https://cloud.google.com/pubsub/docs/reference/rest/v1/projects.subscriptions/pull#ReceivedMessage
        """"""
        subscriber = self.subscriber_client
        # E501
        subscription_path = f""projects/{project_id}/subscriptions/{subscription}""

        self.log.info(""Pulling max %d messages from subscription (path) %s"", max_messages, subscription_path)
        try:

            response = subscriber.pull(
                request={
                    ""subscription"": subscription_path,
                    ""max_messages"": max_messages,
                    ""return_immediately"": return_immediately,
                },
                retry=retry,
                timeout=timeout,
                metadata=metadata,
            )
            result = getattr(response, 'received_messages', [])
            self.log.info(""Pulled %d messages from subscription (path) %s"", len(result), subscription_path)
            return result
        except (HttpError, GoogleAPICallError) as e:
            raise PubSubException(f'Error pulling messages from subscription {subscription_path}', e)

    @GoogleBaseHook.fallback_to_default_project_id
    def acknowledge(
        self,
        subscription: str,
        project_id: str,
        ack_ids: Optional[List[str]] = None,
        messages: Optional[List[ReceivedMessage]] = None,
        retry: Optional[Retry] = None,
        timeout: Optional[float] = None,
        metadata: Sequence[Tuple[str, str]] = (),
    ) -> None:
        """"""
        Acknowledges the messages associated with the ``ack_ids`` from Pub/Sub subscription.

        :param subscription: the Pub/Sub subscription name to delete; do not
            include the 'projects/{project}/topics/' prefix.
        :type subscription: str
        :param ack_ids: List of ReceivedMessage ackIds from a previous pull response.
            Mutually exclusive with ``messages`` argument.
        :type ack_ids: list
        :param messages: List of ReceivedMessage objects to acknowledge.
            Mutually exclusive with ``ack_ids`` argument.
        :type messages: list
        :param project_id: Optional, the Google Cloud project name or ID in which to create the topic
            If set to None or missing, the default project_id from the Google Cloud connection is used.
        :type project_id: str
        :param retry: (Optional) A retry object used to retry requests.
            If None is specified, requests will not be retried.
        :type retry: google.api_core.retry.Retry
        :param timeout: (Optional) The amount of time, in seconds, to wait for the request
            to complete. Note that if retry is specified, the timeout applies to each
            individual attempt.
        :type timeout: float
        :param metadata: (Optional) Additional metadata that is provided to the method.
        :type metadata: Sequence[Tuple[str, str]]]
        """"""
        if ack_ids is not None and messages is None:
            pass
        elif ack_ids is None and messages is not None:
            ack_ids = [message.ack_id for message in messages]
        else:
            raise ValueError(""One and only one of 'ack_ids' and 'messages' arguments have to be provided"")

        subscriber = self.subscriber_client
        # E501
        subscription_path = f""projects/{project_id}/subscriptions/{subscription}""

        self.log.info(""Acknowledging %d ack_ids from subscription (path) %s"", len(ack_ids), subscription_path)
        try:

            subscriber.acknowledge(
                request={""subscription"": subscription_path, ""ack_ids"": ack_ids},
                retry=retry,
                timeout=timeout,
                metadata=metadata,
            )
        except (HttpError, GoogleAPICallError) as e:
            raise PubSubException(
                f'Error acknowledging {len(ack_ids)} messages pulled from subscription {subscription_path}',
                e,
            )

        self.log.info(""Acknowledged ack_ids from subscription (path) %s"", subscription_path)",1,587 2000 40 2001 41 58 362 612 2002 40 2003 44 2004 58 813 61 362 44 2005 58 2006 91 813 93 61 470 44 2007 58 2006 91 2008 91 813 44 2009 91 813 93 93 93 61 470 44 41 354 470 58 818 40 41 46 2002 40 2004 61 2004 44 2005 61 2005 44 2007 61 2007 44 41 2003 46 2010 61 470 612 2011 40 2003 41 354 2012 58 362 688 750 2003 46 2010 58 2003 46 2010 61 2012 40 2013 61 2003 46 2014 40 41 44 2015 61 2003 46 2015 41 792 2003 46 2010 64 2016 612 2017 40 2003 41 354 2018 58 362 792 2018 40 2013 61 2003 46 2014 40 41 44 2015 61 2003 46 2015 41 64 2001 46 2019 612 2020 40 2003 44 2021 58 813 44 2022 58 2023 91 620 93 44 2024 58 813 61 2025 44 41 354 470 58 362 2003 46 2026 40 2022 41 2027 61 2003 46 2011 40 41 2028 61 362 2003 46 2029 46 2030 40 362 44 720 40 2022 41 44 2028 41 830 58 664 2031 696 2022 58 2032 61 2027 46 2020 40 2021 61 2028 44 2033 61 2031 46 2034 40 362 44 362 41 44 350 2031 46 2034 40 362 44 123 125 41 41 2032 46 2035 40 41 645 2036 552 2037 58 778 2038 40 362 44 2037 41 2003 46 2029 46 2030 40 362 44 720 40 2022 41 44 2028 41 64 812 612 2026 40 2022 41 354 470 58 664 2031 696 2022 58 330 330 688 362 696 2031 545 713 40 2031 91 362 93 44 813 41 58 830 58 2039 40 2031 91 362 93 41 2040 46 2041 40 362 362 44 2042 44 2043 61 1502 44 41 645 2044 58 767 688 750 713 40 2031 44 620 41 58 778 2038 40 362 41 688 362 750 696 2031 545 362 750 696 2031 58 778 2038 40 362 41 688 362 696 2031 545 750 713 40 2031 91 362 93 44 576 41 58 778 2038 40 362 41 688 40 362 750 696 2031 545 362 696 2031 545 750 2031 91 362 93 41 759 40 362 696 2031 545 750 713 40 2031 91 362 93 44 620 41 41 58 778 2038 40 362 41 64 2001 46 2019 612 2045 40 2003 44 2021 58 813 44 2024 58 813 61 2025 44 2046 58 569 61 443 44 2047 58 2006 91 2048 91 813 44 813 93 93 61 470 44 2049 58 2008 91 2048 44 2050 93 61 470 44 2051 58 2006 91 813 93 61 470 44 2052 58 2006 91 2053 93 61 470 44 2054 58 2006 91 660 93 61 470 44 2055 58 2009 91 2056 91 813 44 813 93 93 61 40 41 44 41 354 470 58 362 2027 61 2003 46 2011 40 41 2028 61 362 330 2047 61 2047 759 123 125 2047 91 362 93 61 362 43 2057 46 2058 40 362 44 362 41 46 2058 40 362 44 362 41 2003 46 2029 46 2030 40 362 44 2028 41 830 58 2027 46 2045 40 2059 61 123 362 58 2028 44 362 58 2047 44 362 58 2049 44 362 58 2051 44 125 44 2052 61 2052 44 2054 61 2054 44 2055 61 2055 44 41 645 2060 58 2003 46 2029 46 2061 40 362 44 2021 41 688 2046 58 778 2038 40 362 41 645 2036 552 2037 58 778 2038 40 362 44 2037 41 2003 46 2029 46 2030 40 362 44 2028 41 64 2001 46 2019 612 2062 40 2003 44 2021 58 813 44 2024 58 813 61 2025 44 2063 58 569 61 443 44 2052 58 2006 91 2053 93 61 470 44 2054 58 2006 91 660 93 61 470 44 2055 58 2009 91 2056 91 813 44 813 93 93 61 40 41 44 41 354 470 58 362 2027 61 2003 46 2011 40 41 2028 61 362 2003 46 2029 46 2030 40 362 44 2028 41 830 58 2027 46 2062 40 2059 61 123 362 58 2028 125 44 2052 61 2052 44 2054 61 2054 44 2055 61 2055 759 40 41 41 645 2064 58 2003 46 2029 46 2061 40 362 44 2028 41 688 2063 58 778 2038 40 362 41 645 2036 552 2037 58 778 2038 40 362 44 2037 41 2003 46 2029 46 2030 40 362 44 2028 41 64 2001 46 2019 612 2065 40 2003 44 2021 58 813 44 2024 58 813 61 2025 44 2066 58 2006 91 813 93 61 470 44 2067 58 2006 91 813 93 61 470 44 2068 58 704 61 1502 44 2046 58 569 61 443 44 2069 58 2006 91 2008 91 620 44 2070 93 93 61 470 44 2071 58 2006 91 569 93 61 470 44 2072 58 2006 91 2008 91 620 44 2073 93 93 61 470 44 2047 58 2006 91 2048 91 813 44 813 93 93 61 470 44 2074 58 569 61 443 44 2075 58 2006 91 2008 91 620 44 2076 93 93 61 470 44 2077 58 2006 91 813 93 61 470 44 2078 58 2006 91 2008 91 620 44 2079 93 93 61 470 44 2080 58 2006 91 2008 91 620 44 2081 93 93 61 470 44 2052 58 2006 91 2053 93 61 470 44 2054 58 2006 91 660 93 61 470 44 2055 58 2009 91 2056 91 813 44 813 93 93 61 40 41 44 41 354 813 58 362 2082 61 2003 46 2017 688 750 2066 58 2066 61 362 688 750 2067 58 2067 61 2024 330 2047 61 2047 759 123 125 2047 91 362 93 61 362 43 2057 46 2058 40 362 44 362 41 46 2058 40 362 44 362 41 2083 61 362 2028 61 362 2003 46 2029 46 2030 40 362 44 2083 44 2028 41 830 58 2082 46 2065 40 2059 61 123 362 58 2083 44 362 58 2028 44 362 58 2069 44 362 58 2068 44 362 58 2071 44 362 58 2072 44 362 58 2047 44 362 58 2074 44 362 58 2075 44 362 58 2077 44 362 58 2078 44 362 58 2080 44 125 44 2052 61 2052 44 2054 61 2054 44 2055 61 2055 44 41 645 2060 58 2003 46 2029 46 2061 40 362 44 2083 41 688 2046 58 778 2038 40 362 41 645 2036 552 2037 58 778 2038 40 362 44 2037 41 2003 46 2029 46 2030 40 362 44 2083 44 2028 41 792 2066 64 2001 46 2019 612 2084 40 2003 44 2066 58 813 44 2024 58 813 61 2025 44 2063 58 569 61 443 44 2052 58 2006 91 2053 93 61 470 44 2054 58 2006 91 660 93 61 470 44 2055 58 2009 91 2056 91 813 44 813 93 93 61 40 41 44 41 354 470 58 362 2082 61 2003 46 2017 330 2083 61 362 2003 46 2029 46 2030 40 362 44 2083 41 830 58 2082 46 2084 40 2059 61 123 362 58 2083 125 44 2052 61 2052 44 2054 61 2054 44 2055 61 2055 44 41 645 2064 58 2003 46 2029 46 2061 40 362 44 2083 41 688 2063 58 778 2038 40 362 41 645 2036 552 2037 58 778 2038 40 362 44 2037 41 2003 46 2029 46 2030 40 362 44 2083 41 64 2001 46 2019 612 2085 40 2003 44 2066 58 813 44 2086 58 704 44 2024 58 813 61 2025 44 2087 58 569 61 443 44 2052 58 2006 91 2053 93 61 470 44 2054 58 2006 91 660 93 61 470 44 2055 58 2009 91 2056 91 813 44 813 93 93 61 40 41 44 41 354 2023 91 2088 93 58 362 2082 61 2003 46 2017 330 2083 61 362 2003 46 2029 46 2030 40 362 44 2086 44 2083 41 830 58 2089 61 2082 46 2085 40 2059 61 123 362 58 2083 44 362 58 2086 44 362 58 2087 44 125 44 2052 61 2052 44 2054 61 2054 44 2055 61 2055 44 41 2035 61 673 40 2089 44 362 44 91 93 41 2003 46 2029 46 2030 40 362 44 720 40 2035 41 44 2083 41 792 2035 645 40 2090 44 2036 41 552 2037 58 778 2038 40 362 44 2037 41 64 2001 46 2019 612 2091 40 2003 44 2066 58 813 44 2024 58 813 44 2092 58 2006 91 2023 91 813 93 93 61 470 44 2022 58 2006 91 2023 91 2088 93 93 61 470 44 2052 58 2006 91 2053 93 61 470 44 2054 58 2006 91 660 93 61 470 44 2055 58 2009 91 2056 91 813 44 813 93 93 61 40 41 44 41 354 470 58 362 688 2092 712 750 470 545 2022 712 470 58 767 629 2092 712 470 545 2022 712 750 470 58 2092 61 91 2031 46 2093 664 2031 696 2022 93 630 58 778 2044 40 362 41 2082 61 2003 46 2017 330 2083 61 362 2003 46 2029 46 2030 40 362 44 720 40 2092 41 44 2083 41 830 58 2082 46 2091 40 2059 61 123 362 58 2083 44 362 58 2092 125 44 2052 61 2052 44 2054 61 2054 44 2055 61 2055 44 41 645 40 2090 44 2036 41 552 2037 58 778 2038 40 362 44 2037 44 41 2003 46 2029 46 2030 40 362 44 2083 41 ,"{'AvgLine': 49, 'CountLine': 567, 'CountStmt': 124, 'MaxNesting': 3, 'AvgLineCode': 24, 'AvgEssential': 2, 'AvgLineBlank': 3, 'CountStmtExe': 112, 'MaxEssential': 6, 'SumEssential': 31, 'AvgCyclomatic': 3, 'CountLineCode': 277, 'CountStmtDecl': 33, 'MaxCyclomatic': 8, 'SumCyclomatic': 39, 'AvgLineComment': 21, 'CountClassBase': 1, 'CountLineBlank': 46, 'CountDeclMethod': 11, 'CountLineCodeExe': 181, 'CountLineComment': 244, 'CountClassCoupled': 7, 'CountClassDerived': 0, 'CountLineCodeDecl': 124, 'CountDeclMethodAll': 38, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '0.88', 'AvgCyclomaticStrict': 4, 'MaxCyclomaticStrict': 15, 'SumCyclomaticStrict': 51, 'AvgCyclomaticModified': 3, 'MaxCyclomaticModified': 8, 'SumCyclomaticModified': 39, 'CountDeclInstanceMethod': 10, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 1}"
128706,Python,"class DefaultErrorStrategy(ErrorStrategy):

    def __init__(self):
        super(DefaultErrorStrategy, self).__init__()
        # Indicates whether the error strategy is currently ""recovering from an
        # error"". This is used to suppress reporting multiple error messages while
        # attempting to recover from a detected syntax error.
        #
        # @see #inErrorRecoveryMode
        #
        self.errorRecoveryMode = False

        # The index into the input stream where the last error occurred.
        # 	This is used to prevent infinite loops where an error is found
        #  but no token is consumed during recovery...another error is found,
        #  ad nauseum.  This is a failsafe mechanism to guarantee that at least
        #  one token/tree node is consumed for two errors.
        #
        self.lastErrorIndex = -1
        self.lastErrorStates = None
        self.nextTokensContext = None
        self.nextTokenState = 0

    # <p>The default implementation simply calls {@link #endErrorCondition} to
    # ensure that the handler is not in error recovery mode.</p>
    def reset(self, recognizer):
        self.endErrorCondition(recognizer)

    #
    # This method is called to enter error recovery mode when a recognition
    # exception is reported.
    #
    # @param recognizer the parser instance
    #
    def beginErrorCondition(self, recognizer):
        self.errorRecoveryMode = True

    def inErrorRecoveryMode(self, recognizer):
        return self.errorRecoveryMode

    #
    # This method is called to leave error recovery mode after recovering from
    # a recognition exception.
    #
    # @param recognizer
    #
    def endErrorCondition(self, recognizer):
        self.errorRecoveryMode = False
        self.lastErrorStates = None
        self.lastErrorIndex = -1

    #
    # {@inheritDoc}
    #
    # <p>The default implementation simply calls {@link #endErrorCondition}.</p>
    #
    def reportMatch(self, recognizer):
        self.endErrorCondition(recognizer)

    #
    # {@inheritDoc}
    #
    # <p>The default implementation returns immediately if the handler is already
    # in error recovery mode. Otherwise, it calls {@link #beginErrorCondition}
    # and dispatches the reporting task based on the runtime type of {@code e}
    # according to the following table.</p>
    #
    # <ul>
    # <li>{@link NoViableAltException}: Dispatches the call to
    # {@link #reportNoViableAlternative}</li>
    # <li>{@link InputMismatchException}: Dispatches the call to
    # {@link #reportInputMismatch}</li>
    # <li>{@link FailedPredicateException}: Dispatches the call to
    # {@link #reportFailedPredicate}</li>
    # <li>All other types: calls {@link Parser#notifyErrorListeners} to report
    # the exception</li>
    # </ul>
    #
    def reportError(self, recognizer, e):
        # if we've already reported an error and have not matched a token
        # yet successfully, don't report any errors.
        if self.inErrorRecoveryMode(recognizer):
            return # don't report spurious errors
        self.beginErrorCondition(recognizer)
        if isinstance( e, NoViableAltException ):
            self.reportNoViableAlternative(recognizer, e)
        elif isinstance( e, InputMismatchException ):
            self.reportInputMismatch(recognizer, e)
        elif isinstance( e, FailedPredicateException ):
            self.reportFailedPredicate(recognizer, e)
        else:
            print(""unknown recognition error type: "" + type(e).__name__)
            recognizer.notifyErrorListeners(e.getOffendingToken(), e.getMessage(), e)

    #
    # {@inheritDoc}
    #
    # <p>The default implementation resynchronizes the parser by consuming tokens
    # until we find one in the resynchronization set--loosely the set of tokens
    # that can follow the current rule.</p>
    #
    def recover(self, recognizer, e):
        if self.lastErrorIndex==recognizer.getInputStream().index \
            and self.lastErrorStates is not None \
            and recognizer.state in self.lastErrorStates:
            # uh oh, another error at same token index and previously-visited
            # state in ATN; must be a case where LT(1) is in the recovery
            # token set so nothing got consumed. Consume a single token
            # at least to prevent an infinite loop; this is a failsafe.
            recognizer.consume()

        self.lastErrorIndex = recognizer._input.index
        if self.lastErrorStates is None:
            self.lastErrorStates = []
        self.lastErrorStates.append(recognizer.state)
        followSet = self.getErrorRecoverySet(recognizer)
        self.consumeUntil(recognizer, followSet)

    # The default implementation of {@link ANTLRErrorStrategy#sync} makes sure
    # that the current lookahead symbol is consistent with what were expecting
    # at this point in the ATN. You can call this anytime but ANTLR only
    # generates code to check before subrules/loops and each iteration.
    #
    # <p>Implements Jim Idle's magic sync mechanism in closures and optional
    # subrules. E.g.,</p>
    #
    # <pre>
    # a : sync ( stuff sync )* ;
    # sync : {consume to what can follow sync} ;
    # </pre>
    #
    # At the start of a sub rule upon error, {@link #sync} performs single
    # token deletion, if possible. If it can't do that, it bails on the current
    # rule and uses the default error recovery, which consumes until the
    # resynchronization set of the current rule.
    #
    # <p>If the sub rule is optional ({@code (...)?}, {@code (...)*}, or block
    # with an empty alternative), then the expected set includes what follows
    # the subrule.</p>
    #
    # <p>During loop iteration, it consumes until it sees a token that can start a
    # sub rule or what follows loop. Yes, that is pretty aggressive. We opt to
    # stay in the loop as long as possible.</p>
    #
    # <p><strong>ORIGINS</strong></p>
    #
    # <p>Previous versions of ANTLR did a poor job of their recovery within loops.
    # A single mismatch token or missing token would force the parser to bail
    # out of the entire rules surrounding the loop. So, for rule</p>
    #
    # <pre>
    # classDef : 'class' ID '{' member* '}'
    # </pre>
    #
    # input with an extra token between members would force the parser to
    # consume until it found the next class definition rather than the next
    # member definition of the current class.
    #
    # <p>This functionality cost a little bit of effort because the parser has to
    # compare token set at the start of the loop and at each iteration. If for
    # some reason speed is suffering for you, you can turn off this
    # functionality by simply overriding this method as a blank { }.</p>
    #
    def sync(self, recognizer):
        # If already recovering, don't try to sync
        if self.inErrorRecoveryMode(recognizer):
            return

        s = recognizer._interp.atn.states[recognizer.state]
        la = recognizer.getTokenStream().LA(1)
        # try cheaper subset first; might get lucky. seems to shave a wee bit off
        nextTokens = recognizer.atn.nextTokens(s)
        if la in nextTokens:
            self.nextTokensContext = None
            self.nextTokenState = ATNState.INVALID_STATE_NUMBER
            return
        elif Token.EPSILON in nextTokens:
            if self.nextTokensContext is None:
                # It's possible the next token won't match information tracked
                # by sync is restricted for performance.
                self.nextTokensContext = recognizer._ctx
                self.nextTokensState = recognizer._stateNumber
            return

        if s.stateType in [ATNState.BLOCK_START, ATNState.STAR_BLOCK_START,
                                ATNState.PLUS_BLOCK_START, ATNState.STAR_LOOP_ENTRY]:
            # report error and recover if possible
            if self.singleTokenDeletion(recognizer)is not None:
                return
            else:
                raise InputMismatchException(recognizer)

        elif s.stateType in [ATNState.PLUS_LOOP_BACK, ATNState.STAR_LOOP_BACK]:
            self.reportUnwantedToken(recognizer)
            expecting = recognizer.getExpectedTokens()
            whatFollowsLoopIterationOrRule = expecting.addSet(self.getErrorRecoverySet(recognizer))
            self.consumeUntil(recognizer, whatFollowsLoopIterationOrRule)

        else:
            # do nothing if we can't identify the exact kind of ATN state
            pass

    # This is called by {@link #reportError} when the exception is a
    # {@link NoViableAltException}.
    #
    # @see #reportError
    #
    # @param recognizer the parser instance
    # @param e the recognition exception
    #
    def reportNoViableAlternative(self, recognizer, e):
        tokens = recognizer.getTokenStream()
        if tokens is not None:
            if e.startToken.type==Token.EOF:
                input = ""<EOF>""
            else:
                input = tokens.getText(e.startToken, e.offendingToken)
        else:
            input = ""<unknown input>""
        msg = ""no viable alternative at input "" + self.escapeWSAndQuote(input)
        recognizer.notifyErrorListeners(msg, e.offendingToken, e)

    #
    # This is called by {@link #reportError} when the exception is an
    # {@link InputMismatchException}.
    #
    # @see #reportError
    #
    # @param recognizer the parser instance
    # @param e the recognition exception
    #
    def reportInputMismatch(self, recognizer, e):
        msg = ""mismatched input "" + self.getTokenErrorDisplay(e.offendingToken) \
              + "" expecting "" + e.getExpectedTokens().toString(recognizer.literalNames, recognizer.symbolicNames)
        recognizer.notifyErrorListeners(msg, e.offendingToken, e)

    #
    # This is called by {@link #reportError} when the exception is a
    # {@link FailedPredicateException}.
    #
    # @see #reportError
    #
    # @param recognizer the parser instance
    # @param e the recognition exception
    #
    def reportFailedPredicate(self, recognizer, e):
        ruleName = recognizer.ruleNames[recognizer._ctx.getRuleIndex()]
        msg = ""rule "" + ruleName + "" "" + e.message
        recognizer.notifyErrorListeners(msg, e.offendingToken, e)

    # This method is called to report a syntax error which requires the removal
    # of a token from the input stream. At the time this method is called, the
    # erroneous symbol is current {@code LT(1)} symbol and has not yet been
    # removed from the input stream. When this method returns,
    # {@code recognizer} is in error recovery mode.
    #
    # <p>This method is called when {@link #singleTokenDeletion} identifies
    # single-token deletion as a viable recovery strategy for a mismatched
    # input error.</p>
    #
    # <p>The default implementation simply returns if the handler is already in
    # error recovery mode. Otherwise, it calls {@link #beginErrorCondition} to
    # enter error recovery mode, followed by calling
    # {@link Parser#notifyErrorListeners}.</p>
    #
    # @param recognizer the parser instance
    #
    def reportUnwantedToken(self, recognizer):
        if self.inErrorRecoveryMode(recognizer):
            return

        self.beginErrorCondition(recognizer)
        t = recognizer.getCurrentToken()
        tokenName = self.getTokenErrorDisplay(t)
        expecting = self.getExpectedTokens(recognizer)
        msg = ""extraneous input "" + tokenName + "" expecting "" \
            + expecting.toString(recognizer.literalNames, recognizer.symbolicNames)
        recognizer.notifyErrorListeners(msg, t, None)

    # This method is called to report a syntax error which requires the
    # insertion of a missing token into the input stream. At the time this
    # method is called, the missing token has not yet been inserted. When this
    # method returns, {@code recognizer} is in error recovery mode.
    #
    # <p>This method is called when {@link #singleTokenInsertion} identifies
    # single-token insertion as a viable recovery strategy for a mismatched
    # input error.</p>
    #
    # <p>The default implementation simply returns if the handler is already in
    # error recovery mode. Otherwise, it calls {@link #beginErrorCondition} to
    # enter error recovery mode, followed by calling
    # {@link Parser#notifyErrorListeners}.</p>
    #
    # @param recognizer the parser instance
    #
    def reportMissingToken(self, recognizer):
        if self.inErrorRecoveryMode(recognizer):
            return
        self.beginErrorCondition(recognizer)
        t = recognizer.getCurrentToken()
        expecting = self.getExpectedTokens(recognizer)
        msg = ""missing "" + expecting.toString(recognizer.literalNames, recognizer.symbolicNames) \
              + "" at "" + self.getTokenErrorDisplay(t)
        recognizer.notifyErrorListeners(msg, t, None)

    # <p>The default implementation attempts to recover from the mismatched input
    # by using single token insertion and deletion as described below. If the
    # recovery attempt fails, this method throws an
    # {@link InputMismatchException}.</p>
    #
    # <p><strong>EXTRA TOKEN</strong> (single token deletion)</p>
    #
    # <p>{@code LA(1)} is not what we are looking for. If {@code LA(2)} has the
    # right token, however, then assume {@code LA(1)} is some extra spurious
    # token and delete it. Then consume and return the next token (which was
    # the {@code LA(2)} token) as the successful result of the match operation.</p>
    #
    # <p>This recovery strategy is implemented by {@link #singleTokenDeletion}.</p>
    #
    # <p><strong>MISSING TOKEN</strong> (single token insertion)</p>
    #
    # <p>If current token (at {@code LA(1)}) is consistent with what could come
    # after the expected {@code LA(1)} token, then assume the token is missing
    # and use the parser's {@link TokenFactory} to create it on the fly. The
    # ""insertion"" is performed by returning the created token as the successful
    # result of the match operation.</p>
    #
    # <p>This recovery strategy is implemented by {@link #singleTokenInsertion}.</p>
    #
    # <p><strong>EXAMPLE</strong></p>
    #
    # <p>For example, Input {@code i=(3;} is clearly missing the {@code ')'}. When
    # the parser returns from the nested call to {@code expr}, it will have
    # call chain:</p>
    #
    # <pre>
    # stat &rarr; expr &rarr; atom
    # </pre>
    #
    # and it will be trying to match the {@code ')'} at this point in the
    # derivation:
    #
    # <pre>
    # =&gt; ID '=' '(' INT ')' ('+' atom)* ';'
    #                    ^
    # </pre>
    #
    # The attempt to match {@code ')'} will fail when it sees {@code ';'} and
    # call {@link #recoverInline}. To recover, it sees that {@code LA(1)==';'}
    # is in the set of tokens that can follow the {@code ')'} token reference
    # in rule {@code atom}. It can assume that you forgot the {@code ')'}.
    #
    def recoverInline(self, recognizer):
        # SINGLE TOKEN DELETION
        matchedSymbol = self.singleTokenDeletion(recognizer)
        if matchedSymbol is not None:
            # we have deleted the extra token.
            # now, move past ttype token as if all were ok
            recognizer.consume()
            return matchedSymbol

        # SINGLE TOKEN INSERTION
        if self.singleTokenInsertion(recognizer):
            return self.getMissingSymbol(recognizer)

        # even that didn't work; must throw the exception
        raise InputMismatchException(recognizer)

    #
    # This method implements the single-token insertion inline error recovery
    # strategy. It is called by {@link #recoverInline} if the single-token
    # deletion strategy fails to recover from the mismatched input. If this
    # method returns {@code true}, {@code recognizer} will be in error recovery
    # mode.
    #
    # <p>This method determines whether or not single-token insertion is viable by
    # checking if the {@code LA(1)} input symbol could be successfully matched
    # if it were instead the {@code LA(2)} symbol. If this method returns
    # {@code true}, the caller is responsible for creating and inserting a
    # token with the correct type to produce this behavior.</p>
    #
    # @param recognizer the parser instance
    # @return {@code true} if single-token insertion is a viable recovery
    # strategy for the current mismatched input, otherwise {@code false}
    #
    def singleTokenInsertion(self, recognizer):
        currentSymbolType = recognizer.getTokenStream().LA(1)
        # if current token is consistent with what could come after current
        # ATN state, then we know we're missing a token; error recovery
        # is free to conjure up and insert the missing token
        atn = recognizer._interp.atn
        currentState = atn.states[recognizer.state]
        next = currentState.transitions[0].target
        expectingAtLL2 = atn.nextTokens(next, recognizer._ctx)
        if currentSymbolType in expectingAtLL2:
            self.reportMissingToken(recognizer)
            return True
        else:
            return False

    # This method implements the single-token deletion inline error recovery
    # strategy. It is called by {@link #recoverInline} to attempt to recover
    # from mismatched input. If this method returns null, the parser and error
    # handler state will not have changed. If this method returns non-null,
    # {@code recognizer} will <em>not</em> be in error recovery mode since the
    # returned token was a successful match.
    #
    # <p>If the single-token deletion is successful, this method calls
    # {@link #reportUnwantedToken} to report the error, followed by
    # {@link Parser#consume} to actually ""delete"" the extraneous token. Then,
    # before returning {@link #reportMatch} is called to signal a successful
    # match.</p>
    #
    # @param recognizer the parser instance
    # @return the successfully matched {@link Token} instance if single-token
    # deletion successfully recovers from the mismatched input, otherwise
    # {@code null}
    #
    def singleTokenDeletion(self, recognizer):
        nextTokenType = recognizer.getTokenStream().LA(2)
        expecting = self.getExpectedTokens(recognizer)
        if nextTokenType in expecting:
            self.reportUnwantedToken(recognizer)
            # print(""recoverFromMismatchedToken deleting "" \
            #     + str(recognizer.getTokenStream().LT(1)) \
            #     + "" since "" + str(recognizer.getTokenStream().LT(2)) \
            #     + "" is what we want"", file=sys.stderr)
            recognizer.consume() # simply delete extra token
            # we want to return the token we're actually matching
            matchedSymbol = recognizer.getCurrentToken()
            self.reportMatch(recognizer) # we know current token is correct
            return matchedSymbol
        else:
            return None

    # Conjure up a missing token during error recovery.
    #
    #  The recognizer attempts to recover from single missing
    #  symbols. But, actions might refer to that missing symbol.
    #  For example, x=ID {f($x);}. The action clearly assumes
    #  that there has been an identifier matched previously and that
    #  $x points at that token. If that token is missing, but
    #  the next token in the stream is what we want we assume that
    #  this token is missing and we keep going. Because we
    #  have to return some token to replace the missing token,
    #  we have to conjure one up. This method gives the user control
    #  over the tokens returned for missing tokens. Mostly,
    #  you will want to create something special for identifier
    #  tokens. For literals such as '{' and ',', the default
    #  action in the parser or tree parser works. It simply creates
    #  a CommonToken of the appropriate type. The text will be the token.
    #  If you change what tokens must be created by the lexer,
    #  override this method to create the appropriate tokens.
    #
    def getMissingSymbol(self, recognizer):
        currentSymbol = recognizer.getCurrentToken()
        expecting = self.getExpectedTokens(recognizer)
        expectedTokenType = expecting[0] # get any element
        if expectedTokenType==Token.EOF:
            tokenText = u""<missing EOF>""
        else:
            name = None
            if expectedTokenType < len(recognizer.literalNames):
                name = recognizer.literalNames[expectedTokenType]
            if name is None and expectedTokenType < len(recognizer.symbolicNames):
                name = recognizer.symbolicNames[expectedTokenType]
            tokenText = u""<missing "" + unicode(name) + u"">""
        current = currentSymbol
        lookback = recognizer.getTokenStream().LT(-1)
        if current.type==Token.EOF and lookback is not None:
            current = lookback
        return recognizer.getTokenFactory().create(current.source,
            expectedTokenType, tokenText, Token.DEFAULT_CHANNEL,
            -1, -1, current.line, current.column)

    def getExpectedTokens(self, recognizer):
        return recognizer.getExpectedTokens()

    # How should a token be displayed in an error message? The default
    #  is to display just the text, but during development you might
    #  want to have a lot of information spit out.  Override in that case
    #  to use t.toString() (which, for CommonToken, dumps everything about
    #  the token). This is better than forcing you to override a method in
    #  your token objects because you don't have to go modify your lexer
    #  so that it creates a new Java type.
    #
    def getTokenErrorDisplay(self, t):
        if t is None:
            return u""<no token>""
        s = t.text
        if s is None:
            if t.type==Token.EOF:
                s = u""<EOF>""
            else:
                s = u""<"" + unicode(t.type) + u"">""
        return self.escapeWSAndQuote(s)

    def escapeWSAndQuote(self, s):
        s = s.replace(u""\n"",u""\\n"")
        s = s.replace(u""\r"",u""\\r"")
        s = s.replace(u""\t"",u""\\t"")
        return u""'"" + s + u""'""

    #  Compute the error recovery set for the current rule.  During
    #  rule invocation, the parser pushes the set of tokens that can
    #  follow that rule reference on the stack; this amounts to
    #  computing FIRST of what follows the rule reference in the
    #  enclosing rule. See LinearApproximator.FIRST().
    #  This local follow set only includes tokens
    #  from within the rule; i.e., the FIRST computation done by
    #  ANTLR stops at the end of a rule.
    #
    #  EXAMPLE
    #
    #  When you find a ""no viable alt exception"", the input is not
    #  consistent with any of the alternatives for rule r.  The best
    #  thing to do is to consume tokens until you see something that
    #  can legally follow a call to r#or* any rule that called r.
    #  You don't want the exact set of viable next tokens because the
    #  input might just be missing a token--you might consume the
    #  rest of the input looking for one of the missing tokens.
    #
    #  Consider grammar:
    #
    #  a : '[' b ']'
    #    | '(' b ')'
    #    ;
    #  b : c '^' INT ;
    #  c : ID
    #    | INT
    #    ;
    #
    #  At each rule invocation, the set of tokens that could follow
    #  that rule is pushed on a stack.  Here are the various
    #  context-sensitive follow sets:
    #
    #  FOLLOW(b1_in_a) = FIRST(']') = ']'
    #  FOLLOW(b2_in_a) = FIRST(')') = ')'
    #  FOLLOW(c_in_b) = FIRST('^') = '^'
    #
    #  Upon erroneous input ""[]"", the call chain is
    #
    #  a -> b -> c
    #
    #  and, hence, the follow context stack is:
    #
    #  depth     follow set       start of rule execution
    #    0         <EOF>                    a (from main())
    #    1          ']'                     b
    #    2          '^'                     c
    #
    #  Notice that ')' is not included, because b would have to have
    #  been called from a different context in rule a for ')' to be
    #  included.
    #
    #  For error recovery, we cannot consider FOLLOW(c)
    #  (context-sensitive or otherwise).  We need the combined set of
    #  all context-sensitive FOLLOW sets--the set of all tokens that
    #  could follow any reference in the call chain.  We need to
    #  resync to one of those tokens.  Note that FOLLOW(c)='^' and if
    #  we resync'd to that token, we'd consume until EOF.  We need to
    #  sync to context-sensitive FOLLOWs for a, b, and c: {']','^'}.
    #  In this case, for input ""[]"", LA(1) is ']' and in the set, so we would
    #  not consume anything. After printing an error, rule c would
    #  return normally.  Rule b would not find the required '^' though.
    #  At this point, it gets a mismatched token error and throws an
    #  exception (since LA(1) is not in the viable following token
    #  set).  The rule exception handler tries to recover, but finds
    #  the same recovery set and doesn't consume anything.  Rule b
    #  exits normally returning to rule a.  Now it finds the ']' (and
    #  with the successful match exits errorRecovery mode).
    #
    #  So, you can see that the parser walks up the call chain looking
    #  for the token that was a member of the recovery set.
    #
    #  Errors are not generated in errorRecovery mode.
    #
    #  ANTLR's error recovery mechanism is based upon original ideas:
    #
    #  ""Algorithms + Data Structures = Programs"" by Niklaus Wirth
    #
    #  and
    #
    #  ""A note on error recovery in recursive descent parsers"":
    #  http:#portal.acm.org/citation.cfm?id=947902.947905
    #
    #  Later, Josef Grosch had some good ideas:
    #
    #  ""Efficient and Comfortable Error Recovery in Recursive Descent
    #  Parsers"":
    #  ftp:#www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip
    #
    #  Like Grosch I implement context-sensitive FOLLOW sets that are combined
    #  at run-time upon error to avoid overhead during parsing.
    #
    def getErrorRecoverySet(self, recognizer):
        atn = recognizer._interp.atn
        ctx = recognizer._ctx
        recoverSet = IntervalSet()
        while ctx is not None and ctx.invokingState>=0:
            # compute what follows who invoked us
            invokingState = atn.states[ctx.invokingState]
            rt = invokingState.transitions[0]
            follow = atn.nextTokens(rt.followState)
            recoverSet.addSet(follow)
            ctx = ctx.parentCtx
        recoverSet.removeOne(Token.EPSILON)
        return recoverSet

    # Consume tokens until one matches the given token set.#
    def consumeUntil(self, recognizer, set_):
        ttype = recognizer.getTokenStream().LA(1)
        while ttype != Token.EOF and not ttype in set_:
            recognizer.consume()
            ttype = recognizer.getTokenStream().LA(1)",1,587 2000 40 2001 41 58 612 2002 40 2003 41 58 818 40 2000 44 2003 41 46 2002 40 41 330 330 330 330 330 330 2003 46 2004 61 443 330 330 330 330 330 330 2003 46 2005 61 45 1501 2003 46 2006 61 470 2003 46 2007 61 470 2003 46 2008 61 1500 330 330 612 2009 40 2003 44 2010 41 58 2003 46 2011 40 2010 41 330 330 330 330 330 330 612 2012 40 2003 44 2010 41 58 2003 46 2004 61 515 612 2013 40 2003 44 2010 41 58 792 2003 46 2004 330 330 330 330 330 330 612 2011 40 2003 44 2010 41 58 2003 46 2004 61 443 2003 46 2006 61 470 2003 46 2005 61 45 1501 330 330 330 330 330 612 2014 40 2003 44 2010 41 58 2003 46 2011 40 2010 41 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 612 2015 40 2003 44 2010 44 2016 41 58 330 330 688 2003 46 2013 40 2010 41 58 792 330 2003 46 2012 40 2010 41 688 713 40 2016 44 2017 41 58 2003 46 2018 40 2010 44 2016 41 629 713 40 2016 44 2019 41 58 2003 46 2020 40 2010 44 2016 41 629 713 40 2016 44 2021 41 58 2003 46 2022 40 2010 44 2016 41 630 58 770 40 362 43 832 40 2016 41 46 2023 41 2010 46 2024 40 2016 46 2025 40 41 44 2016 46 2026 40 41 44 2016 41 330 330 330 330 330 330 330 612 2027 40 2003 44 2010 44 2016 41 58 688 2003 46 2005 323 2010 46 2028 40 41 46 2029 92 545 2003 46 2006 712 750 470 92 545 2010 46 2030 696 2003 46 2006 58 330 330 330 330 2010 46 2031 40 41 2003 46 2005 61 2010 46 2032 46 2029 688 2003 46 2006 712 470 58 2003 46 2006 61 91 93 2003 46 2006 46 2033 40 2010 46 2030 41 2034 61 2003 46 2035 40 2010 41 2003 46 2036 40 2010 44 2034 41 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 612 2037 40 2003 44 2010 41 58 330 688 2003 46 2013 40 2010 41 58 792 2038 61 2010 46 2039 46 2040 46 2041 91 2010 46 2030 93 2042 61 2010 46 2043 40 41 46 2044 40 1501 41 330 2045 61 2010 46 2040 46 2045 40 2038 41 688 2042 696 2045 58 2003 46 2007 61 470 2003 46 2008 61 2046 46 2047 792 629 2048 46 2049 696 2045 58 688 2003 46 2007 712 470 58 330 330 2003 46 2007 61 2010 46 2050 2003 46 2051 61 2010 46 2052 792 688 2038 46 2053 696 91 2046 46 2054 44 2046 46 2055 44 2046 46 2056 44 2046 46 2057 93 58 330 688 2003 46 2058 40 2010 41 712 750 470 58 792 630 58 778 2019 40 2010 41 629 2038 46 2053 696 91 2046 46 2059 44 2046 46 2060 93 58 2003 46 2061 40 2010 41 2062 61 2010 46 2063 40 41 2064 61 2062 46 2065 40 2003 46 2035 40 2010 41 41 2003 46 2036 40 2010 44 2064 41 630 58 330 767 330 330 330 330 330 330 330 330 612 2018 40 2003 44 2010 44 2016 41 58 2066 61 2010 46 2043 40 41 688 2066 712 750 470 58 688 2016 46 2067 46 832 323 2048 46 2068 58 701 61 362 630 58 701 61 2066 46 2069 40 2016 46 2067 44 2016 46 2070 41 630 58 701 61 362 2071 61 362 43 2003 46 2072 40 701 41 2010 46 2024 40 2071 44 2016 46 2070 44 2016 41 330 330 330 330 330 330 330 330 330 612 2020 40 2003 44 2010 44 2016 41 58 2071 61 362 43 2003 46 2073 40 2016 46 2070 41 92 43 362 43 2016 46 2063 40 41 46 2074 40 2010 46 2075 44 2010 46 2076 41 2010 46 2024 40 2071 44 2016 46 2070 44 2016 41 330 330 330 330 330 330 330 330 330 612 2022 40 2003 44 2010 44 2016 41 58 2077 61 2010 46 2078 91 2010 46 2050 46 2079 40 41 93 2071 61 362 43 2077 43 362 43 2016 46 2080 2010 46 2024 40 2071 44 2016 46 2070 44 2016 41 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 612 2061 40 2003 44 2010 41 58 688 2003 46 2013 40 2010 41 58 792 2003 46 2012 40 2010 41 2081 61 2010 46 2082 40 41 2083 61 2003 46 2073 40 2081 41 2062 61 2003 46 2063 40 2010 41 2071 61 362 43 2083 43 362 92 43 2062 46 2074 40 2010 46 2075 44 2010 46 2076 41 2010 46 2024 40 2071 44 2081 44 470 41 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 612 2084 40 2003 44 2010 41 58 688 2003 46 2013 40 2010 41 58 792 2003 46 2012 40 2010 41 2081 61 2010 46 2082 40 41 2062 61 2003 46 2063 40 2010 41 2071 61 362 43 2062 46 2074 40 2010 46 2075 44 2010 46 2076 41 92 43 362 43 2003 46 2073 40 2081 41 2010 46 2024 40 2071 44 2081 44 470 41 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 612 2085 40 2003 44 2010 41 58 330 2086 61 2003 46 2058 40 2010 41 688 2086 712 750 470 58 330 330 2010 46 2031 40 41 792 2086 330 688 2003 46 2087 40 2010 41 58 792 2003 46 2088 40 2010 41 330 778 2019 40 2010 41 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 612 2087 40 2003 44 2010 41 58 2089 61 2010 46 2043 40 41 46 2044 40 1501 41 330 330 330 2040 61 2010 46 2039 46 2040 2090 61 2040 46 2041 91 2010 46 2030 93 745 61 2090 46 2091 91 1500 93 46 2092 2093 61 2040 46 2045 40 745 44 2010 46 2050 41 688 2089 696 2093 58 2003 46 2084 40 2010 41 792 515 630 58 792 443 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 612 2058 40 2003 44 2010 41 58 2094 61 2010 46 2043 40 41 46 2044 40 1502 41 2062 61 2003 46 2063 40 2010 41 688 2094 696 2062 58 2003 46 2061 40 2010 41 330 330 330 330 2010 46 2031 40 41 330 330 2086 61 2010 46 2082 40 41 2003 46 2014 40 2010 41 330 792 2086 630 58 792 470 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 612 2088 40 2003 44 2010 41 58 2095 61 2010 46 2082 40 41 2062 61 2003 46 2063 40 2010 41 2096 61 2062 91 1500 93 330 688 2096 323 2048 46 2068 58 2097 61 362 630 58 2098 61 470 688 2096 60 720 40 2010 46 2075 41 58 2098 61 2010 46 2075 91 2096 93 688 2098 712 470 545 2096 60 720 40 2010 46 2076 41 58 2098 61 2010 46 2076 91 2096 93 2097 61 362 43 2099 40 2098 41 43 362 2100 61 2095 2101 61 2010 46 2043 40 41 46 2102 40 45 1501 41 688 2100 46 832 323 2048 46 2068 545 2101 712 750 470 58 2100 61 2101 792 2010 46 2103 40 41 46 2104 40 2100 46 2105 44 2096 44 2097 44 2048 46 2106 44 45 1501 44 45 1501 44 2100 46 2107 44 2100 46 2108 41 612 2063 40 2003 44 2010 41 58 792 2010 46 2063 40 41 330 330 330 330 330 330 330 330 612 2073 40 2003 44 2081 41 58 688 2081 712 470 58 792 362 2038 61 2081 46 2109 688 2038 712 470 58 688 2081 46 832 323 2048 46 2068 58 2038 61 362 630 58 2038 61 362 43 2099 40 2081 46 832 41 43 362 792 2003 46 2072 40 2038 41 612 2072 40 2003 44 2038 41 58 2038 61 2038 46 2110 40 362 44 362 41 2038 61 2038 46 2110 40 362 44 362 41 2038 61 2038 46 2110 40 362 44 362 41 792 362 43 2038 43 362 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 330 612 2035 40 2003 44 2010 41 58 2040 61 2010 46 2039 46 2040 2111 61 2010 46 2050 2112 61 2113 40 41 870 2111 712 750 470 545 2111 46 2114 325 1500 58 330 2114 61 2040 46 2041 91 2111 46 2114 93 2115 61 2114 46 2091 91 1500 93 2116 61 2040 46 2045 40 2115 46 2117 41 2112 46 2065 40 2116 41 2111 61 2111 46 2118 2112 46 2119 40 2048 46 2049 41 792 2112 330 612 2036 40 2003 44 2010 44 2120 41 58 2121 61 2010 46 2043 40 41 46 2044 40 1501 41 870 2121 340 2048 46 2068 545 750 2121 696 2120 58 2010 46 2031 40 41 2121 61 2010 46 2043 40 41 46 2044 40 1501 41 ,"{'AvgLine': 10, 'CountLine': 615, 'CountStmt': 173, 'MaxNesting': 2, 'AvgLineCode': 8, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 149, 'MaxEssential': 6, 'SumEssential': 30, 'AvgCyclomatic': 2, 'CountLineCode': 194, 'CountStmtDecl': 71, 'MaxCyclomatic': 8, 'SumCyclomatic': 53, 'AvgLineComment': 1, 'CountClassBase': 1, 'CountLineBlank': 32, 'CountDeclMethod': 23, 'CountLineCodeExe': 170, 'CountLineComment': 393, 'CountClassCoupled': 8, 'CountClassDerived': 1, 'CountLineCodeDecl': 71, 'CountDeclMethodAll': 29, 'MaxInheritanceTree': 2, 'RatioCommentToCode': '2.03', 'AvgCyclomaticStrict': 2, 'MaxCyclomaticStrict': 8, 'SumCyclomaticStrict': 59, 'AvgCyclomaticModified': 2, 'MaxCyclomaticModified': 8, 'SumCyclomaticModified': 53, 'CountDeclInstanceMethod': 23, 'CountClassCoupledModified': 6, 'CountDeclInstanceVariable': 6}"
124121,Python,"class HiveCliHook(BaseHook):
    """"""Simple wrapper around the hive CLI.

    It also supports the ``beeline``
    a lighter CLI that runs JDBC and is replacing the heavier
    traditional CLI. To enable ``beeline``, set the use_beeline param in the
    extra field of your connection as in ``{ ""use_beeline"": true }``

    Note that you can also set default hive CLI parameters using the
    ``hive_cli_params`` to be used in your connection as in
    ``{""hive_cli_params"": ""-hiveconf mapred.job.tracker=some.jobtracker:444""}``
    Parameters passed here can be overridden by run_cli's hive_conf param

    The extra connection parameter ``auth`` gets passed as in the ``jdbc``
    connection string as is.

    :param hive_cli_conn_id: Reference to the
        :ref:`Hive CLI connection id <howto/connection:hive_cli>`.
    :type hive_cli_conn_id: str
    :param mapred_queue: queue used by the Hadoop Scheduler (Capacity or Fair)
    :type  mapred_queue: str
    :param mapred_queue_priority: priority within the job queue.
        Possible settings include: VERY_HIGH, HIGH, NORMAL, LOW, VERY_LOW
    :type  mapred_queue_priority: str
    :param mapred_job_name: This name will appear in the jobtracker.
        This can make monitoring easier.
    :type  mapred_job_name: str
    """"""

    conn_name_attr = 'hive_cli_conn_id'
    default_conn_name = 'hive_cli_default'
    conn_type = 'hive_cli'
    hook_name = 'Hive Client Wrapper'

    def __init__(
        self,
        hive_cli_conn_id: str = default_conn_name,
        run_as: Optional[str] = None,
        mapred_queue: Optional[str] = None,
        mapred_queue_priority: Optional[str] = None,
        mapred_job_name: Optional[str] = None,
    ) -> None:
        super().__init__()
        conn = self.get_connection(hive_cli_conn_id)
        self.hive_cli_params: str = conn.extra_dejson.get('hive_cli_params', '')
        self.use_beeline: bool = conn.extra_dejson.get('use_beeline', False)
        self.auth = conn.extra_dejson.get('auth', 'noSasl')
        self.conn = conn
        self.run_as = run_as
        self.sub_process: Any = None

        if mapred_queue_priority:
            mapred_queue_priority = mapred_queue_priority.upper()
            if mapred_queue_priority not in HIVE_QUEUE_PRIORITIES:
                raise AirflowException(
                    f""Invalid Mapred Queue Priority. Valid values are: {', '.join(HIVE_QUEUE_PRIORITIES)}""
                )

        self.mapred_queue = mapred_queue or conf.get('hive', 'default_hive_mapred_queue')
        self.mapred_queue_priority = mapred_queue_priority
        self.mapred_job_name = mapred_job_name

    def _get_proxy_user(self) -> str:
        """"""This function set the proper proxy_user value in case the user overwrite the default.""""""
        conn = self.conn

        proxy_user_value: str = conn.extra_dejson.get('proxy_user', """")
        if proxy_user_value == ""login"" and conn.login:
            return f""hive.server2.proxy.user={conn.login}""
        if proxy_user_value == ""owner"" and self.run_as:
            return f""hive.server2.proxy.user={self.run_as}""
        if proxy_user_value != """":  # There is a custom proxy user
            return f""hive.server2.proxy.user={proxy_user_value}""
        return proxy_user_value  # The default proxy user (undefined)

    def _prepare_cli_cmd(self) -> List[Any]:
        """"""This function creates the command list from available information""""""
        conn = self.conn
        hive_bin = 'hive'
        cmd_extra = []

        if self.use_beeline:
            hive_bin = 'beeline'
            jdbc_url = f""jdbc:hive2://{conn.host}:{conn.port}/{conn.schema}""
            if conf.get('core', 'security') == 'kerberos':
                template = conn.extra_dejson.get('principal', ""hive/_HOST@EXAMPLE.COM"")
                if ""_HOST"" in template:
                    template = utils.replace_hostname_pattern(utils.get_components(template))

                proxy_user = self._get_proxy_user()

                jdbc_url += f"";principal={template};{proxy_user}""
            elif self.auth:
                jdbc_url += "";auth="" + self.auth

            jdbc_url = f'""{jdbc_url}""'

            cmd_extra += ['-u', jdbc_url]
            if conn.login:
                cmd_extra += ['-n', conn.login]
            if conn.password:
                cmd_extra += ['-p', conn.password]

        hive_params_list = self.hive_cli_params.split()

        return [hive_bin] + cmd_extra + hive_params_list

    @staticmethod
    def _prepare_hiveconf(d: Dict[Any, Any]) -> List[Any]:
        """"""
        This function prepares a list of hiveconf params
        from a dictionary of key value pairs.

        :param d:
        :type d: dict

        >>> hh = HiveCliHook()
        >>> hive_conf = {""hive.exec.dynamic.partition"": ""true"",
        ... ""hive.exec.dynamic.partition.mode"": ""nonstrict""}
        >>> hh._prepare_hiveconf(hive_conf)
        [""-hiveconf"", ""hive.exec.dynamic.partition=true"",\
        ""-hiveconf"", ""hive.exec.dynamic.partition.mode=nonstrict""]
        """"""
        if not d:
            return []
        return as_flattened_list(zip([""-hiveconf""] * len(d), [f""{k}={v}"" for k, v in d.items()]))

    def run_cli(
        self,
        hql: str,
        schema: Optional[str] = None,
        verbose: bool = True,
        hive_conf: Optional[Dict[Any, Any]] = None,
    ) -> Any:
        """"""
        Run an hql statement using the hive cli. If hive_conf is specified
        it should be a dict and the entries will be set as key/value pairs
        in HiveConf.

        :param hql: an hql (hive query language) statement to run with hive cli
        :type hql: str
        :param schema: Name of hive schema (database) to use
        :type schema: str
        :param verbose: Provides additional logging. Defaults to True.
        :type verbose: bool
        :param hive_conf: if specified these key value pairs will be passed
            to hive as ``-hiveconf ""key""=""value""``. Note that they will be
            passed after the ``hive_cli_params`` and thus will override
            whatever values are specified in the database.
        :type hive_conf: dict

        >>> hh = HiveCliHook()
        >>> result = hh.run_cli(""USE airflow;"")
        >>> (""OK"" in result)
        True
        """"""
        conn = self.conn
        schema = schema or conn.schema
        if schema:
            hql = f""USE {schema};\n{hql}""

        with TemporaryDirectory(prefix='airflow_hiveop_') as tmp_dir:
            with NamedTemporaryFile(dir=tmp_dir) as f:
                hql += '\n'
                f.write(hql.encode('UTF-8'))
                f.flush()
                hive_cmd = self._prepare_cli_cmd()
                env_context = get_context_from_env_var()
                # Only extend the hive_conf if it is defined.
                if hive_conf:
                    env_context.update(hive_conf)
                hive_conf_params = self._prepare_hiveconf(env_context)
                if self.mapred_queue:
                    hive_conf_params.extend(
                        [
                            '-hiveconf',
                            f'mapreduce.job.queuename={self.mapred_queue}',
                            '-hiveconf',
                            f'mapred.job.queue.name={self.mapred_queue}',
                            '-hiveconf',
                            f'tez.queue.name={self.mapred_queue}',
                        ]
                    )

                if self.mapred_queue_priority:
                    hive_conf_params.extend(
                        ['-hiveconf', f'mapreduce.job.priority={self.mapred_queue_priority}']
                    )

                if self.mapred_job_name:
                    hive_conf_params.extend(['-hiveconf', f'mapred.job.name={self.mapred_job_name}'])

                hive_cmd.extend(hive_conf_params)
                hive_cmd.extend(['-f', f.name])

                if verbose:
                    self.log.info(""%s"", "" "".join(hive_cmd))
                sub_process: Any = subprocess.Popen(
                    hive_cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, cwd=tmp_dir, close_fds=True
                )
                self.sub_process = sub_process
                stdout = ''
                while True:
                    line = sub_process.stdout.readline()
                    if not line:
                        break
                    stdout += line.decode('UTF-8')
                    if verbose:
                        self.log.info(line.decode('UTF-8').strip())
                sub_process.wait()

                if sub_process.returncode:
                    raise AirflowException(stdout)

                return stdout

    def test_hql(self, hql: str) -> None:
        """"""Test an hql statement using the hive cli and EXPLAIN""""""
        create, insert, other = [], [], []
        for query in hql.split(';'):  # naive
            query_original = query
            query = query.lower().strip()

            if query.startswith('create table'):
                create.append(query_original)
            elif query.startswith(('set ', 'add jar ', 'create temporary function')):
                other.append(query_original)
            elif query.startswith('insert'):
                insert.append(query_original)
        other_ = ';'.join(other)
        for query_set in [create, insert]:
            for query in query_set:

                query_preview = ' '.join(query.split())[:50]
                self.log.info(""Testing HQL [%s (...)]"", query_preview)
                if query_set == insert:
                    query = other_ + '; explain ' + query
                else:
                    query = 'explain ' + query
                try:
                    self.run_cli(query, verbose=False)
                except AirflowException as e:
                    message = e.args[0].split('\n')[-2]
                    self.log.info(message)
                    error_loc = re.search(r'(\d+):(\d+)', message)
                    if error_loc and error_loc.group(1).isdigit():
                        lst = int(error_loc.group(1))
                        begin = max(lst - 2, 0)
                        end = min(lst + 3, len(query.split('\n')))
                        context = '\n'.join(query.split('\n')[begin:end])
                        self.log.info(""Context :\n %s"", context)
                else:
                    self.log.info(""SUCCESS"")

    def load_df(
        self,
        df: pandas.DataFrame,
        table: str,
        field_dict: Optional[Dict[Any, Any]] = None,
        delimiter: str = ',',
        encoding: str = 'utf8',
        pandas_kwargs: Any = None,
        **kwargs: Any,
    ) -> None:
        """"""
        Loads a pandas DataFrame into hive.

        Hive data types will be inferred if not passed but column names will
        not be sanitized.

        :param df: DataFrame to load into a Hive table
        :type df: pandas.DataFrame
        :param table: target Hive table, use dot notation to target a
            specific database
        :type table: str
        :param field_dict: mapping from column name to hive data type.
            Note that it must be OrderedDict so as to keep columns' order.
        :type field_dict: collections.OrderedDict
        :param delimiter: field delimiter in the file
        :type delimiter: str
        :param encoding: str encoding to use when writing DataFrame to file
        :type encoding: str
        :param pandas_kwargs: passed to DataFrame.to_csv
        :type pandas_kwargs: dict
        :param kwargs: passed to self.load_file
        """"""

        def _infer_field_types_from_df(df: pandas.DataFrame) -> Dict[Any, Any]:
            dtype_kind_hive_type = {
                'b': 'BOOLEAN',  # boolean
                'i': 'BIGINT',  # signed integer
                'u': 'BIGINT',  # unsigned integer
                'f': 'DOUBLE',  # floating-point
                'c': 'STRING',  # complex floating-point
                'M': 'TIMESTAMP',  # datetime
                'O': 'STRING',  # object
                'S': 'STRING',  # (byte-)string
                'U': 'STRING',  # Unicode
                'V': 'STRING',  # void
            }

            order_type = OrderedDict()
            for col, dtype in df.dtypes.iteritems():
                order_type[col] = dtype_kind_hive_type[dtype.kind]
            return order_type

        if pandas_kwargs is None:
            pandas_kwargs = {}

        with TemporaryDirectory(prefix='airflow_hiveop_') as tmp_dir:
            with NamedTemporaryFile(dir=tmp_dir, mode=""w"") as f:
                if field_dict is None:
                    field_dict = _infer_field_types_from_df(df)

                df.to_csv(
                    path_or_buf=f,
                    sep=delimiter,
                    header=False,
                    index=False,
                    encoding=encoding,
                    date_format=""%Y-%m-%d %H:%M:%S"",
                    **pandas_kwargs,
                )
                f.flush()

                return self.load_file(
                    filepath=f.name, table=table, delimiter=delimiter, field_dict=field_dict, **kwargs
                )

    def load_file(
        self,
        filepath: str,
        table: str,
        delimiter: str = "","",
        field_dict: Optional[Dict[Any, Any]] = None,
        create: bool = True,
        overwrite: bool = True,
        partition: Optional[Dict[str, Any]] = None,
        recreate: bool = False,
        tblproperties: Optional[Dict[str, Any]] = None,
    ) -> None:
        """"""
        Loads a local file into Hive

        Note that the table generated in Hive uses ``STORED AS textfile``
        which isn't the most efficient serialization format. If a
        large amount of data is loaded and/or if the tables gets
        queried considerably, you may want to use this operator only to
        stage the data into a temporary table before loading it into its
        final destination using a ``HiveOperator``.

        :param filepath: local filepath of the file to load
        :type filepath: str
        :param table: target Hive table, use dot notation to target a
            specific database
        :type table: str
        :param delimiter: field delimiter in the file
        :type delimiter: str
        :param field_dict: A dictionary of the fields name in the file
            as keys and their Hive types as values.
            Note that it must be OrderedDict so as to keep columns' order.
        :type field_dict: collections.OrderedDict
        :param create: whether to create the table if it doesn't exist
        :type create: bool
        :param overwrite: whether to overwrite the data in table or partition
        :type overwrite: bool
        :param partition: target partition as a dict of partition columns
            and values
        :type partition: dict
        :param recreate: whether to drop and recreate the table at every
            execution
        :type recreate: bool
        :param tblproperties: TBLPROPERTIES of the hive table being created
        :type tblproperties: dict
        """"""
        hql = ''
        if recreate:
            hql += f""DROP TABLE IF EXISTS {table};\n""
        if create or recreate:
            if field_dict is None:
                raise ValueError(""Must provide a field dict when creating a table"")
            fields = "",\n    "".join(f""`{k.strip('`')}` {v}"" for k, v in field_dict.items())
            hql += f""CREATE TABLE IF NOT EXISTS {table} (\n{fields})\n""
            if partition:
                pfields = "",\n    "".join(p + "" STRING"" for p in partition)
                hql += f""PARTITIONED BY ({pfields})\n""
            hql += ""ROW FORMAT DELIMITED\n""
            hql += f""FIELDS TERMINATED BY '{delimiter}'\n""
            hql += ""STORED AS textfile\n""
            if tblproperties is not None:
                tprops = "", "".join(f""'{k}'='{v}'"" for k, v in tblproperties.items())
                hql += f""TBLPROPERTIES({tprops})\n""
            hql += "";""
            self.log.info(hql)
            self.run_cli(hql)
        hql = f""LOAD DATA LOCAL INPATH '{filepath}' ""
        if overwrite:
            hql += ""OVERWRITE ""
        hql += f""INTO TABLE {table} ""
        if partition:
            pvals = "", "".join(f""{k}='{v}'"" for k, v in partition.items())
            hql += f""PARTITION ({pvals})""

        # As a workaround for HIVE-10541, add a newline character
        # at the end of hql (AIRFLOW-2412).
        hql += ';\n'

        self.log.info(hql)
        self.run_cli(hql)

    def kill(self) -> None:
        """"""Kill Hive cli command""""""
        if hasattr(self, 'sub_process'):
            if self.sub_process.poll() is None:
                print(""Killing the Hive job"")
                self.sub_process.terminate()
                time.sleep(60)
                self.sub_process.kill()",1,587 2000 40 2001 41 58 362 2002 61 362 2003 61 362 2004 61 362 2005 61 362 612 2006 40 2007 44 2008 58 813 61 2003 44 2009 58 2010 91 813 93 61 470 44 2011 58 2010 91 813 93 61 470 44 2012 58 2010 91 813 93 61 470 44 2013 58 2010 91 813 93 61 470 44 41 354 470 58 818 40 41 46 2006 40 41 2014 61 2007 46 2015 40 2008 41 2007 46 2016 58 813 61 2014 46 2017 46 2018 40 362 44 362 41 2007 46 2019 58 569 61 2014 46 2017 46 2018 40 362 44 443 41 2007 46 2020 61 2014 46 2017 46 2018 40 362 44 362 41 2007 46 2014 61 2014 2007 46 2009 61 2009 2007 46 2021 58 2022 61 470 688 2012 58 2012 61 2012 46 2023 40 41 688 2012 750 696 2024 58 778 2025 40 362 41 2007 46 2011 61 2011 759 2026 46 2018 40 362 44 362 41 2007 46 2012 61 2012 2007 46 2013 61 2013 612 2027 40 2007 41 354 813 58 362 2014 61 2007 46 2014 2028 58 813 61 2014 46 2017 46 2018 40 362 44 362 41 688 2028 323 362 545 2014 46 2029 58 792 362 688 2028 323 362 545 2007 46 2009 58 792 362 688 2028 340 362 58 330 792 362 792 2028 330 612 2030 40 2007 41 354 2031 91 2022 93 58 362 2014 61 2007 46 2014 2032 61 362 2033 61 91 93 688 2007 46 2019 58 2032 61 362 2034 61 362 688 2026 46 2018 40 362 44 362 41 323 362 58 2035 61 2014 46 2017 46 2018 40 362 44 362 41 688 362 696 2035 58 2035 61 2036 46 2037 40 2036 46 2038 40 2035 41 41 2039 61 2007 46 2027 40 41 2034 348 362 629 2007 46 2020 58 2034 348 362 43 2007 46 2020 2034 61 362 2033 348 91 362 44 2034 93 688 2014 46 2029 58 2033 348 91 362 44 2014 46 2029 93 688 2014 46 2040 58 2033 348 91 362 44 2014 46 2040 93 2041 61 2007 46 2016 46 2042 40 41 792 91 2032 93 43 2033 43 2041 64 812 612 2043 40 2044 58 2045 91 2022 44 2022 93 41 354 2031 91 2022 93 58 362 688 750 2044 58 792 91 93 792 2046 40 875 40 91 362 93 42 720 40 2044 41 44 91 362 664 2047 44 2048 696 2044 46 2049 40 41 93 41 41 612 2050 40 2007 44 2051 58 813 44 2052 58 2010 91 813 93 61 470 44 2053 58 569 61 515 44 2054 58 2010 91 2045 91 2022 44 2022 93 93 61 470 44 41 354 2022 58 362 2014 61 2007 46 2014 2052 61 2052 759 2014 46 2052 688 2052 58 2051 61 362 871 2055 40 2056 61 362 41 552 2057 58 871 2058 40 622 61 2057 41 552 2059 58 2051 348 362 2059 46 2060 40 2051 46 2061 40 362 41 41 2059 46 2062 40 41 2063 61 2007 46 2030 40 41 2064 61 2065 40 41 330 688 2054 58 2064 46 2066 40 2054 41 2067 61 2007 46 2043 40 2064 41 688 2007 46 2011 58 2067 46 2068 40 91 362 44 362 44 362 44 362 44 362 44 362 44 93 41 688 2007 46 2012 58 2067 46 2068 40 91 362 44 362 93 41 688 2007 46 2013 58 2067 46 2068 40 91 362 44 362 93 41 2063 46 2068 40 2067 41 2063 46 2068 40 91 362 44 2059 46 2069 93 41 688 2053 58 2007 46 2070 46 2071 40 362 44 362 46 2072 40 2063 41 41 2021 58 2022 61 2073 46 2074 40 2063 44 2075 61 2073 46 2076 44 2077 61 2073 46 2078 44 2079 61 2057 44 2080 61 515 41 2007 46 2021 61 2021 2075 61 362 870 515 58 2081 61 2021 46 2075 46 2082 40 41 688 750 2081 58 572 2075 348 2081 46 2083 40 362 41 688 2053 58 2007 46 2070 46 2071 40 2081 46 2083 40 362 41 46 2084 40 41 41 2021 46 2085 40 41 688 2021 46 2086 58 778 2025 40 2075 41 792 2075 612 2087 40 2007 44 2051 58 813 41 354 470 58 362 2088 44 2089 44 2090 61 91 93 44 91 93 44 91 93 664 2091 696 2051 46 2042 40 362 41 58 330 2092 61 2091 2091 61 2091 46 2093 40 41 46 2084 40 41 688 2091 46 2094 40 362 41 58 2088 46 2095 40 2092 41 629 2091 46 2094 40 40 362 44 362 44 362 41 41 58 2090 46 2095 40 2092 41 629 2091 46 2094 40 362 41 58 2089 46 2095 40 2092 41 2096 61 362 46 2072 40 2090 41 664 2097 696 91 2088 44 2089 93 58 664 2091 696 2097 58 2098 61 362 46 2072 40 2091 46 2042 40 41 41 91 58 1503 93 2007 46 2070 46 2071 40 362 44 2098 41 688 2097 323 2089 58 2091 61 2096 43 362 43 2091 630 58 2091 61 362 43 2091 830 58 2007 46 2050 40 2091 44 2053 61 443 41 645 2025 552 2099 58 2100 61 2099 46 2101 91 1500 93 46 2042 40 362 41 91 45 1502 93 2007 46 2070 46 2071 40 2100 41 2102 61 2103 46 2104 40 362 44 2100 41 688 2102 545 2102 46 2105 40 1501 41 46 2106 40 41 58 2107 61 704 40 2102 46 2105 40 1501 41 41 2108 61 733 40 2107 45 1502 44 1500 41 2109 61 735 40 2107 43 1502 44 720 40 2091 46 2042 40 362 41 41 41 2110 61 362 46 2072 40 2091 46 2042 40 362 41 91 2108 58 2109 93 41 2007 46 2070 46 2071 40 362 44 2110 41 630 58 2007 46 2070 46 2071 40 362 41 612 2111 40 2007 44 2112 58 2113 46 2114 44 2115 58 813 44 2116 58 2010 91 2045 91 2022 44 2022 93 93 61 470 44 2117 58 813 61 362 44 2118 58 813 61 362 44 2119 58 2022 61 470 44 350 2120 58 2022 44 41 354 470 58 362 612 2121 40 2112 58 2113 46 2114 41 354 2045 91 2022 44 2022 93 58 2122 61 123 362 58 362 44 330 362 58 362 44 330 362 58 362 44 330 362 58 362 44 330 362 58 362 44 330 362 58 362 44 330 362 58 362 44 330 362 58 362 44 330 362 58 362 44 330 362 58 362 44 330 125 2123 61 2124 40 41 664 2125 44 2126 696 2112 46 2127 46 2128 40 41 58 2123 91 2125 93 61 2122 91 2126 46 2129 93 792 2123 688 2119 712 470 58 2119 61 123 125 871 2055 40 2056 61 362 41 552 2057 58 871 2058 40 622 61 2057 44 2130 61 362 41 552 2059 58 688 2116 712 470 58 2116 61 2121 40 2112 41 2112 46 2131 40 2132 61 2059 44 2133 61 2117 44 2134 61 443 44 2135 61 443 44 2118 61 2118 44 2136 61 362 44 350 2119 44 41 2059 46 2062 40 41 792 2007 46 2137 40 2138 61 2059 46 2069 44 2115 61 2115 44 2117 61 2117 44 2116 61 2116 44 350 2120 41 612 2137 40 2007 44 2138 58 813 44 2115 58 813 44 2117 58 813 61 362 44 2116 58 2010 91 2045 91 2022 44 2022 93 93 61 470 44 2088 58 569 61 515 44 2139 58 569 61 515 44 2140 58 2010 91 2045 91 813 44 2022 93 93 61 470 44 2141 58 569 61 443 44 2142 58 2010 91 2045 91 813 44 2022 93 93 61 470 44 41 354 470 58 362 2051 61 362 688 2141 58 2051 348 362 688 2088 759 2141 58 688 2116 712 470 58 778 2143 40 362 41 2144 61 362 46 2072 40 362 664 2047 44 2048 696 2116 46 2049 40 41 41 2051 348 362 688 2140 58 2145 61 362 46 2072 40 2146 43 362 664 2146 696 2140 41 2051 348 362 2051 348 362 2051 348 362 2051 348 362 688 2142 712 750 470 58 2147 61 362 46 2072 40 362 664 2047 44 2048 696 2142 46 2049 40 41 41 2051 348 362 2051 348 362 2007 46 2070 46 2071 40 2051 41 2007 46 2050 40 2051 41 2051 61 362 688 2139 58 2051 348 362 2051 348 362 688 2140 58 2148 61 362 46 2072 40 362 664 2047 44 2048 696 2140 46 2049 40 41 41 2051 348 362 330 330 2051 348 362 2007 46 2070 46 2071 40 2051 41 2007 46 2050 40 2051 41 612 2149 40 2007 41 354 470 58 362 688 678 40 2007 44 362 41 58 688 2007 46 2021 46 2150 40 41 712 470 58 770 40 362 41 2007 46 2021 46 2151 40 41 2152 46 2153 40 1503 41 2007 46 2021 46 2149 40 41 ,"{'AvgLine': 39, 'CountLine': 418, 'CountStmt': 181, 'MaxNesting': 4, 'AvgLineCode': 26, 'AvgEssential': 1, 'AvgLineBlank': 3, 'CountStmtExe': 170, 'MaxEssential': 4, 'SumEssential': 19, 'AvgCyclomatic': 5, 'CountLineCode': 255, 'CountStmtDecl': 59, 'MaxCyclomatic': 11, 'SumCyclomatic': 53, 'AvgLineComment': 11, 'CountClassBase': 1, 'CountLineBlank': 49, 'CountDeclMethod': 9, 'CountLineCodeExe': 210, 'CountLineComment': 127, 'CountClassCoupled': 5, 'CountClassDerived': 1, 'CountLineCodeDecl': 98, 'CountDeclMethodAll': 16, 'MaxInheritanceTree': 2, 'RatioCommentToCode': '0.50', 'AvgCyclomaticStrict': 5, 'MaxCyclomaticStrict': 12, 'SumCyclomaticStrict': 59, 'AvgCyclomaticModified': 5, 'MaxCyclomaticModified': 11, 'SumCyclomaticModified': 53, 'CountDeclInstanceMethod': 8, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 7}"
128609,Python,"class TokenStreamRewriter(object):
    DEFAULT_PROGRAM_NAME = ""default""
    PROGRAM_INIT_SIZE = 100
    MIN_TOKEN_INDEX = 0

    def __init__(self, tokens):
        """"""
        :type  tokens: antlr4.BufferedTokenStream.BufferedTokenStream
        :param tokens:
        :return:
        """"""
        super(TokenStreamRewriter, self).__init__()
        self.tokens = tokens
        self.programs = {self.DEFAULT_PROGRAM_NAME: []}
        self.lastRewriteTokenIndexes = {}

    def getTokenStream(self):
        return self.tokens

    def rollback(self, instruction_index, program_name):
        ins = self.programs.get(program_name, None)
        if ins:
            self.programs[program_name] = ins[self.MIN_TOKEN_INDEX: instruction_index]

    def deleteProgram(self, program_name=DEFAULT_PROGRAM_NAME):
        self.rollback(self.MIN_TOKEN_INDEX, program_name)

    def insertAfterToken(self, token, text, program_name=DEFAULT_PROGRAM_NAME):
        self.insertAfter(token.tokenIndex, text, program_name)

    def insertAfter(self, index, text, program_name=DEFAULT_PROGRAM_NAME):
        op = self.InsertAfterOp(self.tokens, index + 1, text)
        rewrites = self.getProgram(program_name)
        op.instructionIndex = len(rewrites)
        rewrites.append(op)

    def insertBeforeIndex(self, index, text):
        self.insertBefore(self.DEFAULT_PROGRAM_NAME, index, text)

    def insertBeforeToken(self, token, text, program_name=DEFAULT_PROGRAM_NAME):
        self.insertBefore(program_name, token.tokenIndex, text)

    def insertBefore(self, program_name, index, text):
        op = self.InsertBeforeOp(self.tokens, index, text)
        rewrites = self.getProgram(program_name)
        op.instructionIndex = len(rewrites)
        rewrites.append(op)

    def replaceIndex(self, index, text):
        self.replace(self.DEFAULT_PROGRAM_NAME, index, index, text)

    def replaceRange(self, from_idx, to_idx, text):
        self.replace(self.DEFAULT_PROGRAM_NAME, from_idx, to_idx, text)

    def replaceSingleToken(self, token, text):
        self.replace(self.DEFAULT_PROGRAM_NAME, token.tokenIndex, token.tokenIndex, text)

    def replaceRangeTokens(self, from_token, to_token, text, program_name=DEFAULT_PROGRAM_NAME):
        self.replace(program_name, from_token.tokenIndex, to_token.tokenIndex, text)

    def replace(self, program_name, from_idx, to_idx, text):
        if any((from_idx > to_idx, from_idx < 0, to_idx < 0, to_idx >= len(self.tokens.tokens))):
            raise ValueError(
                'replace: range invalid: {}..{}(size={})'.format(from_idx, to_idx, len(self.tokens.tokens)))
        op = self.ReplaceOp(from_idx, to_idx, self.tokens, text)
        rewrites = self.getProgram(program_name)
        op.instructionIndex = len(rewrites)
        rewrites.append(op)

    def deleteToken(self, token):
        self.delete(self.DEFAULT_PROGRAM_NAME, token, token)

    def deleteIndex(self, index):
        self.delete(self.DEFAULT_PROGRAM_NAME, index, index)

    def delete(self, program_name, from_idx, to_idx):
        if isinstance(from_idx, Token):
            self.replace(program_name, from_idx.tokenIndex, to_idx.tokenIndex, """")
        else:
            self.replace(program_name, from_idx, to_idx, """")

    def lastRewriteTokenIndex(self, program_name=DEFAULT_PROGRAM_NAME):
        return self.lastRewriteTokenIndexes.get(program_name, -1)

    def setLastRewriteTokenIndex(self, program_name, i):
        self.lastRewriteTokenIndexes[program_name] = i

    def getProgram(self, program_name):
        return self.programs.setdefault(program_name, [])

    def getDefaultText(self):
        return self.getText(self.DEFAULT_PROGRAM_NAME, 0, len(self.tokens.tokens) - 1)

    def getText(self, program_name, start, stop):
        """"""
        :return: the text in tokens[start, stop](closed interval)
        """"""
        rewrites = self.programs.get(program_name)

        # ensure start/end are in range
        if stop > len(self.tokens.tokens) - 1:
            stop = len(self.tokens.tokens) - 1
        if start < 0:
            start = 0

        # if no instructions to execute
        if not rewrites: return self.tokens.getText(start, stop)
        buf = StringIO()
        indexToOp = self._reduceToSingleOperationPerIndex(rewrites)
        i = start
        while all((i <= stop, i < len(self.tokens.tokens))):
            op = indexToOp.pop(i, None)
            token = self.tokens.get(i)
            if op is None:
                if token.type != Token.EOF: buf.write(token.text)
                i += 1
            else:
                i = op.execute(buf)

        if stop == len(self.tokens.tokens) - 1:
            for op in indexToOp.values():
                if op.index >= len(self.tokens.tokens) - 1: buf.write(
                    op.text)  # TODO: this check is probably not needed

        return buf.getvalue()

    def _reduceToSingleOperationPerIndex(self, rewrites):
        # Walk replaces
        for i, rop in enumerate(rewrites):
            if any((rop is None, not isinstance(rop, TokenStreamRewriter.ReplaceOp))):
                continue
            # Wipe prior inserts within range
            inserts = [op for op in rewrites[:i] if type(op) is TokenStreamRewriter.InsertBeforeOp]
            for iop in inserts:
                if iop.index == rop.index:
                    rewrites[iop.instructionIndex] = None
                    rop.text = '{}{}'.format(iop.text, rop.text)
                elif all((iop.index > rop.index, iop.index <= rop.last_index)):
                    rewrites[iop.instructionIndex] = None

            # Drop any prior replaces contained within
            prevReplaces = [op for op in rewrites[:i] if type(op) is TokenStreamRewriter.ReplaceOp]
            for prevRop in prevReplaces:
                if all((prevRop.index >= rop.index, prevRop.last_index <= rop.last_index)):
                    rewrites[prevRop.instructionIndex] = None
                    continue
                isDisjoint = any((prevRop.last_index < rop.index, prevRop.index > rop.last_index))
                if all((prevRop.text is None, rop.text is None, not isDisjoint)):
                    rewrites[prevRop.instructionIndex] = None
                    rop.index = min(prevRop.index, rop.index)
                    rop.last_index = min(prevRop.last_index, rop.last_index)
                    print('New rop {}'.format(rop))
                elif (not(isDisjoint)):
                    raise ValueError(""replace op boundaries of {} overlap with previous {}"".format(rop, prevRop))

        # Walk inserts before
        for i, iop in enumerate(rewrites):
            if any((iop is None, not isinstance(iop, TokenStreamRewriter.InsertBeforeOp))):
                continue
            prevInserts = [op for op in rewrites[:i] if isinstance(op, TokenStreamRewriter.InsertBeforeOp)]
            for prev_index, prevIop in enumerate(prevInserts):
                if prevIop.index == iop.index and type(prevIop) is TokenStreamRewriter.InsertBeforeOp:
                    iop.text += prevIop.text
                    rewrites[prev_index] = None
                elif prevIop.index == iop.index and type(prevIop) is TokenStreamRewriter.InsertAfterOp:
                    iop.text = prevIop.text + iop.text
                    rewrites[prev_index] = None
            # look for replaces where iop.index is in range; error
            prevReplaces = [op for op in rewrites[:i] if type(op) is TokenStreamRewriter.ReplaceOp]
            for rop in prevReplaces:
                if iop.index == rop.index:
                    rop.text = iop.text + rop.text
                    rewrites[i] = None
                    continue
                if all((iop.index >= rop.index, iop.index <= rop.last_index)):
                    raise ValueError(""insert op {} within boundaries of previous {}"".format(iop, rop))

        reduced = {}
        for i, op in enumerate(rewrites):
            if op is None: continue
            if reduced.get(op.index): raise ValueError('should be only one op per index')
            reduced[op.index] = op

        return reduced

    class RewriteOperation(object):

        def __init__(self, tokens, index, text=""""):
            """"""
            :type tokens: CommonTokenStream
            :param tokens:
            :param index:
            :param text:
            :return:
            """"""
            self.tokens = tokens
            self.index = index
            self.text = text
            self.instructionIndex = 0

        def execute(self, buf):
            """"""
            :type buf: StringIO.StringIO
            :param buf:
            :return:
            """"""
            return self.index

        def __str__(self):
            return '<{}@{}:""{}"">'.format(self.__class__.__name__, self.tokens.get(self.index), self.text)

    class InsertBeforeOp(RewriteOperation):

        def __init__(self, tokens, index, text=""""):
            super(TokenStreamRewriter.InsertBeforeOp, self).__init__(tokens, index, text)

        def execute(self, buf):
            buf.write(self.text)
            if self.tokens.get(self.index).type != Token.EOF:
                buf.write(self.tokens.get(self.index).text)
            return self.index + 1

    class InsertAfterOp(InsertBeforeOp):
        pass

    class ReplaceOp(RewriteOperation):

        def __init__(self, from_idx, to_idx, tokens, text):
            super(TokenStreamRewriter.ReplaceOp, self).__init__(tokens, from_idx, text)
            self.last_index = to_idx

        def execute(self, buf):
            if self.text:
                buf.write(self.text)
            return self.last_index + 1

        def __str__(self):
            if self.text:
                return '<ReplaceOp@{}..{}:""{}"">'.format(self.tokens.get(self.index), self.tokens.get(self.last_index),
                                                        self.text)",1,587 2000 40 755 41 58 2001 61 362 2002 61 1503 2003 61 1500 612 2004 40 2005 44 2006 41 58 362 818 40 2000 44 2005 41 46 2004 40 41 2005 46 2006 61 2006 2005 46 2007 61 123 2005 46 2001 58 91 93 125 2005 46 2008 61 123 125 612 2009 40 2005 41 58 792 2005 46 2006 612 2010 40 2005 44 2011 44 2012 41 58 2013 61 2005 46 2007 46 2014 40 2012 44 470 41 688 2013 58 2005 46 2007 91 2012 93 61 2013 91 2005 46 2003 58 2011 93 612 2015 40 2005 44 2012 61 2001 41 58 2005 46 2010 40 2005 46 2003 44 2012 41 612 2016 40 2005 44 2017 44 2018 44 2012 61 2001 41 58 2005 46 2019 40 2017 46 2020 44 2018 44 2012 41 612 2019 40 2005 44 2021 44 2018 44 2012 61 2001 41 58 2022 61 2005 46 2023 40 2005 46 2006 44 2021 43 1501 44 2018 41 2024 61 2005 46 2025 40 2012 41 2022 46 2026 61 720 40 2024 41 2024 46 2027 40 2022 41 612 2028 40 2005 44 2021 44 2018 41 58 2005 46 2029 40 2005 46 2001 44 2021 44 2018 41 612 2030 40 2005 44 2017 44 2018 44 2012 61 2001 41 58 2005 46 2029 40 2012 44 2017 46 2020 44 2018 41 612 2029 40 2005 44 2012 44 2021 44 2018 41 58 2022 61 2005 46 2031 40 2005 46 2006 44 2021 44 2018 41 2024 61 2005 46 2025 40 2012 41 2022 46 2026 61 720 40 2024 41 2024 46 2027 40 2022 41 612 2032 40 2005 44 2021 44 2018 41 58 2005 46 2033 40 2005 46 2001 44 2021 44 2021 44 2018 41 612 2034 40 2005 44 2035 44 2036 44 2018 41 58 2005 46 2033 40 2005 46 2001 44 2035 44 2036 44 2018 41 612 2037 40 2005 44 2017 44 2018 41 58 2005 46 2033 40 2005 46 2001 44 2017 46 2020 44 2017 46 2020 44 2018 41 612 2038 40 2005 44 2039 44 2040 44 2018 44 2012 61 2001 41 58 2005 46 2033 40 2012 44 2039 46 2020 44 2040 46 2020 44 2018 41 612 2033 40 2005 44 2012 44 2035 44 2036 44 2018 41 58 688 548 40 40 2035 62 2036 44 2035 60 1500 44 2036 60 1500 44 2036 325 720 40 2005 46 2006 46 2006 41 41 41 58 778 2041 40 362 46 666 40 2035 44 2036 44 720 40 2005 46 2006 46 2006 41 41 41 2022 61 2005 46 2042 40 2035 44 2036 44 2005 46 2006 44 2018 41 2024 61 2005 46 2025 40 2012 41 2022 46 2026 61 720 40 2024 41 2024 46 2027 40 2022 41 612 2043 40 2005 44 2017 41 58 2005 46 2044 40 2005 46 2001 44 2017 44 2017 41 612 2045 40 2005 44 2021 41 58 2005 46 2044 40 2005 46 2001 44 2021 44 2021 41 612 2044 40 2005 44 2012 44 2035 44 2036 41 58 688 713 40 2035 44 2046 41 58 2005 46 2033 40 2012 44 2035 46 2020 44 2036 46 2020 44 362 41 630 58 2005 46 2033 40 2012 44 2035 44 2036 44 362 41 612 2047 40 2005 44 2012 61 2001 41 58 792 2005 46 2008 46 2014 40 2012 44 45 1501 41 612 2048 40 2005 44 2012 44 2049 41 58 2005 46 2008 91 2012 93 61 2049 612 2025 40 2005 44 2012 41 58 792 2005 46 2007 46 2050 40 2012 44 91 93 41 612 2051 40 2005 41 58 792 2005 46 2052 40 2005 46 2001 44 1500 44 720 40 2005 46 2006 46 2006 41 45 1501 41 612 2052 40 2005 44 2012 44 2053 44 2054 41 58 362 2024 61 2005 46 2007 46 2014 40 2012 41 330 688 2054 62 720 40 2005 46 2006 46 2006 41 45 1501 58 2054 61 720 40 2005 46 2006 46 2006 41 45 1501 688 2053 60 1500 58 2053 61 1500 330 688 750 2024 58 792 2005 46 2006 46 2052 40 2053 44 2054 41 2055 61 2056 40 41 2057 61 2005 46 2058 40 2024 41 2049 61 2053 870 544 40 40 2049 329 2054 44 2049 60 720 40 2005 46 2006 46 2006 41 41 41 58 2022 61 2057 46 2059 40 2049 44 470 41 2017 61 2005 46 2006 46 2014 40 2049 41 688 2022 712 470 58 688 2017 46 832 340 2046 46 2060 58 2055 46 2061 40 2017 46 2018 41 2049 348 1501 630 58 2049 61 2022 46 2062 40 2055 41 688 2054 323 720 40 2005 46 2006 46 2006 41 45 1501 58 664 2022 696 2057 46 2063 40 41 58 688 2022 46 2021 325 720 40 2005 46 2006 46 2006 41 45 1501 58 2055 46 2061 40 2022 46 2018 41 330 792 2055 46 2064 40 41 612 2058 40 2005 44 2024 41 58 330 664 2049 44 2065 696 641 40 2024 41 58 688 548 40 40 2065 712 470 44 750 713 40 2065 44 2000 46 2042 41 41 41 58 605 330 2066 61 91 2022 664 2022 696 2024 91 58 2049 93 688 832 40 2022 41 712 2000 46 2031 93 664 2067 696 2066 58 688 2067 46 2021 323 2065 46 2021 58 2024 91 2067 46 2026 93 61 470 2065 46 2018 61 362 46 666 40 2067 46 2018 44 2065 46 2018 41 629 544 40 40 2067 46 2021 62 2065 46 2021 44 2067 46 2021 329 2065 46 2068 41 41 58 2024 91 2067 46 2026 93 61 470 330 2069 61 91 2022 664 2022 696 2024 91 58 2049 93 688 832 40 2022 41 712 2000 46 2042 93 664 2070 696 2069 58 688 544 40 40 2070 46 2021 325 2065 46 2021 44 2070 46 2068 329 2065 46 2068 41 41 58 2024 91 2070 46 2026 93 61 470 605 2071 61 548 40 40 2070 46 2068 60 2065 46 2021 44 2070 46 2021 62 2065 46 2068 41 41 688 544 40 40 2070 46 2018 712 470 44 2065 46 2018 712 470 44 750 2071 41 41 58 2024 91 2070 46 2026 93 61 470 2065 46 2021 61 735 40 2070 46 2021 44 2065 46 2021 41 2065 46 2068 61 735 40 2070 46 2068 44 2065 46 2068 41 770 40 362 46 666 40 2065 41 41 629 40 750 40 2071 41 41 58 778 2041 40 362 46 666 40 2065 44 2070 41 41 330 664 2049 44 2067 696 641 40 2024 41 58 688 548 40 40 2067 712 470 44 750 713 40 2067 44 2000 46 2031 41 41 41 58 605 2072 61 91 2022 664 2022 696 2024 91 58 2049 93 688 713 40 2022 44 2000 46 2031 41 93 664 2073 44 2074 696 641 40 2072 41 58 688 2074 46 2021 323 2067 46 2021 545 832 40 2074 41 712 2000 46 2031 58 2067 46 2018 348 2074 46 2018 2024 91 2073 93 61 470 629 2074 46 2021 323 2067 46 2021 545 832 40 2074 41 712 2000 46 2023 58 2067 46 2018 61 2074 46 2018 43 2067 46 2018 2024 91 2073 93 61 470 330 2069 61 91 2022 664 2022 696 2024 91 58 2049 93 688 832 40 2022 41 712 2000 46 2042 93 664 2065 696 2069 58 688 2067 46 2021 323 2065 46 2021 58 2065 46 2018 61 2067 46 2018 43 2065 46 2018 2024 91 2049 93 61 470 605 688 544 40 40 2067 46 2021 325 2065 46 2021 44 2067 46 2021 329 2065 46 2068 41 41 58 778 2041 40 362 46 666 40 2067 44 2065 41 41 2075 61 123 125 664 2049 44 2022 696 641 40 2024 41 58 688 2022 712 470 58 605 688 2075 46 2014 40 2022 46 2021 41 58 778 2041 40 362 41 2075 91 2022 46 2021 93 61 2022 792 2075 587 2076 40 755 41 58 612 2004 40 2005 44 2006 44 2021 44 2018 61 362 41 58 362 2005 46 2006 61 2006 2005 46 2021 61 2021 2005 46 2018 61 2018 2005 46 2026 61 1500 612 2062 40 2005 44 2055 41 58 362 792 2005 46 2021 612 2077 40 2005 41 58 792 362 46 666 40 2005 46 2078 46 2079 44 2005 46 2006 46 2014 40 2005 46 2021 41 44 2005 46 2018 41 587 2031 40 2076 41 58 612 2004 40 2005 44 2006 44 2021 44 2018 61 362 41 58 818 40 2000 46 2031 44 2005 41 46 2004 40 2006 44 2021 44 2018 41 612 2062 40 2005 44 2055 41 58 2055 46 2061 40 2005 46 2018 41 688 2005 46 2006 46 2014 40 2005 46 2021 41 46 832 340 2046 46 2060 58 2055 46 2061 40 2005 46 2006 46 2014 40 2005 46 2021 41 46 2018 41 792 2005 46 2021 43 1501 587 2023 40 2031 41 58 767 587 2042 40 2076 41 58 612 2004 40 2005 44 2035 44 2036 44 2006 44 2018 41 58 818 40 2000 46 2042 44 2005 41 46 2004 40 2006 44 2035 44 2018 41 2005 46 2068 61 2036 612 2062 40 2005 44 2055 41 58 688 2005 46 2018 58 2055 46 2061 40 2005 46 2018 41 792 2005 46 2068 43 1501 612 2077 40 2005 41 58 688 2005 46 2018 58 792 362 46 666 40 2005 46 2006 46 2014 40 2005 46 2021 41 44 2005 46 2006 46 2014 40 2005 46 2068 41 44 2005 46 2018 41 ,"{'AvgLine': 6, 'CountLine': 240, 'CountStmt': 167, 'MaxNesting': 3, 'AvgLineCode': 5, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 131, 'MaxEssential': 15, 'SumEssential': 45, 'AvgCyclomatic': 2, 'CountLineCode': 170, 'CountStmtDecl': 69, 'MaxCyclomatic': 21, 'SumCyclomatic': 66, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 43, 'CountDeclMethod': 23, 'CountLineCodeExe': 134, 'CountLineComment': 28, 'CountClassCoupled': 7, 'CountClassDerived': 0, 'CountLineCodeDecl': 69, 'CountDeclMethodAll': 23, 'MaxInheritanceTree': 1, 'RatioCommentToCode': '0.16', 'AvgCyclomaticStrict': 2, 'MaxCyclomaticStrict': 23, 'SumCyclomaticStrict': 68, 'AvgCyclomaticModified': 2, 'MaxCyclomaticModified': 21, 'SumCyclomaticModified': 66, 'CountDeclInstanceMethod': 23, 'CountClassCoupledModified': 4, 'CountDeclInstanceVariable': 3}"
131084,Python,"class BaseFormSet(RenderableFormMixin):
    """"""
    A collection of instances of the same Form class.
    """"""
    deletion_widget = CheckboxInput
    ordering_widget = NumberInput
    default_error_messages = {
        'missing_management_form': _(
            'ManagementForm data is missing or has been tampered with. Missing fields: '
            '%(field_names)s. You may need to file a bug report if the issue persists.'
        ),
    }
    template_name = 'django/forms/formsets/default.html'
    template_name_p = 'django/forms/formsets/p.html'
    template_name_table = 'django/forms/formsets/table.html'
    template_name_ul = 'django/forms/formsets/ul.html'

    def __init__(self, data=None, files=None, auto_id='id_%s', prefix=None,
                 initial=None, error_class=ErrorList, form_kwargs=None,
                 error_messages=None):
        self.is_bound = data is not None or files is not None
        self.prefix = prefix or self.get_default_prefix()
        self.auto_id = auto_id
        self.data = data or {}
        self.files = files or {}
        self.initial = initial
        self.form_kwargs = form_kwargs or {}
        self.error_class = error_class
        self._errors = None
        self._non_form_errors = None

        messages = {}
        for cls in reversed(type(self).__mro__):
            messages.update(getattr(cls, 'default_error_messages', {}))
        if error_messages is not None:
            messages.update(error_messages)
        self.error_messages = messages

    def __iter__(self):
        """"""Yield the forms in the order they should be rendered.""""""
        return iter(self.forms)

    def __getitem__(self, index):
        """"""Return the form at the given index, based on the rendering order.""""""
        return self.forms[index]

    def __len__(self):
        return len(self.forms)

    def __bool__(self):
        """"""
        Return True since all formsets have a management form which is not
        included in the length.
        """"""
        return True

    def __repr__(self):
        if self._errors is None:
            is_valid = 'Unknown'
        else:
            is_valid = (
                self.is_bound and
                not self._non_form_errors and
                not any(form_errors for form_errors in self._errors)
            )
        return '<%s: bound=%s valid=%s total_forms=%s>' % (
            self.__class__.__qualname__,
            self.is_bound,
            is_valid,
            self.total_form_count(),
        )

    @cached_property
    def management_form(self):
        """"""Return the ManagementForm instance for this FormSet.""""""
        if self.is_bound:
            form = ManagementForm(self.data, auto_id=self.auto_id, prefix=self.prefix, renderer=self.renderer)
            form.full_clean()
        else:
            form = ManagementForm(
                auto_id=self.auto_id,
                prefix=self.prefix,
                initial={
                    TOTAL_FORM_COUNT: self.total_form_count(),
                    INITIAL_FORM_COUNT: self.initial_form_count(),
                    MIN_NUM_FORM_COUNT: self.min_num,
                    MAX_NUM_FORM_COUNT: self.max_num,
                },
                renderer=self.renderer,
            )
        return form

    def total_form_count(self):
        """"""Return the total number of forms in this FormSet.""""""
        if self.is_bound:
            # return absolute_max if it is lower than the actual total form
            # count in the data; this is DoS protection to prevent clients
            # from forcing the server to instantiate arbitrary numbers of
            # forms
            return min(self.management_form.cleaned_data[TOTAL_FORM_COUNT], self.absolute_max)
        else:
            initial_forms = self.initial_form_count()
            total_forms = max(initial_forms, self.min_num) + self.extra
            # Allow all existing related objects/inlines to be displayed,
            # but don't allow extra beyond max_num.
            if initial_forms > self.max_num >= 0:
                total_forms = initial_forms
            elif total_forms > self.max_num >= 0:
                total_forms = self.max_num
        return total_forms

    def initial_form_count(self):
        """"""Return the number of forms that are required in this FormSet.""""""
        if self.is_bound:
            return self.management_form.cleaned_data[INITIAL_FORM_COUNT]
        else:
            # Use the length of the initial data if it's there, 0 otherwise.
            initial_forms = len(self.initial) if self.initial else 0
        return initial_forms

    @cached_property
    def forms(self):
        """"""Instantiate forms at first property access.""""""
        # DoS protection is included in total_form_count()
        return [
            self._construct_form(i, **self.get_form_kwargs(i))
            for i in range(self.total_form_count())
        ]

    def get_form_kwargs(self, index):
        """"""
        Return additional keyword arguments for each individual formset form.

        index will be None if the form being constructed is a new empty
        form.
        """"""
        return self.form_kwargs.copy()

    def _construct_form(self, i, **kwargs):
        """"""Instantiate and return the i-th form instance in a formset.""""""
        defaults = {
            'auto_id': self.auto_id,
            'prefix': self.add_prefix(i),
            'error_class': self.error_class,
            # Don't render the HTML 'required' attribute as it may cause
            # incorrect validation for extra, optional, and deleted
            # forms in the formset.
            'use_required_attribute': False,
            'renderer': self.renderer,
        }
        if self.is_bound:
            defaults['data'] = self.data
            defaults['files'] = self.files
        if self.initial and 'initial' not in kwargs:
            try:
                defaults['initial'] = self.initial[i]
            except IndexError:
                pass
        # Allow extra forms to be empty, unless they're part of
        # the minimum forms.
        if i >= self.initial_form_count() and i >= self.min_num:
            defaults['empty_permitted'] = True
        defaults.update(kwargs)
        form = self.form(**defaults)
        self.add_fields(form, i)
        return form

    @property
    def initial_forms(self):
        """"""Return a list of all the initial forms in this formset.""""""
        return self.forms[:self.initial_form_count()]

    @property
    def extra_forms(self):
        """"""Return a list of all the extra forms in this formset.""""""
        return self.forms[self.initial_form_count():]

    @property
    def empty_form(self):
        form = self.form(
            auto_id=self.auto_id,
            prefix=self.add_prefix('__prefix__'),
            empty_permitted=True,
            use_required_attribute=False,
            **self.get_form_kwargs(None),
            renderer=self.renderer,
        )
        self.add_fields(form, None)
        return form

    @property
    def cleaned_data(self):
        """"""
        Return a list of form.cleaned_data dicts for every form in self.forms.
        """"""
        if not self.is_valid():
            raise AttributeError(""'%s' object has no attribute 'cleaned_data'"" % self.__class__.__name__)
        return [form.cleaned_data for form in self.forms]

    @property
    def deleted_forms(self):
        """"""Return a list of forms that have been marked for deletion.""""""
        if not self.is_valid() or not self.can_delete:
            return []
        # construct _deleted_form_indexes which is just a list of form indexes
        # that have had their deletion widget set to True
        if not hasattr(self, '_deleted_form_indexes'):
            self._deleted_form_indexes = []
            for i, form in enumerate(self.forms):
                # if this is an extra form and hasn't changed, don't consider it
                if i >= self.initial_form_count() and not form.has_changed():
                    continue
                if self._should_delete_form(form):
                    self._deleted_form_indexes.append(i)
        return [self.forms[i] for i in self._deleted_form_indexes]

    @property
    def ordered_forms(self):
        """"""
        Return a list of form in the order specified by the incoming data.
        Raise an AttributeError if ordering is not allowed.
        """"""
        if not self.is_valid() or not self.can_order:
            raise AttributeError(""'%s' object has no attribute 'ordered_forms'"" % self.__class__.__name__)
        # Construct _ordering, which is a list of (form_index, order_field_value)
        # tuples. After constructing this list, we'll sort it by order_field_value
        # so we have a way to get to the form indexes in the order specified
        # by the form data.
        if not hasattr(self, '_ordering'):
            self._ordering = []
            for i, form in enumerate(self.forms):
                # if this is an extra form and hasn't changed, don't consider it
                if i >= self.initial_form_count() and not form.has_changed():
                    continue
                # don't add data marked for deletion to self.ordered_data
                if self.can_delete and self._should_delete_form(form):
                    continue
                self._ordering.append((i, form.cleaned_data[ORDERING_FIELD_NAME]))
            # After we're done populating self._ordering, sort it.
            # A sort function to order things numerically ascending, but
            # None should be sorted below anything else. Allowing None as
            # a comparison value makes it so we can leave ordering fields
            # blank.

            def compare_ordering_key(k):
                if k[1] is None:
                    return (1, 0)  # +infinity, larger than any number
                return (0, k[1])
            self._ordering.sort(key=compare_ordering_key)
        # Return a list of form.cleaned_data dicts in the order specified by
        # the form data.
        return [self.forms[i[0]] for i in self._ordering]

    @classmethod
    def get_default_prefix(cls):
        return 'form'

    @classmethod
    def get_deletion_widget(cls):
        return cls.deletion_widget

    @classmethod
    def get_ordering_widget(cls):
        return cls.ordering_widget

    def non_form_errors(self):
        """"""
        Return an ErrorList of errors that aren't associated with a particular
        form -- i.e., from formset.clean(). Return an empty ErrorList if there
        are none.
        """"""
        if self._non_form_errors is None:
            self.full_clean()
        return self._non_form_errors

    @property
    def errors(self):
        """"""Return a list of form.errors for every form in self.forms.""""""
        if self._errors is None:
            self.full_clean()
        return self._errors

    def total_error_count(self):
        """"""Return the number of errors across all forms in the formset.""""""
        return len(self.non_form_errors()) +\
            sum(len(form_errors) for form_errors in self.errors)

    def _should_delete_form(self, form):
        """"""Return whether or not the form was marked for deletion.""""""
        return form.cleaned_data.get(DELETION_FIELD_NAME, False)

    def is_valid(self):
        """"""Return True if every form in self.forms is valid.""""""
        if not self.is_bound:
            return False
        # Accessing errors triggers a full clean the first time only.
        self.errors
        # List comprehension ensures is_valid() is called for all forms.
        # Forms due to be deleted shouldn't cause the formset to be invalid.
        forms_valid = all([
            form.is_valid() for form in self.forms
            if not (self.can_delete and self._should_delete_form(form))
        ])
        return forms_valid and not self.non_form_errors()

    def full_clean(self):
        """"""
        Clean all of self.data and populate self._errors and
        self._non_form_errors.
        """"""
        self._errors = []
        self._non_form_errors = self.error_class(error_class='nonform', renderer=self.renderer)
        empty_forms_count = 0

        if not self.is_bound:  # Stop further processing.
            return

        if not self.management_form.is_valid():
            error = ValidationError(
                self.error_messages['missing_management_form'],
                params={
                    'field_names': ', '.join(
                        self.management_form.add_prefix(field_name)
                        for field_name in self.management_form.errors
                    ),
                },
                code='missing_management_form',
            )
            self._non_form_errors.append(error)

        for i, form in enumerate(self.forms):
            # Empty forms are unchanged forms beyond those with initial data.
            if not form.has_changed() and i >= self.initial_form_count():
                empty_forms_count += 1
            # Accessing errors calls full_clean() if necessary.
            # _should_delete_form() requires cleaned_data.
            form_errors = form.errors
            if self.can_delete and self._should_delete_form(form):
                continue
            self._errors.append(form_errors)
        try:
            if (self.validate_max and
                    self.total_form_count() - len(self.deleted_forms) > self.max_num) or \
                    self.management_form.cleaned_data[TOTAL_FORM_COUNT] > self.absolute_max:
                raise ValidationError(ngettext(
                    ""Please submit at most %d form."",
                    ""Please submit at most %d forms."", self.max_num) % self.max_num,
                    code='too_many_forms',
                )
            if (self.validate_min and
                    self.total_form_count() - len(self.deleted_forms) - empty_forms_count < self.min_num):
                raise ValidationError(ngettext(
                    ""Please submit at least %d form."",
                    ""Please submit at least %d forms."", self.min_num) % self.min_num,
                    code='too_few_forms')
            # Give self.clean() a chance to do cross-form validation.
            self.clean()
        except ValidationError as e:
            self._non_form_errors = self.error_class(
                e.error_list,
                error_class='nonform',
                renderer=self.renderer,
            )

    def clean(self):
        """"""
        Hook for doing any extra formset-wide cleaning after Form.clean() has
        been called on every form. Any ValidationError raised by this method
        will not be associated with a particular form; it will be accessible
        via formset.non_form_errors()
        """"""
        pass

    def has_changed(self):
        """"""Return True if data in any form differs from initial.""""""
        return any(form.has_changed() for form in self)

    def add_fields(self, form, index):
        """"""A hook for adding extra fields on to each form instance.""""""
        initial_form_count = self.initial_form_count()
        if self.can_order:
            # Only pre-fill the ordering field for initial forms.
            if index is not None and index < initial_form_count:
                form.fields[ORDERING_FIELD_NAME] = IntegerField(
                    label=_('Order'),
                    initial=index + 1,
                    required=False,
                    widget=self.get_ordering_widget(),
                )
            else:
                form.fields[ORDERING_FIELD_NAME] = IntegerField(
                    label=_('Order'),
                    required=False,
                    widget=self.get_ordering_widget(),
                )
        if self.can_delete and (self.can_delete_extra or index < initial_form_count):
            form.fields[DELETION_FIELD_NAME] = BooleanField(
                label=_('Delete'),
                required=False,
                widget=self.get_deletion_widget(),
            )

    def add_prefix(self, index):
        return '%s-%s' % (self.prefix, index)

    def is_multipart(self):
        """"""
        Return True if the formset needs to be multipart, i.e. it
        has FileInput, or False otherwise.
        """"""
        if self.forms:
            return self.forms[0].is_multipart()
        else:
            return self.empty_form.is_multipart()

    @property
    def media(self):
        # All the forms on a FormSet are the same, so you only need to
        # interrogate the first form for media.
        if self.forms:
            return self.forms[0].media
        else:
            return self.empty_form.media

    def get_context(self):
        return {'formset': self}",1,587 2000 40 2001 41 58 362 2002 61 2003 2004 61 2005 2006 61 123 362 58 2007 40 362 362 41 44 125 2008 61 362 2009 61 362 2010 61 362 2011 61 362 612 2012 40 2013 44 2014 61 470 44 2015 61 470 44 2016 61 362 44 2017 61 470 44 2018 61 470 44 2019 61 2020 44 2021 61 470 44 2022 61 470 41 58 2013 46 2023 61 2014 712 750 470 759 2015 712 750 470 2013 46 2017 61 2017 759 2013 46 2024 40 41 2013 46 2016 61 2016 2013 46 2014 61 2014 759 123 125 2013 46 2015 61 2015 759 123 125 2013 46 2018 61 2018 2013 46 2021 61 2021 759 123 125 2013 46 2019 61 2019 2013 46 2025 61 470 2013 46 2026 61 470 2027 61 123 125 664 2028 696 793 40 832 40 2013 41 46 2029 41 58 2027 46 2030 40 673 40 2028 44 362 44 123 125 41 41 688 2022 712 750 470 58 2027 46 2030 40 2022 41 2013 46 2022 61 2027 612 2031 40 2013 41 58 362 792 717 40 2013 46 2032 41 612 2033 40 2013 44 2034 41 58 362 792 2013 46 2032 91 2034 93 612 2035 40 2013 41 58 792 720 40 2013 46 2032 41 612 2036 40 2013 41 58 362 792 515 612 2037 40 2013 41 58 688 2013 46 2025 712 470 58 2038 61 362 630 58 2038 61 40 2013 46 2023 545 750 2013 46 2026 545 750 548 40 2039 664 2039 696 2013 46 2025 41 41 792 362 37 40 2013 46 2040 46 2041 44 2013 46 2023 44 2038 44 2013 46 2042 40 41 44 41 64 2043 612 2044 40 2013 41 58 362 688 2013 46 2023 58 2045 61 2046 40 2013 46 2014 44 2016 61 2013 46 2016 44 2017 61 2013 46 2017 44 2047 61 2013 46 2047 41 2045 46 2048 40 41 630 58 2045 61 2046 40 2016 61 2013 46 2016 44 2017 61 2013 46 2017 44 2018 61 123 2049 58 2013 46 2042 40 41 44 2050 58 2013 46 2051 40 41 44 2052 58 2013 46 2053 44 2054 58 2013 46 2055 44 125 44 2047 61 2013 46 2047 44 41 792 2045 612 2042 40 2013 41 58 362 688 2013 46 2023 58 330 330 330 330 792 735 40 2013 46 2044 46 2056 91 2049 93 44 2013 46 2057 41 630 58 2058 61 2013 46 2051 40 41 2059 61 733 40 2058 44 2013 46 2053 41 43 2013 46 2060 330 330 688 2058 62 2013 46 2055 325 1500 58 2059 61 2058 629 2059 62 2013 46 2055 325 1500 58 2059 61 2013 46 2055 792 2059 612 2051 40 2013 41 58 362 688 2013 46 2023 58 792 2013 46 2044 46 2056 91 2050 93 630 58 330 2058 61 720 40 2013 46 2018 41 688 2013 46 2018 630 1500 792 2058 64 2043 612 2032 40 2013 41 58 362 330 792 91 2013 46 2061 40 2062 44 350 2013 46 2063 40 2062 41 41 664 2062 696 779 40 2013 46 2042 40 41 41 93 612 2063 40 2013 44 2034 41 58 362 792 2013 46 2021 46 2064 40 41 612 2061 40 2013 44 2062 44 350 2065 41 58 362 2066 61 123 362 58 2013 46 2016 44 362 58 2013 46 2067 40 2062 41 44 362 58 2013 46 2019 44 330 330 330 362 58 443 44 362 58 2013 46 2047 44 125 688 2013 46 2023 58 2066 91 362 93 61 2013 46 2014 2066 91 362 93 61 2013 46 2015 688 2013 46 2018 545 362 750 696 2065 58 830 58 2066 91 362 93 61 2013 46 2018 91 2062 93 645 2068 58 767 330 330 688 2062 325 2013 46 2051 40 41 545 2062 325 2013 46 2053 58 2066 91 362 93 61 515 2066 46 2030 40 2065 41 2045 61 2013 46 2045 40 350 2066 41 2013 46 2069 40 2045 44 2062 41 792 2045 64 774 612 2058 40 2013 41 58 362 792 2013 46 2032 91 58 2013 46 2051 40 41 93 64 774 612 2070 40 2013 41 58 362 792 2013 46 2032 91 2013 46 2051 40 41 58 93 64 774 612 2071 40 2013 41 58 2045 61 2013 46 2045 40 2016 61 2013 46 2016 44 2017 61 2013 46 2067 40 362 41 44 2072 61 515 44 2073 61 443 44 350 2013 46 2063 40 470 41 44 2047 61 2013 46 2047 44 41 2013 46 2069 40 2045 44 470 41 792 2045 64 774 612 2056 40 2013 41 58 362 688 750 2013 46 2038 40 41 58 778 2074 40 362 37 2013 46 2040 46 2075 41 792 91 2045 46 2056 664 2045 696 2013 46 2032 93 64 774 612 2076 40 2013 41 58 362 688 750 2013 46 2038 40 41 759 750 2013 46 2077 58 792 91 93 330 330 688 750 678 40 2013 44 362 41 58 2013 46 2078 61 91 93 664 2062 44 2045 696 641 40 2013 46 2032 41 58 330 688 2062 325 2013 46 2051 40 41 545 750 2045 46 2079 40 41 58 605 688 2013 46 2080 40 2045 41 58 2013 46 2078 46 2081 40 2062 41 792 91 2013 46 2032 91 2062 93 664 2062 696 2013 46 2078 93 64 774 612 2082 40 2013 41 58 362 688 750 2013 46 2038 40 41 759 750 2013 46 2083 58 778 2074 40 362 37 2013 46 2040 46 2075 41 330 330 330 330 688 750 678 40 2013 44 362 41 58 2013 46 2084 61 91 93 664 2062 44 2045 696 641 40 2013 46 2032 41 58 330 688 2062 325 2013 46 2051 40 41 545 750 2045 46 2079 40 41 58 605 330 688 2013 46 2077 545 2013 46 2080 40 2045 41 58 605 2013 46 2084 46 2081 40 40 2062 44 2045 46 2056 91 2085 93 41 41 330 330 330 330 330 612 2086 40 2087 41 58 688 2087 91 1501 93 712 470 58 792 40 1501 44 1500 41 330 792 40 1500 44 2087 91 1501 93 41 2013 46 2084 46 2088 40 2089 61 2086 41 330 330 792 91 2013 46 2032 91 2062 91 1500 93 93 664 2062 696 2013 46 2084 93 64 588 612 2024 40 2028 41 58 792 362 64 588 612 2090 40 2028 41 58 792 2028 46 2002 64 588 612 2091 40 2028 41 58 792 2028 46 2004 612 2092 40 2013 41 58 362 688 2013 46 2026 712 470 58 2013 46 2048 40 41 792 2013 46 2026 64 774 612 2093 40 2013 41 58 362 688 2013 46 2025 712 470 58 2013 46 2048 40 41 792 2013 46 2025 612 2094 40 2013 41 58 362 792 720 40 2013 46 2092 40 41 41 43 92 817 40 720 40 2039 41 664 2039 696 2013 46 2093 41 612 2080 40 2013 44 2045 41 58 362 792 2045 46 2056 46 2095 40 2096 44 443 41 612 2038 40 2013 41 58 362 688 750 2013 46 2023 58 792 443 330 2013 46 2093 330 330 2097 61 544 40 91 2045 46 2038 40 41 664 2045 696 2013 46 2032 688 750 40 2013 46 2077 545 2013 46 2080 40 2045 41 41 93 41 792 2097 545 750 2013 46 2092 40 41 612 2048 40 2013 41 58 362 2013 46 2025 61 91 93 2013 46 2026 61 2013 46 2019 40 2019 61 362 44 2047 61 2013 46 2047 41 2098 61 1500 688 750 2013 46 2023 58 330 792 688 750 2013 46 2044 46 2038 40 41 58 2099 61 2100 40 2013 46 2022 91 362 93 44 2101 61 123 362 58 362 46 2102 40 2013 46 2044 46 2067 40 2103 41 664 2103 696 2013 46 2044 46 2093 41 44 125 44 2104 61 362 44 41 2013 46 2026 46 2081 40 2099 41 664 2062 44 2045 696 641 40 2013 46 2032 41 58 330 688 750 2045 46 2079 40 41 545 2062 325 2013 46 2051 40 41 58 2098 348 1501 330 330 2039 61 2045 46 2093 688 2013 46 2077 545 2013 46 2080 40 2045 41 58 605 2013 46 2025 46 2081 40 2039 41 830 58 688 40 2013 46 2105 545 2013 46 2042 40 41 45 720 40 2013 46 2076 41 62 2013 46 2055 41 759 92 2013 46 2044 46 2056 91 2049 93 62 2013 46 2057 58 778 2100 40 2106 40 362 44 362 44 2013 46 2055 41 37 2013 46 2055 44 2104 61 362 44 41 688 40 2013 46 2107 545 2013 46 2042 40 41 45 720 40 2013 46 2076 41 45 2098 60 2013 46 2053 41 58 778 2100 40 2106 40 362 44 362 44 2013 46 2053 41 37 2013 46 2053 44 2104 61 362 41 330 2013 46 2108 40 41 645 2100 552 2109 58 2013 46 2026 61 2013 46 2019 40 2109 46 2110 44 2019 61 362 44 2047 61 2013 46 2047 44 41 612 2108 40 2013 41 58 362 767 612 2079 40 2013 41 58 362 792 548 40 2045 46 2079 40 41 664 2045 696 2013 41 612 2069 40 2013 44 2045 44 2034 41 58 362 2051 61 2013 46 2051 40 41 688 2013 46 2083 58 330 688 2034 712 750 470 545 2034 60 2051 58 2045 46 2111 91 2085 93 61 2112 40 2113 61 2007 40 362 41 44 2018 61 2034 43 1501 44 2114 61 443 44 2115 61 2013 46 2091 40 41 44 41 630 58 2045 46 2111 91 2085 93 61 2112 40 2113 61 2007 40 362 41 44 2114 61 443 44 2115 61 2013 46 2091 40 41 44 41 688 2013 46 2077 545 40 2013 46 2116 759 2034 60 2051 41 58 2045 46 2111 91 2096 93 61 2117 40 2113 61 2007 40 362 41 44 2114 61 443 44 2115 61 2013 46 2090 40 41 44 41 612 2067 40 2013 44 2034 41 58 792 362 37 40 2013 46 2017 44 2034 41 612 2118 40 2013 41 58 362 688 2013 46 2032 58 792 2013 46 2032 91 1500 93 46 2118 40 41 630 58 792 2013 46 2071 46 2118 40 41 64 774 612 2119 40 2013 41 58 330 330 688 2013 46 2032 58 792 2013 46 2032 91 1500 93 46 2119 630 58 792 2013 46 2071 46 2119 612 2120 40 2013 41 58 792 123 362 58 2013 125 ,"{'AvgLine': 10, 'CountLine': 426, 'CountStmt': 190, 'MaxNesting': 3, 'AvgLineCode': 7, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 154, 'MaxEssential': 7, 'SumEssential': 50, 'AvgCyclomatic': 2, 'CountLineCode': 293, 'CountStmtDecl': 74, 'MaxCyclomatic': 9, 'SumCyclomatic': 76, 'AvgLineComment': 2, 'CountClassBase': 1, 'CountLineBlank': 40, 'CountDeclMethod': 34, 'CountLineCodeExe': 242, 'CountLineComment': 95, 'CountClassCoupled': 7, 'CountClassDerived': 12, 'CountLineCodeDecl': 92, 'CountDeclMethodAll': 39, 'MaxInheritanceTree': 2, 'RatioCommentToCode': '0.32', 'AvgCyclomaticStrict': 2, 'MaxCyclomaticStrict': 14, 'SumCyclomaticStrict': 100, 'AvgCyclomaticModified': 2, 'MaxCyclomaticModified': 9, 'SumCyclomaticModified': 76, 'CountDeclInstanceMethod': 31, 'CountClassCoupledModified': 3, 'CountDeclInstanceVariable': 15}"
132765,Python,"class ChangeListTests(TestCase):
    factory = RequestFactory()

    @classmethod
    def setUpTestData(cls):
        cls.superuser = User.objects.create_superuser(username='super', email='a@b.com', password='xxx')

    def _create_superuser(self, username):
        return User.objects.create_superuser(username=username, email='a@b.com', password='xxx')

    def _mocked_authenticated_request(self, url, user):
        request = self.factory.get(url)
        request.user = user
        return request

    def test_repr(self):
        m = ChildAdmin(Child, custom_site)
        request = self.factory.get('/child/')
        request.user = self.superuser
        cl = m.get_changelist_instance(request)
        self.assertEqual(repr(cl), '<ChangeList: model=Child model_admin=ChildAdmin>')

    def test_specified_ordering_by_f_expression(self):
        class OrderedByFBandAdmin(admin.ModelAdmin):
            list_display = ['name', 'genres', 'nr_of_members']
            ordering = (
                F('nr_of_members').desc(nulls_last=True),
                Upper(F('name')).asc(),
                F('genres').asc(),
            )

        m = OrderedByFBandAdmin(Band, custom_site)
        request = self.factory.get('/band/')
        request.user = self.superuser
        cl = m.get_changelist_instance(request)
        self.assertEqual(cl.get_ordering_field_columns(), {3: 'desc', 2: 'asc'})

    def test_specified_ordering_by_f_expression_without_asc_desc(self):
        class OrderedByFBandAdmin(admin.ModelAdmin):
            list_display = ['name', 'genres', 'nr_of_members']
            ordering = (F('nr_of_members'), Upper('name'), F('genres'))

        m = OrderedByFBandAdmin(Band, custom_site)
        request = self.factory.get('/band/')
        request.user = self.superuser
        cl = m.get_changelist_instance(request)
        self.assertEqual(cl.get_ordering_field_columns(), {3: 'asc', 2: 'asc'})

    def test_select_related_preserved(self):
        """"""
        Regression test for #10348: ChangeList.get_queryset() shouldn't
        overwrite a custom select_related provided by ModelAdmin.get_queryset().
        """"""
        m = ChildAdmin(Child, custom_site)
        request = self.factory.get('/child/')
        request.user = self.superuser
        cl = m.get_changelist_instance(request)
        self.assertEqual(cl.queryset.query.select_related, {'parent': {}})

    def test_select_related_preserved_when_multi_valued_in_search_fields(self):
        parent = Parent.objects.create(name='Mary')
        Child.objects.create(parent=parent, name='Danielle')
        Child.objects.create(parent=parent, name='Daniel')

        m = ParentAdmin(Parent, custom_site)
        request = self.factory.get('/parent/', data={SEARCH_VAR: 'daniel'})
        request.user = self.superuser

        cl = m.get_changelist_instance(request)
        self.assertEqual(cl.queryset.count(), 1)
        # select_related is preserved.
        self.assertEqual(cl.queryset.query.select_related, {'child': {}})

    def test_select_related_as_tuple(self):
        ia = InvitationAdmin(Invitation, custom_site)
        request = self.factory.get('/invitation/')
        request.user = self.superuser
        cl = ia.get_changelist_instance(request)
        self.assertEqual(cl.queryset.query.select_related, {'player': {}})

    def test_select_related_as_empty_tuple(self):
        ia = InvitationAdmin(Invitation, custom_site)
        ia.list_select_related = ()
        request = self.factory.get('/invitation/')
        request.user = self.superuser
        cl = ia.get_changelist_instance(request)
        self.assertIs(cl.queryset.query.select_related, False)

    def test_get_select_related_custom_method(self):
        class GetListSelectRelatedAdmin(admin.ModelAdmin):
            list_display = ('band', 'player')

            def get_list_select_related(self, request):
                return ('band', 'player')

        ia = GetListSelectRelatedAdmin(Invitation, custom_site)
        request = self.factory.get('/invitation/')
        request.user = self.superuser
        cl = ia.get_changelist_instance(request)
        self.assertEqual(cl.queryset.query.select_related, {'player': {}, 'band': {}})

    def test_many_search_terms(self):
        parent = Parent.objects.create(name='Mary')
        Child.objects.create(parent=parent, name='Danielle')
        Child.objects.create(parent=parent, name='Daniel')

        m = ParentAdmin(Parent, custom_site)
        request = self.factory.get('/parent/', data={SEARCH_VAR: 'daniel ' * 80})
        request.user = self.superuser

        cl = m.get_changelist_instance(request)
        with CaptureQueriesContext(connection) as context:
            object_count = cl.queryset.count()
        self.assertEqual(object_count, 1)
        self.assertEqual(context.captured_queries[0]['sql'].count('JOIN'), 1)

    def test_related_field_multiple_search_terms(self):
        """"""
        Searches over multi-valued relationships return rows from related
        models only when all searched fields match that row.
        """"""
        parent = Parent.objects.create(name='Mary')
        Child.objects.create(parent=parent, name='Danielle', age=18)
        Child.objects.create(parent=parent, name='Daniel', age=19)

        m = ParentAdminTwoSearchFields(Parent, custom_site)

        request = self.factory.get('/parent/', data={SEARCH_VAR: 'danielle 19'})
        request.user = self.superuser
        cl = m.get_changelist_instance(request)
        self.assertEqual(cl.queryset.count(), 0)

        request = self.factory.get('/parent/', data={SEARCH_VAR: 'daniel 19'})
        request.user = self.superuser
        cl = m.get_changelist_instance(request)
        self.assertEqual(cl.queryset.count(), 1)

    def test_result_list_empty_changelist_value(self):
        """"""
        Regression test for #14982: EMPTY_CHANGELIST_VALUE should be honored
        for relationship fields
        """"""
        new_child = Child.objects.create(name='name', parent=None)
        request = self.factory.get('/child/')
        request.user = self.superuser
        m = ChildAdmin(Child, custom_site)
        cl = m.get_changelist_instance(request)
        cl.formset = None
        template = Template('{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}')
        context = Context({'cl': cl, 'opts': Child._meta})
        table_output = template.render(context)
        link = reverse('admin:admin_changelist_child_change', args=(new_child.id,))
        row_html = build_tbody_html(new_child.id, link, '<td class=""field-parent nowrap"">-</td>')
        self.assertNotEqual(table_output.find(row_html), -1, 'Failed to find expected row element: %s' % table_output)

    def test_result_list_set_empty_value_display_on_admin_site(self):
        """"""
        Empty value display can be set on AdminSite.
        """"""
        new_child = Child.objects.create(name='name', parent=None)
        request = self.factory.get('/child/')
        request.user = self.superuser
        # Set a new empty display value on AdminSite.
        admin.site.empty_value_display = '???'
        m = ChildAdmin(Child, admin.site)
        cl = m.get_changelist_instance(request)
        cl.formset = None
        template = Template('{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}')
        context = Context({'cl': cl, 'opts': Child._meta})
        table_output = template.render(context)
        link = reverse('admin:admin_changelist_child_change', args=(new_child.id,))
        row_html = build_tbody_html(new_child.id, link, '<td class=""field-parent nowrap"">???</td>')
        self.assertNotEqual(table_output.find(row_html), -1, 'Failed to find expected row element: %s' % table_output)

    def test_result_list_set_empty_value_display_in_model_admin(self):
        """"""
        Empty value display can be set in ModelAdmin or individual fields.
        """"""
        new_child = Child.objects.create(name='name', parent=None)
        request = self.factory.get('/child/')
        request.user = self.superuser
        m = EmptyValueChildAdmin(Child, admin.site)
        cl = m.get_changelist_instance(request)
        cl.formset = None
        template = Template('{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}')
        context = Context({'cl': cl, 'opts': Child._meta})
        table_output = template.render(context)
        link = reverse('admin:admin_changelist_child_change', args=(new_child.id,))
        row_html = build_tbody_html(
            new_child.id,
            link,
            '<td class=""field-age_display"">&amp;dagger;</td>'
            '<td class=""field-age"">-empty-</td>'
        )
        self.assertNotEqual(table_output.find(row_html), -1, 'Failed to find expected row element: %s' % table_output)

    def test_result_list_html(self):
        """"""
        Inclusion tag result_list generates a table when with default
        ModelAdmin settings.
        """"""
        new_parent = Parent.objects.create(name='parent')
        new_child = Child.objects.create(name='name', parent=new_parent)
        request = self.factory.get('/child/')
        request.user = self.superuser
        m = ChildAdmin(Child, custom_site)
        cl = m.get_changelist_instance(request)
        cl.formset = None
        template = Template('{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}')
        context = Context({'cl': cl, 'opts': Child._meta})
        table_output = template.render(context)
        link = reverse('admin:admin_changelist_child_change', args=(new_child.id,))
        row_html = build_tbody_html(new_child.id, link, '<td class=""field-parent nowrap"">%s</td>' % new_parent)
        self.assertNotEqual(table_output.find(row_html), -1, 'Failed to find expected row element: %s' % table_output)

    def test_result_list_editable_html(self):
        """"""
        Regression tests for #11791: Inclusion tag result_list generates a
        table and this checks that the items are nested within the table
        element tags.
        Also a regression test for #13599, verifies that hidden fields
        when list_editable is enabled are rendered in a div outside the
        table.
        """"""
        new_parent = Parent.objects.create(name='parent')
        new_child = Child.objects.create(name='name', parent=new_parent)
        request = self.factory.get('/child/')
        request.user = self.superuser
        m = ChildAdmin(Child, custom_site)

        # Test with list_editable fields
        m.list_display = ['id', 'name', 'parent']
        m.list_display_links = ['id']
        m.list_editable = ['name']
        cl = m.get_changelist_instance(request)
        FormSet = m.get_changelist_formset(request)
        cl.formset = FormSet(queryset=cl.result_list)
        template = Template('{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}')
        context = Context({'cl': cl, 'opts': Child._meta})
        table_output = template.render(context)
        # make sure that hidden fields are in the correct place
        hiddenfields_div = (
            '<div class=""hiddenfields"">'
            '<input type=""hidden"" name=""form-0-id"" value=""%d"" id=""id_form-0-id"">'
            '</div>'
        ) % new_child.id
        self.assertInHTML(hiddenfields_div, table_output, msg_prefix='Failed to find hidden fields')

        # make sure that list editable fields are rendered in divs correctly
        editable_name_field = (
            '<input name=""form-0-name"" value=""name"" class=""vTextField"" '
            'maxlength=""30"" type=""text"" id=""id_form-0-name"">'
        )
        self.assertInHTML(
            '<td class=""field-name"">%s</td>' % editable_name_field,
            table_output,
            msg_prefix='Failed to find ""name"" list_editable field',
        )

    def test_result_list_editable(self):
        """"""
        Regression test for #14312: list_editable with pagination
        """"""
        new_parent = Parent.objects.create(name='parent')
        for i in range(1, 201):
            Child.objects.create(name='name %s' % i, parent=new_parent)
        request = self.factory.get('/child/', data={'p': -1})  # Anything outside range
        request.user = self.superuser
        m = ChildAdmin(Child, custom_site)

        # Test with list_editable fields
        m.list_display = ['id', 'name', 'parent']
        m.list_display_links = ['id']
        m.list_editable = ['name']
        with self.assertRaises(IncorrectLookupParameters):
            m.get_changelist_instance(request)

    def test_custom_paginator(self):
        new_parent = Parent.objects.create(name='parent')
        for i in range(1, 201):
            Child.objects.create(name='name %s' % i, parent=new_parent)

        request = self.factory.get('/child/')
        request.user = self.superuser
        m = CustomPaginationAdmin(Child, custom_site)

        cl = m.get_changelist_instance(request)
        cl.get_results(request)
        self.assertIsInstance(cl.paginator, CustomPaginator)

    def test_no_duplicates_for_m2m_in_list_filter(self):
        """"""
        Regression test for #13902: When using a ManyToMany in list_filter,
        results shouldn't appear more than once. Basic ManyToMany.
        """"""
        blues = Genre.objects.create(name='Blues')
        band = Band.objects.create(name='B.B. King Review', nr_of_members=11)

        band.genres.add(blues)
        band.genres.add(blues)

        m = BandAdmin(Band, custom_site)
        request = self.factory.get('/band/', data={'genres': blues.pk})
        request.user = self.superuser

        cl = m.get_changelist_instance(request)
        cl.get_results(request)

        # There's only one Group instance
        self.assertEqual(cl.result_count, 1)
        # Queryset must be deletable.
        self.assertIs(cl.queryset.query.distinct, False)
        cl.queryset.delete()
        self.assertEqual(cl.queryset.count(), 0)

    def test_no_duplicates_for_through_m2m_in_list_filter(self):
        """"""
        Regression test for #13902: When using a ManyToMany in list_filter,
        results shouldn't appear more than once. With an intermediate model.
        """"""
        lead = Musician.objects.create(name='Vox')
        band = Group.objects.create(name='The Hype')
        Membership.objects.create(group=band, music=lead, role='lead voice')
        Membership.objects.create(group=band, music=lead, role='bass player')

        m = GroupAdmin(Group, custom_site)
        request = self.factory.get('/group/', data={'members': lead.pk})
        request.user = self.superuser

        cl = m.get_changelist_instance(request)
        cl.get_results(request)

        # There's only one Group instance
        self.assertEqual(cl.result_count, 1)
        # Queryset must be deletable.
        self.assertIs(cl.queryset.query.distinct, False)
        cl.queryset.delete()
        self.assertEqual(cl.queryset.count(), 0)

    def test_no_duplicates_for_through_m2m_at_second_level_in_list_filter(self):
        """"""
        When using a ManyToMany in list_filter at the second level behind a
        ForeignKey, results shouldn't appear more than once.
        """"""
        lead = Musician.objects.create(name='Vox')
        band = Group.objects.create(name='The Hype')
        Concert.objects.create(name='Woodstock', group=band)
        Membership.objects.create(group=band, music=lead, role='lead voice')
        Membership.objects.create(group=band, music=lead, role='bass player')

        m = ConcertAdmin(Concert, custom_site)
        request = self.factory.get('/concert/', data={'group__members': lead.pk})
        request.user = self.superuser

        cl = m.get_changelist_instance(request)
        cl.get_results(request)

        # There's only one Concert instance
        self.assertEqual(cl.result_count, 1)
        # Queryset must be deletable.
        self.assertIs(cl.queryset.query.distinct, False)
        cl.queryset.delete()
        self.assertEqual(cl.queryset.count(), 0)

    def test_no_duplicates_for_inherited_m2m_in_list_filter(self):
        """"""
        Regression test for #13902: When using a ManyToMany in list_filter,
        results shouldn't appear more than once. Model managed in the
        admin inherits from the one that defines the relationship.
        """"""
        lead = Musician.objects.create(name='John')
        four = Quartet.objects.create(name='The Beatles')
        Membership.objects.create(group=four, music=lead, role='lead voice')
        Membership.objects.create(group=four, music=lead, role='guitar player')

        m = QuartetAdmin(Quartet, custom_site)
        request = self.factory.get('/quartet/', data={'members': lead.pk})
        request.user = self.superuser

        cl = m.get_changelist_instance(request)
        cl.get_results(request)

        # There's only one Quartet instance
        self.assertEqual(cl.result_count, 1)
        # Queryset must be deletable.
        self.assertIs(cl.queryset.query.distinct, False)
        cl.queryset.delete()
        self.assertEqual(cl.queryset.count(), 0)

    def test_no_duplicates_for_m2m_to_inherited_in_list_filter(self):
        """"""
        Regression test for #13902: When using a ManyToMany in list_filter,
        results shouldn't appear more than once. Target of the relationship
        inherits from another.
        """"""
        lead = ChordsMusician.objects.create(name='Player A')
        three = ChordsBand.objects.create(name='The Chords Trio')
        Invitation.objects.create(band=three, player=lead, instrument='guitar')
        Invitation.objects.create(band=three, player=lead, instrument='bass')

        m = ChordsBandAdmin(ChordsBand, custom_site)
        request = self.factory.get('/chordsband/', data={'members': lead.pk})
        request.user = self.superuser

        cl = m.get_changelist_instance(request)
        cl.get_results(request)

        # There's only one ChordsBand instance
        self.assertEqual(cl.result_count, 1)
        # Queryset must be deletable.
        self.assertIs(cl.queryset.query.distinct, False)
        cl.queryset.delete()
        self.assertEqual(cl.queryset.count(), 0)

    def test_no_duplicates_for_non_unique_related_object_in_list_filter(self):
        """"""
        Regressions tests for #15819: If a field listed in list_filters is a
        non-unique related object, results shouldn't appear more than once.
        """"""
        parent = Parent.objects.create(name='Mary')
        # Two children with the same name
        Child.objects.create(parent=parent, name='Daniel')
        Child.objects.create(parent=parent, name='Daniel')

        m = ParentAdmin(Parent, custom_site)
        request = self.factory.get('/parent/', data={'child__name': 'Daniel'})
        request.user = self.superuser

        cl = m.get_changelist_instance(request)
        # Exists() is applied.
        self.assertEqual(cl.queryset.count(), 1)
        # Queryset must be deletable.
        self.assertIs(cl.queryset.query.distinct, False)
        cl.queryset.delete()
        self.assertEqual(cl.queryset.count(), 0)

    def test_changelist_search_form_validation(self):
        m = ConcertAdmin(Concert, custom_site)
        tests = [
            ({SEARCH_VAR: '\x00'}, 'Null characters are not allowed.'),
            ({SEARCH_VAR: 'some\x00thing'}, 'Null characters are not allowed.'),
        ]
        for case, error in tests:
            with self.subTest(case=case):
                request = self.factory.get('/concert/', case)
                request.user = self.superuser
                request._messages = CookieStorage(request)
                m.get_changelist_instance(request)
                messages = [m.message for m in request._messages]
                self.assertEqual(1, len(messages))
                self.assertEqual(error, messages[0])

    def test_no_duplicates_for_non_unique_related_object_in_search_fields(self):
        """"""
        Regressions tests for #15819: If a field listed in search_fields
        is a non-unique related object, Exists() must be applied.
        """"""
        parent = Parent.objects.create(name='Mary')
        Child.objects.create(parent=parent, name='Danielle')
        Child.objects.create(parent=parent, name='Daniel')

        m = ParentAdmin(Parent, custom_site)
        request = self.factory.get('/parent/', data={SEARCH_VAR: 'daniel'})
        request.user = self.superuser

        cl = m.get_changelist_instance(request)
        # Exists() is applied.
        self.assertEqual(cl.queryset.count(), 1)
        # Queryset must be deletable.
        self.assertIs(cl.queryset.query.distinct, False)
        cl.queryset.delete()
        self.assertEqual(cl.queryset.count(), 0)

    def test_no_duplicates_for_many_to_many_at_second_level_in_search_fields(self):
        """"""
        When using a ManyToMany in search_fields at the second level behind a
        ForeignKey, Exists() must be applied and results shouldn't appear more
        than once.
        """"""
        lead = Musician.objects.create(name='Vox')
        band = Group.objects.create(name='The Hype')
        Concert.objects.create(name='Woodstock', group=band)
        Membership.objects.create(group=band, music=lead, role='lead voice')
        Membership.objects.create(group=band, music=lead, role='bass player')

        m = ConcertAdmin(Concert, custom_site)
        request = self.factory.get('/concert/', data={SEARCH_VAR: 'vox'})
        request.user = self.superuser

        cl = m.get_changelist_instance(request)
        # There's only one Concert instance
        self.assertEqual(cl.queryset.count(), 1)
        # Queryset must be deletable.
        self.assertIs(cl.queryset.query.distinct, False)
        cl.queryset.delete()
        self.assertEqual(cl.queryset.count(), 0)

    def test_multiple_search_fields(self):
        """"""
        All rows containing each of the searched words are returned, where each
        word must be in one of search_fields.
        """"""
        band_duo = Group.objects.create(name='Duo')
        band_hype = Group.objects.create(name='The Hype')
        mary = Musician.objects.create(name='Mary Halvorson')
        jonathan = Musician.objects.create(name='Jonathan Finlayson')
        band_duo.members.set([mary, jonathan])
        Concert.objects.create(name='Tiny desk concert', group=band_duo)
        Concert.objects.create(name='Woodstock concert', group=band_hype)
        # FK lookup.
        concert_model_admin = ConcertAdmin(Concert, custom_site)
        concert_model_admin.search_fields = ['group__name', 'name']
        # Reverse FK lookup.
        group_model_admin = GroupAdmin(Group, custom_site)
        group_model_admin.search_fields = ['name', 'concert__name', 'members__name']
        for search_string, result_count in (
            ('Duo Concert', 1),
            ('Tiny Desk Concert', 1),
            ('Concert', 2),
            ('Other Concert', 0),
            ('Duo Woodstock', 0),
        ):
            with self.subTest(search_string=search_string):
                # FK lookup.
                request = self.factory.get('/concert/', data={SEARCH_VAR: search_string})
                request.user = self.superuser
                concert_changelist = concert_model_admin.get_changelist_instance(request)
                self.assertEqual(concert_changelist.queryset.count(), result_count)
                # Reverse FK lookup.
                request = self.factory.get('/group/', data={SEARCH_VAR: search_string})
                request.user = self.superuser
                group_changelist = group_model_admin.get_changelist_instance(request)
                self.assertEqual(group_changelist.queryset.count(), result_count)
        # Many-to-many lookup.
        for search_string, result_count in (
            ('Finlayson Duo Tiny', 1),
            ('Finlayson', 1),
            ('Finlayson Hype', 0),
            ('Jonathan Finlayson Duo', 1),
            ('Mary Jonathan Duo', 0),
            ('Oscar Finlayson Duo', 0),
        ):
            with self.subTest(search_string=search_string):
                request = self.factory.get('/group/', data={SEARCH_VAR: search_string})
                request.user = self.superuser
                group_changelist = group_model_admin.get_changelist_instance(request)
                self.assertEqual(group_changelist.queryset.count(), result_count)

    def test_pk_in_search_fields(self):
        band = Group.objects.create(name='The Hype')
        Concert.objects.create(name='Woodstock', group=band)

        m = ConcertAdmin(Concert, custom_site)
        m.search_fields = ['group__pk']

        request = self.factory.get('/concert/', data={SEARCH_VAR: band.pk})
        request.user = self.superuser
        cl = m.get_changelist_instance(request)
        self.assertEqual(cl.queryset.count(), 1)

        request = self.factory.get('/concert/', data={SEARCH_VAR: band.pk + 5})
        request.user = self.superuser
        cl = m.get_changelist_instance(request)
        self.assertEqual(cl.queryset.count(), 0)

    def test_builtin_lookup_in_search_fields(self):
        band = Group.objects.create(name='The Hype')
        concert = Concert.objects.create(name='Woodstock', group=band)

        m = ConcertAdmin(Concert, custom_site)
        m.search_fields = ['name__iexact']

        request = self.factory.get('/', data={SEARCH_VAR: 'woodstock'})
        request.user = self.superuser
        cl = m.get_changelist_instance(request)
        self.assertCountEqual(cl.queryset, [concert])

        request = self.factory.get('/', data={SEARCH_VAR: 'wood'})
        request.user = self.superuser
        cl = m.get_changelist_instance(request)
        self.assertCountEqual(cl.queryset, [])

    def test_custom_lookup_in_search_fields(self):
        band = Group.objects.create(name='The Hype')
        concert = Concert.objects.create(name='Woodstock', group=band)

        m = ConcertAdmin(Concert, custom_site)
        m.search_fields = ['group__name__cc']
        with register_lookup(Field, Contains, lookup_name='cc'):
            request = self.factory.get('/', data={SEARCH_VAR: 'Hype'})
            request.user = self.superuser
            cl = m.get_changelist_instance(request)
            self.assertCountEqual(cl.queryset, [concert])

            request = self.factory.get('/', data={SEARCH_VAR: 'Woodstock'})
            request.user = self.superuser
            cl = m.get_changelist_instance(request)
            self.assertCountEqual(cl.queryset, [])

    def test_spanning_relations_with_custom_lookup_in_search_fields(self):
        hype = Group.objects.create(name='The Hype')
        concert = Concert.objects.create(name='Woodstock', group=hype)
        vox = Musician.objects.create(name='Vox', age=20)
        Membership.objects.create(music=vox, group=hype)
        # Register a custom lookup on IntegerField to ensure that field
        # traversing logic in ModelAdmin.get_search_results() works.
        with register_lookup(IntegerField, Exact, lookup_name='exactly'):
            m = ConcertAdmin(Concert, custom_site)
            m.search_fields = ['group__members__age__exactly']

            request = self.factory.get('/', data={SEARCH_VAR: '20'})
            request.user = self.superuser
            cl = m.get_changelist_instance(request)
            self.assertCountEqual(cl.queryset, [concert])

            request = self.factory.get('/', data={SEARCH_VAR: '21'})
            request.user = self.superuser
            cl = m.get_changelist_instance(request)
            self.assertCountEqual(cl.queryset, [])

    def test_custom_lookup_with_pk_shortcut(self):
        self.assertEqual(CharPK._meta.pk.name, 'char_pk')  # Not equal to 'pk'.
        m = admin.ModelAdmin(CustomIdUser, custom_site)

        abc = CharPK.objects.create(char_pk='abc')
        abcd = CharPK.objects.create(char_pk='abcd')
        m = admin.ModelAdmin(CharPK, custom_site)
        m.search_fields = ['pk__exact']

        request = self.factory.get('/', data={SEARCH_VAR: 'abc'})
        request.user = self.superuser
        cl = m.get_changelist_instance(request)
        self.assertCountEqual(cl.queryset, [abc])

        request = self.factory.get('/', data={SEARCH_VAR: 'abcd'})
        request.user = self.superuser
        cl = m.get_changelist_instance(request)
        self.assertCountEqual(cl.queryset, [abcd])

    def test_no_exists_for_m2m_in_list_filter_without_params(self):
        """"""
        If a ManyToManyField is in list_filter but isn't in any lookup params,
        the changelist's query shouldn't have Exists().
        """"""
        m = BandAdmin(Band, custom_site)
        for lookup_params in ({}, {'name': 'test'}):
            request = self.factory.get('/band/', lookup_params)
            request.user = self.superuser
            cl = m.get_changelist_instance(request)
            self.assertNotIn(' EXISTS', str(cl.queryset.query))

        # A ManyToManyField in params does have Exists() applied.
        request = self.factory.get('/band/', {'genres': '0'})
        request.user = self.superuser
        cl = m.get_changelist_instance(request)
        self.assertIn(' EXISTS', str(cl.queryset.query))

    def test_pagination(self):
        """"""
        Regression tests for #12893: Pagination in admins changelist doesn't
        use queryset set by modeladmin.
        """"""
        parent = Parent.objects.create(name='anything')
        for i in range(1, 31):
            Child.objects.create(name='name %s' % i, parent=parent)
            Child.objects.create(name='filtered %s' % i, parent=parent)

        request = self.factory.get('/child/')
        request.user = self.superuser

        # Test default queryset
        m = ChildAdmin(Child, custom_site)
        cl = m.get_changelist_instance(request)
        self.assertEqual(cl.queryset.count(), 60)
        self.assertEqual(cl.paginator.count, 60)
        self.assertEqual(list(cl.paginator.page_range), [1, 2, 3, 4, 5, 6])

        # Test custom queryset
        m = FilteredChildAdmin(Child, custom_site)
        cl = m.get_changelist_instance(request)
        self.assertEqual(cl.queryset.count(), 30)
        self.assertEqual(cl.paginator.count, 30)
        self.assertEqual(list(cl.paginator.page_range), [1, 2, 3])

    def test_computed_list_display_localization(self):
        """"""
        Regression test for #13196: output of functions should be  localized
        in the changelist.
        """"""
        self.client.force_login(self.superuser)
        event = Event.objects.create(date=datetime.date.today())
        response = self.client.get(reverse('admin:admin_changelist_event_changelist'))
        self.assertContains(response, formats.localize(event.date))
        self.assertNotContains(response, str(event.date))

    def test_dynamic_list_display(self):
        """"""
        Regression tests for #14206: dynamic list_display support.
        """"""
        parent = Parent.objects.create(name='parent')
        for i in range(10):
            Child.objects.create(name='child %s' % i, parent=parent)

        user_noparents = self._create_superuser('noparents')
        user_parents = self._create_superuser('parents')

        # Test with user 'noparents'
        m = custom_site._registry[Child]
        request = self._mocked_authenticated_request('/child/', user_noparents)
        response = m.changelist_view(request)
        self.assertNotContains(response, 'Parent object')

        list_display = m.get_list_display(request)
        list_display_links = m.get_list_display_links(request, list_display)
        self.assertEqual(list_display, ['name', 'age'])
        self.assertEqual(list_display_links, ['name'])

        # Test with user 'parents'
        m = DynamicListDisplayChildAdmin(Child, custom_site)
        request = self._mocked_authenticated_request('/child/', user_parents)
        response = m.changelist_view(request)
        self.assertContains(response, 'Parent object')

        custom_site.unregister(Child)

        list_display = m.get_list_display(request)
        list_display_links = m.get_list_display_links(request, list_display)
        self.assertEqual(list_display, ('parent', 'name', 'age'))
        self.assertEqual(list_display_links, ['parent'])

        # Test default implementation
        custom_site.register(Child, ChildAdmin)
        m = custom_site._registry[Child]
        request = self._mocked_authenticated_request('/child/', user_noparents)
        response = m.changelist_view(request)
        self.assertContains(response, 'Parent object')

    def test_show_all(self):
        parent = Parent.objects.create(name='anything')
        for i in range(1, 31):
            Child.objects.create(name='name %s' % i, parent=parent)
            Child.objects.create(name='filtered %s' % i, parent=parent)

        # Add ""show all"" parameter to request
        request = self.factory.get('/child/', data={ALL_VAR: ''})
        request.user = self.superuser

        # Test valid ""show all"" request (number of total objects is under max)
        m = ChildAdmin(Child, custom_site)
        m.list_max_show_all = 200
        # 200 is the max we'll pass to ChangeList
        cl = m.get_changelist_instance(request)
        cl.get_results(request)
        self.assertEqual(len(cl.result_list), 60)

        # Test invalid ""show all"" request (number of total objects over max)
        # falls back to paginated pages
        m = ChildAdmin(Child, custom_site)
        m.list_max_show_all = 30
        # 30 is the max we'll pass to ChangeList for this test
        cl = m.get_changelist_instance(request)
        cl.get_results(request)
        self.assertEqual(len(cl.result_list), 10)

    def test_dynamic_list_display_links(self):
        """"""
        Regression tests for #16257: dynamic list_display_links support.
        """"""
        parent = Parent.objects.create(name='parent')
        for i in range(1, 10):
            Child.objects.create(id=i, name='child %s' % i, parent=parent, age=i)

        m = DynamicListDisplayLinksChildAdmin(Child, custom_site)
        superuser = self._create_superuser('superuser')
        request = self._mocked_authenticated_request('/child/', superuser)
        response = m.changelist_view(request)
        for i in range(1, 10):
            link = reverse('admin:admin_changelist_child_change', args=(i,))
            self.assertContains(response, '<a href=""%s"">%s</a>' % (link, i))

        list_display = m.get_list_display(request)
        list_display_links = m.get_list_display_links(request, list_display)
        self.assertEqual(list_display, ('parent', 'name', 'age'))
        self.assertEqual(list_display_links, ['age'])

    def test_no_list_display_links(self):
        """"""#15185 -- Allow no links from the 'change list' view grid.""""""
        p = Parent.objects.create(name='parent')
        m = NoListDisplayLinksParentAdmin(Parent, custom_site)
        superuser = self._create_superuser('superuser')
        request = self._mocked_authenticated_request('/parent/', superuser)
        response = m.changelist_view(request)
        link = reverse('admin:admin_changelist_parent_change', args=(p.pk,))
        self.assertNotContains(response, '<a href=""%s"">' % link)

    def test_clear_all_filters_link(self):
        self.client.force_login(self.superuser)
        url = reverse('admin:auth_user_changelist')
        response = self.client.get(url)
        self.assertNotContains(response, '&#10006; Clear all filters')
        link = '<a href=""%s"">&#10006; Clear all filters</a>'
        for data, href in (
            ({'is_staff__exact': '0'}, '?'),
            (
                {'is_staff__exact': '0', 'username__startswith': 'test'},
                '?username__startswith=test',
            ),
            (
                {'is_staff__exact': '0', SEARCH_VAR: 'test'},
                '?%s=test' % SEARCH_VAR,
            ),
            (
                {'is_staff__exact': '0', IS_POPUP_VAR: 'id'},
                '?%s=id' % IS_POPUP_VAR,
            ),
        ):
            with self.subTest(data=data):
                response = self.client.get(url, data=data)
                self.assertContains(response, link % href)

    def test_clear_all_filters_link_callable_filter(self):
        self.client.force_login(self.superuser)
        url = reverse('admin:admin_changelist_band_changelist')
        response = self.client.get(url)
        self.assertNotContains(response, '&#10006; Clear all filters')
        link = '<a href=""%s"">&#10006; Clear all filters</a>'
        for data, href in (
            ({'nr_of_members_partition': '5'}, '?'),
            (
                {'nr_of_members_partition': 'more', 'name__startswith': 'test'},
                '?name__startswith=test',
            ),
            (
                {'nr_of_members_partition': '5', IS_POPUP_VAR: 'id'},
                '?%s=id' % IS_POPUP_VAR,
            ),
        ):
            with self.subTest(data=data):
                response = self.client.get(url, data=data)
                self.assertContains(response, link % href)

    def test_no_clear_all_filters_link(self):
        self.client.force_login(self.superuser)
        url = reverse('admin:auth_user_changelist')
        link = '>&#10006; Clear all filters</a>'
        for data in (
            {SEARCH_VAR: 'test'},
            {ORDER_VAR: '-1'},
            {TO_FIELD_VAR: 'id'},
            {PAGE_VAR: '1'},
            {IS_POPUP_VAR: '1'},
            {'username__startswith': 'test'},
        ):
            with self.subTest(data=data):
                response = self.client.get(url, data=data)
                self.assertNotContains(response, link)

    def test_tuple_list_display(self):
        swallow = Swallow.objects.create(origin='Africa', load='12.34', speed='22.2')
        swallow2 = Swallow.objects.create(origin='Africa', load='12.34', speed='22.2')
        swallow_o2o = SwallowOneToOne.objects.create(swallow=swallow2)

        model_admin = SwallowAdmin(Swallow, custom_site)
        superuser = self._create_superuser('superuser')
        request = self._mocked_authenticated_request('/swallow/', superuser)
        response = model_admin.changelist_view(request)
        # just want to ensure it doesn't blow up during rendering
        self.assertContains(response, str(swallow.origin))
        self.assertContains(response, str(swallow.load))
        self.assertContains(response, str(swallow.speed))
        # Reverse one-to-one relations should work.
        self.assertContains(response, '<td class=""field-swallowonetoone"">-</td>')
        self.assertContains(response, '<td class=""field-swallowonetoone"">%s</td>' % swallow_o2o)

    def test_multiuser_edit(self):
        """"""
        Simultaneous edits of list_editable fields on the changelist by
        different users must not result in one user's edits creating a new
        object instead of modifying the correct existing object (#11313).
        """"""
        # To replicate this issue, simulate the following steps:
        # 1. User1 opens an admin changelist with list_editable fields.
        # 2. User2 edits object ""Foo"" such that it moves to another page in
        #    the pagination order and saves.
        # 3. User1 edits object ""Foo"" and saves.
        # 4. The edit made by User1 does not get applied to object ""Foo"" but
        #    instead is used to create a new object (bug).

        # For this test, order the changelist by the 'speed' attribute and
        # display 3 objects per page (SwallowAdmin.list_per_page = 3).

        # Setup the test to reflect the DB state after step 2 where User2 has
        # edited the first swallow object's speed from '4' to '1'.
        a = Swallow.objects.create(origin='Swallow A', load=4, speed=1)
        b = Swallow.objects.create(origin='Swallow B', load=2, speed=2)
        c = Swallow.objects.create(origin='Swallow C', load=5, speed=5)
        d = Swallow.objects.create(origin='Swallow D', load=9, speed=9)

        superuser = self._create_superuser('superuser')
        self.client.force_login(superuser)
        changelist_url = reverse('admin:admin_changelist_swallow_changelist')

        # Send the POST from User1 for step 3. It's still using the changelist
        # ordering from before User2's edits in step 2.
        data = {
            'form-TOTAL_FORMS': '3',
            'form-INITIAL_FORMS': '3',
            'form-MIN_NUM_FORMS': '0',
            'form-MAX_NUM_FORMS': '1000',
            'form-0-uuid': str(d.pk),
            'form-1-uuid': str(c.pk),
            'form-2-uuid': str(a.pk),
            'form-0-load': '9.0',
            'form-0-speed': '9.0',
            'form-1-load': '5.0',
            'form-1-speed': '5.0',
            'form-2-load': '5.0',
            'form-2-speed': '4.0',
            '_save': 'Save',
        }
        response = self.client.post(changelist_url, data, follow=True, extra={'o': '-2'})

        # The object User1 edited in step 3 is displayed on the changelist and
        # has the correct edits applied.
        self.assertContains(response, '1 swallow was changed successfully.')
        self.assertContains(response, a.origin)
        a.refresh_from_db()
        self.assertEqual(a.load, float(data['form-2-load']))
        self.assertEqual(a.speed, float(data['form-2-speed']))
        b.refresh_from_db()
        self.assertEqual(b.load, 2)
        self.assertEqual(b.speed, 2)
        c.refresh_from_db()
        self.assertEqual(c.load, float(data['form-1-load']))
        self.assertEqual(c.speed, float(data['form-1-speed']))
        d.refresh_from_db()
        self.assertEqual(d.load, float(data['form-0-load']))
        self.assertEqual(d.speed, float(data['form-0-speed']))
        # No new swallows were created.
        self.assertEqual(len(Swallow.objects.all()), 4)

    def test_get_edited_object_ids(self):
        a = Swallow.objects.create(origin='Swallow A', load=4, speed=1)
        b = Swallow.objects.create(origin='Swallow B', load=2, speed=2)
        c = Swallow.objects.create(origin='Swallow C', load=5, speed=5)
        superuser = self._create_superuser('superuser')
        self.client.force_login(superuser)
        changelist_url = reverse('admin:admin_changelist_swallow_changelist')
        m = SwallowAdmin(Swallow, custom_site)
        data = {
            'form-TOTAL_FORMS': '3',
            'form-INITIAL_FORMS': '3',
            'form-MIN_NUM_FORMS': '0',
            'form-MAX_NUM_FORMS': '1000',
            'form-0-uuid': str(a.pk),
            'form-1-uuid': str(b.pk),
            'form-2-uuid': str(c.pk),
            'form-0-load': '9.0',
            'form-0-speed': '9.0',
            'form-1-load': '5.0',
            'form-1-speed': '5.0',
            'form-2-load': '5.0',
            'form-2-speed': '4.0',
            '_save': 'Save',
        }
        request = self.factory.post(changelist_url, data=data)
        pks = m._get_edited_object_pks(request, prefix='form')
        self.assertEqual(sorted(pks), sorted([str(a.pk), str(b.pk), str(c.pk)]))

    def test_get_list_editable_queryset(self):
        a = Swallow.objects.create(origin='Swallow A', load=4, speed=1)
        Swallow.objects.create(origin='Swallow B', load=2, speed=2)
        data = {
            'form-TOTAL_FORMS': '2',
            'form-INITIAL_FORMS': '2',
            'form-MIN_NUM_FORMS': '0',
            'form-MAX_NUM_FORMS': '1000',
            'form-0-uuid': str(a.pk),
            'form-0-load': '10',
            '_save': 'Save',
        }
        superuser = self._create_superuser('superuser')
        self.client.force_login(superuser)
        changelist_url = reverse('admin:admin_changelist_swallow_changelist')
        m = SwallowAdmin(Swallow, custom_site)
        request = self.factory.post(changelist_url, data=data)
        queryset = m._get_list_editable_queryset(request, prefix='form')
        self.assertEqual(queryset.count(), 1)
        data['form-0-uuid'] = 'INVALD_PRIMARY_KEY'
        # The unfiltered queryset is returned if there's invalid data.
        request = self.factory.post(changelist_url, data=data)
        queryset = m._get_list_editable_queryset(request, prefix='form')
        self.assertEqual(queryset.count(), 2)

    def test_get_list_editable_queryset_with_regex_chars_in_prefix(self):
        a = Swallow.objects.create(origin='Swallow A', load=4, speed=1)
        Swallow.objects.create(origin='Swallow B', load=2, speed=2)
        data = {
            'form$-TOTAL_FORMS': '2',
            'form$-INITIAL_FORMS': '2',
            'form$-MIN_NUM_FORMS': '0',
            'form$-MAX_NUM_FORMS': '1000',
            'form$-0-uuid': str(a.pk),
            'form$-0-load': '10',
            '_save': 'Save',
        }
        superuser = self._create_superuser('superuser')
        self.client.force_login(superuser)
        changelist_url = reverse('admin:admin_changelist_swallow_changelist')
        m = SwallowAdmin(Swallow, custom_site)
        request = self.factory.post(changelist_url, data=data)
        queryset = m._get_list_editable_queryset(request, prefix='form$')
        self.assertEqual(queryset.count(), 1)

    def test_changelist_view_list_editable_changed_objects_uses_filter(self):
        """"""list_editable edits use a filtered queryset to limit memory usage.""""""
        a = Swallow.objects.create(origin='Swallow A', load=4, speed=1)
        Swallow.objects.create(origin='Swallow B', load=2, speed=2)
        data = {
            'form-TOTAL_FORMS': '2',
            'form-INITIAL_FORMS': '2',
            'form-MIN_NUM_FORMS': '0',
            'form-MAX_NUM_FORMS': '1000',
            'form-0-uuid': str(a.pk),
            'form-0-load': '10',
            '_save': 'Save',
        }
        superuser = self._create_superuser('superuser')
        self.client.force_login(superuser)
        changelist_url = reverse('admin:admin_changelist_swallow_changelist')
        with CaptureQueriesContext(connection) as context:
            response = self.client.post(changelist_url, data=data)
            self.assertEqual(response.status_code, 200)
            self.assertIn('WHERE', context.captured_queries[4]['sql'])
            self.assertIn('IN', context.captured_queries[4]['sql'])
            # Check only the first few characters since the UUID may have dashes.
            self.assertIn(str(a.pk)[:8], context.captured_queries[4]['sql'])

    def test_deterministic_order_for_unordered_model(self):
        """"""
        The primary key is used in the ordering of the changelist's results to
        guarantee a deterministic order, even when the model doesn't have any
        default ordering defined (#17198).
        """"""
        superuser = self._create_superuser('superuser')

        for counter in range(1, 51):
            UnorderedObject.objects.create(id=counter, bool=True)

        class UnorderedObjectAdmin(admin.ModelAdmin):
            list_per_page = 10

        def check_results_order(ascending=False):
            custom_site.register(UnorderedObject, UnorderedObjectAdmin)
            model_admin = UnorderedObjectAdmin(UnorderedObject, custom_site)
            counter = 0 if ascending else 51
            for page in range(1, 6):
                request = self._mocked_authenticated_request('/unorderedobject/?p=%s' % page, superuser)
                response = model_admin.changelist_view(request)
                for result in response.context_data['cl'].result_list:
                    counter += 1 if ascending else -1
                    self.assertEqual(result.id, counter)
            custom_site.unregister(UnorderedObject)

        # When no order is defined at all, everything is ordered by '-pk'.
        check_results_order()

        # When an order field is defined but multiple records have the same
        # value for that field, make sure everything gets ordered by -pk as well.
        UnorderedObjectAdmin.ordering = ['bool']
        check_results_order()

        # When order fields are defined, including the pk itself, use them.
        UnorderedObjectAdmin.ordering = ['bool', '-pk']
        check_results_order()
        UnorderedObjectAdmin.ordering = ['bool', 'pk']
        check_results_order(ascending=True)
        UnorderedObjectAdmin.ordering = ['-id', 'bool']
        check_results_order()
        UnorderedObjectAdmin.ordering = ['id', 'bool']
        check_results_order(ascending=True)

    def test_deterministic_order_for_model_ordered_by_its_manager(self):
        """"""
        The primary key is used in the ordering of the changelist's results to
        guarantee a deterministic order, even when the model has a manager that
        defines a default ordering (#17198).
        """"""
        superuser = self._create_superuser('superuser')

        for counter in range(1, 51):
            OrderedObject.objects.create(id=counter, bool=True, number=counter)

        class OrderedObjectAdmin(admin.ModelAdmin):
            list_per_page = 10

        def check_results_order(ascending=False):
            custom_site.register(OrderedObject, OrderedObjectAdmin)
            model_admin = OrderedObjectAdmin(OrderedObject, custom_site)
            counter = 0 if ascending else 51
            for page in range(1, 6):
                request = self._mocked_authenticated_request('/orderedobject/?p=%s' % page, superuser)
                response = model_admin.changelist_view(request)
                for result in response.context_data['cl'].result_list:
                    counter += 1 if ascending else -1
                    self.assertEqual(result.id, counter)
            custom_site.unregister(OrderedObject)

        # When no order is defined at all, use the model's default ordering (i.e. 'number')
        check_results_order(ascending=True)

        # When an order field is defined but multiple records have the same
        # value for that field, make sure everything gets ordered by -pk as well.
        OrderedObjectAdmin.ordering = ['bool']
        check_results_order()

        # When order fields are defined, including the pk itself, use them.
        OrderedObjectAdmin.ordering = ['bool', '-pk']
        check_results_order()
        OrderedObjectAdmin.ordering = ['bool', 'pk']
        check_results_order(ascending=True)
        OrderedObjectAdmin.ordering = ['-id', 'bool']
        check_results_order()
        OrderedObjectAdmin.ordering = ['id', 'bool']
        check_results_order(ascending=True)

    @isolate_apps('admin_changelist')
    def test_total_ordering_optimization(self):
        class Related(models.Model):
            unique_field = models.BooleanField(unique=True)

            class Meta:
                ordering = ('unique_field',)

        class Model(models.Model):
            unique_field = models.BooleanField(unique=True)
            unique_nullable_field = models.BooleanField(unique=True, null=True)
            related = models.ForeignKey(Related, models.CASCADE)
            other_related = models.ForeignKey(Related, models.CASCADE)
            related_unique = models.OneToOneField(Related, models.CASCADE)
            field = models.BooleanField()
            other_field = models.BooleanField()
            null_field = models.BooleanField(null=True)

            class Meta:
                unique_together = {
                    ('field', 'other_field'),
                    ('field', 'null_field'),
                    ('related', 'other_related_id'),
                }

        class ModelAdmin(admin.ModelAdmin):
            def get_queryset(self, request):
                return Model.objects.none()

        request = self._mocked_authenticated_request('/', self.superuser)
        site = admin.AdminSite(name='admin')
        model_admin = ModelAdmin(Model, site)
        change_list = model_admin.get_changelist_instance(request)
        tests = (
            ([], ['-pk']),
            # Unique non-nullable field.
            (['unique_field'], ['unique_field']),
            (['-unique_field'], ['-unique_field']),
            # Unique nullable field.
            (['unique_nullable_field'], ['unique_nullable_field', '-pk']),
            # Field.
            (['field'], ['field', '-pk']),
            # Related field introspection is not implemented.
            (['related__unique_field'], ['related__unique_field', '-pk']),
            # Related attname unique.
            (['related_unique_id'], ['related_unique_id']),
            # Related ordering introspection is not implemented.
            (['related_unique'], ['related_unique', '-pk']),
            # Composite unique.
            (['field', '-other_field'], ['field', '-other_field']),
            # Composite unique nullable.
            (['-field', 'null_field'], ['-field', 'null_field', '-pk']),
            # Composite unique and nullable.
            (['-field', 'null_field', 'other_field'], ['-field', 'null_field', 'other_field']),
            # Composite unique attnames.
            (['related_id', '-other_related_id'], ['related_id', '-other_related_id']),
            # Composite unique names.
            (['related', '-other_related_id'], ['related', '-other_related_id', '-pk']),
        )
        # F() objects composite unique.
        total_ordering = [F('field'), F('other_field').desc(nulls_last=True)]
        # F() objects composite unique nullable.
        non_total_ordering = [F('field'), F('null_field').desc(nulls_last=True)]
        tests += (
            (total_ordering, total_ordering),
            (non_total_ordering, non_total_ordering + ['-pk']),
        )
        for ordering, expected in tests:
            with self.subTest(ordering=ordering):
                self.assertEqual(change_list._get_deterministic_ordering(ordering), expected)

    @isolate_apps('admin_changelist')
    def test_total_ordering_optimization_meta_constraints(self):
        class Related(models.Model):
            unique_field = models.BooleanField(unique=True)

            class Meta:
                ordering = ('unique_field',)

        class Model(models.Model):
            field_1 = models.BooleanField()
            field_2 = models.BooleanField()
            field_3 = models.BooleanField()
            field_4 = models.BooleanField()
            field_5 = models.BooleanField()
            field_6 = models.BooleanField()
            nullable_1 = models.BooleanField(null=True)
            nullable_2 = models.BooleanField(null=True)
            related_1 = models.ForeignKey(Related, models.CASCADE)
            related_2 = models.ForeignKey(Related, models.CASCADE)
            related_3 = models.ForeignKey(Related, models.CASCADE)
            related_4 = models.ForeignKey(Related, models.CASCADE)

            class Meta:
                constraints = [
                    *[
                        models.UniqueConstraint(fields=fields, name=''.join(fields))
                        for fields in (
                            ['field_1'],
                            ['nullable_1'],
                            ['related_1'],
                            ['related_2_id'],
                            ['field_2', 'field_3'],
                            ['field_2', 'nullable_2'],
                            ['field_2', 'related_3'],
                            ['field_3', 'related_4_id'],
                        )
                    ],
                    models.CheckConstraint(check=models.Q(id__gt=0), name='foo'),
                    models.UniqueConstraint(
                        fields=['field_5'],
                        condition=models.Q(id__gt=10),
                        name='total_ordering_1',
                    ),
                    models.UniqueConstraint(
                        fields=['field_6'],
                        condition=models.Q(),
                        name='total_ordering',
                    ),
                ]

        class ModelAdmin(admin.ModelAdmin):
            def get_queryset(self, request):
                return Model.objects.none()

        request = self._mocked_authenticated_request('/', self.superuser)
        site = admin.AdminSite(name='admin')
        model_admin = ModelAdmin(Model, site)
        change_list = model_admin.get_changelist_instance(request)
        tests = (
            # Unique non-nullable field.
            (['field_1'], ['field_1']),
            # Unique nullable field.
            (['nullable_1'], ['nullable_1', '-pk']),
            # Related attname unique.
            (['related_1_id'], ['related_1_id']),
            (['related_2_id'], ['related_2_id']),
            # Related ordering introspection is not implemented.
            (['related_1'], ['related_1', '-pk']),
            # Composite unique.
            (['-field_2', 'field_3'], ['-field_2', 'field_3']),
            # Composite unique nullable.
            (['field_2', '-nullable_2'], ['field_2', '-nullable_2', '-pk']),
            # Composite unique and nullable.
            (
                ['field_2', '-nullable_2', 'field_3'],
                ['field_2', '-nullable_2', 'field_3'],
            ),
            # Composite field and related field name.
            (['field_2', '-related_3'], ['field_2', '-related_3', '-pk']),
            (['field_3', 'related_4'], ['field_3', 'related_4', '-pk']),
            # Composite field and related field attname.
            (['field_2', 'related_3_id'], ['field_2', 'related_3_id']),
            (['field_3', '-related_4_id'], ['field_3', '-related_4_id']),
            # Partial unique constraint is ignored.
            (['field_5'], ['field_5', '-pk']),
            # Unique constraint with an empty condition.
            (['field_6'], ['field_6']),
        )
        for ordering, expected in tests:
            with self.subTest(ordering=ordering):
                self.assertEqual(change_list._get_deterministic_ordering(ordering), expected)

    def test_dynamic_list_filter(self):
        """"""
        Regression tests for ticket #17646: dynamic list_filter support.
        """"""
        parent = Parent.objects.create(name='parent')
        for i in range(10):
            Child.objects.create(name='child %s' % i, parent=parent)

        user_noparents = self._create_superuser('noparents')
        user_parents = self._create_superuser('parents')

        # Test with user 'noparents'
        m = DynamicListFilterChildAdmin(Child, custom_site)
        request = self._mocked_authenticated_request('/child/', user_noparents)
        response = m.changelist_view(request)
        self.assertEqual(response.context_data['cl'].list_filter, ['name', 'age'])

        # Test with user 'parents'
        m = DynamicListFilterChildAdmin(Child, custom_site)
        request = self._mocked_authenticated_request('/child/', user_parents)
        response = m.changelist_view(request)
        self.assertEqual(response.context_data['cl'].list_filter, ('parent', 'name', 'age'))

    def test_dynamic_search_fields(self):
        child = self._create_superuser('child')
        m = DynamicSearchFieldsChildAdmin(Child, custom_site)
        request = self._mocked_authenticated_request('/child/', child)
        response = m.changelist_view(request)
        self.assertEqual(response.context_data['cl'].search_fields, ('name', 'age'))

    def test_pagination_page_range(self):
        """"""
        Regression tests for ticket #15653: ensure the number of pages
        generated for changelist views are correct.
        """"""
        # instantiating and setting up ChangeList object
        m = GroupAdmin(Group, custom_site)
        request = self.factory.get('/group/')
        request.user = self.superuser
        cl = m.get_changelist_instance(request)
        cl.list_per_page = 10

        ELLIPSIS = cl.paginator.ELLIPSIS
        for number, pages, expected in [
            (1, 1, []),
            (1, 2, [1, 2]),
            (6, 11, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]),
            (6, 12, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]),
            (6, 13, [1, 2, 3, 4, 5, 6, 7, 8, 9, ELLIPSIS, 12, 13]),
            (7, 12, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]),
            (7, 13, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]),
            (7, 14, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ELLIPSIS, 13, 14]),
            (8, 13, [1, 2, ELLIPSIS, 5, 6, 7, 8, 9, 10, 11, 12, 13]),
            (8, 14, [1, 2, ELLIPSIS, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]),
            (8, 15, [1, 2, ELLIPSIS, 5, 6, 7, 8, 9, 10, 11, ELLIPSIS, 14, 15]),
        ]:
            with self.subTest(number=number, pages=pages):
                # assuming exactly `pages * cl.list_per_page` objects
                Group.objects.all().delete()
                for i in range(pages * cl.list_per_page):
                    Group.objects.create(name='test band')

                # setting page number and calculating page range
                cl.page_num = number
                cl.get_results(request)
                self.assertEqual(list(pagination(cl)['page_range']), expected)

    def test_object_tools_displayed_no_add_permission(self):
        """"""
        When ModelAdmin.has_add_permission() returns False, the object-tools
        block is still shown.
        """"""
        superuser = self._create_superuser('superuser')
        m = EventAdmin(Event, custom_site)
        request = self._mocked_authenticated_request('/event/', superuser)
        self.assertFalse(m.has_add_permission(request))
        response = m.changelist_view(request)
        self.assertIn('<ul class=""object-tools"">', response.rendered_content)
        # The ""Add"" button inside the object-tools shouldn't appear.
        self.assertNotIn('Add ', response.rendered_content)

    def test_search_help_text(self):
        superuser = self._create_superuser('superuser')
        m = BandAdmin(Band, custom_site)
        # search_fields without search_help_text.
        m.search_fields = ['name']
        request = self._mocked_authenticated_request('/band/', superuser)
        response = m.changelist_view(request)
        self.assertIsNone(response.context_data['cl'].search_help_text)
        self.assertNotContains(response, '<div class=""help"">')
        # search_fields with search_help_text.
        m.search_help_text = 'Search help text'
        request = self._mocked_authenticated_request('/band/', superuser)
        response = m.changelist_view(request)
        self.assertEqual(response.context_data['cl'].search_help_text, 'Search help text')
        self.assertContains(response, '<div class=""help"">Search help text</div>')


class GetAdminLogTests(TestCase):

    def test_custom_user_pk_not_named_id(self):
        """"""
        {% get_admin_log %} works if the user model's primary key isn't named
        'id'.
        """"""
        context = Context({'user': CustomIdUser()})
        template = Template('{% load log %}{% get_admin_log 10 as admin_log for_user user %}')
        # This template tag just logs.
        self.assertEqual(template.render(context), '')

    def test_no_user(self):
        """"""{% get_admin_log %} works without specifying a user.""""""
        user = User(username='jondoe', password='secret', email='super@example.com')
        user.save()
        ct = ContentType.objects.get_for_model(User)
        LogEntry.objects.log_action(user.pk, ct.pk, user.pk, repr(user), 1)
        t = Template(
            '{% load log %}'
            '{% get_admin_log 100 as admin_log %}'
            '{% for entry in admin_log %}'
            '{{ entry|safe }}'
            '{% endfor %}'
        )
        self.assertEqual(t.render(Context({})), 'Added “<User: jondoe>”.')

    def test_missing_args(self):
        msg = ""'get_admin_log' statements require two arguments""
        with self.assertRaisesMessage(TemplateSyntaxError, msg):
            Template('{% load log %}{% get_admin_log 10 as %}')

    def test_non_integer_limit(self):
        msg = ""First argument to 'get_admin_log' must be an integer""
        with self.assertRaisesMessage(TemplateSyntaxError, msg):
            Template('{% load log %}{% get_admin_log ""10"" as admin_log for_user user %}')

    def test_without_as(self):
        msg = ""Second argument to 'get_admin_log' must be 'as'""
        with self.assertRaisesMessage(TemplateSyntaxError, msg):
            Template('{% load log %}{% get_admin_log 10 ad admin_log for_user user %}')

    def test_without_for_user(self):
        msg = ""Fourth argument to 'get_admin_log' must be 'for_user'""
        with self.assertRaisesMessage(TemplateSyntaxError, msg):
            Template('{% load log %}{% get_admin_log 10 as admin_log foruser user %}')


@override_settings(ROOT_URLCONF='admin_changelist.urls')
class SeleniumTests(AdminSeleniumTestCase):

    available_apps = ['admin_changelist'] + AdminSeleniumTestCase.available_apps

    def setUp(self):
        User.objects.create_superuser(username='super', password='secret', email=None)

    def test_add_row_selection(self):
        """"""
        The status line for selected rows gets updated correctly (#22038).
        """"""
        from selenium.webdriver.common.by import By
        self.admin_login(username='super', password='secret')
        self.selenium.get(self.live_server_url + reverse('admin:auth_user_changelist'))

        form_id = '#changelist-form'

        # Test amount of rows in the Changelist
        rows = self.selenium.find_elements(
            By.CSS_SELECTOR,
            '%s #result_list tbody tr' % form_id
        )
        self.assertEqual(len(rows), 1)
        row = rows[0]

        selection_indicator = self.selenium.find_element(
            By.CSS_SELECTOR,
            '%s .action-counter' % form_id
        )
        all_selector = self.selenium.find_element(By.ID, 'action-toggle')
        row_selector = self.selenium.find_element(
            By.CSS_SELECTOR,
            '%s #result_list tbody tr:first-child .action-select' % form_id
        )

        # Test current selection
        self.assertEqual(selection_indicator.text, ""0 of 1 selected"")
        self.assertIs(all_selector.get_property('checked'), False)
        self.assertEqual(row.get_attribute('class'), '')

        # Select a row and check again
        row_selector.click()
        self.assertEqual(selection_indicator.text, ""1 of 1 selected"")
        self.assertIs(all_selector.get_property('checked'), True)
        self.assertEqual(row.get_attribute('class'), 'selected')

        # Deselect a row and check again
        row_selector.click()
        self.assertEqual(selection_indicator.text, ""0 of 1 selected"")
        self.assertIs(all_selector.get_property('checked'), False)
        self.assertEqual(row.get_attribute('class'), '')

    def test_modifier_allows_multiple_section(self):
        """"""
        Selecting a row and then selecting another row whilst holding shift
        should select all rows in-between.
        """"""
        from selenium.webdriver.common.action_chains import ActionChains
        from selenium.webdriver.common.by import By
        from selenium.webdriver.common.keys import Keys

        Parent.objects.bulk_create([Parent(name='parent%d' % i) for i in range(5)])
        self.admin_login(username='super', password='secret')
        self.selenium.get(self.live_server_url + reverse('admin:admin_changelist_parent_changelist'))
        checkboxes = self.selenium.find_elements(By.CSS_SELECTOR, 'tr input.action-select')
        self.assertEqual(len(checkboxes), 5)
        for c in checkboxes:
            self.assertIs(c.get_property('checked'), False)
        # Check first row. Hold-shift and check next-to-last row.
        checkboxes[0].click()
        ActionChains(self.selenium).key_down(Keys.SHIFT).click(checkboxes[-2]).key_up(Keys.SHIFT).perform()
        for c in checkboxes[:-2]:
            self.assertIs(c.get_property('checked'), True)
        self.assertIs(checkboxes[-1].get_property('checked'), False)

    def test_select_all_across_pages(self):
        from selenium.webdriver.common.by import By
        Parent.objects.bulk_create([Parent(name='parent%d' % i) for i in range(101)])
        self.admin_login(username='super', password='secret')
        self.selenium.get(self.live_server_url + reverse('admin:admin_changelist_parent_changelist'))

        selection_indicator = self.selenium.find_element(By.CSS_SELECTOR, '.action-counter')
        select_all_indicator = self.selenium.find_element(By.CSS_SELECTOR, '.actions .all')
        question = self.selenium.find_element(By.CSS_SELECTOR, '.actions > .question')
        clear = self.selenium.find_element(By.CSS_SELECTOR, '.actions > .clear')
        select_all = self.selenium.find_element(By.ID, 'action-toggle')
        select_across = self.selenium.find_elements(By.NAME, 'select_across')

        self.assertIs(question.is_displayed(), False)
        self.assertIs(clear.is_displayed(), False)
        self.assertIs(select_all.get_property('checked'), False)
        for hidden_input in select_across:
            self.assertEqual(hidden_input.get_property('value'), '0')
        self.assertIs(selection_indicator.is_displayed(), True)
        self.assertEqual(selection_indicator.text, '0 of 100 selected')
        self.assertIs(select_all_indicator.is_displayed(), False)

        select_all.click()
        self.assertIs(question.is_displayed(), True)
        self.assertIs(clear.is_displayed(), False)
        self.assertIs(select_all.get_property('checked'), True)
        for hidden_input in select_across:
            self.assertEqual(hidden_input.get_property('value'), '0')
        self.assertIs(selection_indicator.is_displayed(), True)
        self.assertEqual(selection_indicator.text, '100 of 100 selected')
        self.assertIs(select_all_indicator.is_displayed(), False)

        question.click()
        self.assertIs(question.is_displayed(), False)
        self.assertIs(clear.is_displayed(), True)
        self.assertIs(select_all.get_property('checked'), True)
        for hidden_input in select_across:
            self.assertEqual(hidden_input.get_property('value'), '1')
        self.assertIs(selection_indicator.is_displayed(), False)
        self.assertIs(select_all_indicator.is_displayed(), True)

        clear.click()
        self.assertIs(question.is_displayed(), False)
        self.assertIs(clear.is_displayed(), False)
        self.assertIs(select_all.get_property('checked'), False)
        for hidden_input in select_across:
            self.assertEqual(hidden_input.get_property('value'), '0')
        self.assertIs(selection_indicator.is_displayed(), True)
        self.assertEqual(selection_indicator.text, '0 of 100 selected')
        self.assertIs(select_all_indicator.is_displayed(), False)

    def test_actions_warn_on_pending_edits(self):
        from selenium.webdriver.common.by import By
        Parent.objects.create(name='foo')

        self.admin_login(username='super', password='secret')
        self.selenium.get(self.live_server_url + reverse('admin:admin_changelist_parent_changelist'))

        name_input = self.selenium.find_element(By.ID, 'id_form-0-name')
        name_input.clear()
        name_input.send_keys('bar')
        self.selenium.find_element(By.ID, 'action-toggle').click()
        self.selenium.find_element(By.NAME, 'index').click()  # Go
        alert = self.selenium.switch_to.alert
        try:
            self.assertEqual(
                alert.text,
                'You have unsaved changes on individual editable fields. If you '
                'run an action, your unsaved changes will be lost.'
            )
        finally:
            alert.dismiss()

    def test_save_with_changes_warns_on_pending_action(self):
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import Select

        Parent.objects.create(name='parent')

        self.admin_login(username='super', password='secret')
        self.selenium.get(self.live_server_url + reverse('admin:admin_changelist_parent_changelist'))

        name_input = self.selenium.find_element(By.ID, 'id_form-0-name')
        name_input.clear()
        name_input.send_keys('other name')
        Select(
            self.selenium.find_element(By.NAME, 'action')
        ).select_by_value('delete_selected')
        self.selenium.find_element(By.NAME, '_save').click()
        alert = self.selenium.switch_to.alert
        try:
            self.assertEqual(
                alert.text,
                'You have selected an action, but you haven’t saved your '
                'changes to individual fields yet. Please click OK to save. '
                'You’ll need to re-run the action.',
            )
        finally:
            alert.dismiss()

    def test_save_without_changes_warns_on_pending_action(self):
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import Select

        Parent.objects.create(name='parent')

        self.admin_login(username='super', password='secret')
        self.selenium.get(self.live_server_url + reverse('admin:admin_changelist_parent_changelist'))

        Select(
            self.selenium.find_element(By.NAME, 'action')
        ).select_by_value('delete_selected')
        self.selenium.find_element(By.NAME, '_save').click()
        alert = self.selenium.switch_to.alert
        try:
            self.assertEqual(
                alert.text,
                'You have selected an action, and you haven’t made any '
                'changes on individual fields. You’re probably looking for '
                'the Go button rather than the Save button.',
            )
        finally:
            alert.dismiss()",1,587 2000 40 2001 41 58 2002 61 2003 40 41 64 588 612 2004 40 2005 41 58 2005 46 2006 61 2007 46 2008 46 2009 40 2010 61 362 44 2011 61 362 44 2012 61 362 41 612 2013 40 2014 44 2010 41 58 792 2007 46 2008 46 2009 40 2010 61 2010 44 2011 61 362 44 2012 61 362 41 612 2015 40 2014 44 2016 44 2017 41 58 2018 61 2014 46 2002 46 2019 40 2016 41 2018 46 2017 61 2017 792 2018 612 2020 40 2014 41 58 2021 61 2022 40 2023 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2027 40 787 40 2025 41 44 362 41 612 2028 40 2014 41 58 587 2029 40 2030 46 2031 41 58 2032 61 91 362 44 362 44 362 93 2033 61 40 2034 40 362 41 46 2035 40 2036 61 515 41 44 2037 40 2034 40 362 41 41 46 2038 40 41 44 2034 40 362 41 46 2038 40 41 44 41 2021 61 2029 40 2039 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2027 40 2025 46 2040 40 41 44 123 1502 58 362 44 1502 58 362 125 41 612 2041 40 2014 41 58 587 2029 40 2030 46 2031 41 58 2032 61 91 362 44 362 44 362 93 2033 61 40 2034 40 362 41 44 2037 40 362 41 44 2034 40 362 41 41 2021 61 2029 40 2039 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2027 40 2025 46 2040 40 41 44 123 1502 58 362 44 1502 58 362 125 41 612 2042 40 2014 41 58 362 2021 61 2022 40 2023 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2027 40 2025 46 2043 46 2044 46 2045 44 123 362 58 123 125 125 41 612 2046 40 2014 41 58 2047 61 2048 46 2008 46 2049 40 2050 61 362 41 2023 46 2008 46 2049 40 2047 61 2047 44 2050 61 362 41 2023 46 2008 46 2049 40 2047 61 2047 44 2050 61 362 41 2021 61 2051 40 2048 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 362 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1501 41 330 2014 46 2027 40 2025 46 2043 46 2044 46 2045 44 123 362 58 123 125 125 41 612 2055 40 2014 41 58 2056 61 2057 40 2058 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 41 2018 46 2017 61 2014 46 2006 2025 61 2056 46 2026 40 2018 41 2014 46 2027 40 2025 46 2043 46 2044 46 2045 44 123 362 58 123 125 125 41 612 2059 40 2014 41 58 2056 61 2057 40 2058 44 2024 41 2056 46 2060 61 40 41 2018 61 2014 46 2002 46 2019 40 362 41 2018 46 2017 61 2014 46 2006 2025 61 2056 46 2026 40 2018 41 2014 46 2061 40 2025 46 2043 46 2044 46 2045 44 443 41 612 2062 40 2014 41 58 587 2063 40 2030 46 2031 41 58 2032 61 40 362 44 362 41 612 2064 40 2014 44 2018 41 58 792 40 362 44 362 41 2056 61 2063 40 2058 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 41 2018 46 2017 61 2014 46 2006 2025 61 2056 46 2026 40 2018 41 2014 46 2027 40 2025 46 2043 46 2044 46 2045 44 123 362 58 123 125 44 362 58 123 125 125 41 612 2065 40 2014 41 58 2047 61 2048 46 2008 46 2049 40 2050 61 362 41 2023 46 2008 46 2049 40 2047 61 2047 44 2050 61 362 41 2023 46 2008 46 2049 40 2047 61 2047 44 2050 61 362 41 2021 61 2051 40 2048 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 362 42 1503 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 871 2066 40 2067 41 552 2068 58 2069 61 2025 46 2043 46 2054 40 41 2014 46 2027 40 2069 44 1501 41 2014 46 2027 40 2068 46 2070 91 1500 93 91 362 93 46 2054 40 362 41 44 1501 41 612 2071 40 2014 41 58 362 2047 61 2048 46 2008 46 2049 40 2050 61 362 41 2023 46 2008 46 2049 40 2047 61 2047 44 2050 61 362 44 2072 61 1503 41 2023 46 2008 46 2049 40 2047 61 2047 44 2050 61 362 44 2072 61 1503 41 2021 61 2073 40 2048 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 362 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1500 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 362 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1501 41 612 2074 40 2014 41 58 362 2075 61 2023 46 2008 46 2049 40 2050 61 362 44 2047 61 470 41 2018 61 2014 46 2002 46 2019 40 362 41 2018 46 2017 61 2014 46 2006 2021 61 2022 40 2023 44 2024 41 2025 61 2021 46 2026 40 2018 41 2025 46 2076 61 470 2077 61 2078 40 362 41 2068 61 2079 40 123 362 58 2025 44 362 58 2023 46 2080 125 41 2081 61 2077 46 2082 40 2068 41 2083 61 2084 40 362 44 2085 61 40 2075 46 687 44 41 41 2086 61 2087 40 2075 46 687 44 2083 44 362 41 2014 46 2088 40 2081 46 2089 40 2086 41 44 45 1501 44 362 37 2081 41 612 2090 40 2014 41 58 362 2075 61 2023 46 2008 46 2049 40 2050 61 362 44 2047 61 470 41 2018 61 2014 46 2002 46 2019 40 362 41 2018 46 2017 61 2014 46 2006 330 2030 46 2091 46 2092 61 362 2021 61 2022 40 2023 44 2030 46 2091 41 2025 61 2021 46 2026 40 2018 41 2025 46 2076 61 470 2077 61 2078 40 362 41 2068 61 2079 40 123 362 58 2025 44 362 58 2023 46 2080 125 41 2081 61 2077 46 2082 40 2068 41 2083 61 2084 40 362 44 2085 61 40 2075 46 687 44 41 41 2086 61 2087 40 2075 46 687 44 2083 44 362 41 2014 46 2088 40 2081 46 2089 40 2086 41 44 45 1501 44 362 37 2081 41 612 2093 40 2014 41 58 362 2075 61 2023 46 2008 46 2049 40 2050 61 362 44 2047 61 470 41 2018 61 2014 46 2002 46 2019 40 362 41 2018 46 2017 61 2014 46 2006 2021 61 2094 40 2023 44 2030 46 2091 41 2025 61 2021 46 2026 40 2018 41 2025 46 2076 61 470 2077 61 2078 40 362 41 2068 61 2079 40 123 362 58 2025 44 362 58 2023 46 2080 125 41 2081 61 2077 46 2082 40 2068 41 2083 61 2084 40 362 44 2085 61 40 2075 46 687 44 41 41 2086 61 2087 40 2075 46 687 44 2083 44 362 362 41 2014 46 2088 40 2081 46 2089 40 2086 41 44 45 1501 44 362 37 2081 41 612 2095 40 2014 41 58 362 2096 61 2048 46 2008 46 2049 40 2050 61 362 41 2075 61 2023 46 2008 46 2049 40 2050 61 362 44 2047 61 2096 41 2018 61 2014 46 2002 46 2019 40 362 41 2018 46 2017 61 2014 46 2006 2021 61 2022 40 2023 44 2024 41 2025 61 2021 46 2026 40 2018 41 2025 46 2076 61 470 2077 61 2078 40 362 41 2068 61 2079 40 123 362 58 2025 44 362 58 2023 46 2080 125 41 2081 61 2077 46 2082 40 2068 41 2083 61 2084 40 362 44 2085 61 40 2075 46 687 44 41 41 2086 61 2087 40 2075 46 687 44 2083 44 362 37 2096 41 2014 46 2088 40 2081 46 2089 40 2086 41 44 45 1501 44 362 37 2081 41 612 2097 40 2014 41 58 362 2096 61 2048 46 2008 46 2049 40 2050 61 362 41 2075 61 2023 46 2008 46 2049 40 2050 61 362 44 2047 61 2096 41 2018 61 2014 46 2002 46 2019 40 362 41 2018 46 2017 61 2014 46 2006 2021 61 2022 40 2023 44 2024 41 330 2021 46 2032 61 91 362 44 362 44 362 93 2021 46 2098 61 91 362 93 2021 46 2099 61 91 362 93 2025 61 2021 46 2026 40 2018 41 2100 61 2021 46 2101 40 2018 41 2025 46 2076 61 2100 40 2043 61 2025 46 2102 41 2077 61 2078 40 362 41 2068 61 2079 40 123 362 58 2025 44 362 58 2023 46 2080 125 41 2081 61 2077 46 2082 40 2068 41 330 2103 61 40 362 362 362 41 37 2075 46 687 2014 46 2104 40 2103 44 2081 44 2105 61 362 41 330 2106 61 40 362 362 41 2014 46 2104 40 362 37 2106 44 2081 44 2105 61 362 44 41 612 2107 40 2014 41 58 362 2096 61 2048 46 2008 46 2049 40 2050 61 362 41 664 2108 696 779 40 1501 44 1504 41 58 2023 46 2008 46 2049 40 2050 61 362 37 2108 44 2047 61 2096 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 362 58 45 1501 125 41 330 2018 46 2017 61 2014 46 2006 2021 61 2022 40 2023 44 2024 41 330 2021 46 2032 61 91 362 44 362 44 362 93 2021 46 2098 61 91 362 93 2021 46 2099 61 91 362 93 871 2014 46 2109 40 2110 41 58 2021 46 2026 40 2018 41 612 2111 40 2014 41 58 2096 61 2048 46 2008 46 2049 40 2050 61 362 41 664 2108 696 779 40 1501 44 1504 41 58 2023 46 2008 46 2049 40 2050 61 362 37 2108 44 2047 61 2096 41 2018 61 2014 46 2002 46 2019 40 362 41 2018 46 2017 61 2014 46 2006 2021 61 2112 40 2023 44 2024 41 2025 61 2021 46 2026 40 2018 41 2025 46 2113 40 2018 41 2014 46 2114 40 2025 46 2115 44 2116 41 612 2117 40 2014 41 58 362 2118 61 2119 46 2008 46 2049 40 2050 61 362 41 2120 61 2039 46 2008 46 2049 40 2050 61 362 44 2121 61 1503 41 2120 46 2122 46 2123 40 2118 41 2120 46 2122 46 2123 40 2118 41 2021 61 2124 40 2039 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 362 58 2118 46 2125 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2025 46 2113 40 2018 41 330 2014 46 2027 40 2025 46 2126 44 1501 41 330 2014 46 2061 40 2025 46 2043 46 2044 46 2127 44 443 41 2025 46 2043 46 2128 40 41 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1500 41 612 2129 40 2014 41 58 362 2130 61 2131 46 2008 46 2049 40 2050 61 362 41 2120 61 2132 46 2008 46 2049 40 2050 61 362 41 2133 46 2008 46 2049 40 2134 61 2120 44 2135 61 2130 44 2136 61 362 41 2133 46 2008 46 2049 40 2134 61 2120 44 2135 61 2130 44 2136 61 362 41 2021 61 2137 40 2132 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 362 58 2130 46 2125 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2025 46 2113 40 2018 41 330 2014 46 2027 40 2025 46 2126 44 1501 41 330 2014 46 2061 40 2025 46 2043 46 2044 46 2127 44 443 41 2025 46 2043 46 2128 40 41 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1500 41 612 2138 40 2014 41 58 362 2130 61 2131 46 2008 46 2049 40 2050 61 362 41 2120 61 2132 46 2008 46 2049 40 2050 61 362 41 2139 46 2008 46 2049 40 2050 61 362 44 2134 61 2120 41 2133 46 2008 46 2049 40 2134 61 2120 44 2135 61 2130 44 2136 61 362 41 2133 46 2008 46 2049 40 2134 61 2120 44 2135 61 2130 44 2136 61 362 41 2021 61 2140 40 2139 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 362 58 2130 46 2125 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2025 46 2113 40 2018 41 330 2014 46 2027 40 2025 46 2126 44 1501 41 330 2014 46 2061 40 2025 46 2043 46 2044 46 2127 44 443 41 2025 46 2043 46 2128 40 41 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1500 41 612 2141 40 2014 41 58 362 2130 61 2131 46 2008 46 2049 40 2050 61 362 41 2142 61 2143 46 2008 46 2049 40 2050 61 362 41 2133 46 2008 46 2049 40 2134 61 2142 44 2135 61 2130 44 2136 61 362 41 2133 46 2008 46 2049 40 2134 61 2142 44 2135 61 2130 44 2136 61 362 41 2021 61 2144 40 2143 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 362 58 2130 46 2125 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2025 46 2113 40 2018 41 330 2014 46 2027 40 2025 46 2126 44 1501 41 330 2014 46 2061 40 2025 46 2043 46 2044 46 2127 44 443 41 2025 46 2043 46 2128 40 41 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1500 41 612 2145 40 2014 41 58 362 2130 61 2146 46 2008 46 2049 40 2050 61 362 41 2147 61 2148 46 2008 46 2049 40 2050 61 362 41 2058 46 2008 46 2049 40 2120 61 2147 44 2149 61 2130 44 2150 61 362 41 2058 46 2008 46 2049 40 2120 61 2147 44 2149 61 2130 44 2150 61 362 41 2021 61 2151 40 2148 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 362 58 2130 46 2125 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2025 46 2113 40 2018 41 330 2014 46 2027 40 2025 46 2126 44 1501 41 330 2014 46 2061 40 2025 46 2043 46 2044 46 2127 44 443 41 2025 46 2043 46 2128 40 41 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1500 41 612 2152 40 2014 41 58 362 2047 61 2048 46 2008 46 2049 40 2050 61 362 41 330 2023 46 2008 46 2049 40 2047 61 2047 44 2050 61 362 41 2023 46 2008 46 2049 40 2047 61 2047 44 2050 61 362 41 2021 61 2051 40 2048 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 362 58 362 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 330 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1501 41 330 2014 46 2061 40 2025 46 2043 46 2044 46 2127 44 443 41 2025 46 2043 46 2128 40 41 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1500 41 612 2153 40 2014 41 58 2021 61 2140 40 2139 44 2024 41 2154 61 91 40 123 2053 58 362 125 44 362 41 44 40 123 2053 58 362 125 44 362 41 44 93 664 2155 44 2156 696 2154 58 871 2014 46 2157 40 2155 61 2155 41 58 2018 61 2014 46 2002 46 2019 40 362 44 2155 41 2018 46 2017 61 2014 46 2006 2018 46 2158 61 2159 40 2018 41 2021 46 2026 40 2018 41 2160 61 91 2021 46 2161 664 2021 696 2018 46 2158 93 2014 46 2027 40 1501 44 720 40 2160 41 41 2014 46 2027 40 2156 44 2160 91 1500 93 41 612 2162 40 2014 41 58 362 2047 61 2048 46 2008 46 2049 40 2050 61 362 41 2023 46 2008 46 2049 40 2047 61 2047 44 2050 61 362 41 2023 46 2008 46 2049 40 2047 61 2047 44 2050 61 362 41 2021 61 2051 40 2048 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 362 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 330 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1501 41 330 2014 46 2061 40 2025 46 2043 46 2044 46 2127 44 443 41 2025 46 2043 46 2128 40 41 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1500 41 612 2163 40 2014 41 58 362 2130 61 2131 46 2008 46 2049 40 2050 61 362 41 2120 61 2132 46 2008 46 2049 40 2050 61 362 41 2139 46 2008 46 2049 40 2050 61 362 44 2134 61 2120 41 2133 46 2008 46 2049 40 2134 61 2120 44 2135 61 2130 44 2136 61 362 41 2133 46 2008 46 2049 40 2134 61 2120 44 2135 61 2130 44 2136 61 362 41 2021 61 2140 40 2139 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 362 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 330 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1501 41 330 2014 46 2061 40 2025 46 2043 46 2044 46 2127 44 443 41 2025 46 2043 46 2128 40 41 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1500 41 612 2164 40 2014 41 58 362 2165 61 2132 46 2008 46 2049 40 2050 61 362 41 2166 61 2132 46 2008 46 2049 40 2050 61 362 41 2167 61 2131 46 2008 46 2049 40 2050 61 362 41 2168 61 2131 46 2008 46 2049 40 2050 61 362 41 2165 46 2169 46 801 40 91 2167 44 2168 93 41 2139 46 2008 46 2049 40 2050 61 362 44 2134 61 2165 41 2139 46 2008 46 2049 40 2050 61 362 44 2134 61 2166 41 330 2170 61 2140 40 2139 44 2024 41 2170 46 2171 61 91 362 44 362 93 330 2172 61 2137 40 2132 44 2024 41 2172 46 2171 61 91 362 44 362 44 362 93 664 2173 44 2126 696 40 40 362 44 1501 41 44 40 362 44 1501 41 44 40 362 44 1502 41 44 40 362 44 1500 41 44 40 362 44 1500 41 44 41 58 871 2014 46 2157 40 2173 61 2173 41 58 330 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 2173 125 41 2018 46 2017 61 2014 46 2006 2174 61 2170 46 2026 40 2018 41 2014 46 2027 40 2174 46 2043 46 2054 40 41 44 2126 41 330 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 2173 125 41 2018 46 2017 61 2014 46 2006 2175 61 2172 46 2026 40 2018 41 2014 46 2027 40 2175 46 2043 46 2054 40 41 44 2126 41 330 664 2173 44 2126 696 40 40 362 44 1501 41 44 40 362 44 1501 41 44 40 362 44 1500 41 44 40 362 44 1501 41 44 40 362 44 1500 41 44 40 362 44 1500 41 44 41 58 871 2014 46 2157 40 2173 61 2173 41 58 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 2173 125 41 2018 46 2017 61 2014 46 2006 2175 61 2172 46 2026 40 2018 41 2014 46 2027 40 2175 46 2043 46 2054 40 41 44 2126 41 612 2176 40 2014 41 58 2120 61 2132 46 2008 46 2049 40 2050 61 362 41 2139 46 2008 46 2049 40 2050 61 362 44 2134 61 2120 41 2021 61 2140 40 2139 44 2024 41 2021 46 2171 61 91 362 93 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 2120 46 2125 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1501 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 2120 46 2125 43 1502 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1500 41 612 2177 40 2014 41 58 2120 61 2132 46 2008 46 2049 40 2050 61 362 41 2178 61 2139 46 2008 46 2049 40 2050 61 362 44 2134 61 2120 41 2021 61 2140 40 2139 44 2024 41 2021 46 2171 61 91 362 93 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 362 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2179 40 2025 46 2043 44 91 2178 93 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 362 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2179 40 2025 46 2043 44 91 93 41 612 2180 40 2014 41 58 2120 61 2132 46 2008 46 2049 40 2050 61 362 41 2178 61 2139 46 2008 46 2049 40 2050 61 362 44 2134 61 2120 41 2021 61 2140 40 2139 44 2024 41 2021 46 2171 61 91 362 93 871 2181 40 2182 44 2183 44 2184 61 362 41 58 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 362 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2179 40 2025 46 2043 44 91 2178 93 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 362 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2179 40 2025 46 2043 44 91 93 41 612 2185 40 2014 41 58 2186 61 2132 46 2008 46 2049 40 2050 61 362 41 2178 61 2139 46 2008 46 2049 40 2050 61 362 44 2134 61 2186 41 2187 61 2131 46 2008 46 2049 40 2050 61 362 44 2072 61 1503 41 2133 46 2008 46 2049 40 2135 61 2187 44 2134 61 2186 41 330 330 871 2181 40 2188 44 2189 44 2184 61 362 41 58 2021 61 2140 40 2139 44 2024 41 2021 46 2171 61 91 362 93 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 362 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2179 40 2025 46 2043 44 91 2178 93 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 362 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2179 40 2025 46 2043 44 91 93 41 612 2190 40 2014 41 58 2014 46 2027 40 2191 46 2080 46 2125 46 2050 44 362 41 330 2021 61 2030 46 2031 40 2192 44 2024 41 2193 61 2191 46 2008 46 2049 40 2194 61 362 41 2195 61 2191 46 2008 46 2049 40 2194 61 362 41 2021 61 2030 46 2031 40 2191 44 2024 41 2021 46 2171 61 91 362 93 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 362 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2179 40 2025 46 2043 44 91 2193 93 41 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2053 58 362 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2179 40 2025 46 2043 44 91 2195 93 41 612 2196 40 2014 41 58 362 2021 61 2124 40 2039 44 2024 41 664 2197 696 40 123 125 44 123 362 58 362 125 41 58 2018 61 2014 46 2002 46 2019 40 362 44 2197 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2198 40 362 44 813 40 2025 46 2043 46 2044 41 41 330 2018 61 2014 46 2002 46 2019 40 362 44 123 362 58 362 125 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2014 46 2199 40 362 44 813 40 2025 46 2043 46 2044 41 41 612 2200 40 2014 41 58 362 2047 61 2048 46 2008 46 2049 40 2050 61 362 41 664 2108 696 779 40 1501 44 1503 41 58 2023 46 2008 46 2049 40 2050 61 362 37 2108 44 2047 61 2047 41 2023 46 2008 46 2049 40 2050 61 362 37 2108 44 2047 61 2047 41 2018 61 2014 46 2002 46 2019 40 362 41 2018 46 2017 61 2014 46 2006 330 2021 61 2022 40 2023 44 2024 41 2025 61 2021 46 2026 40 2018 41 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1503 41 2014 46 2027 40 2025 46 2115 46 2054 44 1503 41 2014 46 2027 40 723 40 2025 46 2115 46 2201 41 44 91 1501 44 1502 44 1502 44 1502 44 1502 44 1502 93 41 330 2021 61 2202 40 2023 44 2024 41 2025 61 2021 46 2026 40 2018 41 2014 46 2027 40 2025 46 2043 46 2054 40 41 44 1503 41 2014 46 2027 40 2025 46 2115 46 2054 44 1503 41 2014 46 2027 40 723 40 2025 46 2115 46 2201 41 44 91 1501 44 1502 44 1502 93 41 612 2203 40 2014 41 58 362 2014 46 2204 46 2205 40 2014 46 2006 41 2206 61 2207 46 2008 46 2049 40 2208 61 2209 46 2208 46 2210 40 41 41 2211 61 2014 46 2204 46 2019 40 2084 40 362 41 41 2014 46 2212 40 2211 44 2213 46 2214 40 2206 46 2208 41 41 2014 46 2215 40 2211 44 813 40 2206 46 2208 41 41 612 2216 40 2014 41 58 362 2047 61 2048 46 2008 46 2049 40 2050 61 362 41 664 2108 696 779 40 1502 41 58 2023 46 2008 46 2049 40 2050 61 362 37 2108 44 2047 61 2047 41 2217 61 2014 46 2013 40 362 41 2218 61 2014 46 2013 40 362 41 330 2021 61 2024 46 2219 91 2023 93 2018 61 2014 46 2015 40 362 44 2217 41 2211 61 2021 46 2220 40 2018 41 2014 46 2215 40 2211 44 362 41 2032 61 2021 46 2221 40 2018 41 2098 61 2021 46 2222 40 2018 44 2032 41 2014 46 2027 40 2032 44 91 362 44 362 93 41 2014 46 2027 40 2098 44 91 362 93 41 330 2021 61 2223 40 2023 44 2024 41 2018 61 2014 46 2015 40 362 44 2218 41 2211 61 2021 46 2220 40 2018 41 2014 46 2212 40 2211 44 362 41 2024 46 2224 40 2023 41 2032 61 2021 46 2221 40 2018 41 2098 61 2021 46 2222 40 2018 44 2032 41 2014 46 2027 40 2032 44 40 362 44 362 44 362 41 41 2014 46 2027 40 2098 44 91 362 93 41 330 2024 46 2225 40 2023 44 2022 41 2021 61 2024 46 2219 91 2023 93 2018 61 2014 46 2015 40 362 44 2217 41 2211 61 2021 46 2220 40 2018 41 2014 46 2212 40 2211 44 362 41 612 2226 40 2014 41 58 2047 61 2048 46 2008 46 2049 40 2050 61 362 41 664 2108 696 779 40 1501 44 1503 41 58 2023 46 2008 46 2049 40 2050 61 362 37 2108 44 2047 61 2047 41 2023 46 2008 46 2049 40 2050 61 362 37 2108 44 2047 61 2047 41 330 2018 61 2014 46 2002 46 2019 40 362 44 2052 61 123 2227 58 362 125 41 2018 46 2017 61 2014 46 2006 330 2021 61 2022 40 2023 44 2024 41 2021 46 2228 61 1504 330 2025 61 2021 46 2026 40 2018 41 2025 46 2113 40 2018 41 2014 46 2027 40 720 40 2025 46 2102 41 44 1503 41 330 330 2021 61 2022 40 2023 44 2024 41 2021 46 2228 61 1503 330 2025 61 2021 46 2026 40 2018 41 2025 46 2113 40 2018 41 2014 46 2027 40 720 40 2025 46 2102 41 44 1502 41 612 2229 40 2014 41 58 362 2047 61 2048 46 2008 46 2049 40 2050 61 362 41 664 2108 696 779 40 1501 44 1502 41 58 2023 46 2008 46 2049 40 687 61 2108 44 2050 61 362 37 2108 44 2047 61 2047 44 2072 61 2108 41 2021 61 2230 40 2023 44 2024 41 2006 61 2014 46 2013 40 362 41 2018 61 2014 46 2015 40 362 44 2006 41 2211 61 2021 46 2220 40 2018 41 664 2108 696 779 40 1501 44 1502 41 58 2083 61 2084 40 362 44 2085 61 40 2108 44 41 41 2014 46 2212 40 2211 44 362 37 40 2083 44 2108 41 41 2032 61 2021 46 2221 40 2018 41 2098 61 2021 46 2222 40 2018 44 2032 41 2014 46 2027 40 2032 44 40 362 44 362 44 362 41 41 2014 46 2027 40 2098 44 91 362 93 41 612 2231 40 2014 41 58 362 2232 61 2048 46 2008 46 2049 40 2050 61 362 41 2021 61 2233 40 2048 44 2024 41 2006 61 2014 46 2013 40 362 41 2018 61 2014 46 2015 40 362 44 2006 41 2211 61 2021 46 2220 40 2018 41 2083 61 2084 40 362 44 2085 61 40 2232 46 2125 44 41 41 2014 46 2215 40 2211 44 362 37 2083 41 612 2234 40 2014 41 58 2014 46 2204 46 2205 40 2014 46 2006 41 2016 61 2084 40 362 41 2211 61 2014 46 2204 46 2019 40 2016 41 2014 46 2215 40 2211 44 362 41 2083 61 362 664 2052 44 2235 696 40 40 123 362 58 362 125 44 362 41 44 40 123 362 58 362 44 362 58 362 125 44 362 44 41 44 40 123 362 58 362 44 2053 58 362 125 44 362 37 2053 44 41 44 40 123 362 58 362 44 2236 58 362 125 44 362 37 2236 44 41 44 41 58 871 2014 46 2157 40 2052 61 2052 41 58 2211 61 2014 46 2204 46 2019 40 2016 44 2052 61 2052 41 2014 46 2212 40 2211 44 2083 37 2235 41 612 2237 40 2014 41 58 2014 46 2204 46 2205 40 2014 46 2006 41 2016 61 2084 40 362 41 2211 61 2014 46 2204 46 2019 40 2016 41 2014 46 2215 40 2211 44 362 41 2083 61 362 664 2052 44 2235 696 40 40 123 362 58 362 125 44 362 41 44 40 123 362 58 362 44 362 58 362 125 44 362 44 41 44 40 123 362 58 362 44 2236 58 362 125 44 362 37 2236 44 41 44 41 58 871 2014 46 2157 40 2052 61 2052 41 58 2211 61 2014 46 2204 46 2019 40 2016 44 2052 61 2052 41 2014 46 2212 40 2211 44 2083 37 2235 41 612 2238 40 2014 41 58 2014 46 2204 46 2205 40 2014 46 2006 41 2016 61 2084 40 362 41 2083 61 362 664 2052 696 40 123 2053 58 362 125 44 123 2239 58 362 125 44 123 2240 58 362 125 44 123 2241 58 362 125 44 123 2236 58 362 125 44 123 362 58 362 125 44 41 58 871 2014 46 2157 40 2052 61 2052 41 58 2211 61 2014 46 2204 46 2019 40 2016 44 2052 61 2052 41 2014 46 2215 40 2211 44 2083 41 612 2242 40 2014 41 58 2243 61 2244 46 2008 46 2049 40 2245 61 362 44 2246 61 362 44 2247 61 362 41 2248 61 2244 46 2008 46 2049 40 2245 61 362 44 2246 61 362 44 2247 61 362 41 2249 61 2250 46 2008 46 2049 40 2243 61 2248 41 2251 61 2252 40 2244 44 2024 41 2006 61 2014 46 2013 40 362 41 2018 61 2014 46 2015 40 362 44 2006 41 2211 61 2251 46 2220 40 2018 41 330 2014 46 2212 40 2211 44 813 40 2243 46 2245 41 41 2014 46 2212 40 2211 44 813 40 2243 46 2246 41 41 2014 46 2212 40 2211 44 813 40 2243 46 2247 41 41 330 2014 46 2212 40 2211 44 362 41 2014 46 2212 40 2211 44 362 37 2249 41 612 2253 40 2014 41 58 362 330 330 330 330 330 330 330 330 330 330 330 2254 61 2244 46 2008 46 2049 40 2245 61 362 44 2246 61 1502 44 2247 61 1501 41 2255 61 2244 46 2008 46 2049 40 2245 61 362 44 2246 61 1502 44 2247 61 1502 41 2256 61 2244 46 2008 46 2049 40 2245 61 362 44 2246 61 1502 44 2247 61 1502 41 2257 61 2244 46 2008 46 2049 40 2245 61 362 44 2246 61 1502 44 2247 61 1502 41 2006 61 2014 46 2013 40 362 41 2014 46 2204 46 2205 40 2006 41 2258 61 2084 40 362 41 330 330 2052 61 123 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 813 40 2257 46 2125 41 44 362 58 813 40 2256 46 2125 41 44 362 58 813 40 2254 46 2125 41 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 125 2211 61 2014 46 2204 46 2259 40 2258 44 2052 44 2260 61 515 44 2261 61 123 362 58 362 125 41 330 330 2014 46 2212 40 2211 44 362 41 2014 46 2212 40 2211 44 2254 46 2245 41 2254 46 2262 40 41 2014 46 2027 40 2254 46 2246 44 660 40 2052 91 362 93 41 41 2014 46 2027 40 2254 46 2247 44 660 40 2052 91 362 93 41 41 2255 46 2262 40 41 2014 46 2027 40 2255 46 2246 44 1502 41 2014 46 2027 40 2255 46 2247 44 1502 41 2256 46 2262 40 41 2014 46 2027 40 2256 46 2246 44 660 40 2052 91 362 93 41 41 2014 46 2027 40 2256 46 2247 44 660 40 2052 91 362 93 41 41 2257 46 2262 40 41 2014 46 2027 40 2257 46 2246 44 660 40 2052 91 362 93 41 41 2014 46 2027 40 2257 46 2247 44 660 40 2052 91 362 93 41 41 330 2014 46 2027 40 720 40 2244 46 2008 46 544 40 41 41 44 1502 41 612 2263 40 2014 41 58 2254 61 2244 46 2008 46 2049 40 2245 61 362 44 2246 61 1502 44 2247 61 1501 41 2255 61 2244 46 2008 46 2049 40 2245 61 362 44 2246 61 1502 44 2247 61 1502 41 2256 61 2244 46 2008 46 2049 40 2245 61 362 44 2246 61 1502 44 2247 61 1502 41 2006 61 2014 46 2013 40 362 41 2014 46 2204 46 2205 40 2006 41 2258 61 2084 40 362 41 2021 61 2252 40 2244 44 2024 41 2052 61 123 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 813 40 2254 46 2125 41 44 362 58 813 40 2255 46 2125 41 44 362 58 813 40 2256 46 2125 41 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 125 2018 61 2014 46 2002 46 2259 40 2258 44 2052 61 2052 41 2264 61 2021 46 2265 40 2018 44 2266 61 362 41 2014 46 2027 40 807 40 2264 41 44 807 40 91 813 40 2254 46 2125 41 44 813 40 2255 46 2125 41 44 813 40 2256 46 2125 41 93 41 41 612 2267 40 2014 41 58 2254 61 2244 46 2008 46 2049 40 2245 61 362 44 2246 61 1502 44 2247 61 1501 41 2244 46 2008 46 2049 40 2245 61 362 44 2246 61 1502 44 2247 61 1502 41 2052 61 123 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 813 40 2254 46 2125 41 44 362 58 362 44 362 58 362 44 125 2006 61 2014 46 2013 40 362 41 2014 46 2204 46 2205 40 2006 41 2258 61 2084 40 362 41 2021 61 2252 40 2244 44 2024 41 2018 61 2014 46 2002 46 2259 40 2258 44 2052 61 2052 41 2043 61 2021 46 2268 40 2018 44 2266 61 362 41 2014 46 2027 40 2043 46 2054 40 41 44 1501 41 2052 91 362 93 61 362 330 2018 61 2014 46 2002 46 2259 40 2258 44 2052 61 2052 41 2043 61 2021 46 2268 40 2018 44 2266 61 362 41 2014 46 2027 40 2043 46 2054 40 41 44 1502 41 612 2269 40 2014 41 58 2254 61 2244 46 2008 46 2049 40 2245 61 362 44 2246 61 1502 44 2247 61 1501 41 2244 46 2008 46 2049 40 2245 61 362 44 2246 61 1502 44 2247 61 1502 41 2052 61 123 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 813 40 2254 46 2125 41 44 362 58 362 44 362 58 362 44 125 2006 61 2014 46 2013 40 362 41 2014 46 2204 46 2205 40 2006 41 2258 61 2084 40 362 41 2021 61 2252 40 2244 44 2024 41 2018 61 2014 46 2002 46 2259 40 2258 44 2052 61 2052 41 2043 61 2021 46 2268 40 2018 44 2266 61 362 41 2014 46 2027 40 2043 46 2054 40 41 44 1501 41 612 2270 40 2014 41 58 362 2254 61 2244 46 2008 46 2049 40 2245 61 362 44 2246 61 1502 44 2247 61 1501 41 2244 46 2008 46 2049 40 2245 61 362 44 2246 61 1502 44 2247 61 1502 41 2052 61 123 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 813 40 2254 46 2125 41 44 362 58 362 44 362 58 362 44 125 2006 61 2014 46 2013 40 362 41 2014 46 2204 46 2205 40 2006 41 2258 61 2084 40 362 41 871 2066 40 2067 41 552 2068 58 2211 61 2014 46 2204 46 2259 40 2258 44 2052 61 2052 41 2014 46 2027 40 2211 46 2271 44 1504 41 2014 46 2199 40 362 44 2068 46 2070 91 1502 93 91 362 93 41 2014 46 2199 40 362 44 2068 46 2070 91 1502 93 91 362 93 41 330 2014 46 2199 40 813 40 2254 46 2125 41 91 58 1502 93 44 2068 46 2070 91 1502 93 91 362 93 41 612 2272 40 2014 41 58 362 2006 61 2014 46 2013 40 362 41 664 2273 696 779 40 1501 44 1503 41 58 2274 46 2008 46 2049 40 687 61 2273 44 569 61 515 41 587 2275 40 2030 46 2031 41 58 2276 61 1502 612 2277 40 2278 61 443 41 58 2024 46 2225 40 2274 44 2275 41 2251 61 2275 40 2274 44 2024 41 2273 61 1500 688 2278 630 1503 664 2279 696 779 40 1501 44 1502 41 58 2018 61 2014 46 2015 40 362 37 2279 44 2006 41 2211 61 2251 46 2220 40 2018 41 664 2280 696 2211 46 2281 91 362 93 46 2102 58 2273 348 1501 688 2278 630 45 1501 2014 46 2027 40 2280 46 687 44 2273 41 2024 46 2224 40 2274 41 330 2277 40 41 330 330 2275 46 2033 61 91 362 93 2277 40 41 330 2275 46 2033 61 91 362 44 362 93 2277 40 41 2275 46 2033 61 91 362 44 362 93 2277 40 2278 61 515 41 2275 46 2033 61 91 362 44 362 93 2277 40 41 2275 46 2033 61 91 362 44 362 93 2277 40 2278 61 515 41 612 2282 40 2014 41 58 362 2006 61 2014 46 2013 40 362 41 664 2273 696 779 40 1501 44 1503 41 58 2283 46 2008 46 2049 40 687 61 2273 44 569 61 515 44 2284 61 2273 41 587 2285 40 2030 46 2031 41 58 2276 61 1502 612 2277 40 2278 61 443 41 58 2024 46 2225 40 2283 44 2285 41 2251 61 2285 40 2283 44 2024 41 2273 61 1500 688 2278 630 1503 664 2279 696 779 40 1501 44 1502 41 58 2018 61 2014 46 2015 40 362 37 2279 44 2006 41 2211 61 2251 46 2220 40 2018 41 664 2280 696 2211 46 2281 91 362 93 46 2102 58 2273 348 1501 688 2278 630 45 1501 2014 46 2027 40 2280 46 687 44 2273 41 2024 46 2224 40 2283 41 330 2277 40 2278 61 515 41 330 330 2285 46 2033 61 91 362 93 2277 40 41 330 2285 46 2033 61 91 362 44 362 93 2277 40 41 2285 46 2033 61 91 362 44 362 93 2277 40 2278 61 515 41 2285 46 2033 61 91 362 44 362 93 2277 40 41 2285 46 2033 61 91 362 44 362 93 2277 40 2278 61 515 41 64 2286 40 362 41 612 2287 40 2014 41 58 587 2288 40 2289 46 2290 41 58 2291 61 2289 46 2292 40 2293 61 515 41 587 2294 58 2033 61 40 362 44 41 587 2290 40 2289 46 2290 41 58 2291 61 2289 46 2292 40 2293 61 515 41 2295 61 2289 46 2292 40 2293 61 515 44 2296 61 515 41 2297 61 2289 46 2298 40 2288 44 2289 46 2299 41 2300 61 2289 46 2298 40 2288 44 2289 46 2299 41 2301 61 2289 46 2302 40 2288 44 2289 46 2299 41 2303 61 2289 46 2292 40 41 2304 61 2289 46 2292 40 41 2305 61 2289 46 2292 40 2296 61 515 41 587 2294 58 2306 61 123 40 362 44 362 41 44 40 362 44 362 41 44 40 362 44 362 41 44 125 587 2031 40 2030 46 2031 41 58 612 2307 40 2014 44 2018 41 58 792 2290 46 2008 46 2308 40 41 2018 61 2014 46 2015 40 362 44 2014 46 2006 41 2091 61 2030 46 2309 40 2050 61 362 41 2251 61 2031 40 2290 44 2091 41 2310 61 2251 46 2026 40 2018 41 2154 61 40 40 91 93 44 91 362 93 41 44 330 40 91 362 93 44 91 362 93 41 44 40 91 362 93 44 91 362 93 41 44 330 40 91 362 93 44 91 362 44 362 93 41 44 330 40 91 362 93 44 91 362 44 362 93 41 44 330 40 91 362 93 44 91 362 44 362 93 41 44 330 40 91 362 93 44 91 362 93 41 44 330 40 91 362 93 44 91 362 44 362 93 41 44 330 40 91 362 44 362 93 44 91 362 44 362 93 41 44 330 40 91 362 44 362 93 44 91 362 44 362 44 362 93 41 44 330 40 91 362 44 362 44 362 93 44 91 362 44 362 44 362 93 41 44 330 40 91 362 44 362 93 44 91 362 44 362 93 41 44 330 40 91 362 44 362 93 44 91 362 44 362 44 362 93 41 44 41 330 2311 61 91 2034 40 362 41 44 2034 40 362 41 46 2035 40 2036 61 515 41 93 330 2312 61 91 2034 40 362 41 44 2034 40 362 41 46 2035 40 2036 61 515 41 93 2154 348 40 40 2311 44 2311 41 44 40 2312 44 2312 43 91 362 93 41 44 41 664 2033 44 2313 696 2154 58 871 2014 46 2157 40 2033 61 2033 41 58 2014 46 2027 40 2310 46 2314 40 2033 41 44 2313 41 64 2286 40 362 41 612 2315 40 2014 41 58 587 2288 40 2289 46 2290 41 58 2291 61 2289 46 2292 40 2293 61 515 41 587 2294 58 2033 61 40 362 44 41 587 2290 40 2289 46 2290 41 58 2316 61 2289 46 2292 40 41 2317 61 2289 46 2292 40 41 2318 61 2289 46 2292 40 41 2319 61 2289 46 2292 40 41 2320 61 2289 46 2292 40 41 2321 61 2289 46 2292 40 41 2322 61 2289 46 2292 40 2296 61 515 41 2323 61 2289 46 2292 40 2296 61 515 41 2324 61 2289 46 2298 40 2288 44 2289 46 2299 41 2325 61 2289 46 2298 40 2288 44 2289 46 2299 41 2326 61 2289 46 2298 40 2288 44 2289 46 2299 41 2327 61 2289 46 2298 40 2288 44 2289 46 2299 41 587 2294 58 2328 61 91 42 91 2289 46 2329 40 2330 61 2330 44 2050 61 362 46 2331 40 2330 41 41 664 2330 696 40 91 362 93 44 91 362 93 44 91 362 93 44 91 362 93 44 91 362 44 362 93 44 91 362 44 362 93 44 91 362 44 362 93 44 91 362 44 362 93 44 41 93 44 2289 46 2332 40 2333 61 2289 46 2334 40 2335 61 1500 41 44 2050 61 362 41 44 2289 46 2329 40 2330 61 91 362 93 44 2336 61 2289 46 2334 40 2335 61 1502 41 44 2050 61 362 44 41 44 2289 46 2329 40 2330 61 91 362 93 44 2336 61 2289 46 2334 40 41 44 2050 61 362 44 41 44 93 587 2031 40 2030 46 2031 41 58 612 2307 40 2014 44 2018 41 58 792 2290 46 2008 46 2308 40 41 2018 61 2014 46 2015 40 362 44 2014 46 2006 41 2091 61 2030 46 2309 40 2050 61 362 41 2251 61 2031 40 2290 44 2091 41 2310 61 2251 46 2026 40 2018 41 2154 61 40 330 40 91 362 93 44 91 362 93 41 44 330 40 91 362 93 44 91 362 44 362 93 41 44 330 40 91 362 93 44 91 362 93 41 44 40 91 362 93 44 91 362 93 41 44 330 40 91 362 93 44 91 362 44 362 93 41 44 330 40 91 362 44 362 93 44 91 362 44 362 93 41 44 330 40 91 362 44 362 93 44 91 362 44 362 44 362 93 41 44 330 40 91 362 44 362 44 362 93 44 91 362 44 362 44 362 93 44 41 44 330 40 91 362 44 362 93 44 91 362 44 362 44 362 93 41 44 40 91 362 44 362 93 44 91 362 44 362 44 362 93 41 44 330 40 91 362 44 362 93 44 91 362 44 362 93 41 44 40 91 362 44 362 93 44 91 362 44 362 93 41 44 330 40 91 362 93 44 91 362 44 362 93 41 44 330 40 91 362 93 44 91 362 93 41 44 41 664 2033 44 2313 696 2154 58 871 2014 46 2157 40 2033 61 2033 41 58 2014 46 2027 40 2310 46 2314 40 2033 41 44 2313 41 612 2337 40 2014 41 58 362 2047 61 2048 46 2008 46 2049 40 2050 61 362 41 664 2108 696 779 40 1502 41 58 2023 46 2008 46 2049 40 2050 61 362 37 2108 44 2047 61 2047 41 2217 61 2014 46 2013 40 362 41 2218 61 2014 46 2013 40 362 41 330 2021 61 2338 40 2023 44 2024 41 2018 61 2014 46 2015 40 362 44 2217 41 2211 61 2021 46 2220 40 2018 41 2014 46 2027 40 2211 46 2281 91 362 93 46 2339 44 91 362 44 362 93 41 330 2021 61 2338 40 2023 44 2024 41 2018 61 2014 46 2015 40 362 44 2218 41 2211 61 2021 46 2220 40 2018 41 2014 46 2027 40 2211 46 2281 91 362 93 46 2339 44 40 362 44 362 44 362 41 41 612 2340 40 2014 41 58 2341 61 2014 46 2013 40 362 41 2021 61 2342 40 2023 44 2024 41 2018 61 2014 46 2015 40 362 44 2341 41 2211 61 2021 46 2220 40 2018 41 2014 46 2027 40 2211 46 2281 91 362 93 46 2171 44 40 362 44 362 41 41 612 2343 40 2014 41 58 362 330 2021 61 2137 40 2132 44 2024 41 2018 61 2014 46 2002 46 2019 40 362 41 2018 46 2017 61 2014 46 2006 2025 61 2021 46 2026 40 2018 41 2025 46 2276 61 1502 2344 61 2025 46 2115 46 2344 664 2284 44 2345 44 2313 696 91 40 1501 44 1501 44 91 93 41 44 40 1501 44 1502 44 91 1501 44 1502 93 41 44 40 1502 44 1503 44 91 1501 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1503 93 41 44 40 1502 44 1503 44 91 1501 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1503 44 1503 93 41 44 40 1502 44 1503 44 91 1501 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 2344 44 1503 44 1503 93 41 44 40 1502 44 1503 44 91 1501 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1503 44 1503 93 41 44 40 1502 44 1503 44 91 1501 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1503 44 1503 44 1503 93 41 44 40 1502 44 1503 44 91 1501 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 2344 44 1503 44 1503 93 41 44 40 1502 44 1503 44 91 1501 44 1502 44 2344 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1503 44 1503 44 1503 93 41 44 40 1502 44 1503 44 91 1501 44 1502 44 2344 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1503 44 1503 44 1503 44 1503 93 41 44 40 1502 44 1503 44 91 1501 44 1502 44 2344 44 1502 44 1502 44 1502 44 1502 44 1502 44 1502 44 1503 44 2344 44 1503 44 1503 93 41 44 93 58 871 2014 46 2157 40 2284 61 2284 44 2345 61 2345 41 58 330 2132 46 2008 46 544 40 41 46 2128 40 41 664 2108 696 779 40 2345 42 2025 46 2276 41 58 2132 46 2008 46 2049 40 2050 61 362 41 330 2025 46 2346 61 2284 2025 46 2113 40 2018 41 2014 46 2027 40 723 40 2347 40 2025 41 91 362 93 41 44 2313 41 612 2348 40 2014 41 58 362 2006 61 2014 46 2013 40 362 41 2021 61 2349 40 2207 44 2024 41 2018 61 2014 46 2015 40 362 44 2006 41 2014 46 2350 40 2021 46 2351 40 2018 41 41 2211 61 2021 46 2220 40 2018 41 2014 46 2199 40 362 44 2211 46 2352 41 330 2014 46 2198 40 362 44 2211 46 2352 41 612 2353 40 2014 41 58 2006 61 2014 46 2013 40 362 41 2021 61 2124 40 2039 44 2024 41 330 2021 46 2171 61 91 362 93 2018 61 2014 46 2015 40 362 44 2006 41 2211 61 2021 46 2220 40 2018 41 2014 46 2354 40 2211 46 2281 91 362 93 46 2355 41 2014 46 2215 40 2211 44 362 41 330 2021 46 2355 61 362 2018 61 2014 46 2015 40 362 44 2006 41 2211 61 2021 46 2220 40 2018 41 2014 46 2027 40 2211 46 2281 91 362 93 46 2355 44 362 41 2014 46 2212 40 2211 44 362 41 587 2356 40 2001 41 58 612 2357 40 2014 41 58 362 2068 61 2079 40 123 362 58 2192 40 41 125 41 2077 61 2078 40 362 41 330 2014 46 2027 40 2077 46 2082 40 2068 41 44 362 41 612 2358 40 2014 41 58 362 2017 61 2007 40 2010 61 362 44 2012 61 362 44 2011 61 362 41 2017 46 2359 40 41 2360 61 2361 46 2008 46 2362 40 2007 41 2363 46 2008 46 2364 40 2017 46 2125 44 2360 46 2125 44 2017 46 2125 44 787 40 2017 41 44 1501 41 2365 61 2078 40 362 362 362 362 362 41 2014 46 2027 40 2365 46 2082 40 2079 40 123 125 41 41 44 362 41 612 2366 40 2014 41 58 2367 61 362 871 2014 46 2368 40 2369 44 2367 41 58 2078 40 362 41 612 2370 40 2014 41 58 2367 61 362 871 2014 46 2368 40 2369 44 2367 41 58 2078 40 362 41 612 2371 40 2014 41 58 2367 61 362 871 2014 46 2368 40 2369 44 2367 41 58 2078 40 362 41 612 2372 40 2014 41 58 2367 61 362 871 2014 46 2368 40 2369 44 2367 41 58 2078 40 362 41 64 2373 40 2374 61 362 41 587 2375 40 2376 41 58 2377 61 91 362 93 43 2376 46 2377 612 2378 40 2014 41 58 2007 46 2008 46 2009 40 2010 61 362 44 2012 61 362 44 2011 61 470 41 612 2379 40 2014 41 58 362 668 2380 46 2381 46 2382 46 2383 695 2384 2014 46 2385 40 2010 61 362 44 2012 61 362 41 2014 46 2380 46 2019 40 2014 46 2386 43 2084 40 362 41 41 2387 61 362 330 2388 61 2014 46 2380 46 2389 40 2384 46 2390 44 362 37 2387 41 2014 46 2027 40 720 40 2388 41 44 1501 41 2391 61 2388 91 1500 93 2392 61 2014 46 2380 46 2393 40 2384 46 2390 44 362 37 2387 41 2394 61 2014 46 2380 46 2393 40 2384 46 2395 44 362 41 2396 61 2014 46 2380 46 2393 40 2384 46 2390 44 362 37 2387 41 330 2014 46 2027 40 2392 46 2397 44 362 41 2014 46 2061 40 2394 46 2398 40 362 41 44 443 41 2014 46 2027 40 2391 46 2399 40 362 41 44 362 41 330 2396 46 2400 40 41 2014 46 2027 40 2392 46 2397 44 362 41 2014 46 2061 40 2394 46 2398 40 362 41 44 515 41 2014 46 2027 40 2391 46 2399 40 362 41 44 362 41 330 2396 46 2400 40 41 2014 46 2027 40 2392 46 2397 44 362 41 2014 46 2061 40 2394 46 2398 40 362 41 44 443 41 2014 46 2027 40 2391 46 2399 40 362 41 44 362 41 612 2401 40 2014 41 58 362 668 2380 46 2381 46 2382 46 2402 695 2403 668 2380 46 2381 46 2382 46 2383 695 2384 668 2380 46 2381 46 2382 46 2404 695 2405 2048 46 2008 46 2406 40 91 2048 40 2050 61 362 37 2108 41 664 2108 696 779 40 1502 41 93 41 2014 46 2385 40 2010 61 362 44 2012 61 362 41 2014 46 2380 46 2019 40 2014 46 2386 43 2084 40 362 41 41 2407 61 2014 46 2380 46 2389 40 2384 46 2390 44 362 41 2014 46 2027 40 720 40 2407 41 44 1502 41 664 2256 696 2407 58 2014 46 2061 40 2256 46 2398 40 362 41 44 443 41 330 2407 91 1500 93 46 2400 40 41 2403 40 2014 46 2380 41 46 2408 40 2405 46 2409 41 46 2400 40 2407 91 45 1502 93 41 46 2410 40 2405 46 2409 41 46 2411 40 41 664 2256 696 2407 91 58 45 1502 93 58 2014 46 2061 40 2256 46 2398 40 362 41 44 515 41 2014 46 2061 40 2407 91 45 1501 93 46 2398 40 362 41 44 443 41 612 2412 40 2014 41 58 668 2380 46 2381 46 2382 46 2383 695 2384 2048 46 2008 46 2406 40 91 2048 40 2050 61 362 37 2108 41 664 2108 696 779 40 1504 41 93 41 2014 46 2385 40 2010 61 362 44 2012 61 362 41 2014 46 2380 46 2019 40 2014 46 2386 43 2084 40 362 41 41 2392 61 2014 46 2380 46 2393 40 2384 46 2390 44 362 41 2413 61 2014 46 2380 46 2393 40 2384 46 2390 44 362 41 2414 61 2014 46 2380 46 2393 40 2384 46 2390 44 362 41 2415 61 2014 46 2380 46 2393 40 2384 46 2390 44 362 41 2416 61 2014 46 2380 46 2393 40 2384 46 2395 44 362 41 2417 61 2014 46 2380 46 2389 40 2384 46 2418 44 362 41 2014 46 2061 40 2414 46 2419 40 41 44 443 41 2014 46 2061 40 2415 46 2419 40 41 44 443 41 2014 46 2061 40 2416 46 2398 40 362 41 44 443 41 664 2420 696 2417 58 2014 46 2027 40 2420 46 2398 40 362 41 44 362 41 2014 46 2061 40 2392 46 2419 40 41 44 515 41 2014 46 2027 40 2392 46 2397 44 362 41 2014 46 2061 40 2413 46 2419 40 41 44 443 41 2416 46 2400 40 41 2014 46 2061 40 2414 46 2419 40 41 44 515 41 2014 46 2061 40 2415 46 2419 40 41 44 443 41 2014 46 2061 40 2416 46 2398 40 362 41 44 515 41 664 2420 696 2417 58 2014 46 2027 40 2420 46 2398 40 362 41 44 362 41 2014 46 2061 40 2392 46 2419 40 41 44 515 41 2014 46 2027 40 2392 46 2397 44 362 41 2014 46 2061 40 2413 46 2419 40 41 44 443 41 2414 46 2400 40 41 2014 46 2061 40 2414 46 2419 40 41 44 443 41 2014 46 2061 40 2415 46 2419 40 41 44 515 41 2014 46 2061 40 2416 46 2398 40 362 41 44 515 41 664 2420 696 2417 58 2014 46 2027 40 2420 46 2398 40 362 41 44 362 41 2014 46 2061 40 2392 46 2419 40 41 44 443 41 2014 46 2061 40 2413 46 2419 40 41 44 515 41 2415 46 2400 40 41 2014 46 2061 40 2414 46 2419 40 41 44 443 41 2014 46 2061 40 2415 46 2419 40 41 44 443 41 2014 46 2061 40 2416 46 2398 40 362 41 44 443 41 664 2420 696 2417 58 2014 46 2027 40 2420 46 2398 40 362 41 44 362 41 2014 46 2061 40 2392 46 2419 40 41 44 515 41 2014 46 2027 40 2392 46 2397 44 362 41 2014 46 2061 40 2413 46 2419 40 41 44 443 41 612 2421 40 2014 41 58 668 2380 46 2381 46 2382 46 2383 695 2384 2048 46 2008 46 2049 40 2050 61 362 41 2014 46 2385 40 2010 61 362 44 2012 61 362 41 2014 46 2380 46 2019 40 2014 46 2386 43 2084 40 362 41 41 2422 61 2014 46 2380 46 2393 40 2384 46 2395 44 362 41 2422 46 2415 40 41 2422 46 2423 40 362 41 2014 46 2380 46 2393 40 2384 46 2395 44 362 41 46 2400 40 41 2014 46 2380 46 2393 40 2384 46 2418 44 362 41 46 2400 40 41 330 2424 61 2014 46 2380 46 2425 46 2424 830 58 2014 46 2027 40 2424 46 2397 44 362 362 41 658 58 2424 46 2426 40 41 612 2427 40 2014 41 58 668 2380 46 2381 46 2382 46 2383 695 2384 668 2380 46 2381 46 2428 46 2429 695 2430 2048 46 2008 46 2049 40 2050 61 362 41 2014 46 2385 40 2010 61 362 44 2012 61 362 41 2014 46 2380 46 2019 40 2014 46 2386 43 2084 40 362 41 41 2422 61 2014 46 2380 46 2393 40 2384 46 2395 44 362 41 2422 46 2415 40 41 2422 46 2423 40 362 41 2430 40 2014 46 2380 46 2393 40 2384 46 2418 44 362 41 41 46 2431 40 362 41 2014 46 2380 46 2393 40 2384 46 2418 44 362 41 46 2400 40 41 2424 61 2014 46 2380 46 2425 46 2424 830 58 2014 46 2027 40 2424 46 2397 44 362 362 362 44 41 658 58 2424 46 2426 40 41 612 2432 40 2014 41 58 668 2380 46 2381 46 2382 46 2383 695 2384 668 2380 46 2381 46 2428 46 2429 695 2430 2048 46 2008 46 2049 40 2050 61 362 41 2014 46 2385 40 2010 61 362 44 2012 61 362 41 2014 46 2380 46 2019 40 2014 46 2386 43 2084 40 362 41 41 2430 40 2014 46 2380 46 2393 40 2384 46 2418 44 362 41 41 46 2431 40 362 41 2014 46 2380 46 2393 40 2384 46 2418 44 362 41 46 2400 40 41 2424 61 2014 46 2380 46 2425 46 2424 830 58 2014 46 2027 40 2424 46 2397 44 362 362 362 44 41 658 58 2424 46 2426 40 41 ,"{'AvgLine': 24, 'CountLine': 1634, 'CountStmt': 958, 'MaxNesting': 3, 'AvgLineCode': 19, 'AvgEssential': 1, 'AvgLineBlank': 2, 'CountStmtExe': 854, 'MaxEssential': 1, 'SumEssential': 77, 'AvgCyclomatic': 1, 'CountLineCode': 1198, 'CountStmtDecl': 487, 'MaxCyclomatic': 5, 'SumCyclomatic': 111, 'AvgLineComment': 3, 'CountClassBase': 0, 'CountLineBlank': 198, 'CountDeclMethod': 55, 'CountLineCodeExe': 1087, 'CountLineComment': 249, 'CountClassCoupled': 58, 'CountClassDerived': 0, 'CountLineCodeDecl': 493, 'CountDeclMethodAll': 55, 'MaxInheritanceTree': 0, 'RatioCommentToCode': '0.21', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 5, 'SumCyclomaticStrict': 111, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 5, 'SumCyclomaticModified': 111, 'CountDeclInstanceMethod': 54, 'CountClassCoupledModified': 54, 'CountDeclInstanceVariable': 0}"
134850,Python,"class LookupTests(TestCase):

    @classmethod
    def setUpTestData(cls):
        # Create a few Authors.
        cls.au1 = Author.objects.create(name='Author 1', alias='a1')
        cls.au2 = Author.objects.create(name='Author 2', alias='a2')
        # Create a few Articles.
        cls.a1 = Article.objects.create(
            headline='Article 1',
            pub_date=datetime(2005, 7, 26),
            author=cls.au1,
            slug='a1',
        )
        cls.a2 = Article.objects.create(
            headline='Article 2',
            pub_date=datetime(2005, 7, 27),
            author=cls.au1,
            slug='a2',
        )
        cls.a3 = Article.objects.create(
            headline='Article 3',
            pub_date=datetime(2005, 7, 27),
            author=cls.au1,
            slug='a3',
        )
        cls.a4 = Article.objects.create(
            headline='Article 4',
            pub_date=datetime(2005, 7, 28),
            author=cls.au1,
            slug='a4',
        )
        cls.a5 = Article.objects.create(
            headline='Article 5',
            pub_date=datetime(2005, 8, 1, 9, 0),
            author=cls.au2,
            slug='a5',
        )
        cls.a6 = Article.objects.create(
            headline='Article 6',
            pub_date=datetime(2005, 8, 1, 8, 0),
            author=cls.au2,
            slug='a6',
        )
        cls.a7 = Article.objects.create(
            headline='Article 7',
            pub_date=datetime(2005, 7, 27),
            author=cls.au2,
            slug='a7',
        )
        # Create a few Tags.
        cls.t1 = Tag.objects.create(name='Tag 1')
        cls.t1.articles.add(cls.a1, cls.a2, cls.a3)
        cls.t2 = Tag.objects.create(name='Tag 2')
        cls.t2.articles.add(cls.a3, cls.a4, cls.a5)
        cls.t3 = Tag.objects.create(name='Tag 3')
        cls.t3.articles.add(cls.a5, cls.a6, cls.a7)

    def test_exists(self):
        # We can use .exists() to check that there are some
        self.assertTrue(Article.objects.exists())
        for a in Article.objects.all():
            a.delete()
        # There should be none now!
        self.assertFalse(Article.objects.exists())

    def test_lookup_int_as_str(self):
        # Integer value can be queried using string
        self.assertSequenceEqual(
            Article.objects.filter(id__iexact=str(self.a1.id)),
            [self.a1],
        )

    @skipUnlessDBFeature('supports_date_lookup_using_string')
    def test_lookup_date_as_str(self):
        # A date lookup can be performed using a string search
        self.assertSequenceEqual(
            Article.objects.filter(pub_date__startswith='2005'),
            [self.a5, self.a6, self.a4, self.a2, self.a3, self.a7, self.a1],
        )

    def test_iterator(self):
        # Each QuerySet gets iterator(), which is a generator that ""lazily""
        # returns results using database-level iteration.
        self.assertIsInstance(Article.objects.iterator(), collections.abc.Iterator)

        self.assertQuerysetEqual(
            Article.objects.iterator(),
            [
                'Article 5',
                'Article 6',
                'Article 4',
                'Article 2',
                'Article 3',
                'Article 7',
                'Article 1',
            ],
            transform=attrgetter('headline')
        )
        # iterator() can be used on any QuerySet.
        self.assertQuerysetEqual(
            Article.objects.filter(headline__endswith='4').iterator(),
            ['Article 4'],
            transform=attrgetter('headline'))

    def test_count(self):
        # count() returns the number of objects matching search criteria.
        self.assertEqual(Article.objects.count(), 7)
        self.assertEqual(Article.objects.filter(pub_date__exact=datetime(2005, 7, 27)).count(), 3)
        self.assertEqual(Article.objects.filter(headline__startswith='Blah blah').count(), 0)

        # count() should respect sliced query sets.
        articles = Article.objects.all()
        self.assertEqual(articles.count(), 7)
        self.assertEqual(articles[:4].count(), 4)
        self.assertEqual(articles[1:100].count(), 6)
        self.assertEqual(articles[10:100].count(), 0)

        # Date and date/time lookups can also be done with strings.
        self.assertEqual(Article.objects.filter(pub_date__exact='2005-07-27 00:00:00').count(), 3)

    def test_in_bulk(self):
        # in_bulk() takes a list of IDs and returns a dictionary mapping IDs to objects.
        arts = Article.objects.in_bulk([self.a1.id, self.a2.id])
        self.assertEqual(arts[self.a1.id], self.a1)
        self.assertEqual(arts[self.a2.id], self.a2)
        self.assertEqual(
            Article.objects.in_bulk(),
            {
                self.a1.id: self.a1,
                self.a2.id: self.a2,
                self.a3.id: self.a3,
                self.a4.id: self.a4,
                self.a5.id: self.a5,
                self.a6.id: self.a6,
                self.a7.id: self.a7,
            }
        )
        self.assertEqual(Article.objects.in_bulk([self.a3.id]), {self.a3.id: self.a3})
        self.assertEqual(Article.objects.in_bulk({self.a3.id}), {self.a3.id: self.a3})
        self.assertEqual(Article.objects.in_bulk(frozenset([self.a3.id])), {self.a3.id: self.a3})
        self.assertEqual(Article.objects.in_bulk((self.a3.id,)), {self.a3.id: self.a3})
        self.assertEqual(Article.objects.in_bulk([1000]), {})
        self.assertEqual(Article.objects.in_bulk([]), {})
        self.assertEqual(Article.objects.in_bulk(iter([self.a1.id])), {self.a1.id: self.a1})
        self.assertEqual(Article.objects.in_bulk(iter([])), {})
        with self.assertRaises(TypeError):
            Article.objects.in_bulk(headline__startswith='Blah')

    def test_in_bulk_lots_of_ids(self):
        test_range = 2000
        max_query_params = connection.features.max_query_params
        expected_num_queries = ceil(test_range / max_query_params) if max_query_params else 1
        Author.objects.bulk_create([Author() for i in range(test_range - Author.objects.count())])
        authors = {author.pk: author for author in Author.objects.all()}
        with self.assertNumQueries(expected_num_queries):
            self.assertEqual(Author.objects.in_bulk(authors), authors)

    def test_in_bulk_with_field(self):
        self.assertEqual(
            Article.objects.in_bulk([self.a1.slug, self.a2.slug, self.a3.slug], field_name='slug'),
            {
                self.a1.slug: self.a1,
                self.a2.slug: self.a2,
                self.a3.slug: self.a3,
            }
        )

    def test_in_bulk_meta_constraint(self):
        season_2011 = Season.objects.create(year=2011)
        season_2012 = Season.objects.create(year=2012)
        Season.objects.create(year=2013)
        self.assertEqual(
            Season.objects.in_bulk(
                [season_2011.year, season_2012.year],
                field_name='year',
            ),
            {season_2011.year: season_2011, season_2012.year: season_2012},
        )

    def test_in_bulk_non_unique_field(self):
        msg = ""in_bulk()'s field_name must be a unique field but 'author' isn't.""
        with self.assertRaisesMessage(ValueError, msg):
            Article.objects.in_bulk([self.au1], field_name='author')

    @skipUnlessDBFeature('can_distinct_on_fields')
    def test_in_bulk_distinct_field(self):
        self.assertEqual(
            Article.objects.order_by('headline').distinct('headline').in_bulk(
                [self.a1.headline, self.a5.headline],
                field_name='headline',
            ),
            {self.a1.headline: self.a1, self.a5.headline: self.a5},
        )

    @skipUnlessDBFeature('can_distinct_on_fields')
    def test_in_bulk_multiple_distinct_field(self):
        msg = ""in_bulk()'s field_name must be a unique field but 'pub_date' isn't.""
        with self.assertRaisesMessage(ValueError, msg):
            Article.objects.order_by('headline', 'pub_date').distinct(
                'headline', 'pub_date',
            ).in_bulk(field_name='pub_date')

    @isolate_apps('lookup')
    def test_in_bulk_non_unique_meta_constaint(self):
        class Model(models.Model):
            ean = models.CharField(max_length=100)
            brand = models.CharField(max_length=100)
            name = models.CharField(max_length=80)

            class Meta:
                constraints = [
                    models.UniqueConstraint(
                        fields=['ean'],
                        name='partial_ean_unique',
                        condition=models.Q(is_active=True)
                    ),
                    models.UniqueConstraint(
                        fields=['brand', 'name'],
                        name='together_brand_name_unique',
                    ),
                ]

        msg = ""in_bulk()'s field_name must be a unique field but '%s' isn't.""
        for field_name in ['brand', 'ean']:
            with self.subTest(field_name=field_name):
                with self.assertRaisesMessage(ValueError, msg % field_name):
                    Model.objects.in_bulk(field_name=field_name)

    def test_in_bulk_sliced_queryset(self):
        msg = ""Cannot use 'limit' or 'offset' with in_bulk().""
        with self.assertRaisesMessage(TypeError, msg):
            Article.objects.all()[0:5].in_bulk([self.a1.id, self.a2.id])

    def test_values(self):
        # values() returns a list of dictionaries instead of object instances --
        # and you can specify which fields you want to retrieve.
        self.assertSequenceEqual(
            Article.objects.values('headline'),
            [
                {'headline': 'Article 5'},
                {'headline': 'Article 6'},
                {'headline': 'Article 4'},
                {'headline': 'Article 2'},
                {'headline': 'Article 3'},
                {'headline': 'Article 7'},
                {'headline': 'Article 1'},
            ],
        )
        self.assertSequenceEqual(
            Article.objects.filter(pub_date__exact=datetime(2005, 7, 27)).values('id'),
            [{'id': self.a2.id}, {'id': self.a3.id}, {'id': self.a7.id}],
        )
        self.assertSequenceEqual(
            Article.objects.values('id', 'headline'),
            [
                {'id': self.a5.id, 'headline': 'Article 5'},
                {'id': self.a6.id, 'headline': 'Article 6'},
                {'id': self.a4.id, 'headline': 'Article 4'},
                {'id': self.a2.id, 'headline': 'Article 2'},
                {'id': self.a3.id, 'headline': 'Article 3'},
                {'id': self.a7.id, 'headline': 'Article 7'},
                {'id': self.a1.id, 'headline': 'Article 1'},
            ],
        )
        # You can use values() with iterator() for memory savings,
        # because iterator() uses database-level iteration.
        self.assertSequenceEqual(
            list(Article.objects.values('id', 'headline').iterator()),
            [
                {'headline': 'Article 5', 'id': self.a5.id},
                {'headline': 'Article 6', 'id': self.a6.id},
                {'headline': 'Article 4', 'id': self.a4.id},
                {'headline': 'Article 2', 'id': self.a2.id},
                {'headline': 'Article 3', 'id': self.a3.id},
                {'headline': 'Article 7', 'id': self.a7.id},
                {'headline': 'Article 1', 'id': self.a1.id},
            ],
        )
        # The values() method works with ""extra"" fields specified in extra(select).
        self.assertSequenceEqual(
            Article.objects.extra(select={'id_plus_one': 'id + 1'}).values('id', 'id_plus_one'),
            [
                {'id': self.a5.id, 'id_plus_one': self.a5.id + 1},
                {'id': self.a6.id, 'id_plus_one': self.a6.id + 1},
                {'id': self.a4.id, 'id_plus_one': self.a4.id + 1},
                {'id': self.a2.id, 'id_plus_one': self.a2.id + 1},
                {'id': self.a3.id, 'id_plus_one': self.a3.id + 1},
                {'id': self.a7.id, 'id_plus_one': self.a7.id + 1},
                {'id': self.a1.id, 'id_plus_one': self.a1.id + 1},
            ],
        )
        data = {
            'id_plus_one': 'id+1',
            'id_plus_two': 'id+2',
            'id_plus_three': 'id+3',
            'id_plus_four': 'id+4',
            'id_plus_five': 'id+5',
            'id_plus_six': 'id+6',
            'id_plus_seven': 'id+7',
            'id_plus_eight': 'id+8',
        }
        self.assertSequenceEqual(
            Article.objects.filter(id=self.a1.id).extra(select=data).values(*data),
            [{
                'id_plus_one': self.a1.id + 1,
                'id_plus_two': self.a1.id + 2,
                'id_plus_three': self.a1.id + 3,
                'id_plus_four': self.a1.id + 4,
                'id_plus_five': self.a1.id + 5,
                'id_plus_six': self.a1.id + 6,
                'id_plus_seven': self.a1.id + 7,
                'id_plus_eight': self.a1.id + 8,
            }],
        )
        # You can specify fields from forward and reverse relations, just like filter().
        self.assertSequenceEqual(
            Article.objects.values('headline', 'author__name'),
            [
                {'headline': self.a5.headline, 'author__name': self.au2.name},
                {'headline': self.a6.headline, 'author__name': self.au2.name},
                {'headline': self.a4.headline, 'author__name': self.au1.name},
                {'headline': self.a2.headline, 'author__name': self.au1.name},
                {'headline': self.a3.headline, 'author__name': self.au1.name},
                {'headline': self.a7.headline, 'author__name': self.au2.name},
                {'headline': self.a1.headline, 'author__name': self.au1.name},
            ],
        )
        self.assertSequenceEqual(
            Author.objects.values('name', 'article__headline').order_by('name', 'article__headline'),
            [
                {'name': self.au1.name, 'article__headline': self.a1.headline},
                {'name': self.au1.name, 'article__headline': self.a2.headline},
                {'name': self.au1.name, 'article__headline': self.a3.headline},
                {'name': self.au1.name, 'article__headline': self.a4.headline},
                {'name': self.au2.name, 'article__headline': self.a5.headline},
                {'name': self.au2.name, 'article__headline': self.a6.headline},
                {'name': self.au2.name, 'article__headline': self.a7.headline},
            ],
        )
        self.assertSequenceEqual(
            (
                Author.objects
                .values('name', 'article__headline', 'article__tag__name')
                .order_by('name', 'article__headline', 'article__tag__name')
            ),
            [
                {'name': self.au1.name, 'article__headline': self.a1.headline, 'article__tag__name': self.t1.name},
                {'name': self.au1.name, 'article__headline': self.a2.headline, 'article__tag__name': self.t1.name},
                {'name': self.au1.name, 'article__headline': self.a3.headline, 'article__tag__name': self.t1.name},
                {'name': self.au1.name, 'article__headline': self.a3.headline, 'article__tag__name': self.t2.name},
                {'name': self.au1.name, 'article__headline': self.a4.headline, 'article__tag__name': self.t2.name},
                {'name': self.au2.name, 'article__headline': self.a5.headline, 'article__tag__name': self.t2.name},
                {'name': self.au2.name, 'article__headline': self.a5.headline, 'article__tag__name': self.t3.name},
                {'name': self.au2.name, 'article__headline': self.a6.headline, 'article__tag__name': self.t3.name},
                {'name': self.au2.name, 'article__headline': self.a7.headline, 'article__tag__name': self.t3.name},
            ],
        )
        # However, an exception FieldDoesNotExist will be thrown if you specify
        # a nonexistent field name in values() (a field that is neither in the
        # model nor in extra(select)).
        msg = (
            ""Cannot resolve keyword 'id_plus_two' into field. Choices are: ""
            ""author, author_id, headline, id, id_plus_one, pub_date, slug, tag""
        )
        with self.assertRaisesMessage(FieldError, msg):
            Article.objects.extra(select={'id_plus_one': 'id + 1'}).values('id', 'id_plus_two')
        # If you don't specify field names to values(), all are returned.
        self.assertSequenceEqual(
            Article.objects.filter(id=self.a5.id).values(),
            [{
                'id': self.a5.id,
                'author_id': self.au2.id,
                'headline': 'Article 5',
                'pub_date': datetime(2005, 8, 1, 9, 0),
                'slug': 'a5',
            }],
        )

    def test_values_list(self):
        # values_list() is similar to values(), except that the results are
        # returned as a list of tuples, rather than a list of dictionaries.
        # Within each tuple, the order of the elements is the same as the order
        # of fields in the values_list() call.
        self.assertSequenceEqual(
            Article.objects.values_list('headline'),
            [
                ('Article 5',),
                ('Article 6',),
                ('Article 4',),
                ('Article 2',),
                ('Article 3',),
                ('Article 7',),
                ('Article 1',),
            ],
        )
        self.assertSequenceEqual(
            Article.objects.values_list('id').order_by('id'),
            [(self.a1.id,), (self.a2.id,), (self.a3.id,), (self.a4.id,), (self.a5.id,), (self.a6.id,), (self.a7.id,)],
        )
        self.assertSequenceEqual(
            Article.objects.values_list('id', flat=True).order_by('id'),
            [self.a1.id, self.a2.id, self.a3.id, self.a4.id, self.a5.id, self.a6.id, self.a7.id],
        )
        self.assertSequenceEqual(
            Article.objects.extra(select={'id_plus_one': 'id+1'}).order_by('id').values_list('id'),
            [(self.a1.id,), (self.a2.id,), (self.a3.id,), (self.a4.id,), (self.a5.id,), (self.a6.id,), (self.a7.id,)],
        )
        self.assertSequenceEqual(
            Article.objects.extra(select={'id_plus_one': 'id+1'}).order_by('id').values_list('id_plus_one', 'id'),
            [
                (self.a1.id + 1, self.a1.id),
                (self.a2.id + 1, self.a2.id),
                (self.a3.id + 1, self.a3.id),
                (self.a4.id + 1, self.a4.id),
                (self.a5.id + 1, self.a5.id),
                (self.a6.id + 1, self.a6.id),
                (self.a7.id + 1, self.a7.id)
            ],
        )
        self.assertSequenceEqual(
            Article.objects.extra(select={'id_plus_one': 'id+1'}).order_by('id').values_list('id', 'id_plus_one'),
            [
                (self.a1.id, self.a1.id + 1),
                (self.a2.id, self.a2.id + 1),
                (self.a3.id, self.a3.id + 1),
                (self.a4.id, self.a4.id + 1),
                (self.a5.id, self.a5.id + 1),
                (self.a6.id, self.a6.id + 1),
                (self.a7.id, self.a7.id + 1)
            ],
        )
        args = ('name', 'article__headline', 'article__tag__name')
        self.assertSequenceEqual(
            Author.objects.values_list(*args).order_by(*args),
            [
                (self.au1.name, self.a1.headline, self.t1.name),
                (self.au1.name, self.a2.headline, self.t1.name),
                (self.au1.name, self.a3.headline, self.t1.name),
                (self.au1.name, self.a3.headline, self.t2.name),
                (self.au1.name, self.a4.headline, self.t2.name),
                (self.au2.name, self.a5.headline, self.t2.name),
                (self.au2.name, self.a5.headline, self.t3.name),
                (self.au2.name, self.a6.headline, self.t3.name),
                (self.au2.name, self.a7.headline, self.t3.name),
            ],
        )
        with self.assertRaises(TypeError):
            Article.objects.values_list('id', 'headline', flat=True)

    def test_get_next_previous_by(self):
        # Every DateField and DateTimeField creates get_next_by_FOO() and
        # get_previous_by_FOO() methods. In the case of identical date values,
        # these methods will use the ID as a fallback check. This guarantees
        # that no records are skipped or duplicated.
        self.assertEqual(repr(self.a1.get_next_by_pub_date()), '<Article: Article 2>')
        self.assertEqual(repr(self.a2.get_next_by_pub_date()), '<Article: Article 3>')
        self.assertEqual(repr(self.a2.get_next_by_pub_date(headline__endswith='6')), '<Article: Article 6>')
        self.assertEqual(repr(self.a3.get_next_by_pub_date()), '<Article: Article 7>')
        self.assertEqual(repr(self.a4.get_next_by_pub_date()), '<Article: Article 6>')
        with self.assertRaises(Article.DoesNotExist):
            self.a5.get_next_by_pub_date()
        self.assertEqual(repr(self.a6.get_next_by_pub_date()), '<Article: Article 5>')
        self.assertEqual(repr(self.a7.get_next_by_pub_date()), '<Article: Article 4>')

        self.assertEqual(repr(self.a7.get_previous_by_pub_date()), '<Article: Article 3>')
        self.assertEqual(repr(self.a6.get_previous_by_pub_date()), '<Article: Article 4>')
        self.assertEqual(repr(self.a5.get_previous_by_pub_date()), '<Article: Article 6>')
        self.assertEqual(repr(self.a4.get_previous_by_pub_date()), '<Article: Article 7>')
        self.assertEqual(repr(self.a3.get_previous_by_pub_date()), '<Article: Article 2>')
        self.assertEqual(repr(self.a2.get_previous_by_pub_date()), '<Article: Article 1>')

    def test_escaping(self):
        # Underscores, percent signs and backslashes have special meaning in the
        # underlying SQL code, but Django handles the quoting of them automatically.
        a8 = Article.objects.create(headline='Article_ with underscore', pub_date=datetime(2005, 11, 20))

        self.assertSequenceEqual(
            Article.objects.filter(headline__startswith='Article'),
            [a8, self.a5, self.a6, self.a4, self.a2, self.a3, self.a7, self.a1],
        )
        self.assertSequenceEqual(
            Article.objects.filter(headline__startswith='Article_'),
            [a8],
        )
        a9 = Article.objects.create(headline='Article% with percent sign', pub_date=datetime(2005, 11, 21))
        self.assertSequenceEqual(
            Article.objects.filter(headline__startswith='Article'),
            [a9, a8, self.a5, self.a6, self.a4, self.a2, self.a3, self.a7, self.a1],
        )
        self.assertSequenceEqual(
            Article.objects.filter(headline__startswith='Article%'),
            [a9],
        )
        a10 = Article.objects.create(headline='Article with \\ backslash', pub_date=datetime(2005, 11, 22))
        self.assertSequenceEqual(
            Article.objects.filter(headline__contains='\\'),
            [a10],
        )

    def test_exclude(self):
        pub_date = datetime(2005, 11, 20)
        a8 = Article.objects.create(headline='Article_ with underscore', pub_date=pub_date)
        a9 = Article.objects.create(headline='Article% with percent sign', pub_date=pub_date)
        a10 = Article.objects.create(headline='Article with \\ backslash', pub_date=pub_date)
        # exclude() is the opposite of filter() when doing lookups:
        self.assertSequenceEqual(
            Article.objects.filter(headline__contains='Article').exclude(headline__contains='with'),
            [self.a5, self.a6, self.a4, self.a2, self.a3, self.a7, self.a1],
        )
        self.assertSequenceEqual(
            Article.objects.exclude(headline__startswith=""Article_""),
            [a10, a9, self.a5, self.a6, self.a4, self.a2, self.a3, self.a7, self.a1],
        )
        self.assertSequenceEqual(
            Article.objects.exclude(headline=""Article 7""),
            [a10, a9, a8, self.a5, self.a6, self.a4, self.a2, self.a3, self.a1],
        )

    def test_none(self):
        # none() returns a QuerySet that behaves like any other QuerySet object
        self.assertQuerysetEqual(Article.objects.none(), [])
        self.assertQuerysetEqual(Article.objects.none().filter(headline__startswith='Article'), [])
        self.assertQuerysetEqual(Article.objects.filter(headline__startswith='Article').none(), [])
        self.assertEqual(Article.objects.none().count(), 0)
        self.assertEqual(Article.objects.none().update(headline=""This should not take effect""), 0)
        self.assertQuerysetEqual(Article.objects.none().iterator(), [])

    def test_in(self):
        self.assertSequenceEqual(
            Article.objects.exclude(id__in=[]),
            [self.a5, self.a6, self.a4, self.a2, self.a3, self.a7, self.a1],
        )

    def test_in_empty_list(self):
        self.assertSequenceEqual(Article.objects.filter(id__in=[]), [])

    def test_in_different_database(self):
        with self.assertRaisesMessage(
            ValueError,
            ""Subqueries aren't allowed across different databases. Force the ""
            ""inner query to be evaluated using `list(inner_query)`.""
        ):
            list(Article.objects.filter(id__in=Article.objects.using('other').all()))

    def test_in_keeps_value_ordering(self):
        query = Article.objects.filter(slug__in=['a%d' % i for i in range(1, 8)]).values('pk').query
        self.assertIn(' IN (a1, a2, a3, a4, a5, a6, a7) ', str(query))

    def test_in_ignore_none(self):
        with self.assertNumQueries(1) as ctx:
            self.assertSequenceEqual(
                Article.objects.filter(id__in=[None, self.a1.id]),
                [self.a1],
            )
        sql = ctx.captured_queries[0]['sql']
        self.assertIn('IN (%s)' % self.a1.pk, sql)

    def test_in_ignore_solo_none(self):
        with self.assertNumQueries(0):
            self.assertSequenceEqual(Article.objects.filter(id__in=[None]), [])

    def test_in_ignore_none_with_unhashable_items(self):
        class UnhashableInt(int):
            __hash__ = None

        with self.assertNumQueries(1) as ctx:
            self.assertSequenceEqual(
                Article.objects.filter(id__in=[None, UnhashableInt(self.a1.id)]),
                [self.a1],
            )
        sql = ctx.captured_queries[0]['sql']
        self.assertIn('IN (%s)' % self.a1.pk, sql)

    def test_error_messages(self):
        # Programming errors are pointed out with nice error messages
        with self.assertRaisesMessage(
            FieldError,
            ""Cannot resolve keyword 'pub_date_year' into field. Choices are: ""
            ""author, author_id, headline, id, pub_date, slug, tag""
        ):
            Article.objects.filter(pub_date_year='2005').count()

    def test_unsupported_lookups(self):
        with self.assertRaisesMessage(
            FieldError,
            ""Unsupported lookup 'starts' for CharField or join on the field ""
            ""not permitted, perhaps you meant startswith or istartswith?""
        ):
            Article.objects.filter(headline__starts='Article')

        with self.assertRaisesMessage(
            FieldError,
            ""Unsupported lookup 'is_null' for DateTimeField or join on the field ""
            ""not permitted, perhaps you meant isnull?""
        ):
            Article.objects.filter(pub_date__is_null=True)

        with self.assertRaisesMessage(
            FieldError,
            ""Unsupported lookup 'gobbledygook' for DateTimeField or join on the field ""
            ""not permitted.""
        ):
            Article.objects.filter(pub_date__gobbledygook='blahblah')

    def test_relation_nested_lookup_error(self):
        # An invalid nested lookup on a related field raises a useful error.
        msg = 'Related Field got invalid lookup: editor'
        with self.assertRaisesMessage(FieldError, msg):
            Article.objects.filter(author__editor__name='James')
        msg = 'Related Field got invalid lookup: foo'
        with self.assertRaisesMessage(FieldError, msg):
            Tag.objects.filter(articles__foo='bar')

    def test_regex(self):
        # Create some articles with a bit more interesting headlines for testing field lookups:
        for a in Article.objects.all():
            a.delete()
        now = datetime.now()
        Article.objects.bulk_create([
            Article(pub_date=now, headline='f'),
            Article(pub_date=now, headline='fo'),
            Article(pub_date=now, headline='foo'),
            Article(pub_date=now, headline='fooo'),
            Article(pub_date=now, headline='hey-Foo'),
            Article(pub_date=now, headline='bar'),
            Article(pub_date=now, headline='AbBa'),
            Article(pub_date=now, headline='baz'),
            Article(pub_date=now, headline='baxZ'),
        ])
        # zero-or-more
        self.assertQuerysetEqual(
            Article.objects.filter(headline__regex=r'fo*'),
            Article.objects.filter(headline__in=['f', 'fo', 'foo', 'fooo']),
        )
        self.assertQuerysetEqual(
            Article.objects.filter(headline__iregex=r'fo*'),
            Article.objects.filter(headline__in=['f', 'fo', 'foo', 'fooo', 'hey-Foo']),
        )
        # one-or-more
        self.assertQuerysetEqual(
            Article.objects.filter(headline__regex=r'fo+'),
            Article.objects.filter(headline__in=['fo', 'foo', 'fooo']),
        )
        # wildcard
        self.assertQuerysetEqual(
            Article.objects.filter(headline__regex=r'fooo?'),
            Article.objects.filter(headline__in=['foo', 'fooo']),
        )
        # leading anchor
        self.assertQuerysetEqual(
            Article.objects.filter(headline__regex=r'^b'),
            Article.objects.filter(headline__in=['bar', 'baxZ', 'baz']),
        )
        self.assertQuerysetEqual(
            Article.objects.filter(headline__iregex=r'^a'),
            Article.objects.filter(headline='AbBa'),
        )
        # trailing anchor
        self.assertQuerysetEqual(
            Article.objects.filter(headline__regex=r'z$'),
            Article.objects.filter(headline='baz'),
        )
        self.assertQuerysetEqual(
            Article.objects.filter(headline__iregex=r'z$'),
            Article.objects.filter(headline__in=['baxZ', 'baz']),
        )
        # character sets
        self.assertQuerysetEqual(
            Article.objects.filter(headline__regex=r'ba[rz]'),
            Article.objects.filter(headline__in=['bar', 'baz']),
        )
        self.assertQuerysetEqual(
            Article.objects.filter(headline__regex=r'ba.[RxZ]'),
            Article.objects.filter(headline='baxZ'),
        )
        self.assertQuerysetEqual(
            Article.objects.filter(headline__iregex=r'ba[RxZ]'),
            Article.objects.filter(headline__in=['bar', 'baxZ', 'baz']),
        )

        # and more articles:
        Article.objects.bulk_create([
            Article(pub_date=now, headline='foobar'),
            Article(pub_date=now, headline='foobaz'),
            Article(pub_date=now, headline='ooF'),
            Article(pub_date=now, headline='foobarbaz'),
            Article(pub_date=now, headline='zoocarfaz'),
            Article(pub_date=now, headline='barfoobaz'),
            Article(pub_date=now, headline='bazbaRFOO'),
        ])

        # alternation
        self.assertQuerysetEqual(
            Article.objects.filter(headline__regex=r'oo(f|b)'),
            Article.objects.filter(headline__in=[
                'barfoobaz',
                'foobar',
                'foobarbaz',
                'foobaz',
            ]),
        )
        self.assertQuerysetEqual(
            Article.objects.filter(headline__iregex=r'oo(f|b)'),
            Article.objects.filter(headline__in=[
                'barfoobaz',
                'foobar',
                'foobarbaz',
                'foobaz',
                'ooF',
            ]),
        )
        self.assertQuerysetEqual(
            Article.objects.filter(headline__regex=r'^foo(f|b)'),
            Article.objects.filter(headline__in=['foobar', 'foobarbaz', 'foobaz']),
        )

        # greedy matching
        self.assertQuerysetEqual(
            Article.objects.filter(headline__regex=r'b.*az'),
            Article.objects.filter(headline__in=[
                'barfoobaz',
                'baz',
                'bazbaRFOO',
                'foobarbaz',
                'foobaz',
            ]),
        )
        self.assertQuerysetEqual(
            Article.objects.filter(headline__iregex=r'b.*ar'),
            Article.objects.filter(headline__in=[
                'bar',
                'barfoobaz',
                'bazbaRFOO',
                'foobar',
                'foobarbaz',
            ]),
        )

    @skipUnlessDBFeature('supports_regex_backreferencing')
    def test_regex_backreferencing(self):
        # grouping and backreferences
        now = datetime.now()
        Article.objects.bulk_create([
            Article(pub_date=now, headline='foobar'),
            Article(pub_date=now, headline='foobaz'),
            Article(pub_date=now, headline='ooF'),
            Article(pub_date=now, headline='foobarbaz'),
            Article(pub_date=now, headline='zoocarfaz'),
            Article(pub_date=now, headline='barfoobaz'),
            Article(pub_date=now, headline='bazbaRFOO'),
        ])
        self.assertQuerysetEqual(
            Article.objects.filter(headline__regex=r'b(.).*b\1').values_list('headline', flat=True),
            ['barfoobaz', 'bazbaRFOO', 'foobarbaz'],
        )

    def test_regex_null(self):
        """"""
        A regex lookup does not fail on null/None values
        """"""
        Season.objects.create(year=2012, gt=None)
        self.assertQuerysetEqual(Season.objects.filter(gt__regex=r'^$'), [])

    def test_regex_non_string(self):
        """"""
        A regex lookup does not fail on non-string fields
        """"""
        s = Season.objects.create(year=2013, gt=444)
        self.assertQuerysetEqual(Season.objects.filter(gt__regex=r'^444$'), [s])

    def test_regex_non_ascii(self):
        """"""
        A regex lookup does not trip on non-ASCII characters.
        """"""
        Player.objects.create(name='\u2660')
        Player.objects.get(name__regex='\u2660')

    def test_nonfield_lookups(self):
        """"""
        A lookup query containing non-fields raises the proper exception.
        """"""
        msg = ""Unsupported lookup 'blahblah' for CharField or join on the field not permitted.""
        with self.assertRaisesMessage(FieldError, msg):
            Article.objects.filter(headline__blahblah=99)
        with self.assertRaisesMessage(FieldError, msg):
            Article.objects.filter(headline__blahblah__exact=99)
        msg = (
            ""Cannot resolve keyword 'blahblah' into field. Choices are: ""
            ""author, author_id, headline, id, pub_date, slug, tag""
        )
        with self.assertRaisesMessage(FieldError, msg):
            Article.objects.filter(blahblah=99)

    def test_lookup_collision(self):
        """"""
        Genuine field names don't collide with built-in lookup types
        ('year', 'gt', 'range', 'in' etc.) (#11670).
        """"""
        # 'gt' is used as a code number for the year, e.g. 111=>2009.
        season_2009 = Season.objects.create(year=2009, gt=111)
        season_2009.games.create(home=""Houston Astros"", away=""St. Louis Cardinals"")
        season_2010 = Season.objects.create(year=2010, gt=222)
        season_2010.games.create(home=""Houston Astros"", away=""Chicago Cubs"")
        season_2010.games.create(home=""Houston Astros"", away=""Milwaukee Brewers"")
        season_2010.games.create(home=""Houston Astros"", away=""St. Louis Cardinals"")
        season_2011 = Season.objects.create(year=2011, gt=333)
        season_2011.games.create(home=""Houston Astros"", away=""St. Louis Cardinals"")
        season_2011.games.create(home=""Houston Astros"", away=""Milwaukee Brewers"")
        hunter_pence = Player.objects.create(name=""Hunter Pence"")
        hunter_pence.games.set(Game.objects.filter(season__year__in=[2009, 2010]))
        pudge = Player.objects.create(name=""Ivan Rodriquez"")
        pudge.games.set(Game.objects.filter(season__year=2009))
        pedro_feliz = Player.objects.create(name=""Pedro Feliz"")
        pedro_feliz.games.set(Game.objects.filter(season__year__in=[2011]))
        johnson = Player.objects.create(name=""Johnson"")
        johnson.games.set(Game.objects.filter(season__year__in=[2011]))

        # Games in 2010
        self.assertEqual(Game.objects.filter(season__year=2010).count(), 3)
        self.assertEqual(Game.objects.filter(season__year__exact=2010).count(), 3)
        self.assertEqual(Game.objects.filter(season__gt=222).count(), 3)
        self.assertEqual(Game.objects.filter(season__gt__exact=222).count(), 3)

        # Games in 2011
        self.assertEqual(Game.objects.filter(season__year=2011).count(), 2)
        self.assertEqual(Game.objects.filter(season__year__exact=2011).count(), 2)
        self.assertEqual(Game.objects.filter(season__gt=333).count(), 2)
        self.assertEqual(Game.objects.filter(season__gt__exact=333).count(), 2)
        self.assertEqual(Game.objects.filter(season__year__gt=2010).count(), 2)
        self.assertEqual(Game.objects.filter(season__gt__gt=222).count(), 2)

        # Games played in 2010 and 2011
        self.assertEqual(Game.objects.filter(season__year__in=[2010, 2011]).count(), 5)
        self.assertEqual(Game.objects.filter(season__year__gt=2009).count(), 5)
        self.assertEqual(Game.objects.filter(season__gt__in=[222, 333]).count(), 5)
        self.assertEqual(Game.objects.filter(season__gt__gt=111).count(), 5)

        # Players who played in 2009
        self.assertEqual(Player.objects.filter(games__season__year=2009).distinct().count(), 2)
        self.assertEqual(Player.objects.filter(games__season__year__exact=2009).distinct().count(), 2)
        self.assertEqual(Player.objects.filter(games__season__gt=111).distinct().count(), 2)
        self.assertEqual(Player.objects.filter(games__season__gt__exact=111).distinct().count(), 2)

        # Players who played in 2010
        self.assertEqual(Player.objects.filter(games__season__year=2010).distinct().count(), 1)
        self.assertEqual(Player.objects.filter(games__season__year__exact=2010).distinct().count(), 1)
        self.assertEqual(Player.objects.filter(games__season__gt=222).distinct().count(), 1)
        self.assertEqual(Player.objects.filter(games__season__gt__exact=222).distinct().count(), 1)

        # Players who played in 2011
        self.assertEqual(Player.objects.filter(games__season__year=2011).distinct().count(), 2)
        self.assertEqual(Player.objects.filter(games__season__year__exact=2011).distinct().count(), 2)
        self.assertEqual(Player.objects.filter(games__season__gt=333).distinct().count(), 2)
        self.assertEqual(Player.objects.filter(games__season__year__gt=2010).distinct().count(), 2)
        self.assertEqual(Player.objects.filter(games__season__gt__gt=222).distinct().count(), 2)

    def test_chain_date_time_lookups(self):
        self.assertCountEqual(
            Article.objects.filter(pub_date__month__gt=7),
            [self.a5, self.a6],
        )
        self.assertCountEqual(
            Article.objects.filter(pub_date__day__gte=27),
            [self.a2, self.a3, self.a4, self.a7],
        )
        self.assertCountEqual(
            Article.objects.filter(pub_date__hour__lt=8),
            [self.a1, self.a2, self.a3, self.a4, self.a7],
        )
        self.assertCountEqual(
            Article.objects.filter(pub_date__minute__lte=0),
            [self.a1, self.a2, self.a3, self.a4, self.a5, self.a6, self.a7],
        )

    def test_exact_none_transform(self):
        """"""Transforms are used for __exact=None.""""""
        Season.objects.create(year=1, nulled_text_field='not null')
        self.assertFalse(Season.objects.filter(nulled_text_field__isnull=True))
        self.assertTrue(Season.objects.filter(nulled_text_field__nulled__isnull=True))
        self.assertTrue(Season.objects.filter(nulled_text_field__nulled__exact=None))
        self.assertTrue(Season.objects.filter(nulled_text_field__nulled=None))

    def test_exact_sliced_queryset_limit_one(self):
        self.assertCountEqual(
            Article.objects.filter(author=Author.objects.all()[:1]),
            [self.a1, self.a2, self.a3, self.a4]
        )

    def test_exact_sliced_queryset_limit_one_offset(self):
        self.assertCountEqual(
            Article.objects.filter(author=Author.objects.all()[1:2]),
            [self.a5, self.a6, self.a7]
        )

    def test_exact_sliced_queryset_not_limited_to_one(self):
        msg = (
            'The QuerySet value for an exact lookup must be limited to one '
            'result using slicing.'
        )
        with self.assertRaisesMessage(ValueError, msg):
            list(Article.objects.filter(author=Author.objects.all()[:2]))
        with self.assertRaisesMessage(ValueError, msg):
            list(Article.objects.filter(author=Author.objects.all()[1:]))

    @skipUnless(connection.vendor == 'mysql', 'MySQL-specific workaround.')
    def test_exact_booleanfield(self):
        # MySQL ignores indexes with boolean fields unless they're compared
        # directly to a boolean value.
        product = Product.objects.create(name='Paper', qty_target=5000)
        Stock.objects.create(product=product, short=False, qty_available=5100)
        stock_1 = Stock.objects.create(product=product, short=True, qty_available=180)
        qs = Stock.objects.filter(short=True)
        self.assertSequenceEqual(qs, [stock_1])
        self.assertIn(
            '%s = True' % connection.ops.quote_name('short'),
            str(qs.query),
        )

    @skipUnless(connection.vendor == 'mysql', 'MySQL-specific workaround.')
    def test_exact_booleanfield_annotation(self):
        # MySQL ignores indexes with boolean fields unless they're compared
        # directly to a boolean value.
        qs = Author.objects.annotate(case=Case(
            When(alias='a1', then=True),
            default=False,
            output_field=BooleanField(),
        )).filter(case=True)
        self.assertSequenceEqual(qs, [self.au1])
        self.assertIn(' = True', str(qs.query))

        qs = Author.objects.annotate(
            wrapped=ExpressionWrapper(Q(alias='a1'), output_field=BooleanField()),
        ).filter(wrapped=True)
        self.assertSequenceEqual(qs, [self.au1])
        self.assertIn(' = True', str(qs.query))
        # EXISTS(...) shouldn't be compared to a boolean value.
        qs = Author.objects.annotate(
            exists=Exists(Author.objects.filter(alias='a1', pk=OuterRef('pk'))),
        ).filter(exists=True)
        self.assertSequenceEqual(qs, [self.au1])
        self.assertNotIn(' = True', str(qs.query))

    def test_custom_field_none_rhs(self):
        """"""
        __exact=value is transformed to __isnull=True if Field.get_prep_value()
        converts value to None.
        """"""
        season = Season.objects.create(year=2012, nulled_text_field=None)
        self.assertTrue(Season.objects.filter(pk=season.pk, nulled_text_field__isnull=True))
        self.assertTrue(Season.objects.filter(pk=season.pk, nulled_text_field=''))

    def test_pattern_lookups_with_substr(self):
        a = Author.objects.create(name='John Smith', alias='Johx')
        b = Author.objects.create(name='Rhonda Simpson', alias='sonx')
        tests = (
            ('startswith', [a]),
            ('istartswith', [a]),
            ('contains', [a, b]),
            ('icontains', [a, b]),
            ('endswith', [b]),
            ('iendswith', [b]),
        )
        for lookup, result in tests:
            with self.subTest(lookup=lookup):
                authors = Author.objects.filter(**{'name__%s' % lookup: Substr('alias', 1, 3)})
                self.assertCountEqual(authors, result)

    def test_custom_lookup_none_rhs(self):
        """"""Lookup.can_use_none_as_rhs=True allows None as a lookup value.""""""
        season = Season.objects.create(year=2012, nulled_text_field=None)
        query = Season.objects.get_queryset().query
        field = query.model._meta.get_field('nulled_text_field')
        self.assertIsInstance(query.build_lookup(['isnull_none_rhs'], field, None), IsNullWithNoneAsRHS)
        self.assertTrue(Season.objects.filter(pk=season.pk, nulled_text_field__isnull_none_rhs=True))

    def test_exact_exists(self):
        qs = Article.objects.filter(pk=OuterRef('pk'))
        seasons = Season.objects.annotate(
            pk_exists=Exists(qs),
        ).filter(
            pk_exists=Exists(qs),
        )
        self.assertCountEqual(seasons, Season.objects.all())

    def test_nested_outerref_lhs(self):
        tag = Tag.objects.create(name=self.au1.alias)
        tag.articles.add(self.a1)
        qs = Tag.objects.annotate(
            has_author_alias_match=Exists(
                Article.objects.annotate(
                    author_exists=Exists(
                        Author.objects.filter(alias=OuterRef(OuterRef('name')))
                    ),
                ).filter(author_exists=True)
            ),
        )
        self.assertEqual(qs.get(has_author_alias_match=True), tag)

    def test_exact_query_rhs_with_selected_columns(self):
        newest_author = Author.objects.create(name='Author 2')
        authors_max_ids = Author.objects.filter(
            name='Author 2',
        ).values(
            'name',
        ).annotate(
            max_id=Max('id'),
        ).values('max_id')
        authors = Author.objects.filter(id=authors_max_ids[:1])
        self.assertEqual(authors.get(), newest_author)

    def test_isnull_non_boolean_value(self):
        msg = 'The QuerySet value for an isnull lookup must be True or False.'
        tests = [
            Author.objects.filter(alias__isnull=1),
            Article.objects.filter(author__isnull=1),
            Season.objects.filter(games__isnull=1),
            Freebie.objects.filter(stock__isnull=1),
        ]
        for qs in tests:
            with self.subTest(qs=qs):
                with self.assertRaisesMessage(ValueError, msg):
                    qs.exists()

    def test_lookup_rhs(self):
        product = Product.objects.create(name='GME', qty_target=5000)
        stock_1 = Stock.objects.create(product=product, short=True, qty_available=180)
        stock_2 = Stock.objects.create(product=product, short=False, qty_available=5100)
        Stock.objects.create(product=product, short=False, qty_available=4000)
        self.assertCountEqual(
            Stock.objects.filter(short=Q(qty_available__lt=F('product__qty_target'))),
            [stock_1, stock_2],
        )
        self.assertCountEqual(
            Stock.objects.filter(short=ExpressionWrapper(
                Q(qty_available__lt=F('product__qty_target')),
                output_field=BooleanField(),
            )),
            [stock_1, stock_2],
        )",1,587 2000 40 2001 41 58 64 588 612 2002 40 2003 41 58 330 2003 46 2004 61 2005 46 2006 46 2007 40 2008 61 362 44 2009 61 362 41 2003 46 2010 61 2005 46 2006 46 2007 40 2008 61 362 44 2009 61 362 41 330 2003 46 2011 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 2015 40 1505 44 1502 44 1503 41 44 2016 61 2003 46 2004 44 2017 61 362 44 41 2003 46 2018 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 2015 40 1505 44 1502 44 1503 41 44 2016 61 2003 46 2004 44 2017 61 362 44 41 2003 46 2019 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 2015 40 1505 44 1502 44 1503 41 44 2016 61 2003 46 2004 44 2017 61 362 44 41 2003 46 2020 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 2015 40 1505 44 1502 44 1503 41 44 2016 61 2003 46 2004 44 2017 61 362 44 41 2003 46 2021 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 2015 40 1505 44 1502 44 1501 44 1502 44 1500 41 44 2016 61 2003 46 2010 44 2017 61 362 44 41 2003 46 2022 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 2015 40 1505 44 1502 44 1501 44 1502 44 1500 41 44 2016 61 2003 46 2010 44 2017 61 362 44 41 2003 46 2023 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 2015 40 1505 44 1502 44 1503 41 44 2016 61 2003 46 2010 44 2017 61 362 44 41 330 2003 46 2024 61 2025 46 2006 46 2007 40 2008 61 362 41 2003 46 2024 46 2026 46 2027 40 2003 46 2011 44 2003 46 2018 44 2003 46 2019 41 2003 46 2028 61 2025 46 2006 46 2007 40 2008 61 362 41 2003 46 2028 46 2026 46 2027 40 2003 46 2019 44 2003 46 2020 44 2003 46 2021 41 2003 46 2029 61 2025 46 2006 46 2007 40 2008 61 362 41 2003 46 2029 46 2026 46 2027 40 2003 46 2021 44 2003 46 2022 44 2003 46 2023 41 612 2030 40 2031 41 58 330 2031 46 2032 40 2012 46 2006 46 2033 40 41 41 664 2034 696 2012 46 2006 46 544 40 41 58 2034 46 2035 40 41 330 2031 46 2036 40 2012 46 2006 46 2033 40 41 41 612 2037 40 2031 41 58 330 2031 46 2038 40 2012 46 2006 46 656 40 2039 61 813 40 2031 46 2011 46 687 41 41 44 91 2031 46 2011 93 44 41 64 2040 40 362 41 612 2041 40 2031 41 58 330 2031 46 2038 40 2012 46 2006 46 656 40 2042 61 362 41 44 91 2031 46 2021 44 2031 46 2022 44 2031 46 2020 44 2031 46 2018 44 2031 46 2019 44 2031 46 2023 44 2031 46 2011 93 44 41 612 2043 40 2031 41 58 330 330 2031 46 2044 40 2012 46 2006 46 2045 40 41 44 2046 46 2047 46 2048 41 2031 46 2049 40 2012 46 2006 46 2045 40 41 44 91 362 44 362 44 362 44 362 44 362 44 362 44 362 44 93 44 2050 61 2051 40 362 41 41 330 2031 46 2049 40 2012 46 2006 46 656 40 2052 61 362 41 46 2045 40 41 44 91 362 93 44 2050 61 2051 40 362 41 41 612 2053 40 2031 41 58 330 2031 46 2054 40 2012 46 2006 46 2055 40 41 44 1502 41 2031 46 2054 40 2012 46 2006 46 656 40 2056 61 2015 40 1505 44 1502 44 1503 41 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2012 46 2006 46 656 40 2057 61 362 41 46 2055 40 41 44 1500 41 330 2026 61 2012 46 2006 46 544 40 41 2031 46 2054 40 2026 46 2055 40 41 44 1502 41 2031 46 2054 40 2026 91 58 1502 93 46 2055 40 41 44 1502 41 2031 46 2054 40 2026 91 1501 58 1503 93 46 2055 40 41 44 1502 41 2031 46 2054 40 2026 91 1502 58 1503 93 46 2055 40 41 44 1500 41 330 2031 46 2054 40 2012 46 2006 46 656 40 2056 61 362 41 46 2055 40 41 44 1502 41 612 2058 40 2031 41 58 330 2059 61 2012 46 2006 46 2060 40 91 2031 46 2011 46 687 44 2031 46 2018 46 687 93 41 2031 46 2054 40 2059 91 2031 46 2011 46 687 93 44 2031 46 2011 41 2031 46 2054 40 2059 91 2031 46 2018 46 687 93 44 2031 46 2018 41 2031 46 2054 40 2012 46 2006 46 2060 40 41 44 123 2031 46 2011 46 687 58 2031 46 2011 44 2031 46 2018 46 687 58 2031 46 2018 44 2031 46 2019 46 687 58 2031 46 2019 44 2031 46 2020 46 687 58 2031 46 2020 44 2031 46 2021 46 687 58 2031 46 2021 44 2031 46 2022 46 687 58 2031 46 2022 44 2031 46 2023 46 687 58 2031 46 2023 44 125 41 2031 46 2054 40 2012 46 2006 46 2060 40 91 2031 46 2019 46 687 93 41 44 123 2031 46 2019 46 687 58 2031 46 2019 125 41 2031 46 2054 40 2012 46 2006 46 2060 40 123 2031 46 2019 46 687 125 41 44 123 2031 46 2019 46 687 58 2031 46 2019 125 41 2031 46 2054 40 2012 46 2006 46 2060 40 669 40 91 2031 46 2019 46 687 93 41 41 44 123 2031 46 2019 46 687 58 2031 46 2019 125 41 2031 46 2054 40 2012 46 2006 46 2060 40 40 2031 46 2019 46 687 44 41 41 44 123 2031 46 2019 46 687 58 2031 46 2019 125 41 2031 46 2054 40 2012 46 2006 46 2060 40 91 1504 93 41 44 123 125 41 2031 46 2054 40 2012 46 2006 46 2060 40 91 93 41 44 123 125 41 2031 46 2054 40 2012 46 2006 46 2060 40 717 40 91 2031 46 2011 46 687 93 41 41 44 123 2031 46 2011 46 687 58 2031 46 2011 125 41 2031 46 2054 40 2012 46 2006 46 2060 40 717 40 91 93 41 41 44 123 125 41 871 2031 46 2061 40 2062 41 58 2012 46 2006 46 2060 40 2057 61 362 41 612 2063 40 2031 41 58 2064 61 1505 2065 61 2066 46 2067 46 2065 2068 61 2069 40 2064 47 2065 41 688 2065 630 1501 2005 46 2006 46 2070 40 91 2005 40 41 664 2071 696 779 40 2064 45 2005 46 2006 46 2055 40 41 41 93 41 2072 61 123 2016 46 2073 58 2016 664 2016 696 2005 46 2006 46 544 40 41 125 871 2031 46 2074 40 2068 41 58 2031 46 2054 40 2005 46 2006 46 2060 40 2072 41 44 2072 41 612 2075 40 2031 41 58 2031 46 2054 40 2012 46 2006 46 2060 40 91 2031 46 2011 46 2017 44 2031 46 2018 46 2017 44 2031 46 2019 46 2017 93 44 2076 61 362 41 44 123 2031 46 2011 46 2017 58 2031 46 2011 44 2031 46 2018 46 2017 58 2031 46 2018 44 2031 46 2019 46 2017 58 2031 46 2019 44 125 41 612 2077 40 2031 41 58 2078 61 2079 46 2006 46 2007 40 2080 61 1505 41 2081 61 2079 46 2006 46 2007 40 2080 61 1505 41 2079 46 2006 46 2007 40 2080 61 1505 41 2031 46 2054 40 2079 46 2006 46 2060 40 91 2078 46 2080 44 2081 46 2080 93 44 2076 61 362 44 41 44 123 2078 46 2080 58 2078 44 2081 46 2080 58 2081 125 44 41 612 2082 40 2031 41 58 2083 61 362 871 2031 46 2084 40 2085 44 2083 41 58 2012 46 2006 46 2060 40 91 2031 46 2004 93 44 2076 61 362 41 64 2040 40 362 41 612 2086 40 2031 41 58 2031 46 2054 40 2012 46 2006 46 2087 40 362 41 46 2088 40 362 41 46 2060 40 91 2031 46 2011 46 2013 44 2031 46 2021 46 2013 93 44 2076 61 362 44 41 44 123 2031 46 2011 46 2013 58 2031 46 2011 44 2031 46 2021 46 2013 58 2031 46 2021 125 44 41 64 2040 40 362 41 612 2089 40 2031 41 58 2083 61 362 871 2031 46 2084 40 2085 44 2083 41 58 2012 46 2006 46 2087 40 362 44 362 41 46 2088 40 362 44 362 44 41 46 2060 40 2076 61 362 41 64 2090 40 362 41 612 2091 40 2031 41 58 587 2092 40 2093 46 2092 41 58 2094 61 2093 46 2095 40 2096 61 1503 41 2097 61 2093 46 2095 40 2096 61 1503 41 2008 61 2093 46 2095 40 2096 61 1503 41 587 2098 58 2099 61 91 2093 46 2100 40 2101 61 91 362 93 44 2008 61 362 44 2102 61 2093 46 2103 40 2104 61 515 41 41 44 2093 46 2100 40 2101 61 91 362 44 362 93 44 2008 61 362 44 41 44 93 2083 61 362 664 2076 696 91 362 44 362 93 58 871 2031 46 2105 40 2076 61 2076 41 58 871 2031 46 2084 40 2085 44 2083 37 2076 41 58 2092 46 2006 46 2060 40 2076 61 2076 41 612 2106 40 2031 41 58 2083 61 362 871 2031 46 2084 40 2062 44 2083 41 58 2012 46 2006 46 544 40 41 91 1500 58 1502 93 46 2060 40 91 2031 46 2011 46 687 44 2031 46 2018 46 687 93 41 612 2107 40 2031 41 58 330 330 2031 46 2038 40 2012 46 2006 46 2108 40 362 41 44 91 123 362 58 362 125 44 123 362 58 362 125 44 123 362 58 362 125 44 123 362 58 362 125 44 123 362 58 362 125 44 123 362 58 362 125 44 123 362 58 362 125 44 93 44 41 2031 46 2038 40 2012 46 2006 46 656 40 2056 61 2015 40 1505 44 1502 44 1503 41 41 46 2108 40 362 41 44 91 123 362 58 2031 46 2018 46 687 125 44 123 362 58 2031 46 2019 46 687 125 44 123 362 58 2031 46 2023 46 687 125 93 44 41 2031 46 2038 40 2012 46 2006 46 2108 40 362 44 362 41 44 91 123 362 58 2031 46 2021 46 687 44 362 58 362 125 44 123 362 58 2031 46 2022 46 687 44 362 58 362 125 44 123 362 58 2031 46 2020 46 687 44 362 58 362 125 44 123 362 58 2031 46 2018 46 687 44 362 58 362 125 44 123 362 58 2031 46 2019 46 687 44 362 58 362 125 44 123 362 58 2031 46 2023 46 687 44 362 58 362 125 44 123 362 58 2031 46 2011 46 687 44 362 58 362 125 44 93 44 41 330 330 2031 46 2038 40 723 40 2012 46 2006 46 2108 40 362 44 362 41 46 2045 40 41 41 44 91 123 362 58 362 44 362 58 2031 46 2021 46 687 125 44 123 362 58 362 44 362 58 2031 46 2022 46 687 125 44 123 362 58 362 44 362 58 2031 46 2020 46 687 125 44 123 362 58 362 44 362 58 2031 46 2018 46 687 125 44 123 362 58 362 44 362 58 2031 46 2019 46 687 125 44 123 362 58 362 44 362 58 2031 46 2023 46 687 125 44 123 362 58 362 44 362 58 2031 46 2011 46 687 125 44 93 44 41 330 2031 46 2038 40 2012 46 2006 46 2109 40 2110 61 123 362 58 362 125 41 46 2108 40 362 44 362 41 44 91 123 362 58 2031 46 2021 46 687 44 362 58 2031 46 2021 46 687 43 1501 125 44 123 362 58 2031 46 2022 46 687 44 362 58 2031 46 2022 46 687 43 1501 125 44 123 362 58 2031 46 2020 46 687 44 362 58 2031 46 2020 46 687 43 1501 125 44 123 362 58 2031 46 2018 46 687 44 362 58 2031 46 2018 46 687 43 1501 125 44 123 362 58 2031 46 2019 46 687 44 362 58 2031 46 2019 46 687 43 1501 125 44 123 362 58 2031 46 2023 46 687 44 362 58 2031 46 2023 46 687 43 1501 125 44 123 362 58 2031 46 2011 46 687 44 362 58 2031 46 2011 46 687 43 1501 125 44 93 44 41 2111 61 123 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 125 2031 46 2038 40 2012 46 2006 46 656 40 687 61 2031 46 2011 46 687 41 46 2109 40 2110 61 2111 41 46 2108 40 42 2111 41 44 91 123 362 58 2031 46 2011 46 687 43 1501 44 362 58 2031 46 2011 46 687 43 1502 44 362 58 2031 46 2011 46 687 43 1502 44 362 58 2031 46 2011 46 687 43 1502 44 362 58 2031 46 2011 46 687 43 1502 44 362 58 2031 46 2011 46 687 43 1502 44 362 58 2031 46 2011 46 687 43 1502 44 362 58 2031 46 2011 46 687 43 1502 44 125 93 44 41 330 2031 46 2038 40 2012 46 2006 46 2108 40 362 44 362 41 44 91 123 362 58 2031 46 2021 46 2013 44 362 58 2031 46 2010 46 2008 125 44 123 362 58 2031 46 2022 46 2013 44 362 58 2031 46 2010 46 2008 125 44 123 362 58 2031 46 2020 46 2013 44 362 58 2031 46 2004 46 2008 125 44 123 362 58 2031 46 2018 46 2013 44 362 58 2031 46 2004 46 2008 125 44 123 362 58 2031 46 2019 46 2013 44 362 58 2031 46 2004 46 2008 125 44 123 362 58 2031 46 2023 46 2013 44 362 58 2031 46 2010 46 2008 125 44 123 362 58 2031 46 2011 46 2013 44 362 58 2031 46 2004 46 2008 125 44 93 44 41 2031 46 2038 40 2005 46 2006 46 2108 40 362 44 362 41 46 2087 40 362 44 362 41 44 91 123 362 58 2031 46 2004 46 2008 44 362 58 2031 46 2011 46 2013 125 44 123 362 58 2031 46 2004 46 2008 44 362 58 2031 46 2018 46 2013 125 44 123 362 58 2031 46 2004 46 2008 44 362 58 2031 46 2019 46 2013 125 44 123 362 58 2031 46 2004 46 2008 44 362 58 2031 46 2020 46 2013 125 44 123 362 58 2031 46 2010 46 2008 44 362 58 2031 46 2021 46 2013 125 44 123 362 58 2031 46 2010 46 2008 44 362 58 2031 46 2022 46 2013 125 44 123 362 58 2031 46 2010 46 2008 44 362 58 2031 46 2023 46 2013 125 44 93 44 41 2031 46 2038 40 40 2005 46 2006 46 2108 40 362 44 362 44 362 41 46 2087 40 362 44 362 44 362 41 41 44 91 123 362 58 2031 46 2004 46 2008 44 362 58 2031 46 2011 46 2013 44 362 58 2031 46 2024 46 2008 125 44 123 362 58 2031 46 2004 46 2008 44 362 58 2031 46 2018 46 2013 44 362 58 2031 46 2024 46 2008 125 44 123 362 58 2031 46 2004 46 2008 44 362 58 2031 46 2019 46 2013 44 362 58 2031 46 2024 46 2008 125 44 123 362 58 2031 46 2004 46 2008 44 362 58 2031 46 2019 46 2013 44 362 58 2031 46 2028 46 2008 125 44 123 362 58 2031 46 2004 46 2008 44 362 58 2031 46 2020 46 2013 44 362 58 2031 46 2028 46 2008 125 44 123 362 58 2031 46 2010 46 2008 44 362 58 2031 46 2021 46 2013 44 362 58 2031 46 2028 46 2008 125 44 123 362 58 2031 46 2010 46 2008 44 362 58 2031 46 2021 46 2013 44 362 58 2031 46 2029 46 2008 125 44 123 362 58 2031 46 2010 46 2008 44 362 58 2031 46 2022 46 2013 44 362 58 2031 46 2029 46 2008 125 44 123 362 58 2031 46 2010 46 2008 44 362 58 2031 46 2023 46 2013 44 362 58 2031 46 2029 46 2008 125 44 93 44 41 330 330 330 2083 61 40 362 362 41 871 2031 46 2084 40 2112 44 2083 41 58 2012 46 2006 46 2109 40 2110 61 123 362 58 362 125 41 46 2108 40 362 44 362 41 330 2031 46 2038 40 2012 46 2006 46 656 40 687 61 2031 46 2021 46 687 41 46 2108 40 41 44 91 123 362 58 2031 46 2021 46 687 44 362 58 2031 46 2010 46 687 44 362 58 362 44 362 58 2015 40 1505 44 1502 44 1501 44 1502 44 1500 41 44 362 58 362 44 125 93 44 41 612 2113 40 2031 41 58 330 330 330 330 2031 46 2038 40 2012 46 2006 46 2114 40 362 41 44 91 40 362 44 41 44 40 362 44 41 44 40 362 44 41 44 40 362 44 41 44 40 362 44 41 44 40 362 44 41 44 40 362 44 41 44 93 44 41 2031 46 2038 40 2012 46 2006 46 2114 40 362 41 46 2087 40 362 41 44 91 40 2031 46 2011 46 687 44 41 44 40 2031 46 2018 46 687 44 41 44 40 2031 46 2019 46 687 44 41 44 40 2031 46 2020 46 687 44 41 44 40 2031 46 2021 46 687 44 41 44 40 2031 46 2022 46 687 44 41 44 40 2031 46 2023 46 687 44 41 93 44 41 2031 46 2038 40 2012 46 2006 46 2114 40 362 44 2115 61 515 41 46 2087 40 362 41 44 91 2031 46 2011 46 687 44 2031 46 2018 46 687 44 2031 46 2019 46 687 44 2031 46 2020 46 687 44 2031 46 2021 46 687 44 2031 46 2022 46 687 44 2031 46 2023 46 687 93 44 41 2031 46 2038 40 2012 46 2006 46 2109 40 2110 61 123 362 58 362 125 41 46 2087 40 362 41 46 2114 40 362 41 44 91 40 2031 46 2011 46 687 44 41 44 40 2031 46 2018 46 687 44 41 44 40 2031 46 2019 46 687 44 41 44 40 2031 46 2020 46 687 44 41 44 40 2031 46 2021 46 687 44 41 44 40 2031 46 2022 46 687 44 41 44 40 2031 46 2023 46 687 44 41 93 44 41 2031 46 2038 40 2012 46 2006 46 2109 40 2110 61 123 362 58 362 125 41 46 2087 40 362 41 46 2114 40 362 44 362 41 44 91 40 2031 46 2011 46 687 43 1501 44 2031 46 2011 46 687 41 44 40 2031 46 2018 46 687 43 1501 44 2031 46 2018 46 687 41 44 40 2031 46 2019 46 687 43 1501 44 2031 46 2019 46 687 41 44 40 2031 46 2020 46 687 43 1501 44 2031 46 2020 46 687 41 44 40 2031 46 2021 46 687 43 1501 44 2031 46 2021 46 687 41 44 40 2031 46 2022 46 687 43 1501 44 2031 46 2022 46 687 41 44 40 2031 46 2023 46 687 43 1501 44 2031 46 2023 46 687 41 93 44 41 2031 46 2038 40 2012 46 2006 46 2109 40 2110 61 123 362 58 362 125 41 46 2087 40 362 41 46 2114 40 362 44 362 41 44 91 40 2031 46 2011 46 687 44 2031 46 2011 46 687 43 1501 41 44 40 2031 46 2018 46 687 44 2031 46 2018 46 687 43 1501 41 44 40 2031 46 2019 46 687 44 2031 46 2019 46 687 43 1501 41 44 40 2031 46 2020 46 687 44 2031 46 2020 46 687 43 1501 41 44 40 2031 46 2021 46 687 44 2031 46 2021 46 687 43 1501 41 44 40 2031 46 2022 46 687 44 2031 46 2022 46 687 43 1501 41 44 40 2031 46 2023 46 687 44 2031 46 2023 46 687 43 1501 41 93 44 41 2116 61 40 362 44 362 44 362 41 2031 46 2038 40 2005 46 2006 46 2114 40 42 2116 41 46 2087 40 42 2116 41 44 91 40 2031 46 2004 46 2008 44 2031 46 2011 46 2013 44 2031 46 2024 46 2008 41 44 40 2031 46 2004 46 2008 44 2031 46 2018 46 2013 44 2031 46 2024 46 2008 41 44 40 2031 46 2004 46 2008 44 2031 46 2019 46 2013 44 2031 46 2024 46 2008 41 44 40 2031 46 2004 46 2008 44 2031 46 2019 46 2013 44 2031 46 2028 46 2008 41 44 40 2031 46 2004 46 2008 44 2031 46 2020 46 2013 44 2031 46 2028 46 2008 41 44 40 2031 46 2010 46 2008 44 2031 46 2021 46 2013 44 2031 46 2028 46 2008 41 44 40 2031 46 2010 46 2008 44 2031 46 2021 46 2013 44 2031 46 2029 46 2008 41 44 40 2031 46 2010 46 2008 44 2031 46 2022 46 2013 44 2031 46 2029 46 2008 41 44 40 2031 46 2010 46 2008 44 2031 46 2023 46 2013 44 2031 46 2029 46 2008 41 44 93 44 41 871 2031 46 2061 40 2062 41 58 2012 46 2006 46 2114 40 362 44 362 44 2115 61 515 41 612 2117 40 2031 41 58 330 330 330 330 2031 46 2054 40 787 40 2031 46 2011 46 2118 40 41 41 44 362 41 2031 46 2054 40 787 40 2031 46 2018 46 2118 40 41 41 44 362 41 2031 46 2054 40 787 40 2031 46 2018 46 2118 40 2052 61 362 41 41 44 362 41 2031 46 2054 40 787 40 2031 46 2019 46 2118 40 41 41 44 362 41 2031 46 2054 40 787 40 2031 46 2020 46 2118 40 41 41 44 362 41 871 2031 46 2061 40 2012 46 2119 41 58 2031 46 2021 46 2118 40 41 2031 46 2054 40 787 40 2031 46 2022 46 2118 40 41 41 44 362 41 2031 46 2054 40 787 40 2031 46 2023 46 2118 40 41 41 44 362 41 2031 46 2054 40 787 40 2031 46 2023 46 2120 40 41 41 44 362 41 2031 46 2054 40 787 40 2031 46 2022 46 2120 40 41 41 44 362 41 2031 46 2054 40 787 40 2031 46 2021 46 2120 40 41 41 44 362 41 2031 46 2054 40 787 40 2031 46 2020 46 2120 40 41 41 44 362 41 2031 46 2054 40 787 40 2031 46 2019 46 2120 40 41 41 44 362 41 2031 46 2054 40 787 40 2031 46 2018 46 2120 40 41 41 44 362 41 612 2121 40 2031 41 58 330 330 2122 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 2015 40 1505 44 1503 44 1503 41 41 2031 46 2038 40 2012 46 2006 46 656 40 2057 61 362 41 44 91 2122 44 2031 46 2021 44 2031 46 2022 44 2031 46 2020 44 2031 46 2018 44 2031 46 2019 44 2031 46 2023 44 2031 46 2011 93 44 41 2031 46 2038 40 2012 46 2006 46 656 40 2057 61 362 41 44 91 2122 93 44 41 2123 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 2015 40 1505 44 1503 44 1503 41 41 2031 46 2038 40 2012 46 2006 46 656 40 2057 61 362 41 44 91 2123 44 2122 44 2031 46 2021 44 2031 46 2022 44 2031 46 2020 44 2031 46 2018 44 2031 46 2019 44 2031 46 2023 44 2031 46 2011 93 44 41 2031 46 2038 40 2012 46 2006 46 656 40 2057 61 362 41 44 91 2123 93 44 41 2124 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 2015 40 1505 44 1503 44 1503 41 41 2031 46 2038 40 2012 46 2006 46 656 40 2125 61 362 41 44 91 2124 93 44 41 612 2126 40 2031 41 58 2014 61 2015 40 1505 44 1503 44 1503 41 2122 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 2014 41 2123 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 2014 41 2124 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 2014 41 330 2031 46 2038 40 2012 46 2006 46 656 40 2125 61 362 41 46 2127 40 2125 61 362 41 44 91 2031 46 2021 44 2031 46 2022 44 2031 46 2020 44 2031 46 2018 44 2031 46 2019 44 2031 46 2023 44 2031 46 2011 93 44 41 2031 46 2038 40 2012 46 2006 46 2127 40 2057 61 362 41 44 91 2124 44 2123 44 2031 46 2021 44 2031 46 2022 44 2031 46 2020 44 2031 46 2018 44 2031 46 2019 44 2031 46 2023 44 2031 46 2011 93 44 41 2031 46 2038 40 2012 46 2006 46 2127 40 2013 61 362 41 44 91 2124 44 2123 44 2122 44 2031 46 2021 44 2031 46 2022 44 2031 46 2020 44 2031 46 2018 44 2031 46 2019 44 2031 46 2011 93 44 41 612 2128 40 2031 41 58 330 2031 46 2049 40 2012 46 2006 46 2129 40 41 44 91 93 41 2031 46 2049 40 2012 46 2006 46 2129 40 41 46 656 40 2057 61 362 41 44 91 93 41 2031 46 2049 40 2012 46 2006 46 656 40 2057 61 362 41 46 2129 40 41 44 91 93 41 2031 46 2054 40 2012 46 2006 46 2129 40 41 46 2055 40 41 44 1500 41 2031 46 2054 40 2012 46 2006 46 2129 40 41 46 2130 40 2013 61 362 41 44 1500 41 2031 46 2049 40 2012 46 2006 46 2129 40 41 46 2045 40 41 44 91 93 41 612 2131 40 2031 41 58 2031 46 2038 40 2012 46 2006 46 2127 40 2132 61 91 93 41 44 91 2031 46 2021 44 2031 46 2022 44 2031 46 2020 44 2031 46 2018 44 2031 46 2019 44 2031 46 2023 44 2031 46 2011 93 44 41 612 2133 40 2031 41 58 2031 46 2038 40 2012 46 2006 46 656 40 2132 61 91 93 41 44 91 93 41 612 2134 40 2031 41 58 871 2031 46 2084 40 2085 44 362 362 41 58 723 40 2012 46 2006 46 656 40 2132 61 2012 46 2006 46 2135 40 362 41 46 544 40 41 41 41 612 2136 40 2031 41 58 2137 61 2012 46 2006 46 656 40 2138 61 91 362 37 2071 664 2071 696 779 40 1501 44 1502 41 93 41 46 2108 40 362 41 46 2137 2031 46 2139 40 362 44 813 40 2137 41 41 612 2140 40 2031 41 58 871 2031 46 2074 40 1501 41 552 2141 58 2031 46 2038 40 2012 46 2006 46 656 40 2132 61 91 470 44 2031 46 2011 46 687 93 41 44 91 2031 46 2011 93 44 41 2142 61 2141 46 2143 91 1500 93 91 362 93 2031 46 2139 40 362 37 2031 46 2011 46 2073 44 2142 41 612 2144 40 2031 41 58 871 2031 46 2074 40 1500 41 58 2031 46 2038 40 2012 46 2006 46 656 40 2132 61 91 470 93 41 44 91 93 41 612 2145 40 2031 41 58 587 2146 40 704 41 58 2147 61 470 871 2031 46 2074 40 1501 41 552 2141 58 2031 46 2038 40 2012 46 2006 46 656 40 2132 61 91 470 44 2146 40 2031 46 2011 46 687 41 93 41 44 91 2031 46 2011 93 44 41 2142 61 2141 46 2143 91 1500 93 91 362 93 2031 46 2139 40 362 37 2031 46 2011 46 2073 44 2142 41 612 2148 40 2031 41 58 330 871 2031 46 2084 40 2112 44 362 362 41 58 2012 46 2006 46 656 40 2149 61 362 41 46 2055 40 41 612 2150 40 2031 41 58 871 2031 46 2084 40 2112 44 362 362 41 58 2012 46 2006 46 656 40 2151 61 362 41 871 2031 46 2084 40 2112 44 362 362 41 58 2012 46 2006 46 656 40 2152 61 515 41 871 2031 46 2084 40 2112 44 362 362 41 58 2012 46 2006 46 656 40 2153 61 362 41 612 2154 40 2031 41 58 330 2083 61 362 871 2031 46 2084 40 2112 44 2083 41 58 2012 46 2006 46 656 40 2155 61 362 41 2083 61 362 871 2031 46 2084 40 2112 44 2083 41 58 2025 46 2006 46 656 40 2156 61 362 41 612 2157 40 2031 41 58 330 664 2034 696 2012 46 2006 46 544 40 41 58 2034 46 2035 40 41 2158 61 2015 46 2158 40 41 2012 46 2006 46 2070 40 91 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 93 41 330 2031 46 2049 40 2012 46 2006 46 656 40 2159 61 362 41 44 2012 46 2006 46 656 40 2160 61 91 362 44 362 44 362 44 362 93 41 44 41 2031 46 2049 40 2012 46 2006 46 656 40 2161 61 362 41 44 2012 46 2006 46 656 40 2160 61 91 362 44 362 44 362 44 362 44 362 93 41 44 41 330 2031 46 2049 40 2012 46 2006 46 656 40 2159 61 362 41 44 2012 46 2006 46 656 40 2160 61 91 362 44 362 44 362 93 41 44 41 330 2031 46 2049 40 2012 46 2006 46 656 40 2159 61 362 41 44 2012 46 2006 46 656 40 2160 61 91 362 44 362 93 41 44 41 330 2031 46 2049 40 2012 46 2006 46 656 40 2159 61 362 41 44 2012 46 2006 46 656 40 2160 61 91 362 44 362 44 362 93 41 44 41 2031 46 2049 40 2012 46 2006 46 656 40 2161 61 362 41 44 2012 46 2006 46 656 40 2013 61 362 41 44 41 330 2031 46 2049 40 2012 46 2006 46 656 40 2159 61 362 41 44 2012 46 2006 46 656 40 2013 61 362 41 44 41 2031 46 2049 40 2012 46 2006 46 656 40 2161 61 362 41 44 2012 46 2006 46 656 40 2160 61 91 362 44 362 93 41 44 41 330 2031 46 2049 40 2012 46 2006 46 656 40 2159 61 362 41 44 2012 46 2006 46 656 40 2160 61 91 362 44 362 93 41 44 41 2031 46 2049 40 2012 46 2006 46 656 40 2159 61 362 41 44 2012 46 2006 46 656 40 2013 61 362 41 44 41 2031 46 2049 40 2012 46 2006 46 656 40 2161 61 362 41 44 2012 46 2006 46 656 40 2160 61 91 362 44 362 44 362 93 41 44 41 330 2012 46 2006 46 2070 40 91 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 93 41 330 2031 46 2049 40 2012 46 2006 46 656 40 2159 61 362 41 44 2012 46 2006 46 656 40 2160 61 91 362 44 362 44 362 44 362 44 93 41 44 41 2031 46 2049 40 2012 46 2006 46 656 40 2161 61 362 41 44 2012 46 2006 46 656 40 2160 61 91 362 44 362 44 362 44 362 44 362 44 93 41 44 41 2031 46 2049 40 2012 46 2006 46 656 40 2159 61 362 41 44 2012 46 2006 46 656 40 2160 61 91 362 44 362 44 362 93 41 44 41 330 2031 46 2049 40 2012 46 2006 46 656 40 2159 61 362 41 44 2012 46 2006 46 656 40 2160 61 91 362 44 362 44 362 44 362 44 362 44 93 41 44 41 2031 46 2049 40 2012 46 2006 46 656 40 2161 61 362 41 44 2012 46 2006 46 656 40 2160 61 91 362 44 362 44 362 44 362 44 362 44 93 41 44 41 64 2040 40 362 41 612 2162 40 2031 41 58 330 2158 61 2015 46 2158 40 41 2012 46 2006 46 2070 40 91 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 2012 40 2014 61 2158 44 2013 61 362 41 44 93 41 2031 46 2049 40 2012 46 2006 46 656 40 2159 61 362 41 46 2114 40 362 44 2115 61 515 41 44 91 362 44 362 44 362 93 44 41 612 2163 40 2031 41 58 362 2079 46 2006 46 2007 40 2080 61 1505 44 2164 61 470 41 2031 46 2049 40 2079 46 2006 46 656 40 2165 61 362 41 44 91 93 41 612 2166 40 2031 41 58 362 2167 61 2079 46 2006 46 2007 40 2080 61 1505 44 2164 61 1504 41 2031 46 2049 40 2079 46 2006 46 656 40 2165 61 362 41 44 91 2167 93 41 612 2168 40 2031 41 58 362 2169 46 2006 46 2007 40 2008 61 362 41 2169 46 2006 46 2170 40 2171 61 362 41 612 2172 40 2031 41 58 362 2083 61 362 871 2031 46 2084 40 2112 44 2083 41 58 2012 46 2006 46 656 40 2173 61 1503 41 871 2031 46 2084 40 2112 44 2083 41 58 2012 46 2006 46 656 40 2174 61 1503 41 2083 61 40 362 362 41 871 2031 46 2084 40 2112 44 2083 41 58 2012 46 2006 46 656 40 2175 61 1503 41 612 2176 40 2031 41 58 362 330 2177 61 2079 46 2006 46 2007 40 2080 61 1505 44 2164 61 1504 41 2177 46 2178 46 2007 40 2179 61 362 44 2180 61 362 41 2181 61 2079 46 2006 46 2007 40 2080 61 1505 44 2164 61 1504 41 2181 46 2178 46 2007 40 2179 61 362 44 2180 61 362 41 2181 46 2178 46 2007 40 2179 61 362 44 2180 61 362 41 2181 46 2178 46 2007 40 2179 61 362 44 2180 61 362 41 2078 61 2079 46 2006 46 2007 40 2080 61 1505 44 2164 61 1504 41 2078 46 2178 46 2007 40 2179 61 362 44 2180 61 362 41 2078 46 2178 46 2007 40 2179 61 362 44 2180 61 362 41 2182 61 2169 46 2006 46 2007 40 2008 61 362 41 2182 46 2178 46 801 40 2183 46 2006 46 656 40 2184 61 91 1505 44 1505 93 41 41 2185 61 2169 46 2006 46 2007 40 2008 61 362 41 2185 46 2178 46 801 40 2183 46 2006 46 656 40 2186 61 1505 41 41 2187 61 2169 46 2006 46 2007 40 2008 61 362 41 2187 46 2178 46 801 40 2183 46 2006 46 656 40 2184 61 91 1505 93 41 41 2188 61 2169 46 2006 46 2007 40 2008 61 362 41 2188 46 2178 46 801 40 2183 46 2006 46 656 40 2184 61 91 1505 93 41 41 330 2031 46 2054 40 2183 46 2006 46 656 40 2186 61 1505 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2183 46 2006 46 656 40 2189 61 1505 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2183 46 2006 46 656 40 2190 61 1504 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2183 46 2006 46 656 40 2191 61 1504 41 46 2055 40 41 44 1502 41 330 2031 46 2054 40 2183 46 2006 46 656 40 2186 61 1505 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2183 46 2006 46 656 40 2189 61 1505 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2183 46 2006 46 656 40 2190 61 1504 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2183 46 2006 46 656 40 2191 61 1504 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2183 46 2006 46 656 40 2192 61 1505 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2183 46 2006 46 656 40 2193 61 1504 41 46 2055 40 41 44 1502 41 330 2031 46 2054 40 2183 46 2006 46 656 40 2184 61 91 1505 44 1505 93 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2183 46 2006 46 656 40 2192 61 1505 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2183 46 2006 46 656 40 2194 61 91 1504 44 1504 93 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2183 46 2006 46 656 40 2193 61 1504 41 46 2055 40 41 44 1502 41 330 2031 46 2054 40 2169 46 2006 46 656 40 2195 61 1505 41 46 2088 40 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2169 46 2006 46 656 40 2196 61 1505 41 46 2088 40 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2169 46 2006 46 656 40 2197 61 1504 41 46 2088 40 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2169 46 2006 46 656 40 2198 61 1504 41 46 2088 40 41 46 2055 40 41 44 1502 41 330 2031 46 2054 40 2169 46 2006 46 656 40 2195 61 1505 41 46 2088 40 41 46 2055 40 41 44 1501 41 2031 46 2054 40 2169 46 2006 46 656 40 2196 61 1505 41 46 2088 40 41 46 2055 40 41 44 1501 41 2031 46 2054 40 2169 46 2006 46 656 40 2197 61 1504 41 46 2088 40 41 46 2055 40 41 44 1501 41 2031 46 2054 40 2169 46 2006 46 656 40 2198 61 1504 41 46 2088 40 41 46 2055 40 41 44 1501 41 330 2031 46 2054 40 2169 46 2006 46 656 40 2195 61 1505 41 46 2088 40 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2169 46 2006 46 656 40 2196 61 1505 41 46 2088 40 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2169 46 2006 46 656 40 2197 61 1504 41 46 2088 40 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2169 46 2006 46 656 40 2199 61 1505 41 46 2088 40 41 46 2055 40 41 44 1502 41 2031 46 2054 40 2169 46 2006 46 656 40 2200 61 1504 41 46 2088 40 41 46 2055 40 41 44 1502 41 612 2201 40 2031 41 58 2031 46 2202 40 2012 46 2006 46 656 40 2203 61 1502 41 44 91 2031 46 2021 44 2031 46 2022 93 44 41 2031 46 2202 40 2012 46 2006 46 656 40 2204 61 1503 41 44 91 2031 46 2018 44 2031 46 2019 44 2031 46 2020 44 2031 46 2023 93 44 41 2031 46 2202 40 2012 46 2006 46 656 40 2205 61 1502 41 44 91 2031 46 2011 44 2031 46 2018 44 2031 46 2019 44 2031 46 2020 44 2031 46 2023 93 44 41 2031 46 2202 40 2012 46 2006 46 656 40 2206 61 1500 41 44 91 2031 46 2011 44 2031 46 2018 44 2031 46 2019 44 2031 46 2020 44 2031 46 2021 44 2031 46 2022 44 2031 46 2023 93 44 41 612 2207 40 2031 41 58 362 2079 46 2006 46 2007 40 2080 61 1501 44 2208 61 362 41 2031 46 2036 40 2079 46 2006 46 656 40 2209 61 515 41 41 2031 46 2032 40 2079 46 2006 46 656 40 2210 61 515 41 41 2031 46 2032 40 2079 46 2006 46 656 40 2211 61 470 41 41 2031 46 2032 40 2079 46 2006 46 656 40 2212 61 470 41 41 612 2213 40 2031 41 58 2031 46 2202 40 2012 46 2006 46 656 40 2016 61 2005 46 2006 46 544 40 41 91 58 1501 93 41 44 91 2031 46 2011 44 2031 46 2018 44 2031 46 2019 44 2031 46 2020 93 41 612 2214 40 2031 41 58 2031 46 2202 40 2012 46 2006 46 656 40 2016 61 2005 46 2006 46 544 40 41 91 1501 58 1502 93 41 44 91 2031 46 2021 44 2031 46 2022 44 2031 46 2023 93 41 612 2215 40 2031 41 58 2083 61 40 362 362 41 871 2031 46 2084 40 2085 44 2083 41 58 723 40 2012 46 2006 46 656 40 2016 61 2005 46 2006 46 544 40 41 91 58 1502 93 41 41 871 2031 46 2084 40 2085 44 2083 41 58 723 40 2012 46 2006 46 656 40 2016 61 2005 46 2006 46 544 40 41 91 1501 58 93 41 41 64 2216 40 2066 46 2217 323 362 44 362 41 612 2218 40 2031 41 58 330 330 2219 61 2220 46 2006 46 2007 40 2008 61 362 44 2221 61 1505 41 2222 46 2006 46 2007 40 2219 61 2219 44 2223 61 443 44 2224 61 1505 41 2225 61 2222 46 2006 46 2007 40 2219 61 2219 44 2223 61 515 44 2224 61 1504 41 2226 61 2222 46 2006 46 656 40 2223 61 515 41 2031 46 2038 40 2226 44 91 2225 93 41 2031 46 2139 40 362 37 2066 46 2227 46 2228 40 362 41 44 813 40 2226 46 2137 41 44 41 64 2216 40 2066 46 2217 323 362 44 362 41 612 2229 40 2031 41 58 330 330 2226 61 2005 46 2006 46 2230 40 2231 61 2232 40 2233 40 2009 61 362 44 2234 61 515 41 44 2235 61 443 44 2236 61 2237 40 41 44 41 41 46 656 40 2231 61 515 41 2031 46 2038 40 2226 44 91 2031 46 2004 93 41 2031 46 2139 40 362 44 813 40 2226 46 2137 41 41 2226 61 2005 46 2006 46 2230 40 2238 61 2239 40 2103 40 2009 61 362 41 44 2236 61 2237 40 41 41 44 41 46 656 40 2238 61 515 41 2031 46 2038 40 2226 44 91 2031 46 2004 93 41 2031 46 2139 40 362 44 813 40 2226 46 2137 41 41 330 2226 61 2005 46 2006 46 2230 40 2033 61 2240 40 2005 46 2006 46 656 40 2009 61 362 44 2073 61 2241 40 362 41 41 41 44 41 46 656 40 2033 61 515 41 2031 46 2038 40 2226 44 91 2031 46 2004 93 41 2031 46 2242 40 362 44 813 40 2226 46 2137 41 41 612 2243 40 2031 41 58 362 2244 61 2079 46 2006 46 2007 40 2080 61 1505 44 2208 61 470 41 2031 46 2032 40 2079 46 2006 46 656 40 2073 61 2244 46 2073 44 2209 61 515 41 41 2031 46 2032 40 2079 46 2006 46 656 40 2073 61 2244 46 2073 44 2208 61 362 41 41 612 2245 40 2031 41 58 2034 61 2005 46 2006 46 2007 40 2008 61 362 44 2009 61 362 41 2246 61 2005 46 2006 46 2007 40 2008 61 362 44 2009 61 362 41 2247 61 40 40 362 44 91 2034 93 41 44 40 362 44 91 2034 93 41 44 40 362 44 91 2034 44 2246 93 41 44 40 362 44 91 2034 44 2246 93 41 44 40 362 44 91 2246 93 41 44 40 362 44 91 2246 93 41 44 41 664 2248 44 2249 696 2247 58 871 2031 46 2105 40 2248 61 2248 41 58 2072 61 2005 46 2006 46 656 40 350 123 362 37 2248 58 2250 40 362 44 1501 44 1502 41 125 41 2031 46 2202 40 2072 44 2249 41 612 2251 40 2031 41 58 362 2244 61 2079 46 2006 46 2007 40 2080 61 1505 44 2208 61 470 41 2137 61 2079 46 2006 46 2252 40 41 46 2137 2253 61 2137 46 2254 46 2255 46 2256 40 362 41 2031 46 2044 40 2137 46 2257 40 91 362 93 44 2253 44 470 41 44 2258 41 2031 46 2032 40 2079 46 2006 46 656 40 2073 61 2244 46 2073 44 2259 61 515 41 41 612 2260 40 2031 41 58 2226 61 2012 46 2006 46 656 40 2073 61 2241 40 362 41 41 2261 61 2079 46 2006 46 2230 40 2262 61 2240 40 2226 41 44 41 46 656 40 2262 61 2240 40 2226 41 44 41 2031 46 2202 40 2261 44 2079 46 2006 46 544 40 41 41 612 2263 40 2031 41 58 2264 61 2025 46 2006 46 2007 40 2008 61 2031 46 2004 46 2009 41 2264 46 2026 46 2027 40 2031 46 2011 41 2226 61 2025 46 2006 46 2230 40 2265 61 2240 40 2012 46 2006 46 2230 40 2266 61 2240 40 2005 46 2006 46 656 40 2009 61 2241 40 2241 40 362 41 41 41 41 44 41 46 656 40 2266 61 515 41 41 44 41 2031 46 2054 40 2226 46 2170 40 2265 61 515 41 44 2264 41 612 2267 40 2031 41 58 2268 61 2005 46 2006 46 2007 40 2008 61 362 41 2269 61 2005 46 2006 46 656 40 2008 61 362 44 41 46 2108 40 362 44 41 46 2230 40 2270 61 2271 40 362 41 44 41 46 2108 40 362 41 2072 61 2005 46 2006 46 656 40 687 61 2269 91 58 1501 93 41 2031 46 2054 40 2072 46 2170 40 41 44 2268 41 612 2272 40 2031 41 58 2083 61 362 2247 61 91 2005 46 2006 46 656 40 2273 61 1501 41 44 2012 46 2006 46 656 40 2274 61 1501 41 44 2079 46 2006 46 656 40 2275 61 1501 41 44 2276 46 2006 46 656 40 2277 61 1501 41 44 93 664 2226 696 2247 58 871 2031 46 2105 40 2226 61 2226 41 58 871 2031 46 2084 40 2085 44 2083 41 58 2226 46 2033 40 41 612 2278 40 2031 41 58 2219 61 2220 46 2006 46 2007 40 2008 61 362 44 2221 61 1505 41 2225 61 2222 46 2006 46 2007 40 2219 61 2219 44 2223 61 515 44 2224 61 1504 41 2279 61 2222 46 2006 46 2007 40 2219 61 2219 44 2223 61 443 44 2224 61 1505 41 2222 46 2006 46 2007 40 2219 61 2219 44 2223 61 443 44 2224 61 1505 41 2031 46 2202 40 2222 46 2006 46 656 40 2223 61 2103 40 2280 61 2281 40 362 41 41 41 44 91 2225 44 2279 93 44 41 2031 46 2202 40 2222 46 2006 46 656 40 2223 61 2239 40 2103 40 2280 61 2281 40 362 41 41 44 2236 61 2237 40 41 44 41 41 44 91 2225 44 2279 93 44 41 ,"{'AvgLine': 18, 'CountLine': 1040, 'CountStmt': 377, 'MaxNesting': 3, 'AvgLineCode': 16, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 320, 'MaxEssential': 1, 'SumEssential': 53, 'AvgCyclomatic': 1, 'CountLineCode': 884, 'CountStmtDecl': 129, 'MaxCyclomatic': 2, 'SumCyclomatic': 59, 'AvgLineComment': 1, 'CountClassBase': 0, 'CountLineBlank': 73, 'CountDeclMethod': 53, 'CountLineCodeExe': 819, 'CountLineComment': 83, 'CountClassCoupled': 29, 'CountClassDerived': 0, 'CountLineCodeDecl': 140, 'CountDeclMethodAll': 53, 'MaxInheritanceTree': 0, 'RatioCommentToCode': '0.09', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 2, 'SumCyclomaticStrict': 59, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 2, 'SumCyclomaticModified': 59, 'CountDeclInstanceMethod': 52, 'CountClassCoupledModified': 22, 'CountDeclInstanceVariable': 0}"
126928,Python,"class TestSqoopHook(unittest.TestCase):
    _config = {
        'conn_id': 'sqoop_test',
        'num_mappers': 22,
        'verbose': True,
        'properties': {'mapred.map.max.attempts': '1'},
        'hcatalog_database': 'hive_database',
        'hcatalog_table': 'hive_table',
    }
    _config_export = {
        'table': 'export_data_to',
        'export_dir': '/hdfs/data/to/be/exported',
        'input_null_string': '\\n',
        'input_null_non_string': '\\t',
        'staging_table': 'database.staging',
        'clear_staging_table': True,
        'enclosed_by': '""',
        'escaped_by': '\\',
        'input_fields_terminated_by': '|',
        'input_lines_terminated_by': '\n',
        'input_optionally_enclosed_by': '""',
        'batch': True,
        'relaxed_isolation': True,
        'extra_export_options': collections.OrderedDict(
            [('update-key', 'id'), ('update-mode', 'allowinsert'), ('fetch-size', 1)]
        ),
        'schema': 'domino',
    }
    _config_import = {
        'target_dir': '/hdfs/data/target/location',
        'append': True,
        'file_type': 'parquet',
        'split_by': '\n',
        'direct': True,
        'driver': 'com.microsoft.jdbc.sqlserver.SQLServerDriver',
        'extra_import_options': {
            'hcatalog-storage-stanza': ""\""stored as orcfile\"""",
            'show': '',
            'fetch-size': 1,
        },
    }

    _config_json = {
        'namenode': 'http://0.0.0.0:50070/',
        'job_tracker': 'http://0.0.0.0:50030/',
        'libjars': '/path/to/jars',
        'files': '/path/to/files',
        'archives': '/path/to/archives',
    }

    def setUp(self):
        db.merge_conn(
            Connection(
                conn_id='sqoop_test',
                conn_type='sqoop',
                schema='schema',
                host='rmdbs',
                port=5050,
                extra=json.dumps(self._config_json),
            )
        )
        db.merge_conn(
            Connection(
                conn_id='sqoop_test_mssql',
                conn_type='mssql',
                schema='schema',
                host='rmdbs',
                port=5050,
                extra=None,
            )
        )

    @patch('subprocess.Popen')
    def test_popen(self, mock_popen):
        # Given
        mock_proc = mock.MagicMock()
        mock_proc.returncode = 0
        mock_proc.stdout = StringIO('stdout')
        mock_proc.stderr = StringIO('stderr')
        mock_proc.communicate.return_value = [
            StringIO('stdout\nstdout'),
            StringIO('stderr\nstderr'),
        ]
        mock_popen.return_value.__enter__.return_value = mock_proc

        # When
        hook = SqoopHook(conn_id='sqoop_test')
        hook.export_table(**self._config_export)

        # Then
        assert mock_popen.mock_calls[0] == call(
            [
                'sqoop',
                'export',
                '-fs',
                self._config_json['namenode'],
                '-jt',
                self._config_json['job_tracker'],
                '-libjars',
                self._config_json['libjars'],
                '-files',
                self._config_json['files'],
                '-archives',
                self._config_json['archives'],
                '--connect',
                'rmdbs:5050/schema',
                '--input-null-string',
                self._config_export['input_null_string'],
                '--input-null-non-string',
                self._config_export['input_null_non_string'],
                '--staging-table',
                self._config_export['staging_table'],
                '--clear-staging-table',
                '--enclosed-by',
                self._config_export['enclosed_by'],
                '--escaped-by',
                self._config_export['escaped_by'],
                '--input-fields-terminated-by',
                self._config_export['input_fields_terminated_by'],
                '--input-lines-terminated-by',
                self._config_export['input_lines_terminated_by'],
                '--input-optionally-enclosed-by',
                self._config_export['input_optionally_enclosed_by'],
                '--batch',
                '--relaxed-isolation',
                '--export-dir',
                self._config_export['export_dir'],
                '--update-key',
                'id',
                '--update-mode',
                'allowinsert',
                '--fetch-size',
                str(self._config_export['extra_export_options'].get('fetch-size')),
                '--table',
                self._config_export['table'],
                '--',
                '--schema',
                self._config_export['schema'],
            ],
            stderr=-2,
            stdout=-1,
        )

    def test_submit_none_mappers(self):
        """"""
        Test to check that if value of num_mappers is None, then it shouldn't be in the cmd built.
        """"""
        _config_without_mappers = self._config.copy()
        _config_without_mappers['num_mappers'] = None

        hook = SqoopHook(**_config_without_mappers)
        cmd = ' '.join(hook._prepare_command())
        assert '--num-mappers' not in cmd

    def test_submit(self):
        """"""
        Tests to verify that from connection extra option the options are added to the Sqoop command.
        """"""
        hook = SqoopHook(**self._config)

        cmd = ' '.join(hook._prepare_command())

        # Check if the config has been extracted from the json
        if self._config_json['namenode']:
            assert f""-fs {self._config_json['namenode']}"" in cmd

        if self._config_json['job_tracker']:
            assert f""-jt {self._config_json['job_tracker']}"" in cmd

        if self._config_json['libjars']:
            assert f""-libjars {self._config_json['libjars']}"" in cmd

        if self._config_json['files']:
            assert f""-files {self._config_json['files']}"" in cmd

        if self._config_json['archives']:
            assert f""-archives {self._config_json['archives']}"" in cmd

        assert f""--hcatalog-database {self._config['hcatalog_database']}"" in cmd
        assert f""--hcatalog-table {self._config['hcatalog_table']}"" in cmd

        # Check the regulator stuff passed by the default constructor
        if self._config['verbose']:
            assert ""--verbose"" in cmd

        if self._config['num_mappers']:
            assert f""--num-mappers {self._config['num_mappers']}"" in cmd

        for key, value in self._config['properties'].items():
            assert f""-D {key}={value}"" in cmd

        # We don't have the sqoop binary available, and this is hard to mock,
        # so just accept an exception for now.
        with pytest.raises(OSError):
            hook.export_table(**self._config_export)

        with pytest.raises(OSError):
            hook.import_table(table='table', target_dir='/sqoop/example/path', schema='schema')

        with pytest.raises(OSError):
            hook.import_query(query='SELECT * FROM sometable', target_dir='/sqoop/example/path')

    def test_export_cmd(self):
        """"""
        Tests to verify the hook export command is building correct Sqoop export command.
        """"""
        hook = SqoopHook()

        # The subprocess requires an array but we build the cmd by joining on a space
        cmd = ' '.join(
            hook._export_cmd(
                self._config_export['table'],
                self._config_export['export_dir'],
                input_null_string=self._config_export['input_null_string'],
                input_null_non_string=self._config_export['input_null_non_string'],
                staging_table=self._config_export['staging_table'],
                clear_staging_table=self._config_export['clear_staging_table'],
                enclosed_by=self._config_export['enclosed_by'],
                escaped_by=self._config_export['escaped_by'],
                input_fields_terminated_by=self._config_export['input_fields_terminated_by'],
                input_lines_terminated_by=self._config_export['input_lines_terminated_by'],
                input_optionally_enclosed_by=self._config_export['input_optionally_enclosed_by'],
                batch=self._config_export['batch'],
                relaxed_isolation=self._config_export['relaxed_isolation'],
                extra_export_options=self._config_export['extra_export_options'],
                schema=self._config_export['schema'],
            )
        )

        assert f""--input-null-string {self._config_export['input_null_string']}"" in cmd
        assert f""--input-null-non-string {self._config_export['input_null_non_string']}"" in cmd
        assert f""--staging-table {self._config_export['staging_table']}"" in cmd
        assert f""--enclosed-by {self._config_export['enclosed_by']}"" in cmd
        assert f""--escaped-by {self._config_export['escaped_by']}"" in cmd
        assert f""--input-fields-terminated-by {self._config_export['input_fields_terminated_by']}"" in cmd
        assert f""--input-lines-terminated-by {self._config_export['input_lines_terminated_by']}"" in cmd
        assert f""--input-optionally-enclosed-by {self._config_export['input_optionally_enclosed_by']}"" in cmd
        # these options are from the extra export options
        assert ""--update-key id"" in cmd
        assert ""--update-mode allowinsert"" in cmd

        if self._config_export['clear_staging_table']:
            assert ""--clear-staging-table"" in cmd

        if self._config_export['batch']:
            assert ""--batch"" in cmd

        if self._config_export['relaxed_isolation']:
            assert ""--relaxed-isolation"" in cmd

        if self._config_export['extra_export_options']:
            assert ""--update-key"" in cmd
            assert ""--update-mode"" in cmd
            assert ""--fetch-size"" in cmd

        if self._config_export['schema']:
            assert ""-- --schema"" in cmd

    def test_import_cmd(self):
        """"""
        Tests to verify the hook import command is building correct Sqoop import command.
        """"""
        hook = SqoopHook()

        # The subprocess requires an array but we build the cmd by joining on a space
        cmd = ' '.join(
            hook._import_cmd(
                self._config_import['target_dir'],
                append=self._config_import['append'],
                file_type=self._config_import['file_type'],
                split_by=self._config_import['split_by'],
                direct=self._config_import['direct'],
                driver=self._config_import['driver'],
                extra_import_options=None,
            )
        )

        if self._config_import['append']:
            assert '--append' in cmd

        if self._config_import['direct']:
            assert '--direct' in cmd

        assert f""--target-dir {self._config_import['target_dir']}"" in cmd

        assert f""--driver {self._config_import['driver']}"" in cmd
        assert f""--split-by {self._config_import['split_by']}"" in cmd
        # these are from extra options, but not passed to this cmd import command
        assert '--show' not in cmd
        assert 'hcatalog-storage-stanza \""stored as orcfile\""' not in cmd

        cmd = ' '.join(
            hook._import_cmd(
                target_dir=None,
                append=self._config_import['append'],
                file_type=self._config_import['file_type'],
                split_by=self._config_import['split_by'],
                direct=self._config_import['direct'],
                driver=self._config_import['driver'],
                extra_import_options=self._config_import['extra_import_options'],
            )
        )

        assert '--target-dir' not in cmd
        # these checks are from the extra import options
        assert '--show' in cmd
        assert 'hcatalog-storage-stanza \""stored as orcfile\""' in cmd
        assert '--fetch-size' in cmd

    def test_get_export_format_argument(self):
        """"""
        Tests to verify the hook get format function is building
        correct Sqoop command with correct format type.
        """"""
        hook = SqoopHook()
        assert ""--as-avrodatafile"" in hook._get_export_format_argument('avro')
        assert ""--as-parquetfile"" in hook._get_export_format_argument('parquet')
        assert ""--as-sequencefile"" in hook._get_export_format_argument('sequence')
        assert ""--as-textfile"" in hook._get_export_format_argument('text')
        with pytest.raises(AirflowException):
            hook._get_export_format_argument('unknown')

    def test_cmd_mask_password(self):
        """"""
        Tests to verify the hook masking function will correctly mask a user password in Sqoop command.
        """"""
        hook = SqoopHook()
        assert hook.cmd_mask_password(['--password', 'supersecret']) == ['--password', 'MASKED']

        cmd = ['--target', 'targettable']
        assert hook.cmd_mask_password(cmd) == cmd

    def test_connection_string_preparation(self):
        """"""
        Tests to verify the hook creates the connection string correctly for mssql and not DB connections.
        """"""
        # Case mssql
        hook = SqoopHook(conn_id='sqoop_test_mssql')
        assert f""{hook.conn.host}:{hook.conn.port};databaseName={hook.conn.schema}"" in hook._prepare_command()

        # Case no mssql
        hook = SqoopHook(conn_id='sqoop_test')
        assert f""{hook.conn.host}:{hook.conn.port}/{hook.conn.schema}"" in hook._prepare_command()",1,587 2000 40 2001 46 2002 41 58 2003 61 123 362 58 362 44 362 58 1503 44 362 58 515 44 362 58 123 362 58 362 125 44 362 58 362 44 362 58 362 44 125 2004 61 123 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 515 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 515 44 362 58 515 44 362 58 2005 46 2006 40 91 40 362 44 362 41 44 40 362 44 362 41 44 40 362 44 1501 41 93 41 44 362 58 362 44 125 2007 61 123 362 58 362 44 362 58 515 44 362 58 362 44 362 58 362 44 362 58 515 44 362 58 362 44 362 58 123 362 58 362 44 362 58 362 44 362 58 1501 44 125 44 125 2008 61 123 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 125 612 2009 40 2010 41 58 2011 46 2012 40 2013 40 2014 61 362 44 2015 61 362 44 2016 61 362 44 2017 61 362 44 2018 61 1505 44 2019 61 2020 46 2021 40 2010 46 2008 41 44 41 41 2011 46 2012 40 2013 40 2014 61 362 44 2015 61 362 44 2016 61 362 44 2017 61 362 44 2018 61 1505 44 2019 61 470 44 41 41 64 2022 40 362 41 612 2023 40 2010 44 2024 41 58 330 2025 61 2026 46 2027 40 41 2025 46 2028 61 1500 2025 46 2029 61 2030 40 362 41 2025 46 2031 61 2030 40 362 41 2025 46 2032 46 2033 61 91 2030 40 362 41 44 2030 40 362 41 44 93 2024 46 2033 46 2034 46 2033 61 2025 330 2035 61 2036 40 2014 61 362 41 2035 46 2037 40 350 2010 46 2004 41 330 555 2024 46 2038 91 1500 93 323 2039 40 91 362 44 362 44 362 44 2010 46 2008 91 362 93 44 362 44 2010 46 2008 91 362 93 44 362 44 2010 46 2008 91 362 93 44 362 44 2010 46 2008 91 362 93 44 362 44 2010 46 2008 91 362 93 44 362 44 362 44 362 44 2010 46 2004 91 362 93 44 362 44 2010 46 2004 91 362 93 44 362 44 2010 46 2004 91 362 93 44 362 44 362 44 2010 46 2004 91 362 93 44 362 44 2010 46 2004 91 362 93 44 362 44 2010 46 2004 91 362 93 44 362 44 2010 46 2004 91 362 93 44 362 44 2010 46 2004 91 362 93 44 362 44 362 44 362 44 2010 46 2004 91 362 93 44 362 44 362 44 362 44 362 44 362 44 813 40 2010 46 2004 91 362 93 46 2040 40 362 41 41 44 362 44 2010 46 2004 91 362 93 44 362 44 362 44 2010 46 2004 91 362 93 44 93 44 2031 61 45 1502 44 2029 61 45 1501 44 41 612 2041 40 2010 41 58 362 2042 61 2010 46 2003 46 2043 40 41 2042 91 362 93 61 470 2035 61 2036 40 350 2042 41 2044 61 362 46 2045 40 2035 46 2046 40 41 41 555 362 750 696 2044 612 2047 40 2010 41 58 362 2035 61 2036 40 350 2010 46 2003 41 2044 61 362 46 2045 40 2035 46 2046 40 41 41 330 688 2010 46 2008 91 362 93 58 555 362 696 2044 688 2010 46 2008 91 362 93 58 555 362 696 2044 688 2010 46 2008 91 362 93 58 555 362 696 2044 688 2010 46 2008 91 362 93 58 555 362 696 2044 688 2010 46 2008 91 362 93 58 555 362 696 2044 555 362 696 2044 555 362 696 2044 330 688 2010 46 2003 91 362 93 58 555 362 696 2044 688 2010 46 2003 91 362 93 58 555 362 696 2044 664 2048 44 2049 696 2010 46 2003 91 362 93 46 2050 40 41 58 555 362 696 2044 330 330 871 2051 46 2052 40 2053 41 58 2035 46 2037 40 350 2010 46 2004 41 871 2051 46 2052 40 2053 41 58 2035 46 2054 40 2055 61 362 44 2056 61 362 44 2016 61 362 41 871 2051 46 2052 40 2053 41 58 2035 46 2057 40 2058 61 362 44 2056 61 362 41 612 2059 40 2010 41 58 362 2035 61 2036 40 41 330 2044 61 362 46 2045 40 2035 46 2060 40 2010 46 2004 91 362 93 44 2010 46 2004 91 362 93 44 2061 61 2010 46 2004 91 362 93 44 2062 61 2010 46 2004 91 362 93 44 2063 61 2010 46 2004 91 362 93 44 2064 61 2010 46 2004 91 362 93 44 2065 61 2010 46 2004 91 362 93 44 2066 61 2010 46 2004 91 362 93 44 2067 61 2010 46 2004 91 362 93 44 2068 61 2010 46 2004 91 362 93 44 2069 61 2010 46 2004 91 362 93 44 2070 61 2010 46 2004 91 362 93 44 2071 61 2010 46 2004 91 362 93 44 2072 61 2010 46 2004 91 362 93 44 2016 61 2010 46 2004 91 362 93 44 41 41 555 362 696 2044 555 362 696 2044 555 362 696 2044 555 362 696 2044 555 362 696 2044 555 362 696 2044 555 362 696 2044 555 362 696 2044 330 555 362 696 2044 555 362 696 2044 688 2010 46 2004 91 362 93 58 555 362 696 2044 688 2010 46 2004 91 362 93 58 555 362 696 2044 688 2010 46 2004 91 362 93 58 555 362 696 2044 688 2010 46 2004 91 362 93 58 555 362 696 2044 555 362 696 2044 555 362 696 2044 688 2010 46 2004 91 362 93 58 555 362 696 2044 612 2073 40 2010 41 58 362 2035 61 2036 40 41 330 2044 61 362 46 2045 40 2035 46 2074 40 2010 46 2007 91 362 93 44 2075 61 2010 46 2007 91 362 93 44 2076 61 2010 46 2007 91 362 93 44 2077 61 2010 46 2007 91 362 93 44 2078 61 2010 46 2007 91 362 93 44 2079 61 2010 46 2007 91 362 93 44 2080 61 470 44 41 41 688 2010 46 2007 91 362 93 58 555 362 696 2044 688 2010 46 2007 91 362 93 58 555 362 696 2044 555 362 696 2044 555 362 696 2044 555 362 696 2044 330 555 362 750 696 2044 555 362 750 696 2044 2044 61 362 46 2045 40 2035 46 2074 40 2056 61 470 44 2075 61 2010 46 2007 91 362 93 44 2076 61 2010 46 2007 91 362 93 44 2077 61 2010 46 2007 91 362 93 44 2078 61 2010 46 2007 91 362 93 44 2079 61 2010 46 2007 91 362 93 44 2080 61 2010 46 2007 91 362 93 44 41 41 555 362 750 696 2044 330 555 362 696 2044 555 362 696 2044 555 362 696 2044 612 2081 40 2010 41 58 362 2035 61 2036 40 41 555 362 696 2035 46 2082 40 362 41 555 362 696 2035 46 2082 40 362 41 555 362 696 2035 46 2082 40 362 41 555 362 696 2035 46 2082 40 362 41 871 2051 46 2052 40 2083 41 58 2035 46 2082 40 362 41 612 2084 40 2010 41 58 362 2035 61 2036 40 41 555 2035 46 2085 40 91 362 44 362 93 41 323 91 362 44 362 93 2044 61 91 362 44 362 93 555 2035 46 2085 40 2044 41 323 2044 612 2086 40 2010 41 58 362 330 2035 61 2036 40 2014 61 362 41 555 362 696 2035 46 2046 40 41 330 2035 61 2036 40 2014 61 362 41 555 362 696 2035 46 2046 40 41 ,"{'AvgLine': 31, 'CountLine': 343, 'CountStmt': 111, 'MaxNesting': 1, 'AvgLineCode': 24, 'AvgEssential': 1, 'AvgLineBlank': 3, 'CountStmtExe': 101, 'MaxEssential': 1, 'SumEssential': 9, 'AvgCyclomatic': 2, 'CountLineCode': 265, 'CountStmtDecl': 30, 'MaxCyclomatic': 9, 'SumCyclomatic': 24, 'AvgLineComment': 4, 'CountClassBase': 1, 'CountLineBlank': 42, 'CountDeclMethod': 9, 'CountLineCodeExe': 254, 'CountLineComment': 36, 'CountClassCoupled': 4, 'CountClassDerived': 0, 'CountLineCodeDecl': 31, 'CountDeclMethodAll': 9, 'MaxInheritanceTree': 1, 'RatioCommentToCode': '0.14', 'AvgCyclomaticStrict': 2, 'MaxCyclomaticStrict': 9, 'SumCyclomaticStrict': 24, 'AvgCyclomaticModified': 2, 'MaxCyclomaticModified': 9, 'SumCyclomaticModified': 24, 'CountDeclInstanceMethod': 9, 'CountClassCoupledModified': 3, 'CountDeclInstanceVariable': 0}"
124998,Python,"class TestSSHHook(unittest.TestCase):
    CONN_SSH_WITH_NO_EXTRA = 'ssh_with_no_extra'
    CONN_SSH_WITH_PRIVATE_KEY_EXTRA = 'ssh_with_private_key_extra'
    CONN_SSH_WITH_PRIVATE_KEY_ECDSA_EXTRA = 'ssh_with_private_key_ecdsa_extra'
    CONN_SSH_WITH_PRIVATE_KEY_PASSPHRASE_EXTRA = 'ssh_with_private_key_passphrase_extra'
    CONN_SSH_WITH_TIMEOUT_EXTRA = 'ssh_with_timeout_extra'
    CONN_SSH_WITH_CONN_TIMEOUT_EXTRA = 'ssh_with_conn_timeout_extra'
    CONN_SSH_WITH_TIMEOUT_AND_CONN_TIMEOUT_EXTRA = 'ssh_with_timeout_and_conn_timeout_extra'
    CONN_SSH_WITH_EXTRA = 'ssh_with_extra'
    CONN_SSH_WITH_EXTRA_FALSE_LOOK_FOR_KEYS = 'ssh_with_extra_false_look_for_keys'
    CONN_SSH_WITH_HOST_KEY_EXTRA = 'ssh_with_host_key_extra'
    CONN_SSH_WITH_HOST_KEY_EXTRA_WITH_TYPE = 'ssh_with_host_key_extra_with_type'
    CONN_SSH_WITH_HOST_KEY_AND_NO_HOST_KEY_CHECK_FALSE = 'ssh_with_host_key_and_no_host_key_check_false'
    CONN_SSH_WITH_HOST_KEY_AND_NO_HOST_KEY_CHECK_TRUE = 'ssh_with_host_key_and_no_host_key_check_true'
    CONN_SSH_WITH_NO_HOST_KEY_AND_NO_HOST_KEY_CHECK_FALSE = 'ssh_with_no_host_key_and_no_host_key_check_false'

    @classmethod
    def tearDownClass(cls) -> None:
        with create_session() as session:
            conns_to_reset = [
                cls.CONN_SSH_WITH_NO_EXTRA,
                cls.CONN_SSH_WITH_PRIVATE_KEY_EXTRA,
                cls.CONN_SSH_WITH_PRIVATE_KEY_PASSPHRASE_EXTRA,
                cls.CONN_SSH_WITH_PRIVATE_KEY_ECDSA_EXTRA,
                cls.CONN_SSH_WITH_TIMEOUT_EXTRA,
                cls.CONN_SSH_WITH_CONN_TIMEOUT_EXTRA,
                cls.CONN_SSH_WITH_TIMEOUT_AND_CONN_TIMEOUT_EXTRA,
                cls.CONN_SSH_WITH_EXTRA,
                cls.CONN_SSH_WITH_HOST_KEY_EXTRA,
                cls.CONN_SSH_WITH_HOST_KEY_EXTRA_WITH_TYPE,
                cls.CONN_SSH_WITH_HOST_KEY_AND_NO_HOST_KEY_CHECK_FALSE,
                cls.CONN_SSH_WITH_HOST_KEY_AND_NO_HOST_KEY_CHECK_TRUE,
                cls.CONN_SSH_WITH_NO_HOST_KEY_AND_NO_HOST_KEY_CHECK_FALSE,
            ]
            connections = session.query(Connection).filter(Connection.conn_id.in_(conns_to_reset))
            connections.delete(synchronize_session=False)
            session.commit()

    @classmethod
    def setUpClass(cls) -> None:
        db.merge_conn(
            Connection(
                conn_id=cls.CONN_SSH_WITH_NO_EXTRA,
                host='localhost',
                conn_type='ssh',
                extra=None,
            )
        )
        db.merge_conn(
            Connection(
                conn_id=cls.CONN_SSH_WITH_EXTRA,
                host='localhost',
                conn_type='ssh',
                extra='{""compress"" : true, ""no_host_key_check"" : ""true"", ""allow_host_key_change"": false}',
            )
        )
        db.merge_conn(
            Connection(
                conn_id=cls.CONN_SSH_WITH_EXTRA_FALSE_LOOK_FOR_KEYS,
                host='localhost',
                conn_type='ssh',
                extra='{""compress"" : true, ""no_host_key_check"" : ""true"", '
                '""allow_host_key_change"": false, ""look_for_keys"": false}',
            )
        )
        db.merge_conn(
            Connection(
                conn_id=cls.CONN_SSH_WITH_PRIVATE_KEY_EXTRA,
                host='localhost',
                conn_type='ssh',
                extra=json.dumps({""private_key"": TEST_PRIVATE_KEY}),
            )
        )
        db.merge_conn(
            Connection(
                conn_id=cls.CONN_SSH_WITH_PRIVATE_KEY_PASSPHRASE_EXTRA,
                host='localhost',
                conn_type='ssh',
                extra=json.dumps(
                    {""private_key"": TEST_ENCRYPTED_PRIVATE_KEY, ""private_key_passphrase"": PASSPHRASE}
                ),
            )
        )
        db.merge_conn(
            Connection(
                conn_id=cls.CONN_SSH_WITH_PRIVATE_KEY_ECDSA_EXTRA,
                host='localhost',
                conn_type='ssh',
                extra=json.dumps({""private_key"": TEST_PRIVATE_KEY_ECDSA}),
            )
        )
        db.merge_conn(
            Connection(
                conn_id=cls.CONN_SSH_WITH_TIMEOUT_EXTRA,
                host='localhost',
                conn_type='ssh',
                extra=json.dumps({""timeout"": TEST_TIMEOUT}),
            )
        )
        db.merge_conn(
            Connection(
                conn_id=cls.CONN_SSH_WITH_CONN_TIMEOUT_EXTRA,
                host='localhost',
                conn_type='ssh',
                extra=json.dumps({""conn_timeout"": TEST_CONN_TIMEOUT}),
            )
        )
        db.merge_conn(
            Connection(
                conn_id=cls.CONN_SSH_WITH_TIMEOUT_AND_CONN_TIMEOUT_EXTRA,
                host='localhost',
                conn_type='ssh',
                extra=json.dumps({""conn_timeout"": TEST_CONN_TIMEOUT, 'timeout': TEST_TIMEOUT}),
            )
        )
        db.merge_conn(
            Connection(
                conn_id=cls.CONN_SSH_WITH_HOST_KEY_EXTRA,
                host='localhost',
                conn_type='ssh',
                extra=json.dumps({""private_key"": TEST_PRIVATE_KEY, ""host_key"": TEST_HOST_KEY}),
            )
        )
        db.merge_conn(
            Connection(
                conn_id=cls.CONN_SSH_WITH_HOST_KEY_EXTRA_WITH_TYPE,
                host='localhost',
                conn_type='ssh',
                extra=json.dumps({""private_key"": TEST_PRIVATE_KEY, ""host_key"": ""ssh-rsa "" + TEST_HOST_KEY}),
            )
        )
        db.merge_conn(
            Connection(
                conn_id=cls.CONN_SSH_WITH_HOST_KEY_AND_NO_HOST_KEY_CHECK_FALSE,
                host='remote_host',
                conn_type='ssh',
                extra=json.dumps(
                    {""private_key"": TEST_PRIVATE_KEY, ""host_key"": TEST_HOST_KEY, ""no_host_key_check"": False}
                ),
            )
        )
        db.merge_conn(
            Connection(
                conn_id=cls.CONN_SSH_WITH_HOST_KEY_AND_NO_HOST_KEY_CHECK_TRUE,
                host='remote_host',
                conn_type='ssh',
                extra=json.dumps(
                    {""private_key"": TEST_PRIVATE_KEY, ""host_key"": TEST_HOST_KEY, ""no_host_key_check"": True}
                ),
            )
        )
        db.merge_conn(
            Connection(
                conn_id=cls.CONN_SSH_WITH_NO_HOST_KEY_AND_NO_HOST_KEY_CHECK_FALSE,
                host='remote_host',
                conn_type='ssh',
                extra=json.dumps({""private_key"": TEST_PRIVATE_KEY, ""no_host_key_check"": False}),
            )
        )

    @mock.patch('airflow.providers.ssh.hooks.ssh.paramiko.SSHClient')
    def test_ssh_connection_with_password(self, ssh_mock):
        hook = SSHHook(
            remote_host='remote_host',
            port='port',
            username='username',
            password='password',
            timeout=10,
            key_file='fake.file',
        )

        with hook.get_conn():
            ssh_mock.return_value.connect.assert_called_once_with(
                hostname='remote_host',
                username='username',
                password='password',
                key_filename='fake.file',
                timeout=10,
                compress=True,
                port='port',
                sock=None,
                look_for_keys=True,
            )

    @mock.patch('airflow.providers.ssh.hooks.ssh.paramiko.SSHClient')
    def test_ssh_connection_without_password(self, ssh_mock):
        hook = SSHHook(
            remote_host='remote_host', port='port', username='username', timeout=10, key_file='fake.file'
        )

        with hook.get_conn():
            ssh_mock.return_value.connect.assert_called_once_with(
                hostname='remote_host',
                username='username',
                key_filename='fake.file',
                timeout=10,
                compress=True,
                port='port',
                sock=None,
                look_for_keys=True,
            )

    @mock.patch('airflow.providers.ssh.hooks.ssh.SSHTunnelForwarder')
    def test_tunnel_with_password(self, ssh_mock):
        hook = SSHHook(
            remote_host='remote_host',
            port='port',
            username='username',
            password='password',
            timeout=10,
            key_file='fake.file',
        )

        with hook.get_tunnel(1234):
            ssh_mock.assert_called_once_with(
                'remote_host',
                ssh_port='port',
                ssh_username='username',
                ssh_password='password',
                ssh_pkey='fake.file',
                ssh_proxy=None,
                local_bind_address=('localhost',),
                remote_bind_address=('localhost', 1234),
                logger=hook.log,
            )

    @mock.patch('airflow.providers.ssh.hooks.ssh.SSHTunnelForwarder')
    def test_tunnel_without_password(self, ssh_mock):
        hook = SSHHook(
            remote_host='remote_host', port='port', username='username', timeout=10, key_file='fake.file'
        )

        with hook.get_tunnel(1234):
            ssh_mock.assert_called_once_with(
                'remote_host',
                ssh_port='port',
                ssh_username='username',
                ssh_pkey='fake.file',
                ssh_proxy=None,
                local_bind_address=('localhost',),
                remote_bind_address=('localhost', 1234),
                host_pkey_directories=None,
                logger=hook.log,
            )

    def test_conn_with_extra_parameters(self):
        ssh_hook = SSHHook(ssh_conn_id=self.CONN_SSH_WITH_EXTRA)
        assert ssh_hook.compress is True
        assert ssh_hook.no_host_key_check is True
        assert ssh_hook.allow_host_key_change is False
        assert ssh_hook.look_for_keys is True

    def test_conn_with_extra_parameters_false_look_for_keys(self):
        ssh_hook = SSHHook(ssh_conn_id=self.CONN_SSH_WITH_EXTRA_FALSE_LOOK_FOR_KEYS)
        assert ssh_hook.look_for_keys is False

    @mock.patch('airflow.providers.ssh.hooks.ssh.SSHTunnelForwarder')
    def test_tunnel_with_private_key(self, ssh_mock):
        hook = SSHHook(
            ssh_conn_id=self.CONN_SSH_WITH_PRIVATE_KEY_EXTRA,
            remote_host='remote_host',
            port='port',
            username='username',
            timeout=10,
        )

        with hook.get_tunnel(1234):
            ssh_mock.assert_called_once_with(
                'remote_host',
                ssh_port='port',
                ssh_username='username',
                ssh_pkey=TEST_PKEY,
                ssh_proxy=None,
                local_bind_address=('localhost',),
                remote_bind_address=('localhost', 1234),
                host_pkey_directories=None,
                logger=hook.log,
            )

    @mock.patch('airflow.providers.ssh.hooks.ssh.SSHTunnelForwarder')
    def test_tunnel_with_private_key_passphrase(self, ssh_mock):
        hook = SSHHook(
            ssh_conn_id=self.CONN_SSH_WITH_PRIVATE_KEY_PASSPHRASE_EXTRA,
            remote_host='remote_host',
            port='port',
            username='username',
            timeout=10,
        )

        with hook.get_tunnel(1234):
            ssh_mock.assert_called_once_with(
                'remote_host',
                ssh_port='port',
                ssh_username='username',
                ssh_pkey=TEST_PKEY,
                ssh_proxy=None,
                local_bind_address=('localhost',),
                remote_bind_address=('localhost', 1234),
                host_pkey_directories=None,
                logger=hook.log,
            )

    @mock.patch('airflow.providers.ssh.hooks.ssh.SSHTunnelForwarder')
    def test_tunnel_with_private_key_ecdsa(self, ssh_mock):
        hook = SSHHook(
            ssh_conn_id=self.CONN_SSH_WITH_PRIVATE_KEY_ECDSA_EXTRA,
            remote_host='remote_host',
            port='port',
            username='username',
            timeout=10,
        )

        with hook.get_tunnel(1234):
            ssh_mock.assert_called_once_with(
                'remote_host',
                ssh_port='port',
                ssh_username='username',
                ssh_pkey=TEST_PKEY_ECDSA,
                ssh_proxy=None,
                local_bind_address=('localhost',),
                remote_bind_address=('localhost', 1234),
                host_pkey_directories=None,
                logger=hook.log,
            )

    def test_ssh_connection(self):
        hook = SSHHook(ssh_conn_id='ssh_default')
        with hook.get_conn() as client:
            (_, stdout, _) = client.exec_command('ls')
            assert stdout.read() is not None

    def test_ssh_connection_no_connection_id(self):
        hook = SSHHook(remote_host='localhost')
        assert hook.ssh_conn_id is None
        with hook.get_conn() as client:
            (_, stdout, _) = client.exec_command('ls')
            assert stdout.read() is not None

    def test_ssh_connection_old_cm(self):
        with SSHHook(ssh_conn_id='ssh_default') as hook:
            client = hook.get_conn()
            (_, stdout, _) = client.exec_command('ls')
            assert stdout.read() is not None

    def test_tunnel(self):
        hook = SSHHook(ssh_conn_id='ssh_default')

        import socket
        import subprocess

        subprocess_kwargs = dict(
            args=[""python"", ""-c"", HELLO_SERVER_CMD],
            stdout=subprocess.PIPE,
        )
        with subprocess.Popen(**subprocess_kwargs) as server_handle, hook.get_tunnel(
            local_port=2135, remote_port=2134
        ):
            server_output = server_handle.stdout.read(5)
            assert b""ready"" == server_output
            socket = socket.socket()
            socket.connect((""localhost"", 2135))
            response = socket.recv(5)
            assert response == b""hello""
            socket.close()
            server_handle.communicate()
            assert server_handle.returncode == 0

    @mock.patch('airflow.providers.ssh.hooks.ssh.paramiko.SSHClient')
    def test_ssh_connection_with_private_key_extra(self, ssh_mock):
        hook = SSHHook(
            ssh_conn_id=self.CONN_SSH_WITH_PRIVATE_KEY_EXTRA,
            remote_host='remote_host',
            port='port',
            username='username',
            timeout=10,
        )

        with hook.get_conn():
            ssh_mock.return_value.connect.assert_called_once_with(
                hostname='remote_host',
                username='username',
                pkey=TEST_PKEY,
                timeout=10,
                compress=True,
                port='port',
                sock=None,
                look_for_keys=True,
            )

    @mock.patch('airflow.providers.ssh.hooks.ssh.paramiko.SSHClient')
    def test_ssh_connection_with_private_key_passphrase_extra(self, ssh_mock):
        hook = SSHHook(
            ssh_conn_id=self.CONN_SSH_WITH_PRIVATE_KEY_PASSPHRASE_EXTRA,
            remote_host='remote_host',
            port='port',
            username='username',
            timeout=10,
        )

        with hook.get_conn():
            ssh_mock.return_value.connect.assert_called_once_with(
                hostname='remote_host',
                username='username',
                pkey=TEST_PKEY,
                timeout=10,
                compress=True,
                port='port',
                sock=None,
                look_for_keys=True,
            )

    @mock.patch('airflow.providers.ssh.hooks.ssh.paramiko.SSHClient')
    def test_ssh_connection_with_host_key_extra(self, ssh_client):
        hook = SSHHook(ssh_conn_id=self.CONN_SSH_WITH_HOST_KEY_EXTRA)
        assert hook.host_key is not None
        with hook.get_conn():
            assert ssh_client.return_value.connect.called is True
            assert ssh_client.return_value.get_host_keys.return_value.add.called
            assert ssh_client.return_value.get_host_keys.return_value.add.call_args == mock.call(
                hook.remote_host, 'ssh-rsa', hook.host_key
            )

    @mock.patch('airflow.providers.ssh.hooks.ssh.paramiko.SSHClient')
    def test_ssh_connection_with_host_key_extra_with_type(self, ssh_client):
        hook = SSHHook(ssh_conn_id=self.CONN_SSH_WITH_HOST_KEY_EXTRA_WITH_TYPE)
        assert hook.host_key is not None
        with hook.get_conn():
            assert ssh_client.return_value.connect.called is True
            assert ssh_client.return_value.get_host_keys.return_value.add.called
            assert ssh_client.return_value.get_host_keys.return_value.add.call_args == mock.call(
                hook.remote_host, 'ssh-rsa', hook.host_key
            )

    @mock.patch('airflow.providers.ssh.hooks.ssh.paramiko.SSHClient')
    def test_ssh_connection_with_no_host_key_where_no_host_key_check_is_false(self, ssh_client):
        hook = SSHHook(ssh_conn_id=self.CONN_SSH_WITH_NO_HOST_KEY_AND_NO_HOST_KEY_CHECK_FALSE)
        assert hook.host_key is None
        with hook.get_conn():
            assert ssh_client.return_value.connect.called is True
            assert ssh_client.return_value.get_host_keys.return_value.add.called is False

    @mock.patch('airflow.providers.ssh.hooks.ssh.paramiko.SSHClient')
    def test_ssh_connection_with_conn_timeout(self, ssh_mock):
        hook = SSHHook(
            remote_host='remote_host',
            port='port',
            username='username',
            password='password',
            conn_timeout=20,
            key_file='fake.file',
        )

        with hook.get_conn():
            ssh_mock.return_value.connect.assert_called_once_with(
                hostname='remote_host',
                username='username',
                password='password',
                key_filename='fake.file',
                timeout=20,
                compress=True,
                port='port',
                sock=None,
                look_for_keys=True,
            )

    @mock.patch('airflow.providers.ssh.hooks.ssh.paramiko.SSHClient')
    def test_ssh_connection_with_conn_timeout_and_timeout(self, ssh_mock):
        hook = SSHHook(
            remote_host='remote_host',
            port='port',
            username='username',
            password='password',
            timeout=10,
            conn_timeout=20,
            key_file='fake.file',
        )

        with hook.get_conn():
            ssh_mock.return_value.connect.assert_called_once_with(
                hostname='remote_host',
                username='username',
                password='password',
                key_filename='fake.file',
                timeout=20,
                compress=True,
                port='port',
                sock=None,
                look_for_keys=True,
            )

    @mock.patch('airflow.providers.ssh.hooks.ssh.paramiko.SSHClient')
    def test_ssh_connection_with_timeout_extra(self, ssh_mock):
        hook = SSHHook(
            ssh_conn_id=self.CONN_SSH_WITH_TIMEOUT_EXTRA,
            remote_host='remote_host',
            port='port',
            username='username',
            timeout=10,
        )

        with hook.get_conn():
            ssh_mock.return_value.connect.assert_called_once_with(
                hostname='remote_host',
                username='username',
                timeout=20,
                compress=True,
                port='port',
                sock=None,
                look_for_keys=True,
            )

    @mock.patch('airflow.providers.ssh.hooks.ssh.paramiko.SSHClient')
    def test_ssh_connection_with_conn_timeout_extra(self, ssh_mock):
        hook = SSHHook(
            ssh_conn_id=self.CONN_SSH_WITH_CONN_TIMEOUT_EXTRA,
            remote_host='remote_host',
            port='port',
            username='username',
            timeout=10,
            conn_timeout=15,
        )

        # conn_timeout parameter wins over extra options
        with hook.get_conn():
            ssh_mock.return_value.connect.assert_called_once_with(
                hostname='remote_host',
                username='username',
                timeout=15,
                compress=True,
                port='port',
                sock=None,
                look_for_keys=True,
            )

    @mock.patch('airflow.providers.ssh.hooks.ssh.paramiko.SSHClient')
    def test_ssh_connection_with_timeout_extra_and_conn_timeout_extra(self, ssh_mock):
        hook = SSHHook(
            ssh_conn_id=self.CONN_SSH_WITH_TIMEOUT_AND_CONN_TIMEOUT_EXTRA,
            remote_host='remote_host',
            port='port',
            username='username',
            timeout=10,
            conn_timeout=15,
        )

        # conn_timeout parameter wins over extra options
        with hook.get_conn():
            ssh_mock.return_value.connect.assert_called_once_with(
                hostname='remote_host',
                username='username',
                timeout=15,
                compress=True,
                port='port',
                sock=None,
                look_for_keys=True,
            )

    @parameterized.expand(
        [
            (TEST_TIMEOUT, TEST_CONN_TIMEOUT, True, True, TEST_CONN_TIMEOUT),
            (TEST_TIMEOUT, TEST_CONN_TIMEOUT, True, False, TEST_CONN_TIMEOUT),
            (TEST_TIMEOUT, TEST_CONN_TIMEOUT, False, True, TEST_CONN_TIMEOUT),
            (TEST_TIMEOUT, TEST_CONN_TIMEOUT, False, False, TEST_CONN_TIMEOUT),
            (TEST_TIMEOUT, None, True, True, TEST_CONN_TIMEOUT),
            (TEST_TIMEOUT, None, True, False, TEST_TIMEOUT),
            (TEST_TIMEOUT, None, False, True, TEST_CONN_TIMEOUT),
            (TEST_TIMEOUT, None, False, False, TEST_TIMEOUT),
            (None, TEST_CONN_TIMEOUT, True, True, TEST_CONN_TIMEOUT),
            (None, TEST_CONN_TIMEOUT, True, False, TEST_CONN_TIMEOUT),
            (None, TEST_CONN_TIMEOUT, False, True, TEST_CONN_TIMEOUT),
            (None, TEST_CONN_TIMEOUT, False, False, TEST_CONN_TIMEOUT),
            (None, None, True, True, TEST_CONN_TIMEOUT),
            (None, None, True, False, TEST_TIMEOUT),
            (None, None, False, True, TEST_CONN_TIMEOUT),
            (None, None, False, False, 10),
        ]
    )
    @mock.patch('airflow.providers.ssh.hooks.ssh.paramiko.SSHClient')
    def test_ssh_connection_with_all_timeout_param_and_extra_combinations(
        self, timeout, conn_timeout, timeoutextra, conn_timeoutextra, expected_value, ssh_mock
    ):

        if timeoutextra and conn_timeoutextra:
            ssh_conn_id = self.CONN_SSH_WITH_TIMEOUT_AND_CONN_TIMEOUT_EXTRA
        elif timeoutextra and not conn_timeoutextra:
            ssh_conn_id = self.CONN_SSH_WITH_TIMEOUT_EXTRA
        elif not timeoutextra and conn_timeoutextra:
            ssh_conn_id = self.CONN_SSH_WITH_CONN_TIMEOUT_EXTRA
        else:
            ssh_conn_id = self.CONN_SSH_WITH_NO_EXTRA

        hook = SSHHook(
            ssh_conn_id=ssh_conn_id,
            remote_host='remote_host',
            port='port',
            username='username',
            timeout=timeout,
            conn_timeout=conn_timeout,
        )

        # conn_timeout parameter wins over extra options
        with hook.get_conn():
            ssh_mock.return_value.connect.assert_called_once_with(
                hostname='remote_host',
                username='username',
                timeout=expected_value,
                compress=True,
                port='port',
                sock=None,
                look_for_keys=True,
            )

    def test_openssh_private_key(self):
        # Paramiko behaves differently with OpenSSH generated keys to paramiko
        # generated keys, so we need a test one.
        # This has been generated specifically to put here, it is not otherwise in use
        TEST_OPENSSH_PRIVATE_KEY = ""-----BEGIN OPENSSH "" + textwrap.dedent(
            """"""\
        PRIVATE KEY-----
        b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAlwAAAAdzc2gtcn
        NhAAAAAwEAAQAAAIEAuPKIGPWtIpMDrXwMAvNKQlhQ1gXV/tKyufElw/n6hrr6lvtfGhwX
        DihHMsAF+8+KKWQjWgh0fttbIF3+3C56Ns8hgvgMQJT2nyWd7egwqn+LQa08uCEBEka3MO
        arKzj39P66EZ/KQDD29VErlVOd97dPhaR8pOZvzcHxtLbU6rMAAAIA3uBiZd7gYmUAAAAH
        c3NoLXJzYQAAAIEAuPKIGPWtIpMDrXwMAvNKQlhQ1gXV/tKyufElw/n6hrr6lvtfGhwXDi
        hHMsAF+8+KKWQjWgh0fttbIF3+3C56Ns8hgvgMQJT2nyWd7egwqn+LQa08uCEBEka3MOar
        Kzj39P66EZ/KQDD29VErlVOd97dPhaR8pOZvzcHxtLbU6rMAAAADAQABAAAAgA2QC5b4/T
        dZ3J0uSZs1yC5RV6w6RVUokl68Zm6WuF6E+7dyu6iogrBRF9eK6WVr9M/QPh9uG0zqPSaE
        fhobdm7KeycXmtDtrJnXE2ZSk4oU29++TvYZBrAqAli9aHlSArwiLnOIMzY/kIHoSJLJmd
        jwXykdQ7QAd93KPEnkaMzBAAAAQGTyp6/wWqtqpMmYJ5prCGNtpVOGthW5upeiuQUytE/K
        5pyPoq6dUCUxQpkprtkuNAv/ff9nW6yy1v2DWohKfaEAAABBAO3y+erRXmiMreMOAd1S84
        RK2E/LUHOvClQqf6GnVavmIgkxIYEgjcFiWv4xIkTc1/FN6aX5aT4MB3srvuM7sxEAAABB
        AMb6QAkvxo4hT/xKY0E0nG7zCUMXeBV35MEXQK0/InFC7aZ0tjzFsQJzLe/7q7ljIf+9/O
        rCqNhxgOrv7XrRuYMAAAAKYXNoQHNpbm9wZQE=
        -----END OPENSSH PRIVATE KEY-----
        """"""
        )

        session = settings.Session()
        try:
            conn = Connection(
                conn_id='openssh_pkey',
                host='localhost',
                conn_type='ssh',
                extra={""private_key"": TEST_OPENSSH_PRIVATE_KEY},
            )
            session.add(conn)
            session.flush()
            hook = SSHHook(ssh_conn_id=conn.conn_id)
            assert isinstance(hook.pkey, paramiko.RSAKey)
        finally:
            session.delete(conn)
            session.commit()",1,587 2000 40 2001 46 2002 41 58 2003 61 362 2004 61 362 2005 61 362 2006 61 362 2007 61 362 2008 61 362 2009 61 362 2010 61 362 2011 61 362 2012 61 362 2013 61 362 2014 61 362 2015 61 362 2016 61 362 64 588 612 2017 40 2018 41 354 470 58 871 2019 40 41 552 2020 58 2021 61 91 2018 46 2003 44 2018 46 2004 44 2018 46 2006 44 2018 46 2005 44 2018 46 2007 44 2018 46 2008 44 2018 46 2009 44 2018 46 2010 44 2018 46 2012 44 2018 46 2013 44 2018 46 2014 44 2018 46 2015 44 2018 46 2016 44 93 2022 61 2020 46 2023 40 2024 41 46 656 40 2024 46 2025 46 2026 40 2021 41 41 2022 46 2027 40 2028 61 443 41 2020 46 2029 40 41 64 588 612 2030 40 2018 41 354 470 58 2031 46 2032 40 2024 40 2025 61 2018 46 2003 44 2033 61 362 44 2034 61 362 44 2035 61 470 44 41 41 2031 46 2032 40 2024 40 2025 61 2018 46 2010 44 2033 61 362 44 2034 61 362 44 2035 61 362 44 41 41 2031 46 2032 40 2024 40 2025 61 2018 46 2011 44 2033 61 362 44 2034 61 362 44 2035 61 362 362 44 41 41 2031 46 2032 40 2024 40 2025 61 2018 46 2004 44 2033 61 362 44 2034 61 362 44 2035 61 2036 46 2037 40 123 362 58 2038 125 41 44 41 41 2031 46 2032 40 2024 40 2025 61 2018 46 2006 44 2033 61 362 44 2034 61 362 44 2035 61 2036 46 2037 40 123 362 58 2039 44 362 58 2040 125 41 44 41 41 2031 46 2032 40 2024 40 2025 61 2018 46 2005 44 2033 61 362 44 2034 61 362 44 2035 61 2036 46 2037 40 123 362 58 2041 125 41 44 41 41 2031 46 2032 40 2024 40 2025 61 2018 46 2007 44 2033 61 362 44 2034 61 362 44 2035 61 2036 46 2037 40 123 362 58 2042 125 41 44 41 41 2031 46 2032 40 2024 40 2025 61 2018 46 2008 44 2033 61 362 44 2034 61 362 44 2035 61 2036 46 2037 40 123 362 58 2043 125 41 44 41 41 2031 46 2032 40 2024 40 2025 61 2018 46 2009 44 2033 61 362 44 2034 61 362 44 2035 61 2036 46 2037 40 123 362 58 2043 44 362 58 2042 125 41 44 41 41 2031 46 2032 40 2024 40 2025 61 2018 46 2012 44 2033 61 362 44 2034 61 362 44 2035 61 2036 46 2037 40 123 362 58 2038 44 362 58 2044 125 41 44 41 41 2031 46 2032 40 2024 40 2025 61 2018 46 2013 44 2033 61 362 44 2034 61 362 44 2035 61 2036 46 2037 40 123 362 58 2038 44 362 58 362 43 2044 125 41 44 41 41 2031 46 2032 40 2024 40 2025 61 2018 46 2014 44 2033 61 362 44 2034 61 362 44 2035 61 2036 46 2037 40 123 362 58 2038 44 362 58 2044 44 362 58 443 125 41 44 41 41 2031 46 2032 40 2024 40 2025 61 2018 46 2015 44 2033 61 362 44 2034 61 362 44 2035 61 2036 46 2037 40 123 362 58 2038 44 362 58 2044 44 362 58 515 125 41 44 41 41 2031 46 2032 40 2024 40 2025 61 2018 46 2016 44 2033 61 362 44 2034 61 362 44 2035 61 2036 46 2037 40 123 362 58 2038 44 362 58 443 125 41 44 41 41 64 2045 46 2046 40 362 41 612 2047 40 2048 44 2049 41 58 2050 61 2051 40 2052 61 362 44 2053 61 362 44 2054 61 362 44 2055 61 362 44 2056 61 1502 44 2057 61 362 44 41 871 2050 46 2058 40 41 58 2049 46 2059 46 2060 46 2061 40 2062 61 362 44 2054 61 362 44 2055 61 362 44 2063 61 362 44 2056 61 1502 44 2064 61 515 44 2053 61 362 44 2065 61 470 44 2066 61 515 44 41 64 2045 46 2046 40 362 41 612 2067 40 2048 44 2049 41 58 2050 61 2051 40 2052 61 362 44 2053 61 362 44 2054 61 362 44 2056 61 1502 44 2057 61 362 41 871 2050 46 2058 40 41 58 2049 46 2059 46 2060 46 2061 40 2062 61 362 44 2054 61 362 44 2063 61 362 44 2056 61 1502 44 2064 61 515 44 2053 61 362 44 2065 61 470 44 2066 61 515 44 41 64 2045 46 2046 40 362 41 612 2068 40 2048 44 2049 41 58 2050 61 2051 40 2052 61 362 44 2053 61 362 44 2054 61 362 44 2055 61 362 44 2056 61 1502 44 2057 61 362 44 41 871 2050 46 2069 40 1505 41 58 2049 46 2061 40 362 44 2070 61 362 44 2071 61 362 44 2072 61 362 44 2073 61 362 44 2074 61 470 44 2075 61 40 362 44 41 44 2076 61 40 362 44 1505 41 44 2077 61 2050 46 2078 44 41 64 2045 46 2046 40 362 41 612 2079 40 2048 44 2049 41 58 2050 61 2051 40 2052 61 362 44 2053 61 362 44 2054 61 362 44 2056 61 1502 44 2057 61 362 41 871 2050 46 2069 40 1505 41 58 2049 46 2061 40 362 44 2070 61 362 44 2071 61 362 44 2073 61 362 44 2074 61 470 44 2075 61 40 362 44 41 44 2076 61 40 362 44 1505 41 44 2080 61 470 44 2077 61 2050 46 2078 44 41 612 2081 40 2048 41 58 2082 61 2051 40 2083 61 2048 46 2010 41 555 2082 46 2064 712 515 555 2082 46 2084 712 515 555 2082 46 2085 712 443 555 2082 46 2066 712 515 612 2086 40 2048 41 58 2082 61 2051 40 2083 61 2048 46 2011 41 555 2082 46 2066 712 443 64 2045 46 2046 40 362 41 612 2087 40 2048 44 2049 41 58 2050 61 2051 40 2083 61 2048 46 2004 44 2052 61 362 44 2053 61 362 44 2054 61 362 44 2056 61 1502 44 41 871 2050 46 2069 40 1505 41 58 2049 46 2061 40 362 44 2070 61 362 44 2071 61 362 44 2073 61 2088 44 2074 61 470 44 2075 61 40 362 44 41 44 2076 61 40 362 44 1505 41 44 2080 61 470 44 2077 61 2050 46 2078 44 41 64 2045 46 2046 40 362 41 612 2089 40 2048 44 2049 41 58 2050 61 2051 40 2083 61 2048 46 2006 44 2052 61 362 44 2053 61 362 44 2054 61 362 44 2056 61 1502 44 41 871 2050 46 2069 40 1505 41 58 2049 46 2061 40 362 44 2070 61 362 44 2071 61 362 44 2073 61 2088 44 2074 61 470 44 2075 61 40 362 44 41 44 2076 61 40 362 44 1505 41 44 2080 61 470 44 2077 61 2050 46 2078 44 41 64 2045 46 2046 40 362 41 612 2090 40 2048 44 2049 41 58 2050 61 2051 40 2083 61 2048 46 2005 44 2052 61 362 44 2053 61 362 44 2054 61 362 44 2056 61 1502 44 41 871 2050 46 2069 40 1505 41 58 2049 46 2061 40 362 44 2070 61 362 44 2071 61 362 44 2073 61 2091 44 2074 61 470 44 2075 61 40 362 44 41 44 2076 61 40 362 44 1505 41 44 2080 61 470 44 2077 61 2050 46 2078 44 41 612 2092 40 2048 41 58 2050 61 2051 40 2083 61 362 41 871 2050 46 2058 40 41 552 2093 58 40 2094 44 2095 44 2094 41 61 2093 46 2096 40 362 41 555 2095 46 2097 40 41 712 750 470 612 2098 40 2048 41 58 2050 61 2051 40 2052 61 362 41 555 2050 46 2083 712 470 871 2050 46 2058 40 41 552 2093 58 40 2094 44 2095 44 2094 41 61 2093 46 2096 40 362 41 555 2095 46 2097 40 41 712 750 470 612 2099 40 2048 41 58 871 2051 40 2083 61 362 41 552 2050 58 2093 61 2050 46 2058 40 41 40 2094 44 2095 44 2094 41 61 2093 46 2096 40 362 41 555 2095 46 2097 40 41 712 750 470 612 2100 40 2048 41 58 2050 61 2051 40 2083 61 362 41 695 2101 695 2102 2103 61 620 40 2104 61 91 362 44 362 44 2105 93 44 2095 61 2102 46 2106 44 41 871 2102 46 2107 40 350 2103 41 552 2108 44 2050 46 2069 40 2109 61 1505 44 2110 61 1505 41 58 2111 61 2108 46 2095 46 2097 40 1502 41 555 362 323 2111 2101 61 2101 46 2101 40 41 2101 46 2060 40 40 362 44 1505 41 41 2112 61 2101 46 2113 40 1502 41 555 2112 323 362 2101 46 2114 40 41 2108 46 2115 40 41 555 2108 46 2116 323 1500 64 2045 46 2046 40 362 41 612 2117 40 2048 44 2049 41 58 2050 61 2051 40 2083 61 2048 46 2004 44 2052 61 362 44 2053 61 362 44 2054 61 362 44 2056 61 1502 44 41 871 2050 46 2058 40 41 58 2049 46 2059 46 2060 46 2061 40 2062 61 362 44 2054 61 362 44 2118 61 2088 44 2056 61 1502 44 2064 61 515 44 2053 61 362 44 2065 61 470 44 2066 61 515 44 41 64 2045 46 2046 40 362 41 612 2119 40 2048 44 2049 41 58 2050 61 2051 40 2083 61 2048 46 2006 44 2052 61 362 44 2053 61 362 44 2054 61 362 44 2056 61 1502 44 41 871 2050 46 2058 40 41 58 2049 46 2059 46 2060 46 2061 40 2062 61 362 44 2054 61 362 44 2118 61 2088 44 2056 61 1502 44 2064 61 515 44 2053 61 362 44 2065 61 470 44 2066 61 515 44 41 64 2045 46 2046 40 362 41 612 2120 40 2048 44 2121 41 58 2050 61 2051 40 2083 61 2048 46 2012 41 555 2050 46 2122 712 750 470 871 2050 46 2058 40 41 58 555 2121 46 2059 46 2060 46 2123 712 515 555 2121 46 2059 46 2124 46 2059 46 2125 46 2123 555 2121 46 2059 46 2124 46 2059 46 2125 46 2126 323 2045 46 2127 40 2050 46 2052 44 362 44 2050 46 2122 41 64 2045 46 2046 40 362 41 612 2128 40 2048 44 2121 41 58 2050 61 2051 40 2083 61 2048 46 2013 41 555 2050 46 2122 712 750 470 871 2050 46 2058 40 41 58 555 2121 46 2059 46 2060 46 2123 712 515 555 2121 46 2059 46 2124 46 2059 46 2125 46 2123 555 2121 46 2059 46 2124 46 2059 46 2125 46 2126 323 2045 46 2127 40 2050 46 2052 44 362 44 2050 46 2122 41 64 2045 46 2046 40 362 41 612 2129 40 2048 44 2121 41 58 2050 61 2051 40 2083 61 2048 46 2016 41 555 2050 46 2122 712 470 871 2050 46 2058 40 41 58 555 2121 46 2059 46 2060 46 2123 712 515 555 2121 46 2059 46 2124 46 2059 46 2125 46 2123 712 443 64 2045 46 2046 40 362 41 612 2130 40 2048 44 2049 41 58 2050 61 2051 40 2052 61 362 44 2053 61 362 44 2054 61 362 44 2055 61 362 44 2131 61 1503 44 2057 61 362 44 41 871 2050 46 2058 40 41 58 2049 46 2059 46 2060 46 2061 40 2062 61 362 44 2054 61 362 44 2055 61 362 44 2063 61 362 44 2056 61 1503 44 2064 61 515 44 2053 61 362 44 2065 61 470 44 2066 61 515 44 41 64 2045 46 2046 40 362 41 612 2132 40 2048 44 2049 41 58 2050 61 2051 40 2052 61 362 44 2053 61 362 44 2054 61 362 44 2055 61 362 44 2056 61 1502 44 2131 61 1503 44 2057 61 362 44 41 871 2050 46 2058 40 41 58 2049 46 2059 46 2060 46 2061 40 2062 61 362 44 2054 61 362 44 2055 61 362 44 2063 61 362 44 2056 61 1503 44 2064 61 515 44 2053 61 362 44 2065 61 470 44 2066 61 515 44 41 64 2045 46 2046 40 362 41 612 2133 40 2048 44 2049 41 58 2050 61 2051 40 2083 61 2048 46 2007 44 2052 61 362 44 2053 61 362 44 2054 61 362 44 2056 61 1502 44 41 871 2050 46 2058 40 41 58 2049 46 2059 46 2060 46 2061 40 2062 61 362 44 2054 61 362 44 2056 61 1503 44 2064 61 515 44 2053 61 362 44 2065 61 470 44 2066 61 515 44 41 64 2045 46 2046 40 362 41 612 2134 40 2048 44 2049 41 58 2050 61 2051 40 2083 61 2048 46 2008 44 2052 61 362 44 2053 61 362 44 2054 61 362 44 2056 61 1502 44 2131 61 1503 44 41 330 871 2050 46 2058 40 41 58 2049 46 2059 46 2060 46 2061 40 2062 61 362 44 2054 61 362 44 2056 61 1503 44 2064 61 515 44 2053 61 362 44 2065 61 470 44 2066 61 515 44 41 64 2045 46 2046 40 362 41 612 2135 40 2048 44 2049 41 58 2050 61 2051 40 2083 61 2048 46 2009 44 2052 61 362 44 2053 61 362 44 2054 61 362 44 2056 61 1502 44 2131 61 1503 44 41 330 871 2050 46 2058 40 41 58 2049 46 2059 46 2060 46 2061 40 2062 61 362 44 2054 61 362 44 2056 61 1503 44 2064 61 515 44 2053 61 362 44 2065 61 470 44 2066 61 515 44 41 64 2136 46 2137 40 91 40 2042 44 2043 44 515 44 515 44 2043 41 44 40 2042 44 2043 44 515 44 443 44 2043 41 44 40 2042 44 2043 44 443 44 515 44 2043 41 44 40 2042 44 2043 44 443 44 443 44 2043 41 44 40 2042 44 470 44 515 44 515 44 2043 41 44 40 2042 44 470 44 515 44 443 44 2042 41 44 40 2042 44 470 44 443 44 515 44 2043 41 44 40 2042 44 470 44 443 44 443 44 2042 41 44 40 470 44 2043 44 515 44 515 44 2043 41 44 40 470 44 2043 44 515 44 443 44 2043 41 44 40 470 44 2043 44 443 44 515 44 2043 41 44 40 470 44 2043 44 443 44 443 44 2043 41 44 40 470 44 470 44 515 44 515 44 2043 41 44 40 470 44 470 44 515 44 443 44 2042 41 44 40 470 44 470 44 443 44 515 44 2043 41 44 40 470 44 470 44 443 44 443 44 1502 41 44 93 41 64 2045 46 2046 40 362 41 612 2138 40 2048 44 2056 44 2131 44 2139 44 2140 44 2141 44 2049 41 58 688 2139 545 2140 58 2083 61 2048 46 2009 629 2139 545 750 2140 58 2083 61 2048 46 2007 629 750 2139 545 2140 58 2083 61 2048 46 2008 630 58 2083 61 2048 46 2003 2050 61 2051 40 2083 61 2083 44 2052 61 362 44 2053 61 362 44 2054 61 362 44 2056 61 2056 44 2131 61 2131 44 41 330 871 2050 46 2058 40 41 58 2049 46 2059 46 2060 46 2061 40 2062 61 362 44 2054 61 362 44 2056 61 2141 44 2064 61 515 44 2053 61 362 44 2065 61 470 44 2066 61 515 44 41 612 2142 40 2048 41 58 330 330 330 2143 61 362 43 2144 46 2145 40 362 41 2020 61 2146 46 2147 40 41 830 58 2148 61 2024 40 2025 61 362 44 2033 61 362 44 2034 61 362 44 2035 61 123 362 58 2143 125 44 41 2020 46 2125 40 2148 41 2020 46 2149 40 41 2050 61 2051 40 2083 61 2148 46 2025 41 555 713 40 2050 46 2118 44 2150 46 2151 41 658 58 2020 46 2027 40 2148 41 2020 46 2029 40 41 ,"{'AvgLine': 21, 'CountLine': 652, 'CountStmt': 172, 'MaxNesting': 1, 'AvgLineCode': 20, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 142, 'MaxEssential': 1, 'SumEssential': 27, 'AvgCyclomatic': 1, 'CountLineCode': 599, 'CountStmtDecl': 81, 'MaxCyclomatic': 4, 'SumCyclomatic': 30, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 47, 'CountDeclMethod': 27, 'CountLineCodeExe': 527, 'CountLineComment': 6, 'CountClassCoupled': 3, 'CountClassDerived': 0, 'CountLineCodeDecl': 127, 'CountDeclMethodAll': 27, 'MaxInheritanceTree': 1, 'RatioCommentToCode': '0.01', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 7, 'SumCyclomaticStrict': 33, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 4, 'SumCyclomaticModified': 30, 'CountDeclInstanceMethod': 25, 'CountClassCoupledModified': 2, 'CountDeclInstanceVariable': 0}"
125659,Python,"class TestKubernetesPodOperatorSystem(unittest.TestCase):
    def get_current_task_name(self):
        # reverse test name to make pod name unique (it has limited length)
        return ""_"" + unittest.TestCase.id(self).replace(""."", ""_"")[::-1]

    def setUp(self):
        self.maxDiff = None
        self.api_client = ApiClient()
        self.expected_pod = {
            'apiVersion': 'v1',
            'kind': 'Pod',
            'metadata': {
                'namespace': 'default',
                'name': ANY,
                'annotations': {},
                'labels': {
                    'foo': 'bar',
                    'kubernetes_pod_operator': 'True',
                    'airflow_version': airflow_version.replace('+', '-'),
                    'execution_date': '2016-01-01T0100000100-a2f50a31f',
                    'dag_id': 'dag',
                    'task_id': ANY,
                    'try_number': '1',
                },
            },
            'spec': {
                'affinity': {},
                'containers': [
                    {
                        'image': 'ubuntu:16.04',
                        'args': [""echo 10""],
                        'command': [""bash"", ""-cx""],
                        'env': [],
                        'envFrom': [],
                        'resources': {},
                        'name': 'base',
                        'ports': [],
                        'volumeMounts': [],
                    }
                ],
                'hostNetwork': False,
                'imagePullSecrets': [],
                'initContainers': [],
                'nodeSelector': {},
                'restartPolicy': 'Never',
                'securityContext': {},
                'tolerations': [],
                'volumes': [],
            },
        }

    def tearDown(self) -> None:
        client = kube_client.get_kube_client(in_cluster=False)
        client.delete_collection_namespaced_pod(namespace=""default"")
        import time

        time.sleep(1)

    def test_do_xcom_push_defaults_false(self):
        new_config_path = '/tmp/kube_config'
        old_config_path = get_kubeconfig_path()
        shutil.copy(old_config_path, new_config_path)

        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
            config_file=new_config_path,
        )
        assert not k.do_xcom_push

    def test_config_path_move(self):
        new_config_path = '/tmp/kube_config'
        old_config_path = get_kubeconfig_path()
        shutil.copy(old_config_path, new_config_path)

        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test1"",
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
            config_file=new_config_path,
        )
        context = create_context(k)
        k.execute(context)
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        assert self.expected_pod == actual_pod

    def test_working_pod(self):
        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
        )
        context = create_context(k)
        k.execute(context)
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        assert self.expected_pod['spec'] == actual_pod['spec']
        assert self.expected_pod['metadata']['labels'] == actual_pod['metadata']['labels']

    def test_delete_operator_pod(self):
        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
            is_delete_operator_pod=True,
        )
        context = create_context(k)
        k.execute(context)
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        assert self.expected_pod['spec'] == actual_pod['spec']
        assert self.expected_pod['metadata']['labels'] == actual_pod['metadata']['labels']

    def test_pod_hostnetwork(self):
        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
            hostnetwork=True,
        )
        context = create_context(k)
        k.execute(context)
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        self.expected_pod['spec']['hostNetwork'] = True
        assert self.expected_pod['spec'] == actual_pod['spec']
        assert self.expected_pod['metadata']['labels'] == actual_pod['metadata']['labels']

    def test_pod_dnspolicy(self):
        dns_policy = ""ClusterFirstWithHostNet""
        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
            hostnetwork=True,
            dnspolicy=dns_policy,
        )
        context = create_context(k)
        k.execute(context)
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        self.expected_pod['spec']['hostNetwork'] = True
        self.expected_pod['spec']['dnsPolicy'] = dns_policy
        assert self.expected_pod['spec'] == actual_pod['spec']
        assert self.expected_pod['metadata']['labels'] == actual_pod['metadata']['labels']

    def test_pod_schedulername(self):
        scheduler_name = ""default-scheduler""
        k = KubernetesPodOperator(
            namespace=""default"",
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
            schedulername=scheduler_name,
        )
        context = create_context(k)
        k.execute(context)
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        self.expected_pod['spec']['schedulerName'] = scheduler_name
        assert self.expected_pod == actual_pod

    def test_pod_node_selectors(self):
        node_selectors = {'beta.kubernetes.io/os': 'linux'}
        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
            node_selectors=node_selectors,
        )
        context = create_context(k)
        k.execute(context)
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        self.expected_pod['spec']['nodeSelector'] = node_selectors
        assert self.expected_pod == actual_pod

    def test_pod_resources(self):
        resources = k8s.V1ResourceRequirements(
            requests={'memory': '64Mi', 'cpu': '250m', 'ephemeral-storage': '1Gi'},
            limits={'memory': '64Mi', 'cpu': 0.25, 'nvidia.com/gpu': None, 'ephemeral-storage': '2Gi'},
        )
        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
            resources=resources,
        )
        context = create_context(k)
        k.execute(context)
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        self.expected_pod['spec']['containers'][0]['resources'] = {
            'requests': {'memory': '64Mi', 'cpu': '250m', 'ephemeral-storage': '1Gi'},
            'limits': {'memory': '64Mi', 'cpu': 0.25, 'nvidia.com/gpu': None, 'ephemeral-storage': '2Gi'},
        }
        assert self.expected_pod == actual_pod

    def test_pod_affinity(self):
        affinity = {
            'nodeAffinity': {
                'requiredDuringSchedulingIgnoredDuringExecution': {
                    'nodeSelectorTerms': [
                        {
                            'matchExpressions': [
                                {'key': 'beta.kubernetes.io/os', 'operator': 'In', 'values': ['linux']}
                            ]
                        }
                    ]
                }
            }
        }
        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
            affinity=affinity,
        )
        context = create_context(k)
        k.execute(context=context)
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        self.expected_pod['spec']['affinity'] = affinity
        assert self.expected_pod == actual_pod

    def test_port(self):
        port = k8s.V1ContainerPort(
            name='http',
            container_port=80,
        )

        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
            ports=[port],
        )
        context = create_context(k)
        k.execute(context=context)
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        self.expected_pod['spec']['containers'][0]['ports'] = [{'name': 'http', 'containerPort': 80}]
        assert self.expected_pod == actual_pod

    def test_volume_mount(self):
        with mock.patch.object(PodLauncher, 'log') as mock_logger:
            volume_mount = k8s.V1VolumeMount(
                name='test-volume', mount_path='/tmp/test_volume', sub_path=None, read_only=False
            )

            volume = k8s.V1Volume(
                name='test-volume',
                persistent_volume_claim=k8s.V1PersistentVolumeClaimVolumeSource(claim_name='test-volume'),
            )

            args = [
                ""echo \""retrieved from mount\"" > /tmp/test_volume/test.txt ""
                ""&& cat /tmp/test_volume/test.txt""
            ]
            k = KubernetesPodOperator(
                namespace='default',
                image=""ubuntu:16.04"",
                cmds=[""bash"", ""-cx""],
                arguments=args,
                labels={""foo"": ""bar""},
                volume_mounts=[volume_mount],
                volumes=[volume],
                name=""test-"" + str(random.randint(0, 1000000)),
                task_id=""task"" + self.get_current_task_name(),
                in_cluster=False,
                do_xcom_push=False,
            )
            context = create_context(k)
            k.execute(context=context)
            mock_logger.info.assert_any_call('retrieved from mount')
            actual_pod = self.api_client.sanitize_for_serialization(k.pod)
            self.expected_pod['spec']['containers'][0]['args'] = args
            self.expected_pod['spec']['containers'][0]['volumeMounts'] = [
                {'name': 'test-volume', 'mountPath': '/tmp/test_volume', 'readOnly': False}
            ]
            self.expected_pod['spec']['volumes'] = [
                {'name': 'test-volume', 'persistentVolumeClaim': {'claimName': 'test-volume'}}
            ]
            assert self.expected_pod == actual_pod

    def test_run_as_user_root(self):
        security_context = {
            'securityContext': {
                'runAsUser': 0,
            }
        }
        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
            security_context=security_context,
        )
        context = create_context(k)
        k.execute(context)
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        self.expected_pod['spec']['securityContext'] = security_context
        assert self.expected_pod == actual_pod

    def test_run_as_user_non_root(self):
        security_context = {
            'securityContext': {
                'runAsUser': 1000,
            }
        }

        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
            security_context=security_context,
        )
        context = create_context(k)
        k.execute(context)
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        self.expected_pod['spec']['securityContext'] = security_context
        assert self.expected_pod == actual_pod

    def test_fs_group(self):
        security_context = {
            'securityContext': {
                'fsGroup': 1000,
            }
        }

        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-fs-group"",
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
            security_context=security_context,
        )
        context = create_context(k)
        k.execute(context)
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        self.expected_pod['spec']['securityContext'] = security_context
        assert self.expected_pod == actual_pod

    def test_faulty_image(self):
        bad_image_name = ""foobar""
        k = KubernetesPodOperator(
            namespace='default',
            image=bad_image_name,
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
            startup_timeout_seconds=5,
        )
        with pytest.raises(AirflowException):
            context = create_context(k)
            k.execute(context)
            actual_pod = self.api_client.sanitize_for_serialization(k.pod)
            self.expected_pod['spec']['containers'][0]['image'] = bad_image_name
            assert self.expected_pod == actual_pod

    def test_faulty_service_account(self):
        bad_service_account_name = ""foobar""
        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
            startup_timeout_seconds=5,
            service_account_name=bad_service_account_name,
        )
        with pytest.raises(ApiException):
            context = create_context(k)
            k.execute(context)
            actual_pod = self.api_client.sanitize_for_serialization(k.pod)
            self.expected_pod['spec']['serviceAccountName'] = bad_service_account_name
            assert self.expected_pod == actual_pod

    def test_pod_failure(self):
        """"""
        Tests that the task fails when a pod reports a failure
        """"""
        bad_internal_command = [""foobar 10 ""]
        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=bad_internal_command,
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
        )
        with pytest.raises(AirflowException):
            context = create_context(k)
            k.execute(context)
            actual_pod = self.api_client.sanitize_for_serialization(k.pod)
            self.expected_pod['spec']['containers'][0]['args'] = bad_internal_command
            assert self.expected_pod == actual_pod

    def test_xcom_push(self):
        return_value = '{""foo"": ""bar""\n, ""buzz"": 2}'
        args = [f'echo \'{return_value}\' > /airflow/xcom/return.json']
        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=args,
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=True,
        )
        context = create_context(k)
        assert k.execute(context) == json.loads(return_value)
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        volume = self.api_client.sanitize_for_serialization(PodDefaults.VOLUME)
        volume_mount = self.api_client.sanitize_for_serialization(PodDefaults.VOLUME_MOUNT)
        container = self.api_client.sanitize_for_serialization(PodDefaults.SIDECAR_CONTAINER)
        self.expected_pod['spec']['containers'][0]['args'] = args
        self.expected_pod['spec']['containers'][0]['volumeMounts'].insert(0, volume_mount)
        self.expected_pod['spec']['volumes'].insert(0, volume)
        self.expected_pod['spec']['containers'].append(container)
        assert self.expected_pod == actual_pod

    @mock.patch(""airflow.providers.cncf.kubernetes.utils.pod_launcher.PodLauncher.start_pod"")
    @mock.patch(""airflow.providers.cncf.kubernetes.utils.pod_launcher.PodLauncher.monitor_pod"")
    @mock.patch(""airflow.kubernetes.kube_client.get_kube_client"")
    def test_envs_from_secrets(self, mock_client, monitor_mock, start_mock):
        # GIVEN
        from airflow.utils.state import State

        secret_ref = 'secret_name'
        secrets = [Secret('env', None, secret_ref)]
        # WHEN
        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            secrets=secrets,
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
        )
        # THEN
        monitor_mock.return_value = (State.SUCCESS, None, None)
        context = create_context(k)
        k.execute(context)
        assert start_mock.call_args[0][0].spec.containers[0].env_from == [
            k8s.V1EnvFromSource(secret_ref=k8s.V1SecretEnvSource(name=secret_ref))
        ]

    def test_env_vars(self):
        # WHEN
        env_vars = [
            k8s.V1EnvVar(name=""ENV1"", value=""val1""),
            k8s.V1EnvVar(name=""ENV2"", value=""val2""),
            k8s.V1EnvVar(
                name=""ENV3"",
                value_from=k8s.V1EnvVarSource(field_ref=k8s.V1ObjectFieldSelector(field_path=""status.podIP"")),
            ),
        ]

        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            env_vars=env_vars,
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
        )

        context = create_context(k)
        k.execute(context)

        # THEN
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        self.expected_pod['spec']['containers'][0]['env'] = [
            {'name': 'ENV1', 'value': 'val1'},
            {'name': 'ENV2', 'value': 'val2'},
            {'name': 'ENV3', 'valueFrom': {'fieldRef': {'fieldPath': 'status.podIP'}}},
        ]
        assert self.expected_pod == actual_pod

    def test_pod_template_file_system(self):
        fixture = sys.path[0] + '/tests/kubernetes/basic_pod.yaml'
        k = KubernetesPodOperator(
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            pod_template_file=fixture,
            do_xcom_push=True,
        )

        context = create_context(k)
        result = k.execute(context)
        assert result is not None
        assert result == {""hello"": ""world""}

    def test_pod_template_file_with_overrides_system(self):
        fixture = sys.path[0] + '/tests/kubernetes/basic_pod.yaml'
        k = KubernetesPodOperator(
            task_id=""task"" + self.get_current_task_name(),
            labels={""foo"": ""bar"", ""fizz"": ""buzz""},
            env_vars=[k8s.V1EnvVar(name=""env_name"", value=""value"")],
            in_cluster=False,
            pod_template_file=fixture,
            do_xcom_push=True,
        )

        context = create_context(k)
        result = k.execute(context)
        assert result is not None
        assert k.pod.metadata.labels == {
            'fizz': 'buzz',
            'foo': 'bar',
            'airflow_version': mock.ANY,
            'dag_id': 'dag',
            'execution_date': mock.ANY,
            'kubernetes_pod_operator': 'True',
            'task_id': mock.ANY,
            'try_number': '1',
        }
        assert k.pod.spec.containers[0].env == [k8s.V1EnvVar(name=""env_name"", value=""value"")]
        assert result == {""hello"": ""world""}

    def test_pod_template_file_with_full_pod_spec(self):
        fixture = sys.path[0] + '/tests/kubernetes/basic_pod.yaml'
        pod_spec = k8s.V1Pod(
            metadata=k8s.V1ObjectMeta(
                labels={""foo"": ""bar"", ""fizz"": ""buzz""},
            ),
            spec=k8s.V1PodSpec(
                containers=[
                    k8s.V1Container(
                        name=""base"",
                        env=[k8s.V1EnvVar(name=""env_name"", value=""value"")],
                    )
                ]
            ),
        )
        k = KubernetesPodOperator(
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            pod_template_file=fixture,
            full_pod_spec=pod_spec,
            do_xcom_push=True,
        )

        context = create_context(k)
        result = k.execute(context)
        assert result is not None
        assert k.pod.metadata.labels == {
            'fizz': 'buzz',
            'foo': 'bar',
            'airflow_version': mock.ANY,
            'dag_id': 'dag',
            'execution_date': mock.ANY,
            'kubernetes_pod_operator': 'True',
            'task_id': mock.ANY,
            'try_number': '1',
        }
        assert k.pod.spec.containers[0].env == [k8s.V1EnvVar(name=""env_name"", value=""value"")]
        assert result == {""hello"": ""world""}

    def test_full_pod_spec(self):
        pod_spec = k8s.V1Pod(
            metadata=k8s.V1ObjectMeta(
                labels={""foo"": ""bar"", ""fizz"": ""buzz""}, namespace=""default"", name=""test-pod""
            ),
            spec=k8s.V1PodSpec(
                containers=[
                    k8s.V1Container(
                        name=""base"",
                        image=""perl"",
                        command=[""/bin/bash""],
                        args=[""-c"", 'echo {\\""hello\\"" : \\""world\\""} | cat > /airflow/xcom/return.json'],
                        env=[k8s.V1EnvVar(name=""env_name"", value=""value"")],
                    )
                ],
                restart_policy=""Never"",
            ),
        )
        k = KubernetesPodOperator(
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            full_pod_spec=pod_spec,
            do_xcom_push=True,
        )

        context = create_context(k)
        result = k.execute(context)
        assert result is not None
        assert k.pod.metadata.labels == {
            'fizz': 'buzz',
            'foo': 'bar',
            'airflow_version': mock.ANY,
            'dag_id': 'dag',
            'execution_date': mock.ANY,
            'kubernetes_pod_operator': 'True',
            'task_id': mock.ANY,
            'try_number': '1',
        }
        assert k.pod.spec.containers[0].env == [k8s.V1EnvVar(name=""env_name"", value=""value"")]
        assert result == {""hello"": ""world""}

    def test_init_container(self):
        # GIVEN
        volume_mounts = [
            k8s.V1VolumeMount(mount_path='/etc/foo', name='test-volume', sub_path=None, read_only=True)
        ]

        init_environments = [
            k8s.V1EnvVar(name='key1', value='value1'),
            k8s.V1EnvVar(name='key2', value='value2'),
        ]

        init_container = k8s.V1Container(
            name=""init-container"",
            image=""ubuntu:16.04"",
            env=init_environments,
            volume_mounts=volume_mounts,
            command=[""bash"", ""-cx""],
            args=[""echo 10""],
        )

        volume = k8s.V1Volume(
            name='test-volume',
            persistent_volume_claim=k8s.V1PersistentVolumeClaimVolumeSource(claim_name='test-volume'),
        )
        expected_init_container = {
            'name': 'init-container',
            'image': 'ubuntu:16.04',
            'command': ['bash', '-cx'],
            'args': ['echo 10'],
            'env': [{'name': 'key1', 'value': 'value1'}, {'name': 'key2', 'value': 'value2'}],
            'volumeMounts': [{'mountPath': '/etc/foo', 'name': 'test-volume', 'readOnly': True}],
        }

        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            volumes=[volume],
            init_containers=[init_container],
            in_cluster=False,
            do_xcom_push=False,
        )
        context = create_context(k)
        k.execute(context)
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        self.expected_pod['spec']['initContainers'] = [expected_init_container]
        self.expected_pod['spec']['volumes'] = [
            {'name': 'test-volume', 'persistentVolumeClaim': {'claimName': 'test-volume'}}
        ]
        assert self.expected_pod == actual_pod

    @mock.patch(""airflow.providers.cncf.kubernetes.utils.pod_launcher.PodLauncher.start_pod"")
    @mock.patch(""airflow.providers.cncf.kubernetes.utils.pod_launcher.PodLauncher.monitor_pod"")
    @mock.patch(""airflow.kubernetes.kube_client.get_kube_client"")
    def test_pod_template_file(self, mock_client, monitor_mock, start_mock):
        from airflow.utils.state import State

        path = sys.path[0] + '/tests/kubernetes/pod.yaml'
        k = KubernetesPodOperator(
            task_id=""task"" + self.get_current_task_name(),
            random_name_suffix=False,
            pod_template_file=path,
            do_xcom_push=True,
        )

        monitor_mock.return_value = (State.SUCCESS, None, None)
        context = create_context(k)
        with self.assertLogs(k.log, level=logging.DEBUG) as cm:
            k.execute(context)
            expected_line = textwrap.dedent(
                """"""\
            DEBUG:airflow.task.operators:Starting pod:
            api_version: v1
            kind: Pod
            metadata:
              annotations: {}
              cluster_name: null
              creation_timestamp: null
              deletion_grace_period_seconds: null\
            """"""
            ).strip()
            assert any(line.startswith(expected_line) for line in cm.output)

        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        expected_dict = {
            'apiVersion': 'v1',
            'kind': 'Pod',
            'metadata': {
                'annotations': {},
                'labels': {
                    'dag_id': 'dag',
                    'execution_date': mock.ANY,
                    'kubernetes_pod_operator': 'True',
                    'task_id': mock.ANY,
                    'try_number': '1',
                },
                'name': 'memory-demo',
                'namespace': 'mem-example',
            },
            'spec': {
                'affinity': {},
                'containers': [
                    {
                        'args': ['--vm', '1', '--vm-bytes', '150M', '--vm-hang', '1'],
                        'command': ['stress'],
                        'env': [],
                        'envFrom': [],
                        'image': 'ghcr.io/apache/airflow-stress:1.0.4-2021.07.04',
                        'name': 'base',
                        'ports': [],
                        'resources': {'limits': {'memory': '200Mi'}, 'requests': {'memory': '100Mi'}},
                        'volumeMounts': [{'mountPath': '/airflow/xcom', 'name': 'xcom'}],
                    },
                    {
                        'command': ['sh', '-c', 'trap ""exit 0"" INT; while true; do sleep 1; done;'],
                        'image': 'alpine',
                        'name': 'airflow-xcom-sidecar',
                        'resources': {'requests': {'cpu': '1m'}},
                        'volumeMounts': [{'mountPath': '/airflow/xcom', 'name': 'xcom'}],
                    },
                ],
                'hostNetwork': False,
                'imagePullSecrets': [],
                'initContainers': [],
                'nodeSelector': {},
                'restartPolicy': 'Never',
                'securityContext': {},
                'tolerations': [],
                'volumes': [{'emptyDir': {}, 'name': 'xcom'}],
            },
        }
        version = actual_pod['metadata']['labels']['airflow_version']
        assert version.startswith(airflow_version)
        del actual_pod['metadata']['labels']['airflow_version']
        assert expected_dict == actual_pod

    @mock.patch(""airflow.providers.cncf.kubernetes.utils.pod_launcher.PodLauncher.start_pod"")
    @mock.patch(""airflow.providers.cncf.kubernetes.utils.pod_launcher.PodLauncher.monitor_pod"")
    @mock.patch(""airflow.kubernetes.kube_client.get_kube_client"")
    def test_pod_priority_class_name(self, mock_client, monitor_mock, start_mock):
        """"""Test ability to assign priorityClassName to pod""""""
        from airflow.utils.state import State

        priority_class_name = ""medium-test""
        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""echo 10""],
            labels={""foo"": ""bar""},
            name=""test-"" + str(random.randint(0, 1000000)),
            task_id=""task"" + self.get_current_task_name(),
            in_cluster=False,
            do_xcom_push=False,
            priority_class_name=priority_class_name,
        )

        monitor_mock.return_value = (State.SUCCESS, None, None)
        context = create_context(k)
        k.execute(context)
        actual_pod = self.api_client.sanitize_for_serialization(k.pod)
        self.expected_pod['spec']['priorityClassName'] = priority_class_name
        assert self.expected_pod == actual_pod

    def test_pod_name(self):
        pod_name_too_long = ""a"" * 221
        with pytest.raises(AirflowException):
            KubernetesPodOperator(
                namespace='default',
                image=""ubuntu:16.04"",
                cmds=[""bash"", ""-cx""],
                arguments=[""echo 10""],
                labels={""foo"": ""bar""},
                name=pod_name_too_long,
                task_id=""task"" + self.get_current_task_name(),
                in_cluster=False,
                do_xcom_push=False,
            )

    @mock.patch(""airflow.providers.cncf.kubernetes.utils.pod_launcher.PodLauncher.monitor_pod"")
    def test_on_kill(self, monitor_mock):
        from airflow.utils.state import State

        client = kube_client.get_kube_client(in_cluster=False)
        name = ""test""
        namespace = ""default""
        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""sleep 1000""],
            labels={""foo"": ""bar""},
            name=""test"",
            task_id=name,
            in_cluster=False,
            do_xcom_push=False,
            termination_grace_period=0,
        )
        context = create_context(k)
        monitor_mock.return_value = (State.SUCCESS, None, None)
        k.execute(context)
        name = k.pod.metadata.name
        pod = client.read_namespaced_pod(name=name, namespace=namespace)
        assert pod.status.phase == ""Running""
        k.on_kill()
        with pytest.raises(ApiException):
            pod = client.read_namespaced_pod(name=name, namespace=namespace)

    def test_reattach_failing_pod_once(self):
        from airflow.utils.state import State

        client = kube_client.get_kube_client(in_cluster=False)
        name = ""test""
        namespace = ""default""
        k = KubernetesPodOperator(
            namespace='default',
            image=""ubuntu:16.04"",
            cmds=[""bash"", ""-cx""],
            arguments=[""exit 1""],
            labels={""foo"": ""bar""},
            name=""test"",
            task_id=name,
            in_cluster=False,
            do_xcom_push=False,
            is_delete_operator_pod=False,
            termination_grace_period=0,
        )

        context = create_context(k)

        with mock.patch(
            ""airflow.providers.cncf.kubernetes.utils.pod_launcher.PodLauncher.monitor_pod""
        ) as monitor_mock:
            monitor_mock.return_value = (State.SUCCESS, None, None)
            k.execute(context)
            name = k.pod.metadata.name
            pod = client.read_namespaced_pod(name=name, namespace=namespace)
            while pod.status.phase != ""Failed"":
                pod = client.read_namespaced_pod(name=name, namespace=namespace)
        with pytest.raises(AirflowException):
            k.execute(context)
        pod = client.read_namespaced_pod(name=name, namespace=namespace)
        assert pod.metadata.labels[""already_checked""] == ""True""
        with mock.patch(
            ""airflow.providers.cncf.kubernetes""
            "".operators.kubernetes_pod.KubernetesPodOperator""
            "".create_new_pod_for_operator""
        ) as create_mock:
            create_mock.return_value = (""success"", {}, {})
            k.execute(context)
            create_mock.assert_called_once()",1,587 2000 40 2001 46 2002 41 58 612 2003 40 2004 41 58 330 792 362 43 2001 46 2002 46 687 40 2004 41 46 2005 40 362 44 362 41 91 58 58 45 1501 93 612 2006 40 2004 41 58 2004 46 2007 61 470 2004 46 2008 61 2009 40 41 2004 46 2010 61 123 362 58 362 44 362 58 362 44 362 58 123 362 58 362 44 362 58 2011 44 362 58 123 125 44 362 58 123 362 58 362 44 362 58 362 44 362 58 2012 46 2005 40 362 44 362 41 44 362 58 362 44 362 58 362 44 362 58 2011 44 362 58 362 44 125 44 125 44 362 58 123 362 58 123 125 44 362 58 91 123 362 58 362 44 362 58 91 362 93 44 362 58 91 362 44 362 93 44 362 58 91 93 44 362 58 91 93 44 362 58 123 125 44 362 58 362 44 362 58 91 93 44 362 58 91 93 44 125 93 44 362 58 443 44 362 58 91 93 44 362 58 91 93 44 362 58 123 125 44 362 58 362 44 362 58 123 125 44 362 58 91 93 44 362 58 91 93 44 125 44 125 612 2013 40 2004 41 354 470 58 2014 61 2015 46 2016 40 2017 61 443 41 2014 46 2018 40 2019 61 362 41 695 2020 2020 46 2021 40 1501 41 612 2022 40 2004 41 58 2023 61 362 2024 61 2025 40 41 2026 46 2027 40 2024 44 2023 41 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 2039 61 2023 44 41 555 750 2028 46 2038 612 2040 40 2004 41 58 2023 61 362 2024 61 2025 40 41 2026 46 2027 40 2024 44 2023 41 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 2039 61 2023 44 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 555 2004 46 2010 323 2044 612 2047 40 2004 41 58 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 555 2004 46 2010 91 362 93 323 2044 91 362 93 555 2004 46 2010 91 362 93 91 362 93 323 2044 91 362 93 91 362 93 612 2048 40 2004 41 58 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 2049 61 515 44 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 555 2004 46 2010 91 362 93 323 2044 91 362 93 555 2004 46 2010 91 362 93 91 362 93 323 2044 91 362 93 91 362 93 612 2050 40 2004 41 58 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 2051 61 515 44 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 61 515 555 2004 46 2010 91 362 93 323 2044 91 362 93 555 2004 46 2010 91 362 93 91 362 93 323 2044 91 362 93 91 362 93 612 2052 40 2004 41 58 2053 61 362 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 2051 61 515 44 2054 61 2053 44 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 61 515 2004 46 2010 91 362 93 91 362 93 61 2053 555 2004 46 2010 91 362 93 323 2044 91 362 93 555 2004 46 2010 91 362 93 91 362 93 323 2044 91 362 93 91 362 93 612 2055 40 2004 41 58 2056 61 362 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 2057 61 2056 44 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 61 2056 555 2004 46 2010 323 2044 612 2058 40 2004 41 58 2059 61 123 362 58 362 125 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 2059 61 2059 44 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 61 2059 555 2004 46 2010 323 2044 612 2060 40 2004 41 58 2061 61 2062 46 2063 40 2064 61 123 362 58 362 44 362 58 362 44 362 58 362 125 44 2065 61 123 362 58 362 44 362 58 1500 44 362 58 470 44 362 58 362 125 44 41 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 2061 61 2061 44 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 91 1500 93 91 362 93 61 123 362 58 123 362 58 362 44 362 58 362 44 362 58 362 125 44 362 58 123 362 58 362 44 362 58 1500 44 362 58 470 44 362 58 362 125 44 125 555 2004 46 2010 323 2044 612 2066 40 2004 41 58 2067 61 123 362 58 123 362 58 123 362 58 91 123 362 58 91 123 362 58 362 44 362 58 362 44 362 58 91 362 93 125 93 125 93 125 125 125 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 2067 61 2067 44 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 61 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 61 2067 555 2004 46 2010 323 2044 612 2068 40 2004 41 58 2069 61 2062 46 2070 40 2034 61 362 44 2071 61 1503 44 41 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 2072 61 91 2069 93 44 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 61 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 91 1500 93 91 362 93 61 91 123 362 58 362 44 362 58 1503 125 93 555 2004 46 2010 323 2044 612 2073 40 2004 41 58 871 2074 46 2075 46 755 40 2076 44 362 41 552 2077 58 2078 61 2062 46 2079 40 2034 61 362 44 2080 61 362 44 2081 61 470 44 2082 61 443 41 2083 61 2062 46 2084 40 2034 61 362 44 2085 61 2062 46 2086 40 2087 61 362 41 44 41 2088 61 91 362 362 93 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 2088 44 2033 61 123 362 58 362 125 44 2089 61 91 2078 93 44 2090 61 91 2083 93 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 61 2041 41 2077 46 2091 46 2092 40 362 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 91 1500 93 91 362 93 61 2088 2004 46 2010 91 362 93 91 362 93 91 1500 93 91 362 93 61 91 123 362 58 362 44 362 58 362 44 362 58 443 125 93 2004 46 2010 91 362 93 91 362 93 61 91 123 362 58 362 44 362 58 123 362 58 362 125 125 93 555 2004 46 2010 323 2044 612 2093 40 2004 41 58 2094 61 123 362 58 123 362 58 1500 44 125 125 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 2094 61 2094 44 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 61 2094 555 2004 46 2010 323 2044 612 2095 40 2004 41 58 2094 61 123 362 58 123 362 58 1504 44 125 125 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 2094 61 2094 44 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 61 2094 555 2004 46 2010 323 2044 612 2096 40 2004 41 58 2094 61 123 362 58 123 362 58 1504 44 125 125 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 2094 61 2094 44 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 61 2094 555 2004 46 2010 323 2044 612 2097 40 2004 41 58 2098 61 362 2028 61 2029 40 2019 61 362 44 2030 61 2098 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 2099 61 1502 44 41 871 2100 46 2101 40 2102 41 58 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 91 1500 93 91 362 93 61 2098 555 2004 46 2010 323 2044 612 2103 40 2004 41 58 2104 61 362 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 2099 61 1502 44 2105 61 2104 44 41 871 2100 46 2101 40 2106 41 58 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 61 2104 555 2004 46 2010 323 2044 612 2107 40 2004 41 58 362 2108 61 91 362 93 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 2108 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 41 871 2100 46 2101 40 2102 41 58 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 91 1500 93 91 362 93 61 2108 555 2004 46 2010 323 2044 612 2109 40 2004 41 58 2110 61 362 2088 61 91 362 93 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 2088 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 515 44 41 2041 61 2042 40 2028 41 555 2028 46 2043 40 2041 41 323 2111 46 2112 40 2110 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2083 61 2004 46 2008 46 2045 40 2113 46 2114 41 2078 61 2004 46 2008 46 2045 40 2113 46 2115 41 2116 61 2004 46 2008 46 2045 40 2113 46 2117 41 2004 46 2010 91 362 93 91 362 93 91 1500 93 91 362 93 61 2088 2004 46 2010 91 362 93 91 362 93 91 1500 93 91 362 93 46 2118 40 1500 44 2078 41 2004 46 2010 91 362 93 91 362 93 46 2118 40 1500 44 2083 41 2004 46 2010 91 362 93 91 362 93 46 2119 40 2116 41 555 2004 46 2010 323 2044 64 2074 46 2075 40 362 41 64 2074 46 2075 40 362 41 64 2074 46 2075 40 362 41 612 2120 40 2004 44 2121 44 2122 44 2123 41 58 330 668 2124 46 2125 46 2126 695 2127 2128 61 362 2129 61 91 2130 40 362 44 470 44 2128 41 93 330 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2129 61 2129 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 41 330 2122 46 2110 61 40 2127 46 2131 44 470 44 470 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 555 2123 46 2132 91 1500 93 91 1500 93 46 2133 46 2134 91 1500 93 46 2135 323 91 2062 46 2136 40 2128 61 2062 46 2137 40 2034 61 2128 41 41 93 612 2138 40 2004 41 58 330 2139 61 91 2062 46 2140 40 2034 61 362 44 2141 61 362 41 44 2062 46 2140 40 2034 61 362 44 2141 61 362 41 44 2062 46 2140 40 2034 61 362 44 2142 61 2062 46 2143 40 2144 61 2062 46 2145 40 2146 61 362 41 41 44 41 44 93 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2139 61 2139 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 330 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 91 1500 93 91 362 93 61 91 123 362 58 362 44 362 58 362 125 44 123 362 58 362 44 362 58 362 125 44 123 362 58 362 44 362 58 123 362 58 123 362 58 362 125 125 125 44 93 555 2004 46 2010 323 2044 612 2147 40 2004 41 58 2148 61 2149 46 2150 91 1500 93 43 362 2028 61 2029 40 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2151 61 2148 44 2038 61 515 44 41 2041 61 2042 40 2028 41 2152 61 2028 46 2043 40 2041 41 555 2152 712 750 470 555 2152 323 123 362 58 362 125 612 2153 40 2004 41 58 2148 61 2149 46 2150 91 1500 93 43 362 2028 61 2029 40 2037 61 362 43 2004 46 2003 40 41 44 2033 61 123 362 58 362 44 362 58 362 125 44 2139 61 91 2062 46 2140 40 2034 61 362 44 2141 61 362 41 93 44 2017 61 443 44 2151 61 2148 44 2038 61 515 44 41 2041 61 2042 40 2028 41 2152 61 2028 46 2043 40 2041 41 555 2152 712 750 470 555 2028 46 2046 46 2154 46 2033 323 123 362 58 362 44 362 58 362 44 362 58 2074 46 2011 44 362 58 362 44 362 58 2074 46 2011 44 362 58 362 44 362 58 2074 46 2011 44 362 58 362 44 125 555 2028 46 2046 46 2133 46 2134 91 1500 93 46 2155 323 91 2062 46 2140 40 2034 61 362 44 2141 61 362 41 93 555 2152 323 123 362 58 362 125 612 2156 40 2004 41 58 2148 61 2149 46 2150 91 1500 93 43 362 2157 61 2062 46 2158 40 2154 61 2062 46 2159 40 2033 61 123 362 58 362 44 362 58 362 125 44 41 44 2133 61 2062 46 2160 40 2134 61 91 2062 46 2161 40 2034 61 362 44 2155 61 91 2062 46 2140 40 2034 61 362 44 2141 61 362 41 93 44 41 93 41 44 41 2028 61 2029 40 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2151 61 2148 44 2162 61 2157 44 2038 61 515 44 41 2041 61 2042 40 2028 41 2152 61 2028 46 2043 40 2041 41 555 2152 712 750 470 555 2028 46 2046 46 2154 46 2033 323 123 362 58 362 44 362 58 362 44 362 58 2074 46 2011 44 362 58 362 44 362 58 2074 46 2011 44 362 58 362 44 362 58 2074 46 2011 44 362 58 362 44 125 555 2028 46 2046 46 2133 46 2134 91 1500 93 46 2155 323 91 2062 46 2140 40 2034 61 362 44 2141 61 362 41 93 555 2152 323 123 362 58 362 125 612 2163 40 2004 41 58 2157 61 2062 46 2158 40 2154 61 2062 46 2159 40 2033 61 123 362 58 362 44 362 58 362 125 44 2019 61 362 44 2034 61 362 41 44 2133 61 2062 46 2160 40 2134 61 91 2062 46 2161 40 2034 61 362 44 2030 61 362 44 2164 61 91 362 93 44 2088 61 91 362 44 362 93 44 2155 61 91 2062 46 2140 40 2034 61 362 44 2141 61 362 41 93 44 41 93 44 2165 61 362 44 41 44 41 2028 61 2029 40 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2162 61 2157 44 2038 61 515 44 41 2041 61 2042 40 2028 41 2152 61 2028 46 2043 40 2041 41 555 2152 712 750 470 555 2028 46 2046 46 2154 46 2033 323 123 362 58 362 44 362 58 362 44 362 58 2074 46 2011 44 362 58 362 44 362 58 2074 46 2011 44 362 58 362 44 362 58 2074 46 2011 44 362 58 362 44 125 555 2028 46 2046 46 2133 46 2134 91 1500 93 46 2155 323 91 2062 46 2140 40 2034 61 362 44 2141 61 362 41 93 555 2152 323 123 362 58 362 125 612 2166 40 2004 41 58 330 2089 61 91 2062 46 2079 40 2080 61 362 44 2034 61 362 44 2081 61 470 44 2082 61 515 41 93 2167 61 91 2062 46 2140 40 2034 61 362 44 2141 61 362 41 44 2062 46 2140 40 2034 61 362 44 2141 61 362 41 44 93 2168 61 2062 46 2161 40 2034 61 362 44 2030 61 362 44 2155 61 2167 44 2089 61 2089 44 2164 61 91 362 44 362 93 44 2088 61 91 362 93 44 41 2083 61 2062 46 2084 40 2034 61 362 44 2085 61 2062 46 2086 40 2087 61 362 41 44 41 2169 61 123 362 58 362 44 362 58 362 44 362 58 91 362 44 362 93 44 362 58 91 362 93 44 362 58 91 123 362 58 362 44 362 58 362 125 44 123 362 58 362 44 362 58 362 125 93 44 362 58 91 123 362 58 362 44 362 58 362 44 362 58 515 125 93 44 125 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2090 61 91 2083 93 44 2170 61 91 2168 93 44 2017 61 443 44 2038 61 443 44 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 61 91 2169 93 2004 46 2010 91 362 93 91 362 93 61 91 123 362 58 362 44 362 58 123 362 58 362 125 125 93 555 2004 46 2010 323 2044 64 2074 46 2075 40 362 41 64 2074 46 2075 40 362 41 64 2074 46 2075 40 362 41 612 2171 40 2004 44 2121 44 2122 44 2123 41 58 668 2124 46 2125 46 2126 695 2127 2150 61 2149 46 2150 91 1500 93 43 362 2028 61 2029 40 2037 61 362 43 2004 46 2003 40 41 44 2172 61 443 44 2151 61 2150 44 2038 61 515 44 41 2122 46 2110 61 40 2127 46 2131 44 470 44 470 41 2041 61 2042 40 2028 41 871 2004 46 2173 40 2028 46 2174 44 2175 61 2176 46 2177 41 552 2178 58 2028 46 2043 40 2041 41 2179 61 2180 46 2181 40 362 41 46 2182 40 41 555 548 40 2183 46 2184 40 2179 41 664 2183 696 2178 46 2185 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2186 61 123 362 58 362 44 362 58 362 44 362 58 123 362 58 123 125 44 362 58 123 362 58 362 44 362 58 2074 46 2011 44 362 58 362 44 362 58 2074 46 2011 44 362 58 362 44 125 44 362 58 362 44 362 58 362 44 125 44 362 58 123 362 58 123 125 44 362 58 91 123 362 58 91 362 44 362 44 362 44 362 44 362 44 362 93 44 362 58 91 362 93 44 362 58 91 93 44 362 58 91 93 44 362 58 362 44 362 58 362 44 362 58 91 93 44 362 58 123 362 58 123 362 58 362 125 44 362 58 123 362 58 362 125 125 44 362 58 91 123 362 58 362 44 362 58 362 125 93 44 125 44 123 362 58 91 362 44 362 44 362 93 44 362 58 362 44 362 58 362 44 362 58 123 362 58 123 362 58 362 125 125 44 362 58 91 123 362 58 362 44 362 58 362 125 93 44 125 44 93 44 362 58 443 44 362 58 91 93 44 362 58 91 93 44 362 58 123 125 44 362 58 362 44 362 58 123 125 44 362 58 91 93 44 362 58 91 123 362 58 123 125 44 362 58 362 125 93 44 125 44 125 2187 61 2044 91 362 93 91 362 93 91 362 93 555 2187 46 2184 40 2012 41 616 2044 91 362 93 91 362 93 91 362 93 555 2186 323 2044 64 2074 46 2075 40 362 41 64 2074 46 2075 40 362 41 64 2074 46 2075 40 362 41 612 2188 40 2004 44 2121 44 2122 44 2123 41 58 362 668 2124 46 2125 46 2126 695 2127 2189 61 362 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 43 813 40 2035 46 2036 40 1500 44 1507 41 41 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 2189 61 2189 44 41 2122 46 2110 61 40 2127 46 2131 44 470 44 470 41 2041 61 2042 40 2028 41 2028 46 2043 40 2041 41 2044 61 2004 46 2008 46 2045 40 2028 46 2046 41 2004 46 2010 91 362 93 91 362 93 61 2189 555 2004 46 2010 323 2044 612 2190 40 2004 41 58 2191 61 362 42 1504 871 2100 46 2101 40 2102 41 58 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 2191 44 2037 61 362 43 2004 46 2003 40 41 44 2017 61 443 44 2038 61 443 44 41 64 2074 46 2075 40 362 41 612 2192 40 2004 44 2122 41 58 668 2124 46 2125 46 2126 695 2127 2014 61 2015 46 2016 40 2017 61 443 41 2034 61 362 2019 61 362 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 44 2037 61 2034 44 2017 61 443 44 2038 61 443 44 2193 61 1500 44 41 2041 61 2042 40 2028 41 2122 46 2110 61 40 2127 46 2131 44 470 44 470 41 2028 46 2043 40 2041 41 2034 61 2028 46 2046 46 2154 46 2034 2046 61 2014 46 2194 40 2034 61 2034 44 2019 61 2019 41 555 2046 46 2195 46 2196 323 362 2028 46 2197 40 41 871 2100 46 2101 40 2106 41 58 2046 61 2014 46 2194 40 2034 61 2034 44 2019 61 2019 41 612 2198 40 2004 41 58 668 2124 46 2125 46 2126 695 2127 2014 61 2015 46 2016 40 2017 61 443 41 2034 61 362 2019 61 362 2028 61 2029 40 2019 61 362 44 2030 61 362 44 2031 61 91 362 44 362 93 44 2032 61 91 362 93 44 2033 61 123 362 58 362 125 44 2034 61 362 44 2037 61 2034 44 2017 61 443 44 2038 61 443 44 2049 61 443 44 2193 61 1500 44 41 2041 61 2042 40 2028 41 871 2074 46 2075 40 362 41 552 2122 58 2122 46 2110 61 40 2127 46 2131 44 470 44 470 41 2028 46 2043 40 2041 41 2034 61 2028 46 2046 46 2154 46 2034 2046 61 2014 46 2194 40 2034 61 2034 44 2019 61 2019 41 870 2046 46 2195 46 2196 340 362 58 2046 61 2014 46 2194 40 2034 61 2034 44 2019 61 2019 41 871 2100 46 2101 40 2102 41 58 2028 46 2043 40 2041 41 2046 61 2014 46 2194 40 2034 61 2034 44 2019 61 2019 41 555 2046 46 2154 46 2033 91 362 93 323 362 871 2074 46 2075 40 362 362 362 41 552 2199 58 2199 46 2110 61 40 362 44 123 125 44 123 125 41 2028 46 2043 40 2041 41 2199 46 2200 40 41 ,"{'AvgLine': 26, 'CountLine': 950, 'CountStmt': 311, 'MaxNesting': 2, 'AvgLineCode': 25, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 270, 'MaxEssential': 1, 'SumEssential': 34, 'AvgCyclomatic': 1, 'CountLineCode': 877, 'CountStmtDecl': 181, 'MaxCyclomatic': 2, 'SumCyclomatic': 35, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 62, 'CountDeclMethod': 34, 'CountLineCodeExe': 826, 'CountLineComment': 11, 'CountClassCoupled': 7, 'CountClassDerived': 0, 'CountLineCodeDecl': 189, 'CountDeclMethodAll': 34, 'MaxInheritanceTree': 1, 'RatioCommentToCode': '0.01', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 2, 'SumCyclomaticStrict': 35, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 2, 'SumCyclomaticModified': 35, 'CountDeclInstanceMethod': 34, 'CountClassCoupledModified': 6, 'CountDeclInstanceVariable': 3}"
131316,Python,"class AutodetectorTests(TestCase):
    """"""
    Tests the migration autodetector.
    """"""

    author_empty = ModelState(""testapp"", ""Author"", [(""id"", models.AutoField(primary_key=True))])
    author_name = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200)),
    ])
    author_name_null = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, null=True)),
    ])
    author_name_longer = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=400)),
    ])
    author_name_renamed = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""names"", models.CharField(max_length=200)),
    ])
    author_name_default = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default='Ada Lovelace')),
    ])
    author_name_check_constraint = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200)),
    ],
        {'constraints': [models.CheckConstraint(check=models.Q(name__contains='Bob'), name='name_contains_bob')]},
    )
    author_dates_of_birth_auto_now = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""date_of_birth"", models.DateField(auto_now=True)),
        (""date_time_of_birth"", models.DateTimeField(auto_now=True)),
        (""time_of_birth"", models.TimeField(auto_now=True)),
    ])
    author_dates_of_birth_auto_now_add = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""date_of_birth"", models.DateField(auto_now_add=True)),
        (""date_time_of_birth"", models.DateTimeField(auto_now_add=True)),
        (""time_of_birth"", models.TimeField(auto_now_add=True)),
    ])
    author_name_deconstructible_1 = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default=DeconstructibleObject())),
    ])
    author_name_deconstructible_2 = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default=DeconstructibleObject())),
    ])
    author_name_deconstructible_3 = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default=models.IntegerField())),
    ])
    author_name_deconstructible_4 = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default=models.IntegerField())),
    ])
    author_name_deconstructible_list_1 = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default=[DeconstructibleObject(), 123])),
    ])
    author_name_deconstructible_list_2 = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default=[DeconstructibleObject(), 123])),
    ])
    author_name_deconstructible_list_3 = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default=[DeconstructibleObject(), 999])),
    ])
    author_name_deconstructible_tuple_1 = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default=(DeconstructibleObject(), 123))),
    ])
    author_name_deconstructible_tuple_2 = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default=(DeconstructibleObject(), 123))),
    ])
    author_name_deconstructible_tuple_3 = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default=(DeconstructibleObject(), 999))),
    ])
    author_name_deconstructible_dict_1 = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default={
            'item': DeconstructibleObject(), 'otheritem': 123
        })),
    ])
    author_name_deconstructible_dict_2 = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default={
            'item': DeconstructibleObject(), 'otheritem': 123
        })),
    ])
    author_name_deconstructible_dict_3 = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default={
            'item': DeconstructibleObject(), 'otheritem': 999
        })),
    ])
    author_name_nested_deconstructible_1 = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default=DeconstructibleObject(
            DeconstructibleObject(1),
            (DeconstructibleObject('t1'), DeconstructibleObject('t2'),),
            a=DeconstructibleObject('A'),
            b=DeconstructibleObject(B=DeconstructibleObject('c')),
        ))),
    ])
    author_name_nested_deconstructible_2 = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default=DeconstructibleObject(
            DeconstructibleObject(1),
            (DeconstructibleObject('t1'), DeconstructibleObject('t2'),),
            a=DeconstructibleObject('A'),
            b=DeconstructibleObject(B=DeconstructibleObject('c')),
        ))),
    ])
    author_name_nested_deconstructible_changed_arg = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default=DeconstructibleObject(
            DeconstructibleObject(1),
            (DeconstructibleObject('t1'), DeconstructibleObject('t2-changed'),),
            a=DeconstructibleObject('A'),
            b=DeconstructibleObject(B=DeconstructibleObject('c')),
        ))),
    ])
    author_name_nested_deconstructible_extra_arg = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default=DeconstructibleObject(
            DeconstructibleObject(1),
            (DeconstructibleObject('t1'), DeconstructibleObject('t2'),),
            None,
            a=DeconstructibleObject('A'),
            b=DeconstructibleObject(B=DeconstructibleObject('c')),
        ))),
    ])
    author_name_nested_deconstructible_changed_kwarg = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default=DeconstructibleObject(
            DeconstructibleObject(1),
            (DeconstructibleObject('t1'), DeconstructibleObject('t2'),),
            a=DeconstructibleObject('A'),
            b=DeconstructibleObject(B=DeconstructibleObject('c-changed')),
        ))),
    ])
    author_name_nested_deconstructible_extra_kwarg = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200, default=DeconstructibleObject(
            DeconstructibleObject(1),
            (DeconstructibleObject('t1'), DeconstructibleObject('t2'),),
            a=DeconstructibleObject('A'),
            b=DeconstructibleObject(B=DeconstructibleObject('c')),
            c=None,
        ))),
    ])
    author_custom_pk = ModelState(""testapp"", ""Author"", [(""pk_field"", models.IntegerField(primary_key=True))])
    author_with_biography_non_blank = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField()),
        (""biography"", models.TextField()),
    ])
    author_with_biography_blank = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(blank=True)),
        (""biography"", models.TextField(blank=True)),
    ])
    author_with_book = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200)),
        (""book"", models.ForeignKey(""otherapp.Book"", models.CASCADE)),
    ])
    author_with_book_order_wrt = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200)),
        (""book"", models.ForeignKey(""otherapp.Book"", models.CASCADE)),
    ], options={""order_with_respect_to"": ""book""})
    author_renamed_with_book = ModelState(""testapp"", ""Writer"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200)),
        (""book"", models.ForeignKey(""otherapp.Book"", models.CASCADE)),
    ])
    author_with_publisher_string = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200)),
        (""publisher_name"", models.CharField(max_length=200)),
    ])
    author_with_publisher = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200)),
        (""publisher"", models.ForeignKey(""testapp.Publisher"", models.CASCADE)),
    ])
    author_with_user = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200)),
        (""user"", models.ForeignKey(""auth.User"", models.CASCADE)),
    ])
    author_with_custom_user = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=200)),
        (""user"", models.ForeignKey(""thirdapp.CustomUser"", models.CASCADE)),
    ])
    author_proxy = ModelState(""testapp"", ""AuthorProxy"", [], {""proxy"": True}, (""testapp.author"",))
    author_proxy_options = ModelState(""testapp"", ""AuthorProxy"", [], {
        ""proxy"": True,
        ""verbose_name"": ""Super Author"",
    }, (""testapp.author"",))
    author_proxy_notproxy = ModelState(""testapp"", ""AuthorProxy"", [], {}, (""testapp.author"",))
    author_proxy_third = ModelState(""thirdapp"", ""AuthorProxy"", [], {""proxy"": True}, (""testapp.author"",))
    author_proxy_third_notproxy = ModelState(""thirdapp"", ""AuthorProxy"", [], {}, (""testapp.author"",))
    author_proxy_proxy = ModelState(""testapp"", ""AAuthorProxyProxy"", [], {""proxy"": True}, (""testapp.authorproxy"",))
    author_unmanaged = ModelState(""testapp"", ""AuthorUnmanaged"", [], {""managed"": False}, (""testapp.author"",))
    author_unmanaged_managed = ModelState(""testapp"", ""AuthorUnmanaged"", [], {}, (""testapp.author"",))
    author_unmanaged_default_pk = ModelState(""testapp"", ""Author"", [(""id"", models.AutoField(primary_key=True))])
    author_unmanaged_custom_pk = ModelState(""testapp"", ""Author"", [
        (""pk_field"", models.IntegerField(primary_key=True)),
    ])
    author_with_m2m = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""publishers"", models.ManyToManyField(""testapp.Publisher"")),
    ])
    author_with_m2m_blank = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""publishers"", models.ManyToManyField(""testapp.Publisher"", blank=True)),
    ])
    author_with_m2m_through = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""publishers"", models.ManyToManyField(""testapp.Publisher"", through=""testapp.Contract"")),
    ])
    author_with_renamed_m2m_through = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""publishers"", models.ManyToManyField(""testapp.Publisher"", through=""testapp.Deal"")),
    ])
    author_with_former_m2m = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
        (""publishers"", models.CharField(max_length=100)),
    ])
    author_with_options = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
    ], {
        ""permissions"": [('can_hire', 'Can hire')],
        ""verbose_name"": ""Authi"",
    })
    author_with_db_table_options = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
    ], {""db_table"": ""author_one""})
    author_with_new_db_table_options = ModelState(""testapp"", ""Author"", [
        (""id"", models.AutoField(primary_key=True)),
    ], {""db_table"": ""author_two""})
    author_renamed_with_db_table_options = ModelState(""testapp"", ""NewAuthor"", [
        (""id"", models.AutoField(primary_key=True)),
    ], {""db_table"": ""author_one""})
    author_renamed_with_new_db_table_options = ModelState(""testapp"", ""NewAuthor"", [
        (""id"", models.AutoField(primary_key=True)),
    ], {""db_table"": ""author_three""})
    contract = ModelState(""testapp"", ""Contract"", [
        (""id"", models.AutoField(primary_key=True)),
        (""author"", models.ForeignKey(""testapp.Author"", models.CASCADE)),
        (""publisher"", models.ForeignKey(""testapp.Publisher"", models.CASCADE)),
    ])
    contract_renamed = ModelState(""testapp"", ""Deal"", [
        (""id"", models.AutoField(primary_key=True)),
        (""author"", models.ForeignKey(""testapp.Author"", models.CASCADE)),
        (""publisher"", models.ForeignKey(""testapp.Publisher"", models.CASCADE)),
    ])
    publisher = ModelState(""testapp"", ""Publisher"", [
        (""id"", models.AutoField(primary_key=True)),
        (""name"", models.CharField(max_length=100)),
    ])
    publisher_with_author = ModelState(""testapp"", ""Publisher"", [
        (""id"", models.AutoField(primary_key=True)),
        (""author"", models.ForeignKey(""testapp.Author"", models.CASCADE)),
        (""name"", models.CharField(max_length=100)),
    ])
    publisher_with_aardvark_author = ModelState(""testapp"", ""Publisher"", [
        (""id"", models.AutoField(primary_key=True)),
        (""author"", models.ForeignKey(""testapp.Aardvark"", models.CASCADE)),
        (""name"", models.CharField(max_length=100)),
    ])
    publisher_with_book = ModelState(""testapp"", ""Publisher"", [
        (""id"", models.AutoField(primary_key=True)),
        (""author"", models.ForeignKey(""otherapp.Book"", models.CASCADE)),
        (""name"", models.CharField(max_length=100)),
    ])
    other_pony = ModelState(""otherapp"", ""Pony"", [
        (""id"", models.AutoField(primary_key=True)),
    ])
    other_pony_food = ModelState(""otherapp"", ""Pony"", [
        (""id"", models.AutoField(primary_key=True)),
    ], managers=[
        ('food_qs', FoodQuerySet.as_manager()),
        ('food_mgr', FoodManager('a', 'b')),
        ('food_mgr_kwargs', FoodManager('x', 'y', 3, 4)),
    ])
    other_stable = ModelState(""otherapp"", ""Stable"", [(""id"", models.AutoField(primary_key=True))])
    third_thing = ModelState(""thirdapp"", ""Thing"", [(""id"", models.AutoField(primary_key=True))])
    book = ModelState(""otherapp"", ""Book"", [
        (""id"", models.AutoField(primary_key=True)),
        (""author"", models.ForeignKey(""testapp.Author"", models.CASCADE)),
        (""title"", models.CharField(max_length=200)),
    ])
    book_proxy_fk = ModelState(""otherapp"", ""Book"", [
        (""id"", models.AutoField(primary_key=True)),
        (""author"", models.ForeignKey(""thirdapp.AuthorProxy"", models.CASCADE)),
        (""title"", models.CharField(max_length=200)),
    ])
    book_proxy_proxy_fk = ModelState(""otherapp"", ""Book"", [
        (""id"", models.AutoField(primary_key=True)),
        (""author"", models.ForeignKey(""testapp.AAuthorProxyProxy"", models.CASCADE)),
    ])
    book_migrations_fk = ModelState(""otherapp"", ""Book"", [
        (""id"", models.AutoField(primary_key=True)),
        (""author"", models.ForeignKey(""migrations.UnmigratedModel"", models.CASCADE)),
        (""title"", models.CharField(max_length=200)),
    ])
    book_with_no_author_fk = ModelState(""otherapp"", ""Book"", [
        (""id"", models.AutoField(primary_key=True)),
        (""author"", models.IntegerField()),
        (""title"", models.CharField(max_length=200)),
    ])
    book_with_no_author = ModelState(""otherapp"", ""Book"", [
        (""id"", models.AutoField(primary_key=True)),
        (""title"", models.CharField(max_length=200)),
    ])
    book_with_author_renamed = ModelState(""otherapp"", ""Book"", [
        (""id"", models.AutoField(primary_key=True)),
        (""author"", models.ForeignKey(""testapp.Writer"", models.CASCADE)),
        (""title"", models.CharField(max_length=200)),
    ])
    book_with_field_and_author_renamed = ModelState(""otherapp"", ""Book"", [
        (""id"", models.AutoField(primary_key=True)),
        (""writer"", models.ForeignKey(""testapp.Writer"", models.CASCADE)),
        (""title"", models.CharField(max_length=200)),
    ])
    book_with_multiple_authors = ModelState(""otherapp"", ""Book"", [
        (""id"", models.AutoField(primary_key=True)),
        (""authors"", models.ManyToManyField(""testapp.Author"")),
        (""title"", models.CharField(max_length=200)),
    ])
    book_with_multiple_authors_through_attribution = ModelState(""otherapp"", ""Book"", [
        (""id"", models.AutoField(primary_key=True)),
        (""authors"", models.ManyToManyField(""testapp.Author"", through=""otherapp.Attribution"")),
        (""title"", models.CharField(max_length=200)),
    ])
    book_indexes = ModelState(""otherapp"", ""Book"", [
        (""id"", models.AutoField(primary_key=True)),
        (""author"", models.ForeignKey(""testapp.Author"", models.CASCADE)),
        (""title"", models.CharField(max_length=200)),
    ], {
        ""indexes"": [models.Index(fields=[""author"", ""title""], name=""book_title_author_idx"")],
    })
    book_unordered_indexes = ModelState(""otherapp"", ""Book"", [
        (""id"", models.AutoField(primary_key=True)),
        (""author"", models.ForeignKey(""testapp.Author"", models.CASCADE)),
        (""title"", models.CharField(max_length=200)),
    ], {
        ""indexes"": [models.Index(fields=[""title"", ""author""], name=""book_author_title_idx"")],
    })
    book_foo_together = ModelState(""otherapp"", ""Book"", [
        (""id"", models.AutoField(primary_key=True)),
        (""author"", models.ForeignKey(""testapp.Author"", models.CASCADE)),
        (""title"", models.CharField(max_length=200)),
    ], {
        ""index_together"": {(""author"", ""title"")},
        ""unique_together"": {(""author"", ""title"")},
    })
    book_foo_together_2 = ModelState(""otherapp"", ""Book"", [
        (""id"", models.AutoField(primary_key=True)),
        (""author"", models.ForeignKey(""testapp.Author"", models.CASCADE)),
        (""title"", models.CharField(max_length=200)),
    ], {
        ""index_together"": {(""title"", ""author"")},
        ""unique_together"": {(""title"", ""author"")},
    })
    book_foo_together_3 = ModelState(""otherapp"", ""Book"", [
        (""id"", models.AutoField(primary_key=True)),
        (""newfield"", models.IntegerField()),
        (""author"", models.ForeignKey(""testapp.Author"", models.CASCADE)),
        (""title"", models.CharField(max_length=200)),
    ], {
        ""index_together"": {(""title"", ""newfield"")},
        ""unique_together"": {(""title"", ""newfield"")},
    })
    book_foo_together_4 = ModelState(""otherapp"", ""Book"", [
        (""id"", models.AutoField(primary_key=True)),
        (""newfield2"", models.IntegerField()),
        (""author"", models.ForeignKey(""testapp.Author"", models.CASCADE)),
        (""title"", models.CharField(max_length=200)),
    ], {
        ""index_together"": {(""title"", ""newfield2"")},
        ""unique_together"": {(""title"", ""newfield2"")},
    })
    attribution = ModelState(""otherapp"", ""Attribution"", [
        (""id"", models.AutoField(primary_key=True)),
        (""author"", models.ForeignKey(""testapp.Author"", models.CASCADE)),
        (""book"", models.ForeignKey(""otherapp.Book"", models.CASCADE)),
    ])
    edition = ModelState(""thirdapp"", ""Edition"", [
        (""id"", models.AutoField(primary_key=True)),
        (""book"", models.ForeignKey(""otherapp.Book"", models.CASCADE)),
    ])
    custom_user = ModelState(""thirdapp"", ""CustomUser"", [
        (""id"", models.AutoField(primary_key=True)),
        (""username"", models.CharField(max_length=255)),
    ], bases=(AbstractBaseUser,))
    custom_user_no_inherit = ModelState(""thirdapp"", ""CustomUser"", [
        (""id"", models.AutoField(primary_key=True)),
        (""username"", models.CharField(max_length=255)),
    ])
    aardvark = ModelState(""thirdapp"", ""Aardvark"", [(""id"", models.AutoField(primary_key=True))])
    aardvark_testapp = ModelState(""testapp"", ""Aardvark"", [(""id"", models.AutoField(primary_key=True))])
    aardvark_based_on_author = ModelState(""testapp"", ""Aardvark"", [], bases=(""testapp.Author"",))
    aardvark_pk_fk_author = ModelState(""testapp"", ""Aardvark"", [
        (""id"", models.OneToOneField(""testapp.Author"", models.CASCADE, primary_key=True)),
    ])
    knight = ModelState(""eggs"", ""Knight"", [(""id"", models.AutoField(primary_key=True))])
    rabbit = ModelState(""eggs"", ""Rabbit"", [
        (""id"", models.AutoField(primary_key=True)),
        (""knight"", models.ForeignKey(""eggs.Knight"", models.CASCADE)),
        (""parent"", models.ForeignKey(""eggs.Rabbit"", models.CASCADE)),
    ], {
        ""unique_together"": {(""parent"", ""knight"")},
        ""indexes"": [models.Index(fields=[""parent"", ""knight""], name='rabbit_circular_fk_index')],
    })

    def repr_changes(self, changes, include_dependencies=False):
        output = """"
        for app_label, migrations_ in sorted(changes.items()):
            output += ""  %s:\n"" % app_label
            for migration in migrations_:
                output += ""    %s\n"" % migration.name
                for operation in migration.operations:
                    output += ""      %s\n"" % operation
                if include_dependencies:
                    output += ""      Dependencies:\n""
                    if migration.dependencies:
                        for dep in migration.dependencies:
                            output += ""        %s\n"" % (dep,)
                    else:
                        output += ""        None\n""
        return output

    def assertNumberMigrations(self, changes, app_label, number):
        if len(changes.get(app_label, [])) != number:
            self.fail(""Incorrect number of migrations (%s) for %s (expected %s)\n%s"" % (
                len(changes.get(app_label, [])),
                app_label,
                number,
                self.repr_changes(changes),
            ))

    def assertMigrationDependencies(self, changes, app_label, position, dependencies):
        if not changes.get(app_label):
            self.fail(""No migrations found for %s\n%s"" % (app_label, self.repr_changes(changes)))
        if len(changes[app_label]) < position + 1:
            self.fail(""No migration at index %s for %s\n%s"" % (position, app_label, self.repr_changes(changes)))
        migration = changes[app_label][position]
        if set(migration.dependencies) != set(dependencies):
            self.fail(""Migration dependencies mismatch for %s.%s (expected %s):\n%s"" % (
                app_label,
                migration.name,
                dependencies,
                self.repr_changes(changes, include_dependencies=True),
            ))

    def assertOperationTypes(self, changes, app_label, position, types):
        if not changes.get(app_label):
            self.fail(""No migrations found for %s\n%s"" % (app_label, self.repr_changes(changes)))
        if len(changes[app_label]) < position + 1:
            self.fail(""No migration at index %s for %s\n%s"" % (position, app_label, self.repr_changes(changes)))
        migration = changes[app_label][position]
        real_types = [operation.__class__.__name__ for operation in migration.operations]
        if types != real_types:
            self.fail(""Operation type mismatch for %s.%s (expected %s):\n%s"" % (
                app_label,
                migration.name,
                types,
                self.repr_changes(changes),
            ))

    def assertOperationAttributes(self, changes, app_label, position, operation_position, **attrs):
        if not changes.get(app_label):
            self.fail(""No migrations found for %s\n%s"" % (app_label, self.repr_changes(changes)))
        if len(changes[app_label]) < position + 1:
            self.fail(""No migration at index %s for %s\n%s"" % (position, app_label, self.repr_changes(changes)))
        migration = changes[app_label][position]
        if len(changes[app_label]) < position + 1:
            self.fail(""No operation at index %s for %s.%s\n%s"" % (
                operation_position,
                app_label,
                migration.name,
                self.repr_changes(changes),
            ))
        operation = migration.operations[operation_position]
        for attr, value in attrs.items():
            if getattr(operation, attr, None) != value:
                self.fail(""Attribute mismatch for %s.%s op #%s, %s (expected %r, got %r):\n%s"" % (
                    app_label,
                    migration.name,
                    operation_position,
                    attr,
                    value,
                    getattr(operation, attr, None),
                    self.repr_changes(changes),
                ))

    def assertOperationFieldAttributes(self, changes, app_label, position, operation_position, **attrs):
        if not changes.get(app_label):
            self.fail(""No migrations found for %s\n%s"" % (app_label, self.repr_changes(changes)))
        if len(changes[app_label]) < position + 1:
            self.fail(""No migration at index %s for %s\n%s"" % (position, app_label, self.repr_changes(changes)))
        migration = changes[app_label][position]
        if len(changes[app_label]) < position + 1:
            self.fail(""No operation at index %s for %s.%s\n%s"" % (
                operation_position,
                app_label,
                migration.name,
                self.repr_changes(changes),
            ))
        operation = migration.operations[operation_position]
        if not hasattr(operation, 'field'):
            self.fail(""No field attribute for %s.%s op #%s."" % (
                app_label,
                migration.name,
                operation_position,
            ))
        field = operation.field
        for attr, value in attrs.items():
            if getattr(field, attr, None) != value:
                self.fail(""Field attribute mismatch for %s.%s op #%s, field.%s (expected %r, got %r):\n%s"" % (
                    app_label,
                    migration.name,
                    operation_position,
                    attr,
                    value,
                    getattr(field, attr, None),
                    self.repr_changes(changes),
                ))

    def make_project_state(self, model_states):
        ""Shortcut to make ProjectStates from lists of predefined models""
        project_state = ProjectState()
        for model_state in model_states:
            project_state.add_model(model_state.clone())
        return project_state

    def get_changes(self, before_states, after_states, questioner=None):
        if not isinstance(before_states, ProjectState):
            before_states = self.make_project_state(before_states)
        if not isinstance(after_states, ProjectState):
            after_states = self.make_project_state(after_states)
        return MigrationAutodetector(
            before_states,
            after_states,
            questioner,
        )._detect_changes()

    def test_arrange_for_graph(self):
        """"""Tests auto-naming of migrations for graph matching.""""""
        # Make a fake graph
        graph = MigrationGraph()
        graph.add_node((""testapp"", ""0001_initial""), None)
        graph.add_node((""testapp"", ""0002_foobar""), None)
        graph.add_node((""otherapp"", ""0001_initial""), None)
        graph.add_dependency(""testapp.0002_foobar"", (""testapp"", ""0002_foobar""), (""testapp"", ""0001_initial""))
        graph.add_dependency(""testapp.0002_foobar"", (""testapp"", ""0002_foobar""), (""otherapp"", ""0001_initial""))
        # Use project state to make a new migration change set
        before = self.make_project_state([self.publisher, self.other_pony])
        after = self.make_project_state([
            self.author_empty, self.publisher, self.other_pony, self.other_stable,
        ])
        autodetector = MigrationAutodetector(before, after)
        changes = autodetector._detect_changes()
        # Run through arrange_for_graph
        changes = autodetector.arrange_for_graph(changes, graph)
        # Make sure there's a new name, deps match, etc.
        self.assertEqual(changes[""testapp""][0].name, ""0003_author"")
        self.assertEqual(changes[""testapp""][0].dependencies, [(""testapp"", ""0002_foobar"")])
        self.assertEqual(changes[""otherapp""][0].name, '0002_stable')
        self.assertEqual(changes[""otherapp""][0].dependencies, [(""otherapp"", ""0001_initial"")])

    def test_arrange_for_graph_with_multiple_initial(self):
        # Make a fake graph.
        graph = MigrationGraph()
        # Use project state to make a new migration change set.
        before = self.make_project_state([])
        after = self.make_project_state([self.author_with_book, self.book, self.attribution])
        autodetector = MigrationAutodetector(before, after, MigrationQuestioner({'ask_initial': True}))
        changes = autodetector._detect_changes()
        changes = autodetector.arrange_for_graph(changes, graph)

        self.assertEqual(changes['otherapp'][0].name, '0001_initial')
        self.assertEqual(changes['otherapp'][0].dependencies, [])
        self.assertEqual(changes['otherapp'][1].name, '0002_initial')
        self.assertCountEqual(
            changes['otherapp'][1].dependencies,
            [('testapp', '0001_initial'), ('otherapp', '0001_initial')],
        )
        self.assertEqual(changes['testapp'][0].name, '0001_initial')
        self.assertEqual(changes['testapp'][0].dependencies, [('otherapp', '0001_initial')])

    def test_trim_apps(self):
        """"""
        Trim does not remove dependencies but does remove unwanted apps.
        """"""
        # Use project state to make a new migration change set
        before = self.make_project_state([])
        after = self.make_project_state([self.author_empty, self.other_pony, self.other_stable, self.third_thing])
        autodetector = MigrationAutodetector(before, after, MigrationQuestioner({""ask_initial"": True}))
        changes = autodetector._detect_changes()
        # Run through arrange_for_graph
        graph = MigrationGraph()
        changes = autodetector.arrange_for_graph(changes, graph)
        changes[""testapp""][0].dependencies.append((""otherapp"", ""0001_initial""))
        changes = autodetector._trim_to_apps(changes, {""testapp""})
        # Make sure there's the right set of migrations
        self.assertEqual(changes[""testapp""][0].name, ""0001_initial"")
        self.assertEqual(changes[""otherapp""][0].name, ""0001_initial"")
        self.assertNotIn(""thirdapp"", changes)

    def test_custom_migration_name(self):
        """"""Tests custom naming of migrations for graph matching.""""""
        # Make a fake graph
        graph = MigrationGraph()
        graph.add_node((""testapp"", ""0001_initial""), None)
        graph.add_node((""testapp"", ""0002_foobar""), None)
        graph.add_node((""otherapp"", ""0001_initial""), None)
        graph.add_dependency(""testapp.0002_foobar"", (""testapp"", ""0002_foobar""), (""testapp"", ""0001_initial""))

        # Use project state to make a new migration change set
        before = self.make_project_state([])
        after = self.make_project_state([self.author_empty, self.other_pony, self.other_stable])
        autodetector = MigrationAutodetector(before, after)
        changes = autodetector._detect_changes()

        # Run through arrange_for_graph
        migration_name = 'custom_name'
        changes = autodetector.arrange_for_graph(changes, graph, migration_name)

        # Make sure there's a new name, deps match, etc.
        self.assertEqual(changes[""testapp""][0].name, ""0003_%s"" % migration_name)
        self.assertEqual(changes[""testapp""][0].dependencies, [(""testapp"", ""0002_foobar"")])
        self.assertEqual(changes[""otherapp""][0].name, ""0002_%s"" % migration_name)
        self.assertEqual(changes[""otherapp""][0].dependencies, [(""otherapp"", ""0001_initial"")])

    def test_new_model(self):
        """"""Tests autodetection of new models.""""""
        changes = self.get_changes([], [self.other_pony_food])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'otherapp', 1)
        self.assertOperationTypes(changes, 'otherapp', 0, [""CreateModel""])
        self.assertOperationAttributes(changes, ""otherapp"", 0, 0, name=""Pony"")
        self.assertEqual([name for name, mgr in changes['otherapp'][0].operations[0].managers],
                         ['food_qs', 'food_mgr', 'food_mgr_kwargs'])

    def test_old_model(self):
        """"""Tests deletion of old models.""""""
        changes = self.get_changes([self.author_empty], [])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""DeleteModel""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""Author"")

    def test_add_field(self):
        """"""Tests autodetection of new fields.""""""
        changes = self.get_changes([self.author_empty], [self.author_name])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AddField""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""name"")

    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_addition',
                side_effect=AssertionError(""Should not have prompted for not null addition""))
    def test_add_date_fields_with_auto_now_not_asking_for_default(self, mocked_ask_method):
        changes = self.get_changes([self.author_empty], [self.author_dates_of_birth_auto_now])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AddField"", ""AddField"", ""AddField""])
        self.assertOperationFieldAttributes(changes, ""testapp"", 0, 0, auto_now=True)
        self.assertOperationFieldAttributes(changes, ""testapp"", 0, 1, auto_now=True)
        self.assertOperationFieldAttributes(changes, ""testapp"", 0, 2, auto_now=True)

    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_addition',
                side_effect=AssertionError(""Should not have prompted for not null addition""))
    def test_add_date_fields_with_auto_now_add_not_asking_for_null_addition(self, mocked_ask_method):
        changes = self.get_changes([self.author_empty], [self.author_dates_of_birth_auto_now_add])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AddField"", ""AddField"", ""AddField""])
        self.assertOperationFieldAttributes(changes, ""testapp"", 0, 0, auto_now_add=True)
        self.assertOperationFieldAttributes(changes, ""testapp"", 0, 1, auto_now_add=True)
        self.assertOperationFieldAttributes(changes, ""testapp"", 0, 2, auto_now_add=True)

    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_auto_now_add_addition')
    def test_add_date_fields_with_auto_now_add_asking_for_default(self, mocked_ask_method):
        changes = self.get_changes([self.author_empty], [self.author_dates_of_birth_auto_now_add])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AddField"", ""AddField"", ""AddField""])
        self.assertOperationFieldAttributes(changes, ""testapp"", 0, 0, auto_now_add=True)
        self.assertOperationFieldAttributes(changes, ""testapp"", 0, 1, auto_now_add=True)
        self.assertOperationFieldAttributes(changes, ""testapp"", 0, 2, auto_now_add=True)
        self.assertEqual(mocked_ask_method.call_count, 3)

    def test_remove_field(self):
        """"""Tests autodetection of removed fields.""""""
        changes = self.get_changes([self.author_name], [self.author_empty])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""RemoveField""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""name"")

    def test_alter_field(self):
        """"""Tests autodetection of new fields.""""""
        changes = self.get_changes([self.author_name], [self.author_name_longer])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AlterField""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""name"", preserve_default=True)

    def test_supports_functools_partial(self):
        def _content_file_name(instance, filename, key, **kwargs):
            return '{}/{}'.format(instance, filename)

        def content_file_name(key, **kwargs):
            return functools.partial(_content_file_name, key, **kwargs)

        # An unchanged partial reference.
        before = [ModelState(""testapp"", ""Author"", [
            (""id"", models.AutoField(primary_key=True)),
            (""file"", models.FileField(max_length=200, upload_to=content_file_name('file'))),
        ])]
        after = [ModelState(""testapp"", ""Author"", [
            (""id"", models.AutoField(primary_key=True)),
            (""file"", models.FileField(max_length=200, upload_to=content_file_name('file'))),
        ])]
        changes = self.get_changes(before, after)
        self.assertNumberMigrations(changes, 'testapp', 0)

        # A changed partial reference.
        args_changed = [ModelState(""testapp"", ""Author"", [
            (""id"", models.AutoField(primary_key=True)),
            (""file"", models.FileField(max_length=200, upload_to=content_file_name('other-file'))),
        ])]
        changes = self.get_changes(before, args_changed)
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, ['AlterField'])
        # Can't use assertOperationFieldAttributes because we need the
        # deconstructed version, i.e., the exploded func/args/keywords rather
        # than the partial: we don't care if it's not the same instance of the
        # partial, only if it's the same source function, args, and keywords.
        value = changes['testapp'][0].operations[0].field.upload_to
        self.assertEqual(
            (_content_file_name, ('other-file',), {}),
            (value.func, value.args, value.keywords)
        )

        kwargs_changed = [ModelState(""testapp"", ""Author"", [
            (""id"", models.AutoField(primary_key=True)),
            (""file"", models.FileField(max_length=200, upload_to=content_file_name('file', spam='eggs'))),
        ])]
        changes = self.get_changes(before, kwargs_changed)
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, ['AlterField'])
        value = changes['testapp'][0].operations[0].field.upload_to
        self.assertEqual(
            (_content_file_name, ('file',), {'spam': 'eggs'}),
            (value.func, value.args, value.keywords)
        )

    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_alteration',
                side_effect=AssertionError(""Should not have prompted for not null addition""))
    def test_alter_field_to_not_null_with_default(self, mocked_ask_method):
        """"""
        #23609 - Tests autodetection of nullable to non-nullable alterations.
        """"""
        changes = self.get_changes([self.author_name_null], [self.author_name_default])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AlterField""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""name"", preserve_default=True)
        self.assertOperationFieldAttributes(changes, ""testapp"", 0, 0, default='Ada Lovelace')

    @mock.patch(
        'django.db.migrations.questioner.MigrationQuestioner.ask_not_null_alteration',
        return_value=models.NOT_PROVIDED,
    )
    def test_alter_field_to_not_null_without_default(self, mocked_ask_method):
        """"""
        #23609 - Tests autodetection of nullable to non-nullable alterations.
        """"""
        changes = self.get_changes([self.author_name_null], [self.author_name])
        self.assertEqual(mocked_ask_method.call_count, 1)
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AlterField""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""name"", preserve_default=True)
        self.assertOperationFieldAttributes(changes, ""testapp"", 0, 0, default=models.NOT_PROVIDED)

    @mock.patch(
        'django.db.migrations.questioner.MigrationQuestioner.ask_not_null_alteration',
        return_value='Some Name',
    )
    def test_alter_field_to_not_null_oneoff_default(self, mocked_ask_method):
        """"""
        #23609 - Tests autodetection of nullable to non-nullable alterations.
        """"""
        changes = self.get_changes([self.author_name_null], [self.author_name])
        self.assertEqual(mocked_ask_method.call_count, 1)
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AlterField""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""name"", preserve_default=False)
        self.assertOperationFieldAttributes(changes, ""testapp"", 0, 0, default=""Some Name"")

    def test_rename_field(self):
        """"""Tests autodetection of renamed fields.""""""
        changes = self.get_changes(
            [self.author_name], [self.author_name_renamed], MigrationQuestioner({""ask_rename"": True})
        )
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""RenameField""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name=""name"", new_name=""names"")

    def test_rename_field_foreign_key_to_field(self):
        before = [
            ModelState('app', 'Foo', [
                ('id', models.AutoField(primary_key=True)),
                ('field', models.IntegerField(unique=True)),
            ]),
            ModelState('app', 'Bar', [
                ('id', models.AutoField(primary_key=True)),
                ('foo', models.ForeignKey('app.Foo', models.CASCADE, to_field='field')),
            ]),
        ]
        after = [
            ModelState('app', 'Foo', [
                ('id', models.AutoField(primary_key=True)),
                ('renamed_field', models.IntegerField(unique=True)),
            ]),
            ModelState('app', 'Bar', [
                ('id', models.AutoField(primary_key=True)),
                ('foo', models.ForeignKey('app.Foo', models.CASCADE, to_field='renamed_field')),
            ]),
        ]
        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'app', 1)
        self.assertOperationTypes(changes, 'app', 0, ['RenameField'])
        self.assertOperationAttributes(changes, 'app', 0, 0, old_name='field', new_name='renamed_field')

    def test_rename_foreign_object_fields(self):
        fields = ('first', 'second')
        renamed_fields = ('first_renamed', 'second_renamed')
        before = [
            ModelState('app', 'Foo', [
                ('id', models.AutoField(primary_key=True)),
                ('first', models.IntegerField()),
                ('second', models.IntegerField()),
            ], options={'unique_together': {fields}}),
            ModelState('app', 'Bar', [
                ('id', models.AutoField(primary_key=True)),
                ('first', models.IntegerField()),
                ('second', models.IntegerField()),
                ('foo', models.ForeignObject(
                    'app.Foo', models.CASCADE, from_fields=fields, to_fields=fields,
                )),
            ]),
        ]
        # Case 1: to_fields renames.
        after = [
            ModelState('app', 'Foo', [
                ('id', models.AutoField(primary_key=True)),
                ('first_renamed', models.IntegerField()),
                ('second_renamed', models.IntegerField()),
            ], options={'unique_together': {renamed_fields}}),
            ModelState('app', 'Bar', [
                ('id', models.AutoField(primary_key=True)),
                ('first', models.IntegerField()),
                ('second', models.IntegerField()),
                ('foo', models.ForeignObject(
                    'app.Foo', models.CASCADE, from_fields=fields, to_fields=renamed_fields,
                )),
            ]),
        ]
        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))
        self.assertNumberMigrations(changes, 'app', 1)
        self.assertOperationTypes(changes, 'app', 0, ['RenameField', 'RenameField', 'AlterUniqueTogether'])
        self.assertOperationAttributes(
            changes, 'app', 0, 0, model_name='foo', old_name='first', new_name='first_renamed',
        )
        self.assertOperationAttributes(
            changes, 'app', 0, 1, model_name='foo', old_name='second', new_name='second_renamed',
        )
        # Case 2: from_fields renames.
        after = [
            ModelState('app', 'Foo', [
                ('id', models.AutoField(primary_key=True)),
                ('first', models.IntegerField()),
                ('second', models.IntegerField()),
            ], options={'unique_together': {fields}}),
            ModelState('app', 'Bar', [
                ('id', models.AutoField(primary_key=True)),
                ('first_renamed', models.IntegerField()),
                ('second_renamed', models.IntegerField()),
                ('foo', models.ForeignObject(
                    'app.Foo', models.CASCADE, from_fields=renamed_fields, to_fields=fields,
                )),
            ]),
        ]
        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))
        self.assertNumberMigrations(changes, 'app', 1)
        self.assertOperationTypes(changes, 'app', 0, ['RenameField', 'RenameField'])
        self.assertOperationAttributes(
            changes, 'app', 0, 0, model_name='bar', old_name='first', new_name='first_renamed',
        )
        self.assertOperationAttributes(
            changes, 'app', 0, 1, model_name='bar', old_name='second', new_name='second_renamed',
        )

    def test_rename_referenced_primary_key(self):
        before = [
            ModelState('app', 'Foo', [
                ('id', models.CharField(primary_key=True, serialize=False)),
            ]),
            ModelState('app', 'Bar', [
                ('id', models.AutoField(primary_key=True)),
                ('foo', models.ForeignKey('app.Foo', models.CASCADE)),
            ]),
        ]
        after = [
            ModelState('app', 'Foo', [
                ('renamed_id', models.CharField(primary_key=True, serialize=False))
            ]),
            ModelState('app', 'Bar', [
                ('id', models.AutoField(primary_key=True)),
                ('foo', models.ForeignKey('app.Foo', models.CASCADE)),
            ]),
        ]
        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))
        self.assertNumberMigrations(changes, 'app', 1)
        self.assertOperationTypes(changes, 'app', 0, ['RenameField'])
        self.assertOperationAttributes(changes, 'app', 0, 0, old_name='id', new_name='renamed_id')

    def test_rename_field_preserved_db_column(self):
        """"""
        RenameField is used if a field is renamed and db_column equal to the
        old field's column is added.
        """"""
        before = [
            ModelState('app', 'Foo', [
                ('id', models.AutoField(primary_key=True)),
                ('field', models.IntegerField()),
            ]),
        ]
        after = [
            ModelState('app', 'Foo', [
                ('id', models.AutoField(primary_key=True)),
                ('renamed_field', models.IntegerField(db_column='field')),
            ]),
        ]
        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))
        self.assertNumberMigrations(changes, 'app', 1)
        self.assertOperationTypes(changes, 'app', 0, ['AlterField', 'RenameField'])
        self.assertOperationAttributes(
            changes, 'app', 0, 0, model_name='foo', name='field',
        )
        self.assertEqual(changes['app'][0].operations[0].field.deconstruct(), (
            'field', 'django.db.models.IntegerField', [], {'db_column': 'field'},
        ))
        self.assertOperationAttributes(
            changes, 'app', 0, 1, model_name='foo', old_name='field',
            new_name='renamed_field',
        )

    def test_rename_related_field_preserved_db_column(self):
        before = [
            ModelState('app', 'Foo', [
                ('id', models.AutoField(primary_key=True)),
            ]),
            ModelState('app', 'Bar', [
                ('id', models.AutoField(primary_key=True)),
                ('foo', models.ForeignKey('app.Foo', models.CASCADE)),
            ]),
        ]
        after = [
            ModelState('app', 'Foo', [
                ('id', models.AutoField(primary_key=True)),
            ]),
            ModelState('app', 'Bar', [
                ('id', models.AutoField(primary_key=True)),
                ('renamed_foo', models.ForeignKey('app.Foo', models.CASCADE, db_column='foo_id')),
            ]),
        ]
        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))
        self.assertNumberMigrations(changes, 'app', 1)
        self.assertOperationTypes(changes, 'app', 0, ['AlterField', 'RenameField'])
        self.assertOperationAttributes(
            changes, 'app', 0, 0, model_name='bar', name='foo',
        )
        self.assertEqual(changes['app'][0].operations[0].field.deconstruct(), (
            'foo',
            'django.db.models.ForeignKey',
            [],
            {'to': 'app.foo', 'on_delete': models.CASCADE, 'db_column': 'foo_id'},
        ))
        self.assertOperationAttributes(
            changes, 'app', 0, 1, model_name='bar', old_name='foo',
            new_name='renamed_foo',
        )

    def test_rename_model(self):
        """"""Tests autodetection of renamed models.""""""
        changes = self.get_changes(
            [self.author_with_book, self.book],
            [self.author_renamed_with_book, self.book_with_author_renamed],
            MigrationQuestioner({""ask_rename_model"": True}),
        )
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""RenameModel""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name=""Author"", new_name=""Writer"")
        # Now that RenameModel handles related fields too, there should be
        # no AlterField for the related field.
        self.assertNumberMigrations(changes, 'otherapp', 0)

    def test_rename_model_case(self):
        """"""
        Model name is case-insensitive. Changing case doesn't lead to any
        autodetected operations.
        """"""
        author_renamed = ModelState('testapp', 'author', [
            ('id', models.AutoField(primary_key=True)),
        ])
        changes = self.get_changes(
            [self.author_empty, self.book],
            [author_renamed, self.book],
            questioner=MigrationQuestioner({'ask_rename_model': True}),
        )
        self.assertNumberMigrations(changes, 'testapp', 0)
        self.assertNumberMigrations(changes, 'otherapp', 0)

    def test_renamed_referenced_m2m_model_case(self):
        publisher_renamed = ModelState('testapp', 'publisher', [
            ('id', models.AutoField(primary_key=True)),
            ('name', models.CharField(max_length=100)),
        ])
        changes = self.get_changes(
            [self.publisher, self.author_with_m2m],
            [publisher_renamed, self.author_with_m2m],
            questioner=MigrationQuestioner({'ask_rename_model': True}),
        )
        self.assertNumberMigrations(changes, 'testapp', 0)
        self.assertNumberMigrations(changes, 'otherapp', 0)

    def test_rename_m2m_through_model(self):
        """"""
        Tests autodetection of renamed models that are used in M2M relations as
        through models.
        """"""
        changes = self.get_changes(
            [self.author_with_m2m_through, self.publisher, self.contract],
            [self.author_with_renamed_m2m_through, self.publisher, self.contract_renamed],
            MigrationQuestioner({'ask_rename_model': True})
        )
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, ['RenameModel'])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name='Contract', new_name='Deal')

    def test_rename_model_with_renamed_rel_field(self):
        """"""
        Tests autodetection of renamed models while simultaneously renaming one
        of the fields that relate to the renamed model.
        """"""
        changes = self.get_changes(
            [self.author_with_book, self.book],
            [self.author_renamed_with_book, self.book_with_field_and_author_renamed],
            MigrationQuestioner({""ask_rename"": True, ""ask_rename_model"": True}),
        )
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""RenameModel""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name=""Author"", new_name=""Writer"")
        # Right number/type of migrations for related field rename?
        # Alter is already taken care of.
        self.assertNumberMigrations(changes, 'otherapp', 1)
        self.assertOperationTypes(changes, 'otherapp', 0, [""RenameField""])
        self.assertOperationAttributes(changes, 'otherapp', 0, 0, old_name=""author"", new_name=""writer"")

    def test_rename_model_with_fks_in_different_position(self):
        """"""
        #24537 - The order of fields in a model does not influence
        the RenameModel detection.
        """"""
        before = [
            ModelState(""testapp"", ""EntityA"", [
                (""id"", models.AutoField(primary_key=True)),
            ]),
            ModelState(""testapp"", ""EntityB"", [
                (""id"", models.AutoField(primary_key=True)),
                (""some_label"", models.CharField(max_length=255)),
                (""entity_a"", models.ForeignKey(""testapp.EntityA"", models.CASCADE)),
            ]),
        ]
        after = [
            ModelState(""testapp"", ""EntityA"", [
                (""id"", models.AutoField(primary_key=True)),
            ]),
            ModelState(""testapp"", ""RenamedEntityB"", [
                (""id"", models.AutoField(primary_key=True)),
                (""entity_a"", models.ForeignKey(""testapp.EntityA"", models.CASCADE)),
                (""some_label"", models.CharField(max_length=255)),
            ]),
        ]
        changes = self.get_changes(before, after, MigrationQuestioner({""ask_rename_model"": True}))
        self.assertNumberMigrations(changes, ""testapp"", 1)
        self.assertOperationTypes(changes, ""testapp"", 0, [""RenameModel""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, old_name=""EntityB"", new_name=""RenamedEntityB"")

    def test_rename_model_reverse_relation_dependencies(self):
        """"""
        The migration to rename a model pointed to by a foreign key in another
        app must run after the other app's migration that adds the foreign key
        with model's original name. Therefore, the renaming migration has a
        dependency on that other migration.
        """"""
        before = [
            ModelState('testapp', 'EntityA', [
                ('id', models.AutoField(primary_key=True)),
            ]),
            ModelState('otherapp', 'EntityB', [
                ('id', models.AutoField(primary_key=True)),
                ('entity_a', models.ForeignKey('testapp.EntityA', models.CASCADE)),
            ]),
        ]
        after = [
            ModelState('testapp', 'RenamedEntityA', [
                ('id', models.AutoField(primary_key=True)),
            ]),
            ModelState('otherapp', 'EntityB', [
                ('id', models.AutoField(primary_key=True)),
                ('entity_a', models.ForeignKey('testapp.RenamedEntityA', models.CASCADE)),
            ]),
        ]
        changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename_model': True}))
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertMigrationDependencies(changes, 'testapp', 0, [('otherapp', '__first__')])
        self.assertOperationTypes(changes, 'testapp', 0, ['RenameModel'])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name='EntityA', new_name='RenamedEntityA')

    def test_fk_dependency(self):
        """"""Having a ForeignKey automatically adds a dependency.""""""
        # Note that testapp (author) has no dependencies,
        # otherapp (book) depends on testapp (author),
        # thirdapp (edition) depends on otherapp (book)
        changes = self.get_changes([], [self.author_name, self.book, self.edition])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""CreateModel""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""Author"")
        self.assertMigrationDependencies(changes, 'testapp', 0, [])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'otherapp', 1)
        self.assertOperationTypes(changes, 'otherapp', 0, [""CreateModel""])
        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=""Book"")
        self.assertMigrationDependencies(changes, 'otherapp', 0, [(""testapp"", ""auto_1"")])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'thirdapp', 1)
        self.assertOperationTypes(changes, 'thirdapp', 0, [""CreateModel""])
        self.assertOperationAttributes(changes, 'thirdapp', 0, 0, name=""Edition"")
        self.assertMigrationDependencies(changes, 'thirdapp', 0, [(""otherapp"", ""auto_1"")])

    def test_proxy_fk_dependency(self):
        """"""FK dependencies still work on proxy models.""""""
        # Note that testapp (author) has no dependencies,
        # otherapp (book) depends on testapp (authorproxy)
        changes = self.get_changes([], [self.author_empty, self.author_proxy_third, self.book_proxy_fk])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""CreateModel""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""Author"")
        self.assertMigrationDependencies(changes, 'testapp', 0, [])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'otherapp', 1)
        self.assertOperationTypes(changes, 'otherapp', 0, [""CreateModel""])
        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=""Book"")
        self.assertMigrationDependencies(changes, 'otherapp', 0, [(""thirdapp"", ""auto_1"")])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'thirdapp', 1)
        self.assertOperationTypes(changes, 'thirdapp', 0, [""CreateModel""])
        self.assertOperationAttributes(changes, 'thirdapp', 0, 0, name=""AuthorProxy"")
        self.assertMigrationDependencies(changes, 'thirdapp', 0, [(""testapp"", ""auto_1"")])

    def test_same_app_no_fk_dependency(self):
        """"""
        A migration with a FK between two models of the same app
        does not have a dependency to itself.
        """"""
        changes = self.get_changes([], [self.author_with_publisher, self.publisher])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""CreateModel"", ""CreateModel""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""Publisher"")
        self.assertOperationAttributes(changes, ""testapp"", 0, 1, name=""Author"")
        self.assertMigrationDependencies(changes, 'testapp', 0, [])

    def test_circular_fk_dependency(self):
        """"""
        Having a circular ForeignKey dependency automatically
        resolves the situation into 2 migrations on one side and 1 on the other.
        """"""
        changes = self.get_changes([], [self.author_with_book, self.book, self.publisher_with_book])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""CreateModel"", ""CreateModel""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""Publisher"")
        self.assertOperationAttributes(changes, ""testapp"", 0, 1, name=""Author"")
        self.assertMigrationDependencies(changes, 'testapp', 0, [(""otherapp"", ""auto_1"")])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'otherapp', 2)
        self.assertOperationTypes(changes, 'otherapp', 0, [""CreateModel""])
        self.assertOperationTypes(changes, 'otherapp', 1, [""AddField""])
        self.assertMigrationDependencies(changes, 'otherapp', 0, [])
        self.assertMigrationDependencies(changes, 'otherapp', 1, [(""otherapp"", ""auto_1""), (""testapp"", ""auto_1"")])
        # both split migrations should be `initial`
        self.assertTrue(changes['otherapp'][0].initial)
        self.assertTrue(changes['otherapp'][1].initial)

    def test_same_app_circular_fk_dependency(self):
        """"""
        A migration with a FK between two models of the same app does
        not have a dependency to itself.
        """"""
        changes = self.get_changes([], [self.author_with_publisher, self.publisher_with_author])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""CreateModel"", ""CreateModel"", ""AddField""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""Author"")
        self.assertOperationAttributes(changes, ""testapp"", 0, 1, name=""Publisher"")
        self.assertOperationAttributes(changes, ""testapp"", 0, 2, name=""publisher"")
        self.assertMigrationDependencies(changes, 'testapp', 0, [])

    def test_same_app_circular_fk_dependency_with_unique_together_and_indexes(self):
        """"""
        #22275 - A migration with circular FK dependency does not try
        to create unique together constraint and indexes before creating all
        required fields first.
        """"""
        changes = self.get_changes([], [self.knight, self.rabbit])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'eggs', 1)
        self.assertOperationTypes(
            changes, 'eggs', 0, [""CreateModel"", ""CreateModel"", ""AddIndex"", ""AlterUniqueTogether""]
        )
        self.assertNotIn(""unique_together"", changes['eggs'][0].operations[0].options)
        self.assertNotIn(""unique_together"", changes['eggs'][0].operations[1].options)
        self.assertMigrationDependencies(changes, 'eggs', 0, [])

    def test_alter_db_table_add(self):
        """"""Tests detection for adding db_table in model's options.""""""
        changes = self.get_changes([self.author_empty], [self.author_with_db_table_options])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AlterModelTable""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""author"", table=""author_one"")

    def test_alter_db_table_change(self):
        """"""Tests detection for changing db_table in model's options'.""""""
        changes = self.get_changes([self.author_with_db_table_options], [self.author_with_new_db_table_options])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AlterModelTable""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""author"", table=""author_two"")

    def test_alter_db_table_remove(self):
        """"""Tests detection for removing db_table in model's options.""""""
        changes = self.get_changes([self.author_with_db_table_options], [self.author_empty])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AlterModelTable""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""author"", table=None)

    def test_alter_db_table_no_changes(self):
        """"""
        Alter_db_table doesn't generate a migration if no changes have been made.
        """"""
        changes = self.get_changes([self.author_with_db_table_options], [self.author_with_db_table_options])
        # Right number of migrations?
        self.assertEqual(len(changes), 0)

    def test_keep_db_table_with_model_change(self):
        """"""
        Tests when model changes but db_table stays as-is, autodetector must not
        create more than one operation.
        """"""
        changes = self.get_changes(
            [self.author_with_db_table_options],
            [self.author_renamed_with_db_table_options],
            MigrationQuestioner({""ask_rename_model"": True}),
        )
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""RenameModel""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, old_name=""Author"", new_name=""NewAuthor"")

    def test_alter_db_table_with_model_change(self):
        """"""
        Tests when model and db_table changes, autodetector must create two
        operations.
        """"""
        changes = self.get_changes(
            [self.author_with_db_table_options],
            [self.author_renamed_with_new_db_table_options],
            MigrationQuestioner({""ask_rename_model"": True}),
        )
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""RenameModel"", ""AlterModelTable""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, old_name=""Author"", new_name=""NewAuthor"")
        self.assertOperationAttributes(changes, ""testapp"", 0, 1, name=""newauthor"", table=""author_three"")

    def test_identical_regex_doesnt_alter(self):
        from_state = ModelState(
            ""testapp"", ""model"", [(""id"", models.AutoField(primary_key=True, validators=[
                RegexValidator(
                    re.compile('^[-a-zA-Z0-9_]+\\Z'),
                    'Enter a valid “slug” consisting of letters, numbers, underscores or hyphens.',
                    'invalid'
                )
            ]))]
        )
        to_state = ModelState(
            ""testapp"", ""model"", [(""id"", models.AutoField(primary_key=True, validators=[validate_slug]))]
        )
        changes = self.get_changes([from_state], [to_state])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""testapp"", 0)

    def test_different_regex_does_alter(self):
        from_state = ModelState(
            ""testapp"", ""model"", [(""id"", models.AutoField(primary_key=True, validators=[
                RegexValidator(
                    re.compile('^[a-z]+\\Z', 32),
                    'Enter a valid “slug” consisting of letters, numbers, underscores or hyphens.',
                    'invalid'
                )
            ]))]
        )
        to_state = ModelState(
            ""testapp"", ""model"", [(""id"", models.AutoField(primary_key=True, validators=[validate_slug]))]
        )
        changes = self.get_changes([from_state], [to_state])
        self.assertNumberMigrations(changes, ""testapp"", 1)
        self.assertOperationTypes(changes, ""testapp"", 0, [""AlterField""])

    def test_empty_foo_together(self):
        """"""
        #23452 - Empty unique/index_together shouldn't generate a migration.
        """"""
        # Explicitly testing for not specified, since this is the case after
        # a CreateModel operation w/o any definition on the original model
        model_state_not_specified = ModelState(""a"", ""model"", [(""id"", models.AutoField(primary_key=True))])
        # Explicitly testing for None, since this was the issue in #23452 after
        # an AlterFooTogether operation with e.g. () as value
        model_state_none = ModelState(""a"", ""model"", [
            (""id"", models.AutoField(primary_key=True))
        ], {
            ""index_together"": None,
            ""unique_together"": None,
        })
        # Explicitly testing for the empty set, since we now always have sets.
        # During removal (('col1', 'col2'),) --> () this becomes set([])
        model_state_empty = ModelState(""a"", ""model"", [
            (""id"", models.AutoField(primary_key=True))
        ], {
            ""index_together"": set(),
            ""unique_together"": set(),
        })

        def test(from_state, to_state, msg):
            changes = self.get_changes([from_state], [to_state])
            if changes:
                ops = ', '.join(o.__class__.__name__ for o in changes['a'][0].operations)
                self.fail('Created operation(s) %s from %s' % (ops, msg))

        tests = (
            (model_state_not_specified, model_state_not_specified, '""not specified"" to ""not specified""'),
            (model_state_not_specified, model_state_none, '""not specified"" to ""None""'),
            (model_state_not_specified, model_state_empty, '""not specified"" to ""empty""'),
            (model_state_none, model_state_not_specified, '""None"" to ""not specified""'),
            (model_state_none, model_state_none, '""None"" to ""None""'),
            (model_state_none, model_state_empty, '""None"" to ""empty""'),
            (model_state_empty, model_state_not_specified, '""empty"" to ""not specified""'),
            (model_state_empty, model_state_none, '""empty"" to ""None""'),
            (model_state_empty, model_state_empty, '""empty"" to ""empty""'),
        )

        for t in tests:
            test(*t)

    def test_create_model_with_indexes(self):
        """"""Test creation of new model with indexes already defined.""""""
        author = ModelState('otherapp', 'Author', [
            ('id', models.AutoField(primary_key=True)),
            ('name', models.CharField(max_length=200)),
        ], {'indexes': [models.Index(fields=['name'], name='create_model_with_indexes_idx')]})
        changes = self.get_changes([], [author])
        added_index = models.Index(fields=['name'], name='create_model_with_indexes_idx')
        # Right number of migrations?
        self.assertEqual(len(changes['otherapp']), 1)
        # Right number of actions?
        migration = changes['otherapp'][0]
        self.assertEqual(len(migration.operations), 2)
        # Right actions order?
        self.assertOperationTypes(changes, 'otherapp', 0, ['CreateModel', 'AddIndex'])
        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='Author')
        self.assertOperationAttributes(changes, 'otherapp', 0, 1, model_name='author', index=added_index)

    def test_add_indexes(self):
        """"""Test change detection of new indexes.""""""
        changes = self.get_changes([self.author_empty, self.book], [self.author_empty, self.book_indexes])
        self.assertNumberMigrations(changes, 'otherapp', 1)
        self.assertOperationTypes(changes, 'otherapp', 0, ['AddIndex'])
        added_index = models.Index(fields=['author', 'title'], name='book_title_author_idx')
        self.assertOperationAttributes(changes, 'otherapp', 0, 0, model_name='book', index=added_index)

    def test_remove_indexes(self):
        """"""Test change detection of removed indexes.""""""
        changes = self.get_changes([self.author_empty, self.book_indexes], [self.author_empty, self.book])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'otherapp', 1)
        self.assertOperationTypes(changes, 'otherapp', 0, ['RemoveIndex'])
        self.assertOperationAttributes(changes, 'otherapp', 0, 0, model_name='book', name='book_title_author_idx')

    def test_order_fields_indexes(self):
        """"""Test change detection of reordering of fields in indexes.""""""
        changes = self.get_changes(
            [self.author_empty, self.book_indexes], [self.author_empty, self.book_unordered_indexes]
        )
        self.assertNumberMigrations(changes, 'otherapp', 1)
        self.assertOperationTypes(changes, 'otherapp', 0, ['RemoveIndex', 'AddIndex'])
        self.assertOperationAttributes(changes, 'otherapp', 0, 0, model_name='book', name='book_title_author_idx')
        added_index = models.Index(fields=['title', 'author'], name='book_author_title_idx')
        self.assertOperationAttributes(changes, 'otherapp', 0, 1, model_name='book', index=added_index)

    def test_create_model_with_check_constraint(self):
        """"""Test creation of new model with constraints already defined.""""""
        author = ModelState('otherapp', 'Author', [
            ('id', models.AutoField(primary_key=True)),
            ('name', models.CharField(max_length=200)),
        ], {'constraints': [models.CheckConstraint(check=models.Q(name__contains='Bob'), name='name_contains_bob')]})
        changes = self.get_changes([], [author])
        added_constraint = models.CheckConstraint(check=models.Q(name__contains='Bob'), name='name_contains_bob')
        # Right number of migrations?
        self.assertEqual(len(changes['otherapp']), 1)
        # Right number of actions?
        migration = changes['otherapp'][0]
        self.assertEqual(len(migration.operations), 2)
        # Right actions order?
        self.assertOperationTypes(changes, 'otherapp', 0, ['CreateModel', 'AddConstraint'])
        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='Author')
        self.assertOperationAttributes(changes, 'otherapp', 0, 1, model_name='author', constraint=added_constraint)

    def test_add_constraints(self):
        """"""Test change detection of new constraints.""""""
        changes = self.get_changes([self.author_name], [self.author_name_check_constraint])
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, ['AddConstraint'])
        added_constraint = models.CheckConstraint(check=models.Q(name__contains='Bob'), name='name_contains_bob')
        self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name='author', constraint=added_constraint)

    def test_remove_constraints(self):
        """"""Test change detection of removed constraints.""""""
        changes = self.get_changes([self.author_name_check_constraint], [self.author_name])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, ['RemoveConstraint'])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name='author', name='name_contains_bob')

    def test_add_foo_together(self):
        """"""Tests index/unique_together detection.""""""
        changes = self.get_changes([self.author_empty, self.book], [self.author_empty, self.book_foo_together])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""otherapp"", 1)
        self.assertOperationTypes(changes, ""otherapp"", 0, [""AlterUniqueTogether"", ""AlterIndexTogether""])
        self.assertOperationAttributes(changes, ""otherapp"", 0, 0, name=""book"", unique_together={(""author"", ""title"")})
        self.assertOperationAttributes(changes, ""otherapp"", 0, 1, name=""book"", index_together={(""author"", ""title"")})

    def test_remove_foo_together(self):
        """"""Tests index/unique_together detection.""""""
        changes = self.get_changes([self.author_empty, self.book_foo_together], [self.author_empty, self.book])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""otherapp"", 1)
        self.assertOperationTypes(changes, ""otherapp"", 0, [""AlterUniqueTogether"", ""AlterIndexTogether""])
        self.assertOperationAttributes(changes, ""otherapp"", 0, 0, name=""book"", unique_together=set())
        self.assertOperationAttributes(changes, ""otherapp"", 0, 1, name=""book"", index_together=set())

    def test_foo_together_remove_fk(self):
        """"""Tests unique_together and field removal detection & ordering""""""
        changes = self.get_changes(
            [self.author_empty, self.book_foo_together], [self.author_empty, self.book_with_no_author]
        )
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""otherapp"", 1)
        self.assertOperationTypes(changes, ""otherapp"", 0, [
            ""AlterUniqueTogether"", ""AlterIndexTogether"", ""RemoveField""
        ])
        self.assertOperationAttributes(changes, ""otherapp"", 0, 0, name=""book"", unique_together=set())
        self.assertOperationAttributes(changes, ""otherapp"", 0, 1, name=""book"", index_together=set())
        self.assertOperationAttributes(changes, ""otherapp"", 0, 2, model_name=""book"", name=""author"")

    def test_foo_together_no_changes(self):
        """"""
        index/unique_together doesn't generate a migration if no
        changes have been made.
        """"""
        changes = self.get_changes(
            [self.author_empty, self.book_foo_together], [self.author_empty, self.book_foo_together]
        )
        # Right number of migrations?
        self.assertEqual(len(changes), 0)

    def test_foo_together_ordering(self):
        """"""
        index/unique_together also triggers on ordering changes.
        """"""
        changes = self.get_changes(
            [self.author_empty, self.book_foo_together], [self.author_empty, self.book_foo_together_2]
        )
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""otherapp"", 1)
        self.assertOperationTypes(changes, 'otherapp', 0, [
            'AlterUniqueTogether',
            'AlterIndexTogether',
            'AlterUniqueTogether',
            'AlterIndexTogether',
        ])
        self.assertOperationAttributes(
            changes, 'otherapp', 0, 0, name='book', unique_together=set(),
        )
        self.assertOperationAttributes(
            changes, 'otherapp', 0, 1, name='book', index_together=set(),
        )
        self.assertOperationAttributes(
            changes, 'otherapp', 0, 2, name='book',
            unique_together={('title', 'author')},
        )
        self.assertOperationAttributes(
            changes, 'otherapp', 0, 3, name='book',
            index_together={('title', 'author')},
        )

    def test_add_field_and_foo_together(self):
        """"""
        Added fields will be created before using them in index/unique_together.
        """"""
        changes = self.get_changes([self.author_empty, self.book], [self.author_empty, self.book_foo_together_3])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""otherapp"", 1)
        self.assertOperationTypes(changes, ""otherapp"", 0, [""AddField"", ""AlterUniqueTogether"", ""AlterIndexTogether""])
        self.assertOperationAttributes(changes, ""otherapp"", 0, 1, name=""book"", unique_together={(""title"", ""newfield"")})
        self.assertOperationAttributes(changes, ""otherapp"", 0, 2, name=""book"", index_together={(""title"", ""newfield"")})

    def test_create_model_and_unique_together(self):
        author = ModelState(""otherapp"", ""Author"", [
            (""id"", models.AutoField(primary_key=True)),
            (""name"", models.CharField(max_length=200)),
        ])
        book_with_author = ModelState(""otherapp"", ""Book"", [
            (""id"", models.AutoField(primary_key=True)),
            (""author"", models.ForeignKey(""otherapp.Author"", models.CASCADE)),
            (""title"", models.CharField(max_length=200)),
        ], {
            ""index_together"": {(""title"", ""author"")},
            ""unique_together"": {(""title"", ""author"")},
        })
        changes = self.get_changes([self.book_with_no_author], [author, book_with_author])
        # Right number of migrations?
        self.assertEqual(len(changes['otherapp']), 1)
        # Right number of actions?
        migration = changes['otherapp'][0]
        self.assertEqual(len(migration.operations), 4)
        # Right actions order?
        self.assertOperationTypes(
            changes, 'otherapp', 0,
            ['CreateModel', 'AddField', 'AlterUniqueTogether', 'AlterIndexTogether']
        )

    def test_remove_field_and_foo_together(self):
        """"""
        Removed fields will be removed after updating index/unique_together.
        """"""
        changes = self.get_changes(
            [self.author_empty, self.book_foo_together_3], [self.author_empty, self.book_foo_together]
        )
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""otherapp"", 1)
        self.assertOperationTypes(changes, 'otherapp', 0, [
            'AlterUniqueTogether',
            'AlterIndexTogether',
            'AlterUniqueTogether',
            'AlterIndexTogether',
            'RemoveField',
        ])
        self.assertOperationAttributes(
            changes, 'otherapp', 0, 0, name='book', unique_together=set(),
        )
        self.assertOperationAttributes(
            changes, 'otherapp', 0, 1, name='book', index_together=set(),
        )
        self.assertOperationAttributes(
            changes, 'otherapp', 0, 2, name='book',
            unique_together={('author', 'title')},
        )
        self.assertOperationAttributes(
            changes, 'otherapp', 0, 3, name='book',
            index_together={('author', 'title')},
        )
        self.assertOperationAttributes(
            changes, 'otherapp', 0, 4, model_name='book', name='newfield',
        )

    def test_alter_field_and_foo_together(self):
        """"""Fields are altered after deleting some index/unique_together.""""""
        initial_author = ModelState('testapp', 'Author', [
            ('id', models.AutoField(primary_key=True)),
            ('name', models.CharField(max_length=200)),
            ('age', models.IntegerField(db_index=True)),
        ], {
            'unique_together': {('name',)},
        })
        author_reversed_constraints = ModelState('testapp', 'Author', [
            ('id', models.AutoField(primary_key=True)),
            ('name', models.CharField(max_length=200, unique=True)),
            ('age', models.IntegerField()),
        ], {
            'index_together': {('age',)},
        })
        changes = self.get_changes([initial_author], [author_reversed_constraints])

        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [
            'AlterUniqueTogether',
            'AlterField',
            'AlterField',
            'AlterIndexTogether',
        ])
        self.assertOperationAttributes(
            changes, 'testapp', 0, 0, name='author', unique_together=set(),
        )
        self.assertOperationAttributes(
            changes, 'testapp', 0, 1, model_name='author', name='age',
        )
        self.assertOperationAttributes(
            changes, 'testapp', 0, 2, model_name='author', name='name',
        )
        self.assertOperationAttributes(
            changes, 'testapp', 0, 3, name='author', index_together={('age',)},
        )

    def test_partly_alter_foo_together(self):
        initial_author = ModelState('testapp', 'Author', [
            ('id', models.AutoField(primary_key=True)),
            ('name', models.CharField(max_length=200)),
            ('age', models.IntegerField()),
        ], {
            'unique_together': {('name',), ('age',)},
            'index_together': {('name',)},
        })
        author_reversed_constraints = ModelState('testapp', 'Author', [
            ('id', models.AutoField(primary_key=True)),
            ('name', models.CharField(max_length=200)),
            ('age', models.IntegerField()),
        ], {
            'unique_together': {('age',)},
            'index_together': {('name',), ('age',)},
        })
        changes = self.get_changes([initial_author], [author_reversed_constraints])

        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [
            'AlterUniqueTogether',
            'AlterIndexTogether',
        ])
        self.assertOperationAttributes(
            changes, 'testapp', 0, 0, name='author', unique_together={('age',)},
        )
        self.assertOperationAttributes(
            changes, 'testapp', 0, 1, name='author',
            index_together={('name',), ('age',)},
        )

    def test_rename_field_and_foo_together(self):
        """"""Fields are renamed before updating index/unique_together.""""""
        changes = self.get_changes(
            [self.author_empty, self.book_foo_together_3],
            [self.author_empty, self.book_foo_together_4],
            MigrationQuestioner({""ask_rename"": True}),
        )
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""otherapp"", 1)
        self.assertOperationTypes(changes, 'otherapp', 0, [
            'RenameField',
            'AlterUniqueTogether',
            'AlterIndexTogether',
            'AlterUniqueTogether',
            'AlterIndexTogether',
        ])
        self.assertOperationAttributes(
            changes, 'otherapp', 0, 1, name='book', unique_together=set(),
        )
        self.assertOperationAttributes(
            changes, 'otherapp', 0, 2, name='book', index_together=set(),
        )
        self.assertOperationAttributes(
            changes, 'otherapp', 0, 3, name='book',
            unique_together={('title', 'newfield2')},
        )
        self.assertOperationAttributes(
            changes, 'otherapp', 0, 4, name='book',
            index_together={('title', 'newfield2')},
        )

    def test_proxy(self):
        """"""The autodetector correctly deals with proxy models.""""""
        # First, we test adding a proxy model
        changes = self.get_changes([self.author_empty], [self.author_empty, self.author_proxy])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""testapp"", 1)
        self.assertOperationTypes(changes, ""testapp"", 0, [""CreateModel""])
        self.assertOperationAttributes(
            changes, ""testapp"", 0, 0, name=""AuthorProxy"", options={""proxy"": True, ""indexes"": [], ""constraints"": []}
        )
        # Now, we test turning a proxy model into a non-proxy model
        # It should delete the proxy then make the real one
        changes = self.get_changes(
            [self.author_empty, self.author_proxy], [self.author_empty, self.author_proxy_notproxy]
        )
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""testapp"", 1)
        self.assertOperationTypes(changes, ""testapp"", 0, [""DeleteModel"", ""CreateModel""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""AuthorProxy"")
        self.assertOperationAttributes(changes, ""testapp"", 0, 1, name=""AuthorProxy"", options={})

    def test_proxy_non_model_parent(self):
        class Mixin:
            pass

        author_proxy_non_model_parent = ModelState(
            'testapp',
            'AuthorProxy',
            [],
            {'proxy': True},
            (Mixin, 'testapp.author'),
        )
        changes = self.get_changes(
            [self.author_empty],
            [self.author_empty, author_proxy_non_model_parent],
        )
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, ['CreateModel'])
        self.assertOperationAttributes(
            changes, 'testapp', 0, 0, name='AuthorProxy',
            options={'proxy': True, 'indexes': [], 'constraints': []},
            bases=(Mixin, 'testapp.author'),
        )

    def test_proxy_custom_pk(self):
        """"""
        #23415 - The autodetector must correctly deal with custom FK on proxy
        models.
        """"""
        # First, we test the default pk field name
        changes = self.get_changes([], [self.author_empty, self.author_proxy_third, self.book_proxy_fk])
        # The model the FK is pointing from and to.
        self.assertEqual(
            changes['otherapp'][0].operations[0].fields[2][1].remote_field.model,
            'thirdapp.AuthorProxy',
        )
        # Now, we test the custom pk field name
        changes = self.get_changes([], [self.author_custom_pk, self.author_proxy_third, self.book_proxy_fk])
        # The model the FK is pointing from and to.
        self.assertEqual(
            changes['otherapp'][0].operations[0].fields[2][1].remote_field.model,
            'thirdapp.AuthorProxy',
        )

    def test_proxy_to_mti_with_fk_to_proxy(self):
        # First, test the pk table and field name.
        to_state = self.make_project_state(
            [self.author_empty, self.author_proxy_third, self.book_proxy_fk],
        )
        changes = self.get_changes([], to_state)
        fk_field = changes['otherapp'][0].operations[0].fields[2][1]
        self.assertEqual(
            to_state.get_concrete_model_key(fk_field.remote_field.model),
            ('testapp', 'author'),
        )
        self.assertEqual(fk_field.remote_field.model, 'thirdapp.AuthorProxy')

        # Change AuthorProxy to use MTI.
        from_state = to_state.clone()
        to_state = self.make_project_state(
            [self.author_empty, self.author_proxy_third_notproxy, self.book_proxy_fk],
        )
        changes = self.get_changes(from_state, to_state)
        # Right number/type of migrations for the AuthorProxy model?
        self.assertNumberMigrations(changes, 'thirdapp', 1)
        self.assertOperationTypes(changes, 'thirdapp', 0, ['DeleteModel', 'CreateModel'])
        # Right number/type of migrations for the Book model with a FK to
        # AuthorProxy?
        self.assertNumberMigrations(changes, 'otherapp', 1)
        self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])
        # otherapp should depend on thirdapp.
        self.assertMigrationDependencies(changes, 'otherapp', 0, [('thirdapp', 'auto_1')])
        # Now, test the pk table and field name.
        fk_field = changes['otherapp'][0].operations[0].field
        self.assertEqual(
            to_state.get_concrete_model_key(fk_field.remote_field.model),
            ('thirdapp', 'authorproxy'),
        )
        self.assertEqual(fk_field.remote_field.model, 'thirdapp.AuthorProxy')

    def test_proxy_to_mti_with_fk_to_proxy_proxy(self):
        # First, test the pk table and field name.
        to_state = self.make_project_state([
            self.author_empty,
            self.author_proxy,
            self.author_proxy_proxy,
            self.book_proxy_proxy_fk,
        ])
        changes = self.get_changes([], to_state)
        fk_field = changes['otherapp'][0].operations[0].fields[1][1]
        self.assertEqual(
            to_state.get_concrete_model_key(fk_field.remote_field.model),
            ('testapp', 'author'),
        )
        self.assertEqual(fk_field.remote_field.model, 'testapp.AAuthorProxyProxy')

        # Change AuthorProxy to use MTI. FK still points to AAuthorProxyProxy,
        # a proxy of AuthorProxy.
        from_state = to_state.clone()
        to_state = self.make_project_state([
            self.author_empty,
            self.author_proxy_notproxy,
            self.author_proxy_proxy,
            self.book_proxy_proxy_fk,
        ])
        changes = self.get_changes(from_state, to_state)
        # Right number/type of migrations for the AuthorProxy model?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, ['DeleteModel', 'CreateModel'])
        # Right number/type of migrations for the Book model with a FK to
        # AAuthorProxyProxy?
        self.assertNumberMigrations(changes, 'otherapp', 1)
        self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])
        # otherapp should depend on testapp.
        self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', 'auto_1')])
        # Now, test the pk table and field name.
        fk_field = changes['otherapp'][0].operations[0].field
        self.assertEqual(
            to_state.get_concrete_model_key(fk_field.remote_field.model),
            ('testapp', 'authorproxy'),
        )
        self.assertEqual(fk_field.remote_field.model, 'testapp.AAuthorProxyProxy')

    def test_unmanaged_create(self):
        """"""The autodetector correctly deals with managed models.""""""
        # First, we test adding an unmanaged model
        changes = self.get_changes([self.author_empty], [self.author_empty, self.author_unmanaged])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""CreateModel""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""AuthorUnmanaged"", options={""managed"": False})

    def test_unmanaged_delete(self):
        changes = self.get_changes([self.author_empty, self.author_unmanaged], [self.author_empty])
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, ['DeleteModel'])

    def test_unmanaged_to_managed(self):
        # Now, we test turning an unmanaged model into a managed model
        changes = self.get_changes(
            [self.author_empty, self.author_unmanaged], [self.author_empty, self.author_unmanaged_managed]
        )
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AlterModelOptions""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""authorunmanaged"", options={})

    def test_managed_to_unmanaged(self):
        # Now, we turn managed to unmanaged.
        changes = self.get_changes(
            [self.author_empty, self.author_unmanaged_managed], [self.author_empty, self.author_unmanaged]
        )
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, ""testapp"", 0, [""AlterModelOptions""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""authorunmanaged"", options={""managed"": False})

    def test_unmanaged_custom_pk(self):
        """"""
        #23415 - The autodetector must correctly deal with custom FK on
        unmanaged models.
        """"""
        # First, we test the default pk field name
        changes = self.get_changes([], [self.author_unmanaged_default_pk, self.book])
        # The model the FK on the book model points to.
        fk_field = changes['otherapp'][0].operations[0].fields[2][1]
        self.assertEqual(fk_field.remote_field.model, 'testapp.Author')
        # Now, we test the custom pk field name
        changes = self.get_changes([], [self.author_unmanaged_custom_pk, self.book])
        # The model the FK on the book model points to.
        fk_field = changes['otherapp'][0].operations[0].fields[2][1]
        self.assertEqual(fk_field.remote_field.model, 'testapp.Author')

    @override_settings(AUTH_USER_MODEL=""thirdapp.CustomUser"")
    def test_swappable(self):
        with isolate_lru_cache(apps.get_swappable_settings_name):
            changes = self.get_changes([self.custom_user], [self.custom_user, self.author_with_custom_user])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""CreateModel""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""Author"")
        self.assertMigrationDependencies(changes, 'testapp', 0, [(""__setting__"", ""AUTH_USER_MODEL"")])

    def test_swappable_lowercase(self):
        model_state = ModelState('testapp', 'Document', [
            ('id', models.AutoField(primary_key=True)),
            ('owner', models.ForeignKey(
                settings.AUTH_USER_MODEL.lower(), models.CASCADE,
            )),
        ])
        with isolate_lru_cache(apps.get_swappable_settings_name):
            changes = self.get_changes([], [model_state])
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, ['CreateModel'])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Document')
        self.assertMigrationDependencies(
            changes, 'testapp', 0, [('__setting__', 'AUTH_USER_MODEL')],
        )

    def test_swappable_changed(self):
        with isolate_lru_cache(apps.get_swappable_settings_name):
            before = self.make_project_state([self.custom_user, self.author_with_user])
            with override_settings(AUTH_USER_MODEL=""thirdapp.CustomUser""):
                after = self.make_project_state([self.custom_user, self.author_with_custom_user])
            autodetector = MigrationAutodetector(before, after)
            changes = autodetector._detect_changes()
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AlterField""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name=""author"", name='user')
        fk_field = changes['testapp'][0].operations[0].field
        self.assertEqual(fk_field.remote_field.model, 'thirdapp.CustomUser')

    def test_add_field_with_default(self):
        """"""#22030 - Adding a field with a default should work.""""""
        changes = self.get_changes([self.author_empty], [self.author_name_default])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AddField""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""name"")

    def test_custom_deconstructible(self):
        """"""
        Two instances which deconstruct to the same value aren't considered a
        change.
        """"""
        changes = self.get_changes([self.author_name_deconstructible_1], [self.author_name_deconstructible_2])
        # Right number of migrations?
        self.assertEqual(len(changes), 0)

    def test_deconstruct_field_kwarg(self):
        """"""Field instances are handled correctly by nested deconstruction.""""""
        changes = self.get_changes([self.author_name_deconstructible_3], [self.author_name_deconstructible_4])
        self.assertEqual(changes, {})

    def test_deconstructible_list(self):
        """"""Nested deconstruction descends into lists.""""""
        # When lists contain items that deconstruct to identical values, those lists
        # should be considered equal for the purpose of detecting state changes
        # (even if the original items are unequal).
        changes = self.get_changes(
            [self.author_name_deconstructible_list_1], [self.author_name_deconstructible_list_2]
        )
        self.assertEqual(changes, {})
        # Legitimate differences within the deconstructed lists should be reported
        # as a change
        changes = self.get_changes(
            [self.author_name_deconstructible_list_1], [self.author_name_deconstructible_list_3]
        )
        self.assertEqual(len(changes), 1)

    def test_deconstructible_tuple(self):
        """"""Nested deconstruction descends into tuples.""""""
        # When tuples contain items that deconstruct to identical values, those tuples
        # should be considered equal for the purpose of detecting state changes
        # (even if the original items are unequal).
        changes = self.get_changes(
            [self.author_name_deconstructible_tuple_1], [self.author_name_deconstructible_tuple_2]
        )
        self.assertEqual(changes, {})
        # Legitimate differences within the deconstructed tuples should be reported
        # as a change
        changes = self.get_changes(
            [self.author_name_deconstructible_tuple_1], [self.author_name_deconstructible_tuple_3]
        )
        self.assertEqual(len(changes), 1)

    def test_deconstructible_dict(self):
        """"""Nested deconstruction descends into dict values.""""""
        # When dicts contain items whose values deconstruct to identical values,
        # those dicts should be considered equal for the purpose of detecting
        # state changes (even if the original values are unequal).
        changes = self.get_changes(
            [self.author_name_deconstructible_dict_1], [self.author_name_deconstructible_dict_2]
        )
        self.assertEqual(changes, {})
        # Legitimate differences within the deconstructed dicts should be reported
        # as a change
        changes = self.get_changes(
            [self.author_name_deconstructible_dict_1], [self.author_name_deconstructible_dict_3]
        )
        self.assertEqual(len(changes), 1)

    def test_nested_deconstructible_objects(self):
        """"""
        Nested deconstruction is applied recursively to the args/kwargs of
        deconstructed objects.
        """"""
        # If the items within a deconstructed object's args/kwargs have the same
        # deconstructed values - whether or not the items themselves are different
        # instances - then the object as a whole is regarded as unchanged.
        changes = self.get_changes(
            [self.author_name_nested_deconstructible_1], [self.author_name_nested_deconstructible_2]
        )
        self.assertEqual(changes, {})
        # Differences that exist solely within the args list of a deconstructed object
        # should be reported as changes
        changes = self.get_changes(
            [self.author_name_nested_deconstructible_1], [self.author_name_nested_deconstructible_changed_arg]
        )
        self.assertEqual(len(changes), 1)
        # Additional args should also be reported as a change
        changes = self.get_changes(
            [self.author_name_nested_deconstructible_1], [self.author_name_nested_deconstructible_extra_arg]
        )
        self.assertEqual(len(changes), 1)
        # Differences that exist solely within the kwargs dict of a deconstructed object
        # should be reported as changes
        changes = self.get_changes(
            [self.author_name_nested_deconstructible_1], [self.author_name_nested_deconstructible_changed_kwarg]
        )
        self.assertEqual(len(changes), 1)
        # Additional kwargs should also be reported as a change
        changes = self.get_changes(
            [self.author_name_nested_deconstructible_1], [self.author_name_nested_deconstructible_extra_kwarg]
        )
        self.assertEqual(len(changes), 1)

    def test_deconstruct_type(self):
        """"""
        #22951 -- Uninstantiated classes with deconstruct are correctly returned
        by deep_deconstruct during serialization.
        """"""
        author = ModelState(
            ""testapp"",
            ""Author"",
            [
                (""id"", models.AutoField(primary_key=True)),
                (""name"", models.CharField(
                    max_length=200,
                    # IntegerField intentionally not instantiated.
                    default=models.IntegerField,
                ))
            ],
        )
        changes = self.get_changes([], [author])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""CreateModel""])

    def test_replace_string_with_foreignkey(self):
        """"""
        #22300 - Adding an FK in the same ""spot"" as a deleted CharField should
        work.
        """"""
        changes = self.get_changes([self.author_with_publisher_string], [self.author_with_publisher, self.publisher])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""CreateModel"", ""RemoveField"", ""AddField""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""Publisher"")
        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=""publisher_name"")
        self.assertOperationAttributes(changes, 'testapp', 0, 2, name=""publisher"")

    def test_foreign_key_removed_before_target_model(self):
        """"""
        Removing an FK and the model it targets in the same change must remove
        the FK field before the model to maintain consistency.
        """"""
        changes = self.get_changes(
            [self.author_with_publisher, self.publisher], [self.author_name]
        )  # removes both the model and FK
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""RemoveField"", ""DeleteModel""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""publisher"")
        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=""Publisher"")

    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_addition',
                side_effect=AssertionError(""Should not have prompted for not null addition""))
    def test_add_many_to_many(self, mocked_ask_method):
        """"""#22435 - Adding a ManyToManyField should not prompt for a default.""""""
        changes = self.get_changes([self.author_empty, self.publisher], [self.author_with_m2m, self.publisher])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AddField""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""publishers"")

    def test_alter_many_to_many(self):
        changes = self.get_changes(
            [self.author_with_m2m, self.publisher], [self.author_with_m2m_blank, self.publisher]
        )
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AlterField""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""publishers"")

    def test_create_with_through_model(self):
        """"""
        Adding a m2m with a through model and the models that use it should be
        ordered correctly.
        """"""
        changes = self.get_changes([], [self.author_with_m2m_through, self.publisher, self.contract])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""testapp"", 1)
        self.assertOperationTypes(changes, ""testapp"", 0, [
            'CreateModel', 'CreateModel', 'CreateModel', 'AddField',
        ])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Author')
        self.assertOperationAttributes(changes, 'testapp', 0, 1, name='Publisher')
        self.assertOperationAttributes(changes, 'testapp', 0, 2, name='Contract')
        self.assertOperationAttributes(changes, 'testapp', 0, 3, model_name='author', name='publishers')

    def test_many_to_many_removed_before_through_model(self):
        """"""
        Removing a ManyToManyField and the ""through"" model in the same change
        must remove the field before the model to maintain consistency.
        """"""
        changes = self.get_changes(
            [self.book_with_multiple_authors_through_attribution, self.author_name, self.attribution],
            [self.book_with_no_author, self.author_name],
        )
        # Remove both the through model and ManyToMany
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""otherapp"", 1)
        self.assertOperationTypes(changes, 'otherapp', 0, ['RemoveField', 'DeleteModel'])
        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='authors', model_name='book')
        self.assertOperationAttributes(changes, 'otherapp', 0, 1, name='Attribution')

    def test_many_to_many_removed_before_through_model_2(self):
        """"""
        Removing a model that contains a ManyToManyField and the ""through"" model
        in the same change must remove the field before the model to maintain
        consistency.
        """"""
        changes = self.get_changes(
            [self.book_with_multiple_authors_through_attribution, self.author_name, self.attribution],
            [self.author_name],
        )
        # Remove both the through model and ManyToMany
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""otherapp"", 1)
        self.assertOperationTypes(changes, 'otherapp', 0, ['RemoveField', 'DeleteModel', 'DeleteModel'])
        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='authors', model_name='book')
        self.assertOperationAttributes(changes, 'otherapp', 0, 1, name='Attribution')
        self.assertOperationAttributes(changes, 'otherapp', 0, 2, name='Book')

    def test_m2m_w_through_multistep_remove(self):
        """"""
        A model with a m2m field that specifies a ""through"" model cannot be
        removed in the same migration as that through model as the schema will
        pass through an inconsistent state. The autodetector should produce two
        migrations to avoid this issue.
        """"""
        changes = self.get_changes([self.author_with_m2m_through, self.publisher, self.contract], [self.publisher])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""testapp"", 1)
        self.assertOperationTypes(changes, ""testapp"", 0, [
            ""RemoveField"", ""RemoveField"", ""DeleteModel"", ""DeleteModel""
        ])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""author"", model_name='contract')
        self.assertOperationAttributes(changes, ""testapp"", 0, 1, name=""publisher"", model_name='contract')
        self.assertOperationAttributes(changes, ""testapp"", 0, 2, name=""Author"")
        self.assertOperationAttributes(changes, ""testapp"", 0, 3, name=""Contract"")

    def test_concrete_field_changed_to_many_to_many(self):
        """"""
        #23938 - Changing a concrete field into a ManyToManyField
        first removes the concrete field and then adds the m2m field.
        """"""
        changes = self.get_changes([self.author_with_former_m2m], [self.author_with_m2m, self.publisher])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""testapp"", 1)
        self.assertOperationTypes(changes, ""testapp"", 0, [""CreateModel"", ""RemoveField"", ""AddField""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Publisher')
        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=""publishers"", model_name='author')
        self.assertOperationAttributes(changes, 'testapp', 0, 2, name=""publishers"", model_name='author')

    def test_many_to_many_changed_to_concrete_field(self):
        """"""
        #23938 - Changing a ManyToManyField into a concrete field
        first removes the m2m field and then adds the concrete field.
        """"""
        changes = self.get_changes([self.author_with_m2m, self.publisher], [self.author_with_former_m2m])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""testapp"", 1)
        self.assertOperationTypes(changes, ""testapp"", 0, [""RemoveField"", ""AddField"", ""DeleteModel""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""publishers"", model_name='author')
        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=""publishers"", model_name='author')
        self.assertOperationAttributes(changes, 'testapp', 0, 2, name='Publisher')
        self.assertOperationFieldAttributes(changes, 'testapp', 0, 1, max_length=100)

    def test_non_circular_foreignkey_dependency_removal(self):
        """"""
        If two models with a ForeignKey from one to the other are removed at the
        same time, the autodetector should remove them in the correct order.
        """"""
        changes = self.get_changes([self.author_with_publisher, self.publisher_with_author], [])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""testapp"", 1)
        self.assertOperationTypes(changes, ""testapp"", 0, [""RemoveField"", ""DeleteModel"", ""DeleteModel""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""author"", model_name='publisher')
        self.assertOperationAttributes(changes, ""testapp"", 0, 1, name=""Author"")
        self.assertOperationAttributes(changes, ""testapp"", 0, 2, name=""Publisher"")

    def test_alter_model_options(self):
        """"""Changing a model's options should make a change.""""""
        changes = self.get_changes([self.author_empty], [self.author_with_options])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""testapp"", 1)
        self.assertOperationTypes(changes, ""testapp"", 0, [""AlterModelOptions""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, options={
            ""permissions"": [('can_hire', 'Can hire')],
            ""verbose_name"": ""Authi"",
        })

        # Changing them back to empty should also make a change
        changes = self.get_changes([self.author_with_options], [self.author_empty])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""testapp"", 1)
        self.assertOperationTypes(changes, ""testapp"", 0, [""AlterModelOptions""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""author"", options={})

    def test_alter_model_options_proxy(self):
        """"""Changing a proxy model's options should also make a change.""""""
        changes = self.get_changes(
            [self.author_proxy, self.author_empty], [self.author_proxy_options, self.author_empty]
        )
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""testapp"", 1)
        self.assertOperationTypes(changes, ""testapp"", 0, [""AlterModelOptions""])
        self.assertOperationAttributes(changes, ""testapp"", 0, 0, name=""authorproxy"", options={
            ""verbose_name"": ""Super Author""
        })

    def test_set_alter_order_with_respect_to(self):
        """"""Setting order_with_respect_to adds a field.""""""
        changes = self.get_changes([self.book, self.author_with_book], [self.book, self.author_with_book_order_wrt])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AlterOrderWithRespectTo""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""author"", order_with_respect_to=""book"")

    def test_add_alter_order_with_respect_to(self):
        """"""
        Setting order_with_respect_to when adding the FK too does
        things in the right order.
        """"""
        changes = self.get_changes([self.author_name], [self.book, self.author_with_book_order_wrt])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AddField"", ""AlterOrderWithRespectTo""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name=""author"", name=""book"")
        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=""author"", order_with_respect_to=""book"")

    def test_remove_alter_order_with_respect_to(self):
        """"""
        Removing order_with_respect_to when removing the FK too does
        things in the right order.
        """"""
        changes = self.get_changes([self.book, self.author_with_book_order_wrt], [self.author_name])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AlterOrderWithRespectTo"", ""RemoveField""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""author"", order_with_respect_to=None)
        self.assertOperationAttributes(changes, 'testapp', 0, 1, model_name=""author"", name=""book"")

    def test_add_model_order_with_respect_to(self):
        """"""
        Setting order_with_respect_to when adding the whole model
        does things in the right order.
        """"""
        changes = self.get_changes([], [self.book, self.author_with_book_order_wrt])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""CreateModel""])
        self.assertOperationAttributes(
            changes, 'testapp', 0, 0, name=""Author"", options={'order_with_respect_to': 'book'}
        )
        self.assertNotIn(""_order"", [name for name, field in changes['testapp'][0].operations[0].fields])

    def test_add_model_order_with_respect_to_index_foo_together(self):
        changes = self.get_changes([], [
            self.book,
            ModelState('testapp', 'Author', [
                ('id', models.AutoField(primary_key=True)),
                ('name', models.CharField(max_length=200)),
                ('book', models.ForeignKey('otherapp.Book', models.CASCADE)),
            ], options={
                'order_with_respect_to': 'book',
                'index_together': {('name', '_order')},
                'unique_together': {('id', '_order')},
            }),
        ])
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, ['CreateModel'])
        self.assertOperationAttributes(
            changes,
            'testapp',
            0,
            0,
            name='Author',
            options={
                'order_with_respect_to': 'book',
                'index_together': {('name', '_order')},
                'unique_together': {('id', '_order')},
            },
        )

    def test_add_model_order_with_respect_to_index_constraint(self):
        tests = [
            (
                'AddIndex',
                {'indexes': [
                    models.Index(fields=['_order'], name='book_order_idx'),
                ]},
            ),
            (
                'AddConstraint',
                {'constraints': [
                    models.CheckConstraint(
                        check=models.Q(_order__gt=1),
                        name='book_order_gt_1',
                    ),
                ]},
            ),
        ]
        for operation, extra_option in tests:
            with self.subTest(operation=operation):
                after = ModelState('testapp', 'Author', [
                    ('id', models.AutoField(primary_key=True)),
                    ('name', models.CharField(max_length=200)),
                    ('book', models.ForeignKey('otherapp.Book', models.CASCADE)),
                ], options={
                    'order_with_respect_to': 'book',
                    **extra_option,
                })
                changes = self.get_changes([], [self.book, after])
                self.assertNumberMigrations(changes, 'testapp', 1)
                self.assertOperationTypes(changes, 'testapp', 0, [
                    'CreateModel', operation,
                ])
                self.assertOperationAttributes(
                    changes,
                    'testapp',
                    0,
                    0,
                    name='Author',
                    options={'order_with_respect_to': 'book'},
                )

    def test_set_alter_order_with_respect_to_index_constraint_foo_together(self):
        tests = [
            (
                'AddIndex',
                {'indexes': [
                    models.Index(fields=['_order'], name='book_order_idx'),
                ]},
            ),
            (
                'AddConstraint',
                {'constraints': [
                    models.CheckConstraint(
                        check=models.Q(_order__gt=1),
                        name='book_order_gt_1',
                    ),
                ]},
            ),
            ('AlterIndexTogether', {'index_together': {('name', '_order')}}),
            ('AlterUniqueTogether', {'unique_together': {('id', '_order')}}),
        ]
        for operation, extra_option in tests:
            with self.subTest(operation=operation):
                after = ModelState('testapp', 'Author', [
                    ('id', models.AutoField(primary_key=True)),
                    ('name', models.CharField(max_length=200)),
                    ('book', models.ForeignKey('otherapp.Book', models.CASCADE)),
                ], options={
                    'order_with_respect_to': 'book',
                    **extra_option,
                })
                changes = self.get_changes(
                    [self.book, self.author_with_book],
                    [self.book, after],
                )
                self.assertNumberMigrations(changes, 'testapp', 1)
                self.assertOperationTypes(changes, 'testapp', 0, [
                    'AlterOrderWithRespectTo', operation,
                ])

    def test_alter_model_managers(self):
        """"""
        Changing the model managers adds a new operation.
        """"""
        changes = self.get_changes([self.other_pony], [self.other_pony_food])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'otherapp', 1)
        self.assertOperationTypes(changes, 'otherapp', 0, [""AlterModelManagers""])
        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=""pony"")
        self.assertEqual([name for name, mgr in changes['otherapp'][0].operations[0].managers],
                         ['food_qs', 'food_mgr', 'food_mgr_kwargs'])
        self.assertEqual(changes['otherapp'][0].operations[0].managers[1][1].args, ('a', 'b', 1, 2))
        self.assertEqual(changes['otherapp'][0].operations[0].managers[2][1].args, ('x', 'y', 3, 4))

    def test_swappable_first_inheritance(self):
        """"""Swappable models get their CreateModel first.""""""
        changes = self.get_changes([], [self.custom_user, self.aardvark])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'thirdapp', 1)
        self.assertOperationTypes(changes, 'thirdapp', 0, [""CreateModel"", ""CreateModel""])
        self.assertOperationAttributes(changes, 'thirdapp', 0, 0, name=""CustomUser"")
        self.assertOperationAttributes(changes, 'thirdapp', 0, 1, name=""Aardvark"")

    def test_default_related_name_option(self):
        model_state = ModelState('app', 'model', [
            ('id', models.AutoField(primary_key=True)),
        ], options={'default_related_name': 'related_name'})
        changes = self.get_changes([], [model_state])
        self.assertNumberMigrations(changes, 'app', 1)
        self.assertOperationTypes(changes, 'app', 0, ['CreateModel'])
        self.assertOperationAttributes(
            changes, 'app', 0, 0, name='model',
            options={'default_related_name': 'related_name'},
        )
        altered_model_state = ModelState('app', 'Model', [
            ('id', models.AutoField(primary_key=True)),
        ])
        changes = self.get_changes([model_state], [altered_model_state])
        self.assertNumberMigrations(changes, 'app', 1)
        self.assertOperationTypes(changes, 'app', 0, ['AlterModelOptions'])
        self.assertOperationAttributes(changes, 'app', 0, 0, name='model', options={})

    @override_settings(AUTH_USER_MODEL=""thirdapp.CustomUser"")
    def test_swappable_first_setting(self):
        """"""Swappable models get their CreateModel first.""""""
        with isolate_lru_cache(apps.get_swappable_settings_name):
            changes = self.get_changes([], [self.custom_user_no_inherit, self.aardvark])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'thirdapp', 1)
        self.assertOperationTypes(changes, 'thirdapp', 0, [""CreateModel"", ""CreateModel""])
        self.assertOperationAttributes(changes, 'thirdapp', 0, 0, name=""CustomUser"")
        self.assertOperationAttributes(changes, 'thirdapp', 0, 1, name=""Aardvark"")

    def test_bases_first(self):
        """"""Bases of other models come first.""""""
        changes = self.get_changes([], [self.aardvark_based_on_author, self.author_name])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""CreateModel"", ""CreateModel""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""Author"")
        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=""Aardvark"")

    def test_bases_first_mixed_case_app_label(self):
        app_label = 'MiXedCaseApp'
        changes = self.get_changes([], [
            ModelState(app_label, 'owner', [
                ('id', models.AutoField(primary_key=True)),
            ]),
            ModelState(app_label, 'place', [
                ('id', models.AutoField(primary_key=True)),
                ('owner', models.ForeignKey('MiXedCaseApp.owner', models.CASCADE)),
            ]),
            ModelState(app_label, 'restaurant', [], bases=('MiXedCaseApp.place',)),
        ])
        self.assertNumberMigrations(changes, app_label, 1)
        self.assertOperationTypes(changes, app_label, 0, [
            'CreateModel', 'CreateModel', 'CreateModel',
        ])
        self.assertOperationAttributes(changes, app_label, 0, 0, name='owner')
        self.assertOperationAttributes(changes, app_label, 0, 1, name='place')
        self.assertOperationAttributes(changes, app_label, 0, 2, name='restaurant')

    def test_multiple_bases(self):
        """"""#23956 - Inheriting models doesn't move *_ptr fields into AddField operations.""""""
        A = ModelState(""app"", ""A"", [(""a_id"", models.AutoField(primary_key=True))])
        B = ModelState(""app"", ""B"", [(""b_id"", models.AutoField(primary_key=True))])
        C = ModelState(""app"", ""C"", [], bases=(""app.A"", ""app.B""))
        D = ModelState(""app"", ""D"", [], bases=(""app.A"", ""app.B""))
        E = ModelState(""app"", ""E"", [], bases=(""app.A"", ""app.B""))
        changes = self.get_changes([], [A, B, C, D, E])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, ""app"", 1)
        self.assertOperationTypes(changes, ""app"", 0, [
            ""CreateModel"", ""CreateModel"", ""CreateModel"", ""CreateModel"", ""CreateModel""
        ])
        self.assertOperationAttributes(changes, ""app"", 0, 0, name=""A"")
        self.assertOperationAttributes(changes, ""app"", 0, 1, name=""B"")
        self.assertOperationAttributes(changes, ""app"", 0, 2, name=""C"")
        self.assertOperationAttributes(changes, ""app"", 0, 3, name=""D"")
        self.assertOperationAttributes(changes, ""app"", 0, 4, name=""E"")

    def test_proxy_bases_first(self):
        """"""Bases of proxies come first.""""""
        changes = self.get_changes([], [self.author_empty, self.author_proxy, self.author_proxy_proxy])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""CreateModel"", ""CreateModel"", ""CreateModel""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""Author"")
        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=""AuthorProxy"")
        self.assertOperationAttributes(changes, 'testapp', 0, 2, name=""AAuthorProxyProxy"")

    def test_pk_fk_included(self):
        """"""
        A relation used as the primary key is kept as part of CreateModel.
        """"""
        changes = self.get_changes([], [self.aardvark_pk_fk_author, self.author_name])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""CreateModel"", ""CreateModel""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""Author"")
        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=""Aardvark"")

    def test_first_dependency(self):
        """"""
        A dependency to an app with no migrations uses __first__.
        """"""
        # Load graph
        loader = MigrationLoader(connection)
        before = self.make_project_state([])
        after = self.make_project_state([self.book_migrations_fk])
        after.real_apps = {'migrations'}
        autodetector = MigrationAutodetector(before, after)
        changes = autodetector._detect_changes(graph=loader.graph)
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'otherapp', 1)
        self.assertOperationTypes(changes, 'otherapp', 0, [""CreateModel""])
        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=""Book"")
        self.assertMigrationDependencies(changes, 'otherapp', 0, [(""migrations"", ""__first__"")])

    @override_settings(MIGRATION_MODULES={""migrations"": ""migrations.test_migrations""})
    def test_last_dependency(self):
        """"""
        A dependency to an app with existing migrations uses the
        last migration of that app.
        """"""
        # Load graph
        loader = MigrationLoader(connection)
        before = self.make_project_state([])
        after = self.make_project_state([self.book_migrations_fk])
        after.real_apps = {'migrations'}
        autodetector = MigrationAutodetector(before, after)
        changes = autodetector._detect_changes(graph=loader.graph)
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'otherapp', 1)
        self.assertOperationTypes(changes, 'otherapp', 0, [""CreateModel""])
        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=""Book"")
        self.assertMigrationDependencies(changes, 'otherapp', 0, [(""migrations"", ""0002_second"")])

    def test_alter_fk_before_model_deletion(self):
        """"""
        ForeignKeys are altered _before_ the model they used to
        refer to are deleted.
        """"""
        changes = self.get_changes(
            [self.author_name, self.publisher_with_author],
            [self.aardvark_testapp, self.publisher_with_aardvark_author]
        )
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""CreateModel"", ""AlterField"", ""DeleteModel""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""Aardvark"")
        self.assertOperationAttributes(changes, 'testapp', 0, 1, name=""author"")
        self.assertOperationAttributes(changes, 'testapp', 0, 2, name=""Author"")

    def test_fk_dependency_other_app(self):
        """"""
        #23100 - ForeignKeys correctly depend on other apps' models.
        """"""
        changes = self.get_changes([self.author_name, self.book], [self.author_with_book, self.book])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AddField""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name=""book"")
        self.assertMigrationDependencies(changes, 'testapp', 0, [(""otherapp"", ""__first__"")])

    def test_alter_field_to_fk_dependency_other_app(self):
        changes = self.get_changes(
            [self.author_empty, self.book_with_no_author_fk],
            [self.author_empty, self.book],
        )
        self.assertNumberMigrations(changes, 'otherapp', 1)
        self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])
        self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', '__first__')])

    def test_circular_dependency_mixed_addcreate(self):
        """"""
        #23315 - The dependency resolver knows to put all CreateModel
        before AddField and not become unsolvable.
        """"""
        address = ModelState(""a"", ""Address"", [
            (""id"", models.AutoField(primary_key=True)),
            (""country"", models.ForeignKey(""b.DeliveryCountry"", models.CASCADE)),
        ])
        person = ModelState(""a"", ""Person"", [
            (""id"", models.AutoField(primary_key=True)),
        ])
        apackage = ModelState(""b"", ""APackage"", [
            (""id"", models.AutoField(primary_key=True)),
            (""person"", models.ForeignKey(""a.Person"", models.CASCADE)),
        ])
        country = ModelState(""b"", ""DeliveryCountry"", [
            (""id"", models.AutoField(primary_key=True)),
        ])
        changes = self.get_changes([], [address, person, apackage, country])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'a', 2)
        self.assertNumberMigrations(changes, 'b', 1)
        self.assertOperationTypes(changes, 'a', 0, [""CreateModel"", ""CreateModel""])
        self.assertOperationTypes(changes, 'a', 1, [""AddField""])
        self.assertOperationTypes(changes, 'b', 0, [""CreateModel"", ""CreateModel""])

    @override_settings(AUTH_USER_MODEL=""a.Tenant"")
    def test_circular_dependency_swappable(self):
        """"""
        #23322 - The dependency resolver knows to explicitly resolve
        swappable models.
        """"""
        with isolate_lru_cache(apps.get_swappable_settings_name):
            tenant = ModelState(""a"", ""Tenant"", [
                (""id"", models.AutoField(primary_key=True)),
                (""primary_address"", models.ForeignKey(""b.Address"", models.CASCADE))],
                bases=(AbstractBaseUser,)
            )
            address = ModelState(""b"", ""Address"", [
                (""id"", models.AutoField(primary_key=True)),
                (""tenant"", models.ForeignKey(settings.AUTH_USER_MODEL, models.CASCADE)),
            ])
            changes = self.get_changes([], [address, tenant])

        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'a', 2)
        self.assertOperationTypes(changes, 'a', 0, [""CreateModel""])
        self.assertOperationTypes(changes, 'a', 1, [""AddField""])
        self.assertMigrationDependencies(changes, 'a', 0, [])
        self.assertMigrationDependencies(changes, 'a', 1, [('a', 'auto_1'), ('b', 'auto_1')])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'b', 1)
        self.assertOperationTypes(changes, 'b', 0, [""CreateModel""])
        self.assertMigrationDependencies(changes, 'b', 0, [('__setting__', 'AUTH_USER_MODEL')])

    @override_settings(AUTH_USER_MODEL=""b.Tenant"")
    def test_circular_dependency_swappable2(self):
        """"""
        #23322 - The dependency resolver knows to explicitly resolve
        swappable models but with the swappable not being the first migrated
        model.
        """"""
        with isolate_lru_cache(apps.get_swappable_settings_name):
            address = ModelState(""a"", ""Address"", [
                (""id"", models.AutoField(primary_key=True)),
                (""tenant"", models.ForeignKey(settings.AUTH_USER_MODEL, models.CASCADE)),
            ])
            tenant = ModelState(""b"", ""Tenant"", [
                (""id"", models.AutoField(primary_key=True)),
                (""primary_address"", models.ForeignKey(""a.Address"", models.CASCADE))],
                bases=(AbstractBaseUser,)
            )
            changes = self.get_changes([], [address, tenant])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'a', 2)
        self.assertOperationTypes(changes, 'a', 0, [""CreateModel""])
        self.assertOperationTypes(changes, 'a', 1, [""AddField""])
        self.assertMigrationDependencies(changes, 'a', 0, [])
        self.assertMigrationDependencies(changes, 'a', 1, [('__setting__', 'AUTH_USER_MODEL'), ('a', 'auto_1')])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'b', 1)
        self.assertOperationTypes(changes, 'b', 0, [""CreateModel""])
        self.assertMigrationDependencies(changes, 'b', 0, [('a', 'auto_1')])

    @override_settings(AUTH_USER_MODEL=""a.Person"")
    def test_circular_dependency_swappable_self(self):
        """"""
        #23322 - The dependency resolver knows to explicitly resolve
        swappable models.
        """"""
        with isolate_lru_cache(apps.get_swappable_settings_name):
            person = ModelState(""a"", ""Person"", [
                (""id"", models.AutoField(primary_key=True)),
                (""parent1"", models.ForeignKey(settings.AUTH_USER_MODEL, models.CASCADE, related_name='children'))
            ])
            changes = self.get_changes([], [person])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'a', 1)
        self.assertOperationTypes(changes, 'a', 0, [""CreateModel""])
        self.assertMigrationDependencies(changes, 'a', 0, [])

    @override_settings(AUTH_USER_MODEL='a.User')
    def test_swappable_circular_multi_mti(self):
        with isolate_lru_cache(apps.get_swappable_settings_name):
            parent = ModelState('a', 'Parent', [
                ('user', models.ForeignKey(settings.AUTH_USER_MODEL, models.CASCADE))
            ])
            child = ModelState('a', 'Child', [], bases=('a.Parent',))
            user = ModelState('a', 'User', [], bases=(AbstractBaseUser, 'a.Child'))
            changes = self.get_changes([], [parent, child, user])
        self.assertNumberMigrations(changes, 'a', 1)
        self.assertOperationTypes(changes, 'a', 0, ['CreateModel', 'CreateModel', 'CreateModel', 'AddField'])

    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_addition',
                side_effect=AssertionError(""Should not have prompted for not null addition""))
    def test_add_blank_textfield_and_charfield(self, mocked_ask_method):
        """"""
        #23405 - Adding a NOT NULL and blank `CharField` or `TextField`
        without default should not prompt for a default.
        """"""
        changes = self.get_changes([self.author_empty], [self.author_with_biography_blank])
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AddField"", ""AddField""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0)

    @mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_addition')
    def test_add_non_blank_textfield_and_charfield(self, mocked_ask_method):
        """"""
        #23405 - Adding a NOT NULL and non-blank `CharField` or `TextField`
        without default should prompt for a default.
        """"""
        changes = self.get_changes([self.author_empty], [self.author_with_biography_non_blank])
        self.assertEqual(mocked_ask_method.call_count, 2)
        # Right number/type of migrations?
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, [""AddField"", ""AddField""])
        self.assertOperationAttributes(changes, 'testapp', 0, 0)

    def test_mti_inheritance_model_removal(self):
        Animal = ModelState('app', 'Animal', [
            (""id"", models.AutoField(primary_key=True)),
        ])
        Dog = ModelState('app', 'Dog', [], bases=('app.Animal',))
        changes = self.get_changes([Animal, Dog], [Animal])
        self.assertNumberMigrations(changes, 'app', 1)
        self.assertOperationTypes(changes, 'app', 0, ['DeleteModel'])
        self.assertOperationAttributes(changes, 'app', 0, 0, name='Dog')

    def test_add_model_with_field_removed_from_base_model(self):
        """"""
        Removing a base field takes place before adding a new inherited model
        that has a field with the same name.
        """"""
        before = [
            ModelState('app', 'readable', [
                ('id', models.AutoField(primary_key=True)),
                ('title', models.CharField(max_length=200)),
            ]),
        ]
        after = [
            ModelState('app', 'readable', [
                ('id', models.AutoField(primary_key=True)),
            ]),
            ModelState('app', 'book', [
                ('title', models.CharField(max_length=200)),
            ], bases=('app.readable',)),
        ]
        changes = self.get_changes(before, after)
        self.assertNumberMigrations(changes, 'app', 1)
        self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel'])
        self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')
        self.assertOperationAttributes(changes, 'app', 0, 1, name='book')

    def test_parse_number(self):
        tests = [
            ('no_number', None),
            ('0001_initial', 1),
            ('0002_model3', 2),
            ('0002_auto_20380101_1112', 2),
            ('0002_squashed_0003', 3),
            ('0002_model2_squashed_0003_other4', 3),
            ('0002_squashed_0003_squashed_0004', 4),
            ('0002_model2_squashed_0003_other4_squashed_0005_other6', 5),
            ('0002_custom_name_20380101_1112_squashed_0003_model', 3),
            ('2_squashed_4', 4),
        ]
        for migration_name, expected_number in tests:
            with self.subTest(migration_name=migration_name):
                self.assertEqual(
                    MigrationAutodetector.parse_number(migration_name),
                    expected_number,
                )

    def test_add_custom_fk_with_hardcoded_to(self):
        class HardcodedForeignKey(models.ForeignKey):
            def __init__(self, *args, **kwargs):
                kwargs['to'] = 'testapp.Author'
                super().__init__(*args, **kwargs)

            def deconstruct(self):
                name, path, args, kwargs = super().deconstruct()
                del kwargs['to']
                return name, path, args, kwargs

        book_hardcoded_fk_to = ModelState('testapp', 'Book', [
            ('author', HardcodedForeignKey(on_delete=models.CASCADE)),
        ])
        changes = self.get_changes(
            [self.author_empty],
            [self.author_empty, book_hardcoded_fk_to],
        )
        self.assertNumberMigrations(changes, 'testapp', 1)
        self.assertOperationTypes(changes, 'testapp', 0, ['CreateModel'])
        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Book')",1,587 2000 40 2001 41 58 362 2002 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 93 41 2007 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 2010 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2011 61 515 41 41 44 93 41 2012 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 2013 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 2014 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 362 41 41 44 93 41 2016 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 44 123 362 58 91 2004 46 2017 40 2018 61 2004 46 2019 40 2020 61 362 41 44 2021 61 362 41 93 125 44 41 2022 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2023 40 2024 61 515 41 41 44 40 362 44 2004 46 2025 40 2024 61 515 41 41 44 40 362 44 2004 46 2026 40 2024 61 515 41 41 44 93 41 2027 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2023 40 2028 61 515 41 41 44 40 362 44 2004 46 2025 40 2028 61 515 41 41 44 40 362 44 2004 46 2026 40 2028 61 515 41 41 44 93 41 2029 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 2030 40 41 41 41 44 93 41 2031 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 2030 40 41 41 41 44 93 41 2032 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 2004 46 2033 40 41 41 41 44 93 41 2034 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 2004 46 2033 40 41 41 41 44 93 41 2035 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 91 2030 40 41 44 1504 93 41 41 44 93 41 2036 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 91 2030 40 41 44 1504 93 41 41 44 93 41 2037 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 91 2030 40 41 44 1504 93 41 41 44 93 41 2038 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 40 2030 40 41 44 1504 41 41 41 44 93 41 2039 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 40 2030 40 41 44 1504 41 41 41 44 93 41 2040 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 40 2030 40 41 44 1504 41 41 41 44 93 41 2041 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 123 362 58 2030 40 41 44 362 58 1504 125 41 41 44 93 41 2042 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 123 362 58 2030 40 41 44 362 58 1504 125 41 41 44 93 41 2043 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 123 362 58 2030 40 41 44 362 58 1504 125 41 41 44 93 41 2044 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 2030 40 2030 40 1501 41 44 40 2030 40 362 41 44 2030 40 362 41 44 41 44 2045 61 2030 40 362 41 44 2046 61 2030 40 2047 61 2030 40 362 41 41 44 41 41 41 44 93 41 2048 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 2030 40 2030 40 1501 41 44 40 2030 40 362 41 44 2030 40 362 41 44 41 44 2045 61 2030 40 362 41 44 2046 61 2030 40 2047 61 2030 40 362 41 41 44 41 41 41 44 93 41 2049 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 2030 40 2030 40 1501 41 44 40 2030 40 362 41 44 2030 40 362 41 44 41 44 2045 61 2030 40 362 41 44 2046 61 2030 40 2047 61 2030 40 362 41 41 44 41 41 41 44 93 41 2050 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 2030 40 2030 40 1501 41 44 40 2030 40 362 41 44 2030 40 362 41 44 41 44 470 44 2045 61 2030 40 362 41 44 2046 61 2030 40 2047 61 2030 40 362 41 41 44 41 41 41 44 93 41 2051 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 2030 40 2030 40 1501 41 44 40 2030 40 362 41 44 2030 40 362 41 44 41 44 2045 61 2030 40 362 41 44 2046 61 2030 40 2047 61 2030 40 362 41 41 44 41 41 41 44 93 41 2052 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2015 61 2030 40 2030 40 1501 41 44 40 2030 40 362 41 44 2030 40 362 41 44 41 44 2045 61 2030 40 362 41 44 2046 61 2030 40 2047 61 2030 40 362 41 41 44 2053 61 470 44 41 41 41 44 93 41 2054 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2033 40 2006 61 515 41 41 93 41 2055 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 41 41 44 40 362 44 2004 46 2056 40 41 41 44 93 41 2057 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2058 61 515 41 41 44 40 362 44 2004 46 2056 40 2058 61 515 41 41 44 93 41 2059 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 2062 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 44 2063 61 123 362 58 362 125 41 2064 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 2065 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 2066 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 2067 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 2068 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 2069 61 2003 40 362 44 362 44 91 93 44 123 362 58 515 125 44 40 362 44 41 41 2070 61 2003 40 362 44 362 44 91 93 44 123 362 58 515 44 362 58 362 44 125 44 40 362 44 41 41 2071 61 2003 40 362 44 362 44 91 93 44 123 125 44 40 362 44 41 41 2072 61 2003 40 362 44 362 44 91 93 44 123 362 58 515 125 44 40 362 44 41 41 2073 61 2003 40 362 44 362 44 91 93 44 123 125 44 40 362 44 41 41 2074 61 2003 40 362 44 362 44 91 93 44 123 362 58 515 125 44 40 362 44 41 41 2075 61 2003 40 362 44 362 44 91 93 44 123 362 58 443 125 44 40 362 44 41 41 2076 61 2003 40 362 44 362 44 91 93 44 123 125 44 40 362 44 41 41 2077 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 93 41 2078 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2033 40 2006 61 515 41 41 44 93 41 2079 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2080 40 362 41 41 44 93 41 2081 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2080 40 362 44 2058 61 515 41 41 44 93 41 2082 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2080 40 362 44 2083 61 362 41 41 44 93 41 2084 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2080 40 362 44 2083 61 362 41 41 44 93 41 2085 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1503 41 41 44 93 41 2086 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 44 123 362 58 91 40 362 44 362 41 93 44 362 58 362 44 125 41 2087 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 44 123 362 58 362 125 41 2088 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 44 123 362 58 362 125 41 2089 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 44 123 362 58 362 125 41 2090 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 44 123 362 58 362 125 41 2091 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 2092 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 2093 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1503 41 41 44 93 41 2094 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2008 40 2009 61 1503 41 41 44 93 41 2095 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2008 40 2009 61 1503 41 41 44 93 41 2096 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2008 40 2009 61 1503 41 41 44 93 41 2097 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 41 2098 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 44 2099 61 91 40 362 44 2100 46 2101 40 41 41 44 40 362 44 2102 40 362 44 362 41 41 44 40 362 44 2102 40 362 44 362 44 1502 44 1502 41 41 44 93 41 2103 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 93 41 2104 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 93 41 2105 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 2106 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 2107 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 2108 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 2109 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2033 40 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 2110 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 2111 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 2112 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 2113 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2080 40 362 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 2114 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2080 40 362 44 2083 61 362 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 2115 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 44 123 362 58 91 2004 46 2116 40 2117 61 91 362 44 362 93 44 2021 61 362 41 93 44 125 41 2118 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 44 123 362 58 91 2004 46 2116 40 2117 61 91 362 44 362 93 44 2021 61 362 41 93 44 125 41 2119 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 44 123 362 58 123 40 362 44 362 41 125 44 362 58 123 40 362 44 362 41 125 44 125 41 2120 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 44 123 362 58 123 40 362 44 362 41 125 44 362 58 123 40 362 44 362 41 125 44 125 41 2121 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2033 40 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 44 123 362 58 123 40 362 44 362 41 125 44 362 58 123 40 362 44 362 41 125 44 125 41 2122 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2033 40 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 44 123 362 58 123 40 362 44 362 41 125 44 362 58 123 40 362 44 362 41 125 44 125 41 2123 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 2124 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 2125 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 44 2126 61 40 2127 44 41 41 2128 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 2129 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 93 41 2130 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 93 41 2131 61 2003 40 362 44 362 44 91 93 44 2126 61 40 362 44 41 41 2132 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2133 40 362 44 2004 46 2061 44 2006 61 515 41 41 44 93 41 2134 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 93 41 2135 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 44 123 362 58 123 40 362 44 362 41 125 44 362 58 91 2004 46 2116 40 2117 61 91 362 44 362 93 44 2021 61 362 41 93 44 125 41 612 2136 40 2137 44 2138 44 2139 61 443 41 58 2140 61 362 664 2141 44 2142 696 807 40 2138 46 2143 40 41 41 58 2140 348 362 37 2141 664 2144 696 2142 58 2140 348 362 37 2144 46 2021 664 2145 696 2144 46 2146 58 2140 348 362 37 2145 688 2139 58 2140 348 362 688 2144 46 2147 58 664 2148 696 2144 46 2147 58 2140 348 362 37 40 2148 44 41 630 58 2140 348 362 792 2140 612 2149 40 2137 44 2138 44 2141 44 2150 41 58 688 720 40 2138 46 2151 40 2141 44 91 93 41 41 340 2150 58 2137 46 2152 40 362 37 40 720 40 2138 46 2151 40 2141 44 91 93 41 41 44 2141 44 2150 44 2137 46 2136 40 2138 41 44 41 41 612 2153 40 2137 44 2138 44 2141 44 2154 44 2147 41 58 688 750 2138 46 2151 40 2141 41 58 2137 46 2152 40 362 37 40 2141 44 2137 46 2136 40 2138 41 41 41 688 720 40 2138 91 2141 93 41 60 2154 43 1501 58 2137 46 2152 40 362 37 40 2154 44 2141 44 2137 46 2136 40 2138 41 41 41 2144 61 2138 91 2141 93 91 2154 93 688 801 40 2144 46 2147 41 340 801 40 2147 41 58 2137 46 2152 40 362 37 40 2141 44 2144 46 2021 44 2147 44 2137 46 2136 40 2138 44 2139 61 515 41 44 41 41 612 2155 40 2137 44 2138 44 2141 44 2154 44 2156 41 58 688 750 2138 46 2151 40 2141 41 58 2137 46 2152 40 362 37 40 2141 44 2137 46 2136 40 2138 41 41 41 688 720 40 2138 91 2141 93 41 60 2154 43 1501 58 2137 46 2152 40 362 37 40 2154 44 2141 44 2137 46 2136 40 2138 41 41 41 2144 61 2138 91 2141 93 91 2154 93 2157 61 91 2145 46 2158 46 2159 664 2145 696 2144 46 2146 93 688 2156 340 2157 58 2137 46 2152 40 362 37 40 2141 44 2144 46 2021 44 2156 44 2137 46 2136 40 2138 41 44 41 41 612 2160 40 2137 44 2138 44 2141 44 2154 44 2161 44 350 2162 41 58 688 750 2138 46 2151 40 2141 41 58 2137 46 2152 40 362 37 40 2141 44 2137 46 2136 40 2138 41 41 41 688 720 40 2138 91 2141 93 41 60 2154 43 1501 58 2137 46 2152 40 362 37 40 2154 44 2141 44 2137 46 2136 40 2138 41 41 41 2144 61 2138 91 2141 93 91 2154 93 688 720 40 2138 91 2141 93 41 60 2154 43 1501 58 2137 46 2152 40 362 37 40 2161 44 2141 44 2144 46 2021 44 2137 46 2136 40 2138 41 44 41 41 2145 61 2144 46 2146 91 2161 93 664 2163 44 2164 696 2162 46 2143 40 41 58 688 673 40 2145 44 2163 44 470 41 340 2164 58 2137 46 2152 40 362 37 40 2141 44 2144 46 2021 44 2161 44 2163 44 2164 44 673 40 2145 44 2163 44 470 41 44 2137 46 2136 40 2138 41 44 41 41 612 2165 40 2137 44 2138 44 2141 44 2154 44 2161 44 350 2162 41 58 688 750 2138 46 2151 40 2141 41 58 2137 46 2152 40 362 37 40 2141 44 2137 46 2136 40 2138 41 41 41 688 720 40 2138 91 2141 93 41 60 2154 43 1501 58 2137 46 2152 40 362 37 40 2154 44 2141 44 2137 46 2136 40 2138 41 41 41 2144 61 2138 91 2141 93 91 2154 93 688 720 40 2138 91 2141 93 41 60 2154 43 1501 58 2137 46 2152 40 362 37 40 2161 44 2141 44 2144 46 2021 44 2137 46 2136 40 2138 41 44 41 41 2145 61 2144 46 2146 91 2161 93 688 750 678 40 2145 44 362 41 58 2137 46 2152 40 362 37 40 2141 44 2144 46 2021 44 2161 44 41 41 2166 61 2145 46 2166 664 2163 44 2164 696 2162 46 2143 40 41 58 688 673 40 2166 44 2163 44 470 41 340 2164 58 2137 46 2152 40 362 37 40 2141 44 2144 46 2021 44 2161 44 2163 44 2164 44 673 40 2166 44 2163 44 470 41 44 2137 46 2136 40 2138 41 44 41 41 612 2167 40 2137 44 2168 41 58 362 2169 61 2170 40 41 664 2171 696 2168 58 2169 46 2172 40 2171 46 2173 40 41 41 792 2169 612 2174 40 2137 44 2175 44 2176 44 2177 61 470 41 58 688 750 713 40 2175 44 2170 41 58 2175 61 2137 46 2167 40 2175 41 688 750 713 40 2176 44 2170 41 58 2176 61 2137 46 2167 40 2176 41 792 2178 40 2175 44 2176 44 2177 44 41 46 2179 40 41 612 2180 40 2137 41 58 362 330 2181 61 2182 40 41 2181 46 2183 40 40 362 44 362 41 44 470 41 2181 46 2183 40 40 362 44 362 41 44 470 41 2181 46 2183 40 40 362 44 362 41 44 470 41 2181 46 2184 40 362 44 40 362 44 362 41 44 40 362 44 362 41 41 2181 46 2184 40 362 44 40 362 44 362 41 44 40 362 44 362 41 41 330 2185 61 2137 46 2167 40 91 2137 46 2093 44 2137 46 2097 93 41 2186 61 2137 46 2167 40 91 2137 46 2002 44 2137 46 2093 44 2137 46 2097 44 2137 46 2103 44 93 41 2187 61 2178 40 2185 44 2186 41 2138 61 2187 46 2179 40 41 330 2138 61 2187 46 2188 40 2138 44 2181 41 330 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2021 44 362 41 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2147 44 91 40 362 44 362 41 93 41 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2021 44 362 41 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2147 44 91 40 362 44 362 41 93 41 612 2190 40 2137 41 58 330 2181 61 2182 40 41 330 2185 61 2137 46 2167 40 91 93 41 2186 61 2137 46 2167 40 91 2137 46 2059 44 2137 46 2105 44 2137 46 2123 93 41 2187 61 2178 40 2185 44 2186 44 2191 40 123 362 58 515 125 41 41 2138 61 2187 46 2179 40 41 2138 61 2187 46 2188 40 2138 44 2181 41 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2021 44 362 41 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2147 44 91 93 41 2137 46 2189 40 2138 91 362 93 91 1501 93 46 2021 44 362 41 2137 46 2192 40 2138 91 362 93 91 1501 93 46 2147 44 91 40 362 44 362 41 44 40 362 44 362 41 93 44 41 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2021 44 362 41 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2147 44 91 40 362 44 362 41 93 41 612 2193 40 2137 41 58 362 330 2185 61 2137 46 2167 40 91 93 41 2186 61 2137 46 2167 40 91 2137 46 2002 44 2137 46 2097 44 2137 46 2103 44 2137 46 2104 93 41 2187 61 2178 40 2185 44 2186 44 2191 40 123 362 58 515 125 41 41 2138 61 2187 46 2179 40 41 330 2181 61 2182 40 41 2138 61 2187 46 2188 40 2138 44 2181 41 2138 91 362 93 91 1500 93 46 2147 46 2194 40 40 362 44 362 41 41 2138 61 2187 46 2195 40 2138 44 123 362 125 41 330 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2021 44 362 41 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2021 44 362 41 2137 46 2196 40 362 44 2138 41 612 2197 40 2137 41 58 362 330 2181 61 2182 40 41 2181 46 2183 40 40 362 44 362 41 44 470 41 2181 46 2183 40 40 362 44 362 41 44 470 41 2181 46 2183 40 40 362 44 362 41 44 470 41 2181 46 2184 40 362 44 40 362 44 362 41 44 40 362 44 362 41 41 330 2185 61 2137 46 2167 40 91 93 41 2186 61 2137 46 2167 40 91 2137 46 2002 44 2137 46 2097 44 2137 46 2103 93 41 2187 61 2178 40 2185 44 2186 41 2138 61 2187 46 2179 40 41 330 2198 61 362 2138 61 2187 46 2188 40 2138 44 2181 44 2198 41 330 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2021 44 362 37 2198 41 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2147 44 91 40 362 44 362 41 93 41 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2021 44 362 37 2198 41 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2147 44 91 40 362 44 362 41 93 41 612 2199 40 2137 41 58 362 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2098 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2189 40 91 2021 664 2021 44 2200 696 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2099 93 44 91 362 44 362 44 362 93 41 612 2201 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 93 44 91 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 612 2202 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 93 44 91 2137 46 2007 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 64 2203 46 2204 40 362 44 2205 61 2206 40 362 41 41 612 2207 40 2137 44 2208 41 58 2138 61 2137 46 2174 40 91 2137 46 2002 93 44 91 2137 46 2022 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 93 41 2137 46 2165 40 2138 44 362 44 1500 44 1500 44 2024 61 515 41 2137 46 2165 40 2138 44 362 44 1500 44 1501 44 2024 61 515 41 2137 46 2165 40 2138 44 362 44 1500 44 1502 44 2024 61 515 41 64 2203 46 2204 40 362 44 2205 61 2206 40 362 41 41 612 2209 40 2137 44 2208 41 58 2138 61 2137 46 2174 40 91 2137 46 2002 93 44 91 2137 46 2027 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 93 41 2137 46 2165 40 2138 44 362 44 1500 44 1500 44 2028 61 515 41 2137 46 2165 40 2138 44 362 44 1500 44 1501 44 2028 61 515 41 2137 46 2165 40 2138 44 362 44 1500 44 1502 44 2028 61 515 41 64 2203 46 2204 40 362 41 612 2210 40 2137 44 2208 41 58 2138 61 2137 46 2174 40 91 2137 46 2002 93 44 91 2137 46 2027 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 93 41 2137 46 2165 40 2138 44 362 44 1500 44 1500 44 2028 61 515 41 2137 46 2165 40 2138 44 362 44 1500 44 1501 44 2028 61 515 41 2137 46 2165 40 2138 44 362 44 1500 44 1502 44 2028 61 515 41 2137 46 2189 40 2208 46 2211 44 1502 41 612 2212 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2007 93 44 91 2137 46 2002 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 612 2213 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2007 93 44 91 2137 46 2012 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2214 61 515 41 612 2215 40 2137 41 58 612 2216 40 2217 44 2218 44 2219 44 350 2220 41 58 792 362 46 666 40 2217 44 2218 41 612 2221 40 2219 44 350 2220 41 58 792 2222 46 2223 40 2216 44 2219 44 350 2220 41 330 2185 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2224 40 2009 61 1504 44 2225 61 2221 40 362 41 41 41 44 93 41 93 2186 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2224 40 2009 61 1504 44 2225 61 2221 40 362 41 41 41 44 93 41 93 2138 61 2137 46 2174 40 2185 44 2186 41 2137 46 2149 40 2138 44 362 44 1500 41 330 2226 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2224 40 2009 61 1504 44 2225 61 2221 40 362 41 41 41 44 93 41 93 2138 61 2137 46 2174 40 2185 44 2226 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 330 330 330 330 2164 61 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2166 46 2225 2137 46 2189 40 40 2216 44 40 362 44 41 44 123 125 41 44 40 2164 46 2227 44 2164 46 2228 44 2164 46 2229 41 41 2230 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2224 40 2009 61 1504 44 2225 61 2221 40 362 44 2231 61 362 41 41 41 44 93 41 93 2138 61 2137 46 2174 40 2185 44 2230 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2164 61 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2166 46 2225 2137 46 2189 40 40 2216 44 40 362 44 41 44 123 362 58 362 125 41 44 40 2164 46 2227 44 2164 46 2228 44 2164 46 2229 41 41 64 2203 46 2204 40 362 44 2205 61 2206 40 362 41 41 612 2232 40 2137 44 2208 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2010 93 44 91 2137 46 2014 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2214 61 515 41 2137 46 2165 40 2138 44 362 44 1500 44 1500 44 2015 61 362 41 64 2203 46 2204 40 362 44 2233 61 2004 46 2234 44 41 612 2235 40 2137 44 2208 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2010 93 44 91 2137 46 2007 93 41 2137 46 2189 40 2208 46 2211 44 1501 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2214 61 515 41 2137 46 2165 40 2138 44 362 44 1500 44 1500 44 2015 61 2004 46 2234 41 64 2203 46 2204 40 362 44 2233 61 362 44 41 612 2236 40 2137 44 2208 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2010 93 44 91 2137 46 2007 93 41 2137 46 2189 40 2208 46 2211 44 1501 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2214 61 443 41 2137 46 2165 40 2138 44 362 44 1500 44 1500 44 2015 61 362 41 612 2237 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2007 93 44 91 2137 46 2013 93 44 2191 40 123 362 58 515 125 41 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2238 61 362 44 2239 61 362 41 612 2240 40 2137 41 58 2185 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2033 40 2241 61 515 41 41 44 93 41 44 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 44 2242 61 362 41 41 44 93 41 44 93 2186 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2033 40 2241 61 515 41 41 44 93 41 44 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 44 2242 61 362 41 41 44 93 41 44 93 2138 61 2137 46 2174 40 2185 44 2186 44 2191 40 123 362 58 515 125 41 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2238 61 362 44 2239 61 362 41 612 2243 40 2137 41 58 2117 61 40 362 44 362 41 2244 61 40 362 44 362 41 2185 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2033 40 41 41 44 40 362 44 2004 46 2033 40 41 41 44 93 44 2063 61 123 362 58 123 2117 125 125 41 44 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2033 40 41 41 44 40 362 44 2004 46 2033 40 41 41 44 40 362 44 2004 46 2245 40 362 44 2004 46 2061 44 2246 61 2117 44 2247 61 2117 44 41 41 44 93 41 44 93 330 2186 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2033 40 41 41 44 40 362 44 2004 46 2033 40 41 41 44 93 44 2063 61 123 362 58 123 2244 125 125 41 44 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2033 40 41 41 44 40 362 44 2004 46 2033 40 41 41 44 40 362 44 2004 46 2245 40 362 44 2004 46 2061 44 2246 61 2117 44 2247 61 2244 44 41 41 44 93 41 44 93 2138 61 2137 46 2174 40 2185 44 2186 44 2191 40 123 362 58 515 125 41 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2248 61 362 44 2238 61 362 44 2239 61 362 44 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2248 61 362 44 2238 61 362 44 2239 61 362 44 41 330 2186 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2033 40 41 41 44 40 362 44 2004 46 2033 40 41 41 44 93 44 2063 61 123 362 58 123 2117 125 125 41 44 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2033 40 41 41 44 40 362 44 2004 46 2033 40 41 41 44 40 362 44 2004 46 2245 40 362 44 2004 46 2061 44 2246 61 2244 44 2247 61 2117 44 41 41 44 93 41 44 93 2138 61 2137 46 2174 40 2185 44 2186 44 2191 40 123 362 58 515 125 41 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2248 61 362 44 2238 61 362 44 2239 61 362 44 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2248 61 362 44 2238 61 362 44 2239 61 362 44 41 612 2249 40 2137 41 58 2185 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2008 40 2006 61 515 44 2250 61 443 41 41 44 93 41 44 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 44 93 2186 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2008 40 2006 61 515 44 2250 61 443 41 41 93 41 44 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 44 93 2138 61 2137 46 2174 40 2185 44 2186 44 2191 40 123 362 58 515 125 41 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2238 61 362 44 2239 61 362 41 612 2251 40 2137 41 58 362 2185 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2033 40 41 41 44 93 41 44 93 2186 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2033 40 2252 61 362 41 41 44 93 41 44 93 2138 61 2137 46 2174 40 2185 44 2186 44 2191 40 123 362 58 515 125 41 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2248 61 362 44 2021 61 362 44 41 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2166 46 2253 40 41 44 40 362 44 362 44 91 93 44 123 362 58 362 125 44 41 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2248 61 362 44 2238 61 362 44 2239 61 362 44 41 612 2254 40 2137 41 58 2185 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 41 44 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 44 93 2186 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 41 44 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 44 2252 61 362 41 41 44 93 41 44 93 2138 61 2137 46 2174 40 2185 44 2186 44 2191 40 123 362 58 515 125 41 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2248 61 362 44 2021 61 362 44 41 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2166 46 2253 40 41 44 40 362 44 362 44 91 93 44 123 362 58 362 44 362 58 2004 46 2061 44 362 58 362 125 44 41 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2248 61 362 44 2238 61 362 44 2239 61 362 44 41 612 2255 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2059 44 2137 46 2105 93 44 91 2137 46 2064 44 2137 46 2111 93 44 2191 40 123 362 58 515 125 41 44 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2238 61 362 44 2239 61 362 41 330 330 2137 46 2149 40 2138 44 362 44 1500 41 612 2256 40 2137 41 58 362 2257 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 41 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2105 93 44 91 2257 44 2137 46 2105 93 44 2177 61 2191 40 123 362 58 515 125 41 44 41 2137 46 2149 40 2138 44 362 44 1500 41 2137 46 2149 40 2138 44 362 44 1500 41 612 2258 40 2137 41 58 2259 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1503 41 41 44 93 41 2138 61 2137 46 2174 40 91 2137 46 2093 44 2137 46 2079 93 44 91 2259 44 2137 46 2079 93 44 2177 61 2191 40 123 362 58 515 125 41 44 41 2137 46 2149 40 2138 44 362 44 1500 41 2137 46 2149 40 2138 44 362 44 1500 41 612 2260 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2082 44 2137 46 2093 44 2137 46 2091 93 44 91 2137 46 2084 44 2137 46 2093 44 2137 46 2092 93 44 2191 40 123 362 58 515 125 41 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2238 61 362 44 2239 61 362 41 612 2261 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2059 44 2137 46 2105 93 44 91 2137 46 2064 44 2137 46 2112 93 44 2191 40 123 362 58 515 44 362 58 515 125 41 44 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2238 61 362 44 2239 61 362 41 330 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2238 61 362 44 2239 61 362 41 612 2262 40 2137 41 58 362 2185 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 41 44 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 44 93 2186 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 41 44 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 44 93 2138 61 2137 46 2174 40 2185 44 2186 44 2191 40 123 362 58 515 125 41 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2238 61 362 44 2239 61 362 41 612 2263 40 2137 41 58 362 2185 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 41 44 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 44 93 2186 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 41 44 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 44 93 2138 61 2137 46 2174 40 2185 44 2186 44 2191 40 123 362 58 515 125 41 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2153 40 2138 44 362 44 1500 44 91 40 362 44 362 41 93 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2238 61 362 44 2239 61 362 41 612 2264 40 2137 41 58 362 330 330 330 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2007 44 2137 46 2105 44 2137 46 2124 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2153 40 2138 44 362 44 1500 44 91 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2153 40 2138 44 362 44 1500 44 91 40 362 44 362 41 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2153 40 2138 44 362 44 1500 44 91 40 362 44 362 41 93 41 612 2265 40 2137 41 58 362 330 330 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2002 44 2137 46 2072 44 2137 46 2106 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2153 40 2138 44 362 44 1500 44 91 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2153 40 2138 44 362 44 1500 44 91 40 362 44 362 41 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2153 40 2138 44 362 44 1500 44 91 40 362 44 362 41 93 41 612 2266 40 2137 41 58 362 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2066 44 2137 46 2093 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 2137 46 2153 40 2138 44 362 44 1500 44 91 93 41 612 2267 40 2137 41 58 362 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2059 44 2137 46 2105 44 2137 46 2096 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 2137 46 2153 40 2138 44 362 44 1500 44 91 40 362 44 362 41 93 41 330 2137 46 2149 40 2138 44 362 44 1502 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2155 40 2138 44 362 44 1501 44 91 362 93 41 2137 46 2153 40 2138 44 362 44 1500 44 91 93 41 2137 46 2153 40 2138 44 362 44 1501 44 91 40 362 44 362 41 44 40 362 44 362 41 93 41 330 2137 46 2268 40 2138 91 362 93 91 1500 93 46 2269 41 2137 46 2268 40 2138 91 362 93 91 1501 93 46 2269 41 612 2270 40 2137 41 58 362 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2066 44 2137 46 2094 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 41 2137 46 2153 40 2138 44 362 44 1500 44 91 93 41 612 2271 40 2137 41 58 362 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2134 44 2137 46 2135 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 44 362 93 41 2137 46 2196 40 362 44 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2063 41 2137 46 2196 40 362 44 2138 91 362 93 91 1500 93 46 2146 91 1501 93 46 2063 41 2137 46 2153 40 2138 44 362 44 1500 44 91 93 41 612 2272 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 93 44 91 2137 46 2087 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2273 61 362 41 612 2274 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2087 93 44 91 2137 46 2088 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2273 61 362 41 612 2275 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2087 93 44 91 2137 46 2002 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2273 61 470 41 612 2276 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2087 93 44 91 2137 46 2087 93 41 330 2137 46 2189 40 720 40 2138 41 44 1500 41 612 2277 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2087 93 44 91 2137 46 2089 93 44 2191 40 123 362 58 515 125 41 44 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2238 61 362 44 2239 61 362 41 612 2278 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2087 93 44 91 2137 46 2090 93 44 2191 40 123 362 58 515 125 41 44 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2238 61 362 44 2239 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 44 2273 61 362 41 612 2279 40 2137 41 58 2280 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 44 2281 61 91 2282 40 2283 46 595 40 362 41 44 362 44 362 41 93 41 41 93 41 2284 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 44 2281 61 91 2285 93 41 41 93 41 2138 61 2137 46 2174 40 91 2280 93 44 91 2284 93 41 330 2137 46 2149 40 2138 44 362 44 1500 41 612 2286 40 2137 41 58 2280 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 44 2281 61 91 2282 40 2283 46 595 40 362 44 1503 41 44 362 44 362 41 93 41 41 93 41 2284 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 44 2281 61 91 2285 93 41 41 93 41 2138 61 2137 46 2174 40 91 2280 93 44 91 2284 93 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 612 2287 40 2137 41 58 362 330 330 2288 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 93 41 330 330 2289 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 93 44 123 362 58 470 44 362 58 470 44 125 41 330 330 2290 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 93 44 123 362 58 801 40 41 44 362 58 801 40 41 44 125 41 612 2291 40 2280 44 2284 44 2292 41 58 2138 61 2137 46 2174 40 91 2280 93 44 91 2284 93 41 688 2138 58 2293 61 362 46 2294 40 2295 46 2158 46 2159 664 2295 696 2138 91 362 93 91 1500 93 46 2146 41 2137 46 2152 40 362 37 40 2293 44 2292 41 41 2296 61 40 40 2288 44 2288 44 362 41 44 40 2288 44 2289 44 362 41 44 40 2288 44 2290 44 362 41 44 40 2289 44 2288 44 362 41 44 40 2289 44 2289 44 362 41 44 40 2289 44 2290 44 362 41 44 40 2290 44 2288 44 362 41 44 40 2290 44 2289 44 362 41 44 40 2290 44 2290 44 362 41 44 41 664 2297 696 2296 58 2291 40 42 2297 41 612 2298 40 2137 41 58 362 2299 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 44 123 362 58 91 2004 46 2116 40 2117 61 91 362 93 44 2021 61 362 41 93 125 41 2138 61 2137 46 2174 40 91 93 44 91 2299 93 41 2300 61 2004 46 2116 40 2117 61 91 362 93 44 2021 61 362 41 330 2137 46 2189 40 720 40 2138 91 362 93 41 44 1501 41 330 2144 61 2138 91 362 93 91 1500 93 2137 46 2189 40 720 40 2144 46 2146 41 44 1502 41 330 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2248 61 362 44 2301 61 2300 41 612 2302 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2105 93 44 91 2137 46 2002 44 2137 46 2115 93 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2300 61 2004 46 2116 40 2117 61 91 362 44 362 93 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2248 61 362 44 2301 61 2300 41 612 2303 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2115 93 44 91 2137 46 2002 44 2137 46 2105 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2248 61 362 44 2021 61 362 41 612 2304 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2115 93 44 91 2137 46 2002 44 2137 46 2118 93 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2248 61 362 44 2021 61 362 41 2300 61 2004 46 2116 40 2117 61 91 362 44 362 93 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2248 61 362 44 2301 61 2300 41 612 2305 40 2137 41 58 362 2299 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 44 123 362 58 91 2004 46 2017 40 2018 61 2004 46 2019 40 2020 61 362 41 44 2021 61 362 41 93 125 41 2138 61 2137 46 2174 40 91 93 44 91 2299 93 41 2306 61 2004 46 2017 40 2018 61 2004 46 2019 40 2020 61 362 41 44 2021 61 362 41 330 2137 46 2189 40 720 40 2138 91 362 93 41 44 1501 41 330 2144 61 2138 91 362 93 91 1500 93 2137 46 2189 40 720 40 2144 46 2146 41 44 1502 41 330 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2248 61 362 44 2307 61 2306 41 612 2308 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2007 93 44 91 2137 46 2016 93 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2306 61 2004 46 2017 40 2018 61 2004 46 2019 40 2020 61 362 41 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2248 61 362 44 2307 61 2306 41 612 2309 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2016 93 44 91 2137 46 2007 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2248 61 362 44 2021 61 362 41 612 2310 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2105 93 44 91 2137 46 2002 44 2137 46 2119 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2311 61 123 40 362 44 362 41 125 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 44 2312 61 123 40 362 44 362 41 125 41 612 2313 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2119 93 44 91 2137 46 2002 44 2137 46 2105 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2311 61 801 40 41 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 44 2312 61 801 40 41 41 612 2314 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2119 93 44 91 2137 46 2002 44 2137 46 2110 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2311 61 801 40 41 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 44 2312 61 801 40 41 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2248 61 362 44 2021 61 362 41 612 2315 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2119 93 44 91 2137 46 2002 44 2137 46 2119 93 41 330 2137 46 2189 40 720 40 2138 41 44 1500 41 612 2316 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2119 93 44 91 2137 46 2002 44 2137 46 2120 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 44 362 44 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2311 61 801 40 41 44 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 44 2312 61 801 40 41 44 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 44 2311 61 123 40 362 44 362 41 125 44 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 44 2312 61 123 40 362 44 362 41 125 44 41 612 2317 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2105 93 44 91 2137 46 2002 44 2137 46 2121 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 44 2311 61 123 40 362 44 362 41 125 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 44 2312 61 123 40 362 44 362 41 125 41 612 2318 40 2137 41 58 2299 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 2319 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 44 123 362 58 123 40 362 44 362 41 125 44 362 58 123 40 362 44 362 41 125 44 125 41 2138 61 2137 46 2174 40 91 2137 46 2110 93 44 91 2299 44 2319 93 41 330 2137 46 2189 40 720 40 2138 91 362 93 41 44 1501 41 330 2144 61 2138 91 362 93 91 1500 93 2137 46 2189 40 720 40 2144 46 2146 41 44 1502 41 330 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 44 362 93 41 612 2320 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2121 93 44 91 2137 46 2002 44 2137 46 2119 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 44 362 44 362 44 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2311 61 801 40 41 44 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 44 2312 61 801 40 41 44 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 44 2311 61 123 40 362 44 362 41 125 44 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 44 2312 61 123 40 362 44 362 41 125 44 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2248 61 362 44 2021 61 362 44 41 612 2321 40 2137 41 58 362 2322 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 40 362 44 2004 46 2033 40 2323 61 515 41 41 44 93 44 123 362 58 123 40 362 44 41 125 44 125 41 2324 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 2241 61 515 41 41 44 40 362 44 2004 46 2033 40 41 41 44 93 44 123 362 58 123 40 362 44 41 125 44 125 41 2138 61 2137 46 2174 40 91 2322 93 44 91 2324 93 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 44 362 44 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2311 61 801 40 41 44 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2248 61 362 44 2021 61 362 44 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2248 61 362 44 2021 61 362 44 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 44 2312 61 123 40 362 44 41 125 44 41 612 2325 40 2137 41 58 2322 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 40 362 44 2004 46 2033 40 41 41 44 93 44 123 362 58 123 40 362 44 41 44 40 362 44 41 125 44 362 58 123 40 362 44 41 125 44 125 41 2324 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 40 362 44 2004 46 2033 40 41 41 44 93 44 123 362 58 123 40 362 44 41 125 44 362 58 123 40 362 44 41 44 40 362 44 41 125 44 125 41 2138 61 2137 46 2174 40 91 2322 93 44 91 2324 93 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2311 61 123 40 362 44 41 125 44 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 44 2312 61 123 40 362 44 41 44 40 362 44 41 125 44 41 612 2326 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2121 93 44 91 2137 46 2002 44 2137 46 2122 93 44 2191 40 123 362 58 515 125 41 44 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 44 362 44 362 44 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 44 2311 61 801 40 41 44 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 44 2312 61 801 40 41 44 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 44 2311 61 123 40 362 44 362 41 125 44 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 44 2312 61 123 40 362 44 362 41 125 44 41 612 2327 40 2137 41 58 362 330 2138 61 2137 46 2174 40 91 2137 46 2002 93 44 91 2137 46 2002 44 2137 46 2069 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2063 61 123 362 58 515 44 362 58 91 93 44 362 58 91 93 125 41 330 330 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2069 93 44 91 2137 46 2002 44 2137 46 2071 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 44 2063 61 123 125 41 612 2328 40 2137 41 58 587 2329 58 767 2330 61 2003 40 362 44 362 44 91 93 44 123 362 58 515 125 44 40 2329 44 362 41 44 41 2138 61 2137 46 2174 40 91 2137 46 2002 93 44 91 2137 46 2002 44 2330 93 44 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2063 61 123 362 58 515 44 362 58 91 93 44 362 58 91 93 125 44 2126 61 40 2329 44 362 41 44 41 612 2331 40 2137 41 58 362 330 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2002 44 2137 46 2072 44 2137 46 2106 93 41 330 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2117 91 1502 93 91 1501 93 46 2332 46 2333 44 362 44 41 330 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2054 44 2137 46 2072 44 2137 46 2106 93 41 330 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2117 91 1502 93 91 1501 93 46 2332 46 2333 44 362 44 41 612 2334 40 2137 41 58 330 2284 61 2137 46 2167 40 91 2137 46 2002 44 2137 46 2072 44 2137 46 2106 93 44 41 2138 61 2137 46 2174 40 91 93 44 2284 41 2335 61 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2117 91 1502 93 91 1501 93 2137 46 2189 40 2284 46 2336 40 2335 46 2332 46 2333 41 44 40 362 44 362 41 44 41 2137 46 2189 40 2335 46 2332 46 2333 44 362 41 330 2280 61 2284 46 2173 40 41 2284 61 2137 46 2167 40 91 2137 46 2002 44 2137 46 2073 44 2137 46 2106 93 44 41 2138 61 2137 46 2174 40 2280 44 2284 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 330 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 330 2137 46 2153 40 2138 44 362 44 1500 44 91 40 362 44 362 41 93 41 330 2335 61 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2166 2137 46 2189 40 2284 46 2336 40 2335 46 2332 46 2333 41 44 40 362 44 362 41 44 41 2137 46 2189 40 2335 46 2332 46 2333 44 362 41 612 2337 40 2137 41 58 330 2284 61 2137 46 2167 40 91 2137 46 2002 44 2137 46 2069 44 2137 46 2074 44 2137 46 2107 44 93 41 2138 61 2137 46 2174 40 91 93 44 2284 41 2335 61 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2117 91 1501 93 91 1501 93 2137 46 2189 40 2284 46 2336 40 2335 46 2332 46 2333 41 44 40 362 44 362 41 44 41 2137 46 2189 40 2335 46 2332 46 2333 44 362 41 330 330 2280 61 2284 46 2173 40 41 2284 61 2137 46 2167 40 91 2137 46 2002 44 2137 46 2071 44 2137 46 2074 44 2137 46 2107 44 93 41 2138 61 2137 46 2174 40 2280 44 2284 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 330 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 330 2137 46 2153 40 2138 44 362 44 1500 44 91 40 362 44 362 41 93 41 330 2335 61 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2166 2137 46 2189 40 2284 46 2336 40 2335 46 2332 46 2333 41 44 40 362 44 362 41 44 41 2137 46 2189 40 2335 46 2332 46 2333 44 362 41 612 2338 40 2137 41 58 362 330 2138 61 2137 46 2174 40 91 2137 46 2002 93 44 91 2137 46 2002 44 2137 46 2075 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2063 61 123 362 58 443 125 41 612 2339 40 2137 41 58 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2075 93 44 91 2137 46 2002 93 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 612 2340 40 2137 41 58 330 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2075 93 44 91 2137 46 2002 44 2137 46 2076 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2063 61 123 125 41 612 2341 40 2137 41 58 330 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2076 93 44 91 2137 46 2002 44 2137 46 2075 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2063 61 123 362 58 443 125 41 612 2342 40 2137 41 58 362 330 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2077 44 2137 46 2105 93 41 330 2335 61 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2117 91 1502 93 91 1501 93 2137 46 2189 40 2335 46 2332 46 2333 44 362 41 330 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2078 44 2137 46 2105 93 41 330 2335 61 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2117 91 1502 93 91 1501 93 2137 46 2189 40 2335 46 2332 46 2333 44 362 41 64 2343 40 2344 61 362 41 612 2345 40 2137 41 58 871 2346 40 2347 46 2348 41 58 2138 61 2137 46 2174 40 91 2137 46 2125 93 44 91 2137 46 2125 44 2137 46 2068 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2153 40 2138 44 362 44 1500 44 91 40 362 44 362 41 93 41 612 2349 40 2137 41 58 2171 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 2350 46 2344 46 2351 40 41 44 2004 46 2061 44 41 41 44 93 41 871 2346 40 2347 46 2348 41 58 2138 61 2137 46 2174 40 91 93 44 91 2171 93 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2153 40 2138 44 362 44 1500 44 91 40 362 44 362 41 93 44 41 612 2352 40 2137 41 58 871 2346 40 2347 46 2348 41 58 2185 61 2137 46 2167 40 91 2137 46 2125 44 2137 46 2067 93 41 871 2343 40 2344 61 362 41 58 2186 61 2137 46 2167 40 91 2137 46 2125 44 2137 46 2068 93 41 2187 61 2178 40 2185 44 2186 41 2138 61 2187 46 2179 40 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2248 61 362 44 2021 61 362 41 2335 61 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2166 2137 46 2189 40 2335 46 2332 46 2333 44 362 41 612 2353 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 93 44 91 2137 46 2014 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 612 2354 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2029 93 44 91 2137 46 2031 93 41 330 2137 46 2189 40 720 40 2138 41 44 1500 41 612 2355 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2032 93 44 91 2137 46 2034 93 41 2137 46 2189 40 2138 44 123 125 41 612 2356 40 2137 41 58 362 330 330 330 2138 61 2137 46 2174 40 91 2137 46 2035 93 44 91 2137 46 2036 93 41 2137 46 2189 40 2138 44 123 125 41 330 330 2138 61 2137 46 2174 40 91 2137 46 2035 93 44 91 2137 46 2037 93 41 2137 46 2189 40 720 40 2138 41 44 1501 41 612 2357 40 2137 41 58 362 330 330 330 2138 61 2137 46 2174 40 91 2137 46 2038 93 44 91 2137 46 2039 93 41 2137 46 2189 40 2138 44 123 125 41 330 330 2138 61 2137 46 2174 40 91 2137 46 2038 93 44 91 2137 46 2040 93 41 2137 46 2189 40 720 40 2138 41 44 1501 41 612 2358 40 2137 41 58 362 330 330 330 2138 61 2137 46 2174 40 91 2137 46 2041 93 44 91 2137 46 2042 93 41 2137 46 2189 40 2138 44 123 125 41 330 330 2138 61 2137 46 2174 40 91 2137 46 2041 93 44 91 2137 46 2043 93 41 2137 46 2189 40 720 40 2138 41 44 1501 41 612 2359 40 2137 41 58 362 330 330 330 2138 61 2137 46 2174 40 91 2137 46 2044 93 44 91 2137 46 2048 93 41 2137 46 2189 40 2138 44 123 125 41 330 330 2138 61 2137 46 2174 40 91 2137 46 2044 93 44 91 2137 46 2049 93 41 2137 46 2189 40 720 40 2138 41 44 1501 41 330 2138 61 2137 46 2174 40 91 2137 46 2044 93 44 91 2137 46 2050 93 41 2137 46 2189 40 720 40 2138 41 44 1501 41 330 330 2138 61 2137 46 2174 40 91 2137 46 2044 93 44 91 2137 46 2051 93 41 2137 46 2189 40 720 40 2138 41 44 1501 41 330 2138 61 2137 46 2174 40 91 2137 46 2044 93 44 91 2137 46 2052 93 41 2137 46 2189 40 720 40 2138 41 44 1501 41 612 2360 40 2137 41 58 362 2299 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 44 330 2015 61 2004 46 2033 44 41 41 93 44 41 2138 61 2137 46 2174 40 91 93 44 91 2299 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 612 2361 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2065 93 44 91 2137 46 2066 44 2137 46 2093 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 41 612 2362 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2066 44 2137 46 2093 93 44 91 2137 46 2007 93 41 330 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 64 2203 46 2204 40 362 44 2205 61 2206 40 362 41 41 612 2363 40 2137 44 2208 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2093 93 44 91 2137 46 2079 44 2137 46 2093 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 612 2364 40 2137 41 58 2138 61 2137 46 2174 40 91 2137 46 2079 44 2137 46 2093 93 44 91 2137 46 2081 44 2137 46 2093 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 612 2365 40 2137 41 58 362 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2082 44 2137 46 2093 44 2137 46 2091 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 44 362 44 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2248 61 362 44 2021 61 362 41 612 2366 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2114 44 2137 46 2007 44 2137 46 2123 93 44 91 2137 46 2110 44 2137 46 2007 93 44 41 330 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2248 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 612 2367 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2114 44 2137 46 2007 44 2137 46 2123 93 44 91 2137 46 2007 93 44 41 330 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2248 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 41 612 2368 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2082 44 2137 46 2093 44 2137 46 2091 93 44 91 2137 46 2093 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2248 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 44 2248 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 41 612 2369 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2085 93 44 91 2137 46 2079 44 2137 46 2093 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 44 2248 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 44 2248 61 362 41 612 2370 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2079 44 2137 46 2093 93 44 91 2137 46 2085 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2248 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 44 2248 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 41 2137 46 2165 40 2138 44 362 44 1500 44 1501 44 2009 61 1503 41 612 2371 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2066 44 2137 46 2094 93 44 91 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2248 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 41 612 2372 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 93 44 91 2137 46 2086 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2063 61 123 362 58 91 40 362 44 362 41 93 44 362 58 362 44 125 41 330 2138 61 2137 46 2174 40 91 2137 46 2086 93 44 91 2137 46 2002 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2063 61 123 125 41 612 2373 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2069 44 2137 46 2002 93 44 91 2137 46 2070 44 2137 46 2002 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2063 61 123 362 58 362 125 41 612 2374 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2105 44 2137 46 2059 93 44 91 2137 46 2105 44 2137 46 2062 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2375 61 362 41 612 2376 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2007 93 44 91 2137 46 2105 44 2137 46 2062 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2248 61 362 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 44 2375 61 362 41 612 2377 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2105 44 2137 46 2062 93 44 91 2137 46 2007 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2375 61 470 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2248 61 362 44 2021 61 362 41 612 2378 40 2137 41 58 362 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2105 44 2137 46 2062 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2063 61 123 362 58 362 125 41 2137 46 2196 40 362 44 91 2021 664 2021 44 2166 696 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2117 93 41 612 2379 40 2137 41 58 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2105 44 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 44 2063 61 123 362 58 362 44 362 58 123 40 362 44 362 41 125 44 362 58 123 40 362 44 362 41 125 44 125 41 44 93 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2063 61 123 362 58 362 44 362 58 123 40 362 44 362 41 125 44 362 58 123 40 362 44 362 41 125 44 125 44 41 612 2380 40 2137 41 58 2296 61 91 40 362 44 123 362 58 91 2004 46 2116 40 2117 61 91 362 93 44 2021 61 362 41 44 93 125 44 41 44 40 362 44 123 362 58 91 2004 46 2017 40 2018 61 2004 46 2019 40 2381 61 1501 41 44 2021 61 362 44 41 44 93 125 44 41 44 93 664 2145 44 2382 696 2296 58 871 2137 46 2383 40 2145 61 2145 41 58 2186 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 44 2063 61 123 362 58 362 44 350 2382 44 125 41 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2105 44 2186 93 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 2145 44 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2063 61 123 362 58 362 125 44 41 612 2384 40 2137 41 58 2296 61 91 40 362 44 123 362 58 91 2004 46 2116 40 2117 61 91 362 93 44 2021 61 362 41 44 93 125 44 41 44 40 362 44 123 362 58 91 2004 46 2017 40 2018 61 2004 46 2019 40 2381 61 1501 41 44 2021 61 362 44 41 44 93 125 44 41 44 40 362 44 123 362 58 123 40 362 44 362 41 125 125 41 44 40 362 44 123 362 58 123 40 362 44 362 41 125 125 41 44 93 664 2145 44 2382 696 2296 58 871 2137 46 2383 40 2145 61 2145 41 58 2186 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 44 2063 61 123 362 58 362 44 350 2382 44 125 41 2138 61 2137 46 2174 40 91 2137 46 2105 44 2137 46 2059 93 44 91 2137 46 2105 44 2186 93 44 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 2145 44 93 41 612 2385 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2097 93 44 91 2137 46 2098 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2189 40 91 2021 664 2021 44 2200 696 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2099 93 44 91 362 44 362 44 362 93 41 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2099 91 1501 93 91 1501 93 46 2228 44 40 362 44 362 44 1501 44 1502 41 41 2137 46 2189 40 2138 91 362 93 91 1500 93 46 2146 91 1500 93 46 2099 91 1502 93 91 1501 93 46 2228 44 40 362 44 362 44 1502 44 1502 41 41 612 2386 40 2137 41 58 362 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2125 44 2137 46 2129 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 612 2387 40 2137 41 58 2171 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 44 2063 61 123 362 58 362 125 41 2138 61 2137 46 2174 40 91 93 44 91 2171 93 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2063 61 123 362 58 362 125 44 41 2388 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 41 2138 61 2137 46 2174 40 91 2171 93 44 91 2388 93 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2063 61 123 125 41 64 2343 40 2344 61 362 41 612 2389 40 2137 41 58 362 871 2346 40 2347 46 2348 41 58 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2128 44 2137 46 2129 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 612 2390 40 2137 41 58 362 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2131 44 2137 46 2007 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 612 2391 40 2137 41 58 2141 61 362 2138 61 2137 46 2174 40 91 93 44 91 2003 40 2141 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 41 44 2003 40 2141 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 44 2003 40 2141 44 362 44 91 93 44 2126 61 40 362 44 41 41 44 93 41 2137 46 2149 40 2138 44 2141 44 1501 41 2137 46 2155 40 2138 44 2141 44 1500 44 91 362 44 362 44 362 44 93 41 2137 46 2160 40 2138 44 2141 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 2141 44 1500 44 1501 44 2021 61 362 41 2137 46 2160 40 2138 44 2141 44 1500 44 1502 44 2021 61 362 41 612 2392 40 2137 41 58 362 2393 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 93 41 2047 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 93 41 2394 61 2003 40 362 44 362 44 91 93 44 2126 61 40 362 44 362 41 41 2395 61 2003 40 362 44 362 44 91 93 44 2126 61 40 362 44 362 41 41 2396 61 2003 40 362 44 362 44 91 93 44 2126 61 40 362 44 362 41 41 2138 61 2137 46 2174 40 91 93 44 91 2393 44 2047 44 2394 44 2395 44 2396 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 44 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 41 612 2397 40 2137 41 58 362 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2002 44 2137 46 2069 44 2137 46 2074 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 41 612 2398 40 2137 41 58 362 2138 61 2137 46 2174 40 91 93 44 91 2137 46 2132 44 2137 46 2007 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 612 2399 40 2137 41 58 362 330 2400 61 2401 40 2402 41 2185 61 2137 46 2167 40 91 93 41 2186 61 2137 46 2167 40 91 2137 46 2108 93 41 2186 46 2403 61 123 362 125 2187 61 2178 40 2185 44 2186 41 2138 61 2187 46 2179 40 2181 61 2400 46 2181 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2153 40 2138 44 362 44 1500 44 91 40 362 44 362 41 93 41 64 2343 40 2404 61 123 362 58 362 125 41 612 2405 40 2137 41 58 362 330 2400 61 2401 40 2402 41 2185 61 2137 46 2167 40 91 93 41 2186 61 2137 46 2167 40 91 2137 46 2108 93 41 2186 46 2403 61 123 362 125 2187 61 2178 40 2185 44 2186 41 2138 61 2187 46 2179 40 2181 61 2400 46 2181 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2153 40 2138 44 362 44 1500 44 91 40 362 44 362 41 93 41 612 2406 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2007 44 2137 46 2094 93 44 91 2137 46 2130 44 2137 46 2095 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1502 44 2021 61 362 41 612 2407 40 2137 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2007 44 2137 46 2105 93 44 91 2137 46 2059 44 2137 46 2105 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 2137 46 2153 40 2138 44 362 44 1500 44 91 40 362 44 362 41 93 41 612 2408 40 2137 41 58 2138 61 2137 46 2174 40 91 2137 46 2002 44 2137 46 2109 93 44 91 2137 46 2002 44 2137 46 2105 93 44 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2153 40 2138 44 362 44 1500 44 91 40 362 44 362 41 93 41 612 2409 40 2137 41 58 362 2410 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 2411 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 41 2412 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 44 93 41 2413 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 41 2138 61 2137 46 2174 40 91 93 44 91 2410 44 2411 44 2412 44 2413 93 41 330 2137 46 2149 40 2138 44 362 44 1502 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2155 40 2138 44 362 44 1501 44 91 362 93 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 64 2343 40 2344 61 362 41 612 2414 40 2137 41 58 362 871 2346 40 2347 46 2348 41 58 2415 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 93 44 2126 61 40 2127 44 41 41 2410 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 2350 46 2344 44 2004 46 2061 41 41 44 93 41 2138 61 2137 46 2174 40 91 93 44 91 2410 44 2415 93 41 330 2137 46 2149 40 2138 44 362 44 1502 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2155 40 2138 44 362 44 1501 44 91 362 93 41 2137 46 2153 40 2138 44 362 44 1500 44 91 93 41 2137 46 2153 40 2138 44 362 44 1501 44 91 40 362 44 362 41 44 40 362 44 362 41 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2153 40 2138 44 362 44 1500 44 91 40 362 44 362 41 93 41 64 2343 40 2344 61 362 41 612 2416 40 2137 41 58 362 871 2346 40 2347 46 2348 41 58 2410 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 2350 46 2344 44 2004 46 2061 41 41 44 93 41 2415 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 362 44 2004 46 2061 41 41 93 44 2126 61 40 2127 44 41 41 2138 61 2137 46 2174 40 91 93 44 91 2410 44 2415 93 41 330 2137 46 2149 40 2138 44 362 44 1502 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2155 40 2138 44 362 44 1501 44 91 362 93 41 2137 46 2153 40 2138 44 362 44 1500 44 91 93 41 2137 46 2153 40 2138 44 362 44 1501 44 91 40 362 44 362 41 44 40 362 44 362 41 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2153 40 2138 44 362 44 1500 44 91 40 362 44 362 41 93 41 64 2343 40 2344 61 362 41 612 2417 40 2137 41 58 362 871 2346 40 2347 46 2348 41 58 2411 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2060 40 2350 46 2344 44 2004 46 2061 44 2418 61 362 41 41 93 41 2138 61 2137 46 2174 40 91 93 44 91 2411 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2153 40 2138 44 362 44 1500 44 91 93 41 64 2343 40 2344 61 362 41 612 2419 40 2137 41 58 871 2346 40 2347 46 2348 41 58 2420 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2060 40 2350 46 2344 44 2004 46 2061 41 41 93 41 2421 61 2003 40 362 44 362 44 91 93 44 2126 61 40 362 44 41 41 2422 61 2003 40 362 44 362 44 91 93 44 2126 61 40 2127 44 362 41 41 2138 61 2137 46 2174 40 91 93 44 91 2420 44 2421 44 2422 93 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 44 362 44 362 93 41 64 2203 46 2204 40 362 44 2205 61 2206 40 362 41 41 612 2423 40 2137 44 2208 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 93 44 91 2137 46 2057 93 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 41 64 2203 46 2204 40 362 41 612 2424 40 2137 44 2208 41 58 362 2138 61 2137 46 2174 40 91 2137 46 2002 93 44 91 2137 46 2055 93 41 2137 46 2189 40 2208 46 2211 44 1502 41 330 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 41 612 2425 40 2137 41 58 2426 61 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 41 2427 61 2003 40 362 44 362 44 91 93 44 2126 61 40 362 44 41 41 2138 61 2137 46 2174 40 91 2426 44 2427 93 44 91 2426 93 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 612 2428 40 2137 41 58 362 2185 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 41 44 93 2186 61 91 2003 40 362 44 362 44 91 40 362 44 2004 46 2005 40 2006 61 515 41 41 44 93 41 44 2003 40 362 44 362 44 91 40 362 44 2004 46 2008 40 2009 61 1504 41 41 44 93 44 2126 61 40 362 44 41 41 44 93 2138 61 2137 46 2174 40 2185 44 2186 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 44 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 44 2248 61 362 41 2137 46 2160 40 2138 44 362 44 1500 44 1501 44 2021 61 362 41 612 2429 40 2137 41 58 2296 61 91 40 362 44 470 41 44 40 362 44 1501 41 44 40 362 44 1502 41 44 40 362 44 1502 41 44 40 362 44 1502 41 44 40 362 44 1502 41 44 40 362 44 1502 41 44 40 362 44 1502 41 44 40 362 44 1502 41 44 40 362 44 1502 41 44 93 664 2198 44 2430 696 2296 58 871 2137 46 2383 40 2198 61 2198 41 58 2137 46 2189 40 2178 46 2431 40 2198 41 44 2430 44 41 612 2432 40 2137 41 58 587 2433 40 2004 46 2060 41 58 612 2434 40 2137 44 42 2228 44 350 2220 41 58 2220 91 362 93 61 362 818 40 41 46 2434 40 42 2228 44 350 2220 41 612 2253 40 2137 41 58 2021 44 2435 44 2228 44 2220 61 818 40 41 46 2253 40 41 616 2220 91 362 93 792 2021 44 2435 44 2228 44 2220 2436 61 2003 40 362 44 362 44 91 40 362 44 2433 40 2437 61 2004 46 2061 41 41 44 93 41 2138 61 2137 46 2174 40 91 2137 46 2002 93 44 91 2137 46 2002 44 2436 93 44 41 2137 46 2149 40 2138 44 362 44 1501 41 2137 46 2155 40 2138 44 362 44 1500 44 91 362 93 41 2137 46 2160 40 2138 44 362 44 1500 44 1500 44 2021 61 362 41 ,"{'AvgLine': 16, 'CountLine': 2836, 'CountStmt': 1150, 'MaxNesting': 5, 'AvgLineCode': 12, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 1006, 'MaxEssential': 1, 'SumEssential': 141, 'AvgCyclomatic': 1, 'CountLineCode': 2235, 'CountStmtDecl': 504, 'MaxCyclomatic': 7, 'SumCyclomatic': 173, 'AvgLineComment': 3, 'CountClassBase': 0, 'CountLineBlank': 157, 'CountDeclMethod': 136, 'CountLineCodeExe': 2064, 'CountLineComment': 448, 'CountClassCoupled': 12, 'CountClassDerived': 0, 'CountLineCodeDecl': 534, 'CountDeclMethodAll': 136, 'MaxInheritanceTree': 0, 'RatioCommentToCode': '0.20', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 7, 'SumCyclomaticStrict': 173, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 7, 'SumCyclomaticModified': 173, 'CountDeclInstanceMethod': 136, 'CountClassCoupledModified': 11, 'CountDeclInstanceVariable': 0}"
133867,Python,"class BasicExpressionsTests(TestCase):
    @classmethod
    def setUpTestData(cls):
        cls.example_inc = Company.objects.create(
            name=""Example Inc."", num_employees=2300, num_chairs=5,
            ceo=Employee.objects.create(firstname=""Joe"", lastname=""Smith"", salary=10)
        )
        cls.foobar_ltd = Company.objects.create(
            name=""Foobar Ltd."", num_employees=3, num_chairs=4, based_in_eu=True,
            ceo=Employee.objects.create(firstname=""Frank"", lastname=""Meyer"", salary=20)
        )
        cls.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)
        cls.gmbh = Company.objects.create(name='Test GmbH', num_employees=32, num_chairs=1, ceo=cls.max)

    def setUp(self):
        self.company_query = Company.objects.values(
            ""name"", ""num_employees"", ""num_chairs""
        ).order_by(
            ""name"", ""num_employees"", ""num_chairs""
        )

    def test_annotate_values_aggregate(self):
        companies = Company.objects.annotate(
            salaries=F('ceo__salary'),
        ).values('num_employees', 'salaries').aggregate(
            result=Sum(
                F('salaries') + F('num_employees'),
                output_field=IntegerField()
            ),
        )
        self.assertEqual(companies['result'], 2395)

    def test_annotate_values_filter(self):
        companies = Company.objects.annotate(
            foo=RawSQL('%s', ['value']),
        ).filter(foo='value').order_by('name')
        self.assertSequenceEqual(
            companies,
            [self.example_inc, self.foobar_ltd, self.gmbh],
        )

    def test_annotate_values_count(self):
        companies = Company.objects.annotate(foo=RawSQL('%s', ['value']))
        self.assertEqual(companies.count(), 3)

    @skipUnlessDBFeature('supports_boolean_expr_in_select_clause')
    def test_filtering_on_annotate_that_uses_q(self):
        self.assertEqual(
            Company.objects.annotate(
                num_employees_check=ExpressionWrapper(Q(num_employees__gt=3), output_field=BooleanField())
            ).filter(num_employees_check=True).count(),
            2,
        )

    def test_filtering_on_q_that_is_boolean(self):
        self.assertEqual(
            Company.objects.filter(
                ExpressionWrapper(Q(num_employees__gt=3), output_field=BooleanField())
            ).count(),
            2,
        )

    def test_filtering_on_rawsql_that_is_boolean(self):
        self.assertEqual(
            Company.objects.filter(
                RawSQL('num_employees > %s', (3,), output_field=BooleanField()),
            ).count(),
            2,
        )

    def test_filter_inter_attribute(self):
        # We can filter on attribute relationships on same model obj, e.g.
        # find companies where the number of employees is greater
        # than the number of chairs.
        self.assertSequenceEqual(
            self.company_query.filter(num_employees__gt=F(""num_chairs"")), [
                {
                    ""num_chairs"": 5,
                    ""name"": ""Example Inc."",
                    ""num_employees"": 2300,
                },
                {
                    ""num_chairs"": 1,
                    ""name"": ""Test GmbH"",
                    ""num_employees"": 32
                },
            ],
        )

    def test_update(self):
        # We can set one field to have the value of another field
        # Make sure we have enough chairs
        self.company_query.update(num_chairs=F(""num_employees""))
        self.assertSequenceEqual(
            self.company_query, [
                {
                    ""num_chairs"": 2300,
                    ""name"": ""Example Inc."",
                    ""num_employees"": 2300
                },
                {
                    ""num_chairs"": 3,
                    ""name"": ""Foobar Ltd."",
                    ""num_employees"": 3
                },
                {
                    ""num_chairs"": 32,
                    ""name"": ""Test GmbH"",
                    ""num_employees"": 32
                }
            ],
        )

    def test_arithmetic(self):
        # We can perform arithmetic operations in expressions
        # Make sure we have 2 spare chairs
        self.company_query.update(num_chairs=F(""num_employees"") + 2)
        self.assertSequenceEqual(
            self.company_query, [
                {
                    'num_chairs': 2302,
                    'name': 'Example Inc.',
                    'num_employees': 2300
                },
                {
                    'num_chairs': 5,
                    'name': 'Foobar Ltd.',
                    'num_employees': 3
                },
                {
                    'num_chairs': 34,
                    'name': 'Test GmbH',
                    'num_employees': 32
                }
            ],
        )

    def test_order_of_operations(self):
        # Law of order of operations is followed
        self.company_query.update(num_chairs=F('num_employees') + 2 * F('num_employees'))
        self.assertSequenceEqual(
            self.company_query, [
                {
                    'num_chairs': 6900,
                    'name': 'Example Inc.',
                    'num_employees': 2300
                },
                {
                    'num_chairs': 9,
                    'name': 'Foobar Ltd.',
                    'num_employees': 3
                },
                {
                    'num_chairs': 96,
                    'name': 'Test GmbH',
                    'num_employees': 32
                }
            ],
        )

    def test_parenthesis_priority(self):
        # Law of order of operations can be overridden by parentheses
        self.company_query.update(num_chairs=(F('num_employees') + 2) * F('num_employees'))
        self.assertSequenceEqual(
            self.company_query, [
                {
                    'num_chairs': 5294600,
                    'name': 'Example Inc.',
                    'num_employees': 2300
                },
                {
                    'num_chairs': 15,
                    'name': 'Foobar Ltd.',
                    'num_employees': 3
                },
                {
                    'num_chairs': 1088,
                    'name': 'Test GmbH',
                    'num_employees': 32
                }
            ],
        )

    def test_update_with_fk(self):
        # ForeignKey can become updated with the value of another ForeignKey.
        self.assertEqual(Company.objects.update(point_of_contact=F('ceo')), 3)
        self.assertQuerysetEqual(
            Company.objects.all(),
            ['Joe Smith', 'Frank Meyer', 'Max Mustermann'],
            lambda c: str(c.point_of_contact),
            ordered=False
        )

    def test_update_with_none(self):
        Number.objects.create(integer=1, float=1.0)
        Number.objects.create(integer=2)
        Number.objects.filter(float__isnull=False).update(float=Value(None))
        self.assertQuerysetEqual(
            Number.objects.all(),
            [None, None],
            lambda n: n.float,
            ordered=False
        )

    def test_filter_with_join(self):
        # F Expressions can also span joins
        Company.objects.update(point_of_contact=F('ceo'))
        c = Company.objects.first()
        c.point_of_contact = Employee.objects.create(firstname=""Guido"", lastname=""van Rossum"")
        c.save()

        self.assertQuerysetEqual(
            Company.objects.filter(ceo__firstname=F('point_of_contact__firstname')),
            ['Foobar Ltd.', 'Test GmbH'],
            lambda c: c.name,
            ordered=False
        )

        Company.objects.exclude(
            ceo__firstname=F(""point_of_contact__firstname"")
        ).update(name=""foo"")
        self.assertEqual(
            Company.objects.exclude(
                ceo__firstname=F('point_of_contact__firstname')
            ).get().name,
            ""foo"",
        )

        msg = ""Joined field references are not permitted in this query""
        with self.assertRaisesMessage(FieldError, msg):
            Company.objects.exclude(
                ceo__firstname=F('point_of_contact__firstname')
            ).update(name=F('point_of_contact__lastname'))

    def test_object_update(self):
        # F expressions can be used to update attributes on single objects
        self.gmbh.num_employees = F('num_employees') + 4
        self.gmbh.save()
        self.gmbh.refresh_from_db()
        self.assertEqual(self.gmbh.num_employees, 36)

    def test_new_object_save(self):
        # We should be able to use Funcs when inserting new data
        test_co = Company(name=Lower(Value('UPPER')), num_employees=32, num_chairs=1, ceo=self.max)
        test_co.save()
        test_co.refresh_from_db()
        self.assertEqual(test_co.name, ""upper"")

    def test_new_object_create(self):
        test_co = Company.objects.create(name=Lower(Value('UPPER')), num_employees=32, num_chairs=1, ceo=self.max)
        test_co.refresh_from_db()
        self.assertEqual(test_co.name, ""upper"")

    def test_object_create_with_aggregate(self):
        # Aggregates are not allowed when inserting new data
        msg = 'Aggregate functions are not allowed in this query (num_employees=Max(Value(1))).'
        with self.assertRaisesMessage(FieldError, msg):
            Company.objects.create(
                name='Company', num_employees=Max(Value(1)), num_chairs=1,
                ceo=Employee.objects.create(firstname=""Just"", lastname=""Doit"", salary=30),
            )

    def test_object_update_fk(self):
        # F expressions cannot be used to update attributes which are foreign
        # keys, or attributes which involve joins.
        test_gmbh = Company.objects.get(pk=self.gmbh.pk)
        msg = 'F(ceo)"": ""Company.point_of_contact"" must be a ""Employee"" instance.'
        with self.assertRaisesMessage(ValueError, msg):
            test_gmbh.point_of_contact = F('ceo')

        test_gmbh.point_of_contact = self.gmbh.ceo
        test_gmbh.save()
        test_gmbh.name = F('ceo__lastname')
        msg = 'Joined field references are not permitted in this query'
        with self.assertRaisesMessage(FieldError, msg):
            test_gmbh.save()

    def test_update_inherited_field_value(self):
        msg = 'Joined field references are not permitted in this query'
        with self.assertRaisesMessage(FieldError, msg):
            RemoteEmployee.objects.update(adjusted_salary=F('salary') * 5)

    def test_object_update_unsaved_objects(self):
        # F expressions cannot be used to update attributes on objects which do
        # not yet exist in the database
        acme = Company(name='The Acme Widget Co.', num_employees=12, num_chairs=5, ceo=self.max)
        acme.num_employees = F(""num_employees"") + 16
        msg = (
            'Failed to insert expression ""Col(expressions_company, '
            'expressions.Company.num_employees) + Value(16)"" on '
            'expressions.Company.num_employees. F() expressions can only be '
            'used to update, not to insert.'
        )
        with self.assertRaisesMessage(ValueError, msg):
            acme.save()

        acme.num_employees = 12
        acme.name = Lower(F('name'))
        msg = (
            'Failed to insert expression ""Lower(Col(expressions_company, '
            'expressions.Company.name))"" on expressions.Company.name. F() '
            'expressions can only be used to update, not to insert.'
        )
        with self.assertRaisesMessage(ValueError, msg):
            acme.save()

    def test_ticket_11722_iexact_lookup(self):
        Employee.objects.create(firstname=""John"", lastname=""Doe"")
        test = Employee.objects.create(firstname=""Test"", lastname=""test"")

        queryset = Employee.objects.filter(firstname__iexact=F('lastname'))
        self.assertSequenceEqual(queryset, [test])

    def test_ticket_16731_startswith_lookup(self):
        Employee.objects.create(firstname=""John"", lastname=""Doe"")
        e2 = Employee.objects.create(firstname=""Jack"", lastname=""Jackson"")
        e3 = Employee.objects.create(firstname=""Jack"", lastname=""jackson"")
        self.assertSequenceEqual(
            Employee.objects.filter(lastname__startswith=F('firstname')),
            [e2, e3] if connection.features.has_case_insensitive_like else [e2]
        )
        qs = Employee.objects.filter(lastname__istartswith=F('firstname')).order_by('pk')
        self.assertSequenceEqual(qs, [e2, e3])

    def test_ticket_18375_join_reuse(self):
        # Reverse multijoin F() references and the lookup target the same join.
        # Pre #18375 the F() join was generated first and the lookup couldn't
        # reuse that join.
        qs = Employee.objects.filter(company_ceo_set__num_chairs=F('company_ceo_set__num_employees'))
        self.assertEqual(str(qs.query).count('JOIN'), 1)

    def test_ticket_18375_kwarg_ordering(self):
        # The next query was dict-randomization dependent - if the ""gte=1""
        # was seen first, then the F() will reuse the join generated by the
        # gte lookup, if F() was seen first, then it generated a join the
        # other lookups could not reuse.
        qs = Employee.objects.filter(
            company_ceo_set__num_chairs=F('company_ceo_set__num_employees'),
            company_ceo_set__num_chairs__gte=1,
        )
        self.assertEqual(str(qs.query).count('JOIN'), 1)

    def test_ticket_18375_kwarg_ordering_2(self):
        # Another similar case for F() than above. Now we have the same join
        # in two filter kwargs, one in the lhs lookup, one in F. Here pre
        # #18375 the amount of joins generated was random if dict
        # randomization was enabled, that is the generated query dependent
        # on which clause was seen first.
        qs = Employee.objects.filter(
            company_ceo_set__num_employees=F('pk'),
            pk=F('company_ceo_set__num_employees')
        )
        self.assertEqual(str(qs.query).count('JOIN'), 1)

    def test_ticket_18375_chained_filters(self):
        # F() expressions do not reuse joins from previous filter.
        qs = Employee.objects.filter(
            company_ceo_set__num_employees=F('pk')
        ).filter(
            company_ceo_set__num_employees=F('company_ceo_set__num_employees')
        )
        self.assertEqual(str(qs.query).count('JOIN'), 2)

    def test_order_by_exists(self):
        mary = Employee.objects.create(firstname='Mary', lastname='Mustermann', salary=20)
        mustermanns_by_seniority = Employee.objects.filter(lastname='Mustermann').order_by(
            # Order by whether the employee is the CEO of a company
            Exists(Company.objects.filter(ceo=OuterRef('pk'))).desc()
        )
        self.assertSequenceEqual(mustermanns_by_seniority, [self.max, mary])

    def test_order_by_multiline_sql(self):
        raw_order_by = (
            RawSQL('''
                CASE WHEN num_employees > 1000
                     THEN num_chairs
                     ELSE 0 END
            ''', []).desc(),
            RawSQL('''
                CASE WHEN num_chairs > 1
                     THEN 1
                     ELSE 0 END
            ''', []).asc()
        )
        for qs in (
            Company.objects.all(),
            Company.objects.distinct(),
        ):
            with self.subTest(qs=qs):
                self.assertSequenceEqual(
                    qs.order_by(*raw_order_by),
                    [self.example_inc, self.gmbh, self.foobar_ltd],
                )

    def test_outerref(self):
        inner = Company.objects.filter(point_of_contact=OuterRef('pk'))
        msg = (
            'This queryset contains a reference to an outer query and may only '
            'be used in a subquery.'
        )
        with self.assertRaisesMessage(ValueError, msg):
            inner.exists()

        outer = Employee.objects.annotate(is_point_of_contact=Exists(inner))
        self.assertIs(outer.exists(), True)

    def test_exist_single_field_output_field(self):
        queryset = Company.objects.values('pk')
        self.assertIsInstance(Exists(queryset).output_field, BooleanField)

    def test_subquery(self):
        Company.objects.filter(name='Example Inc.').update(
            point_of_contact=Employee.objects.get(firstname='Joe', lastname='Smith'),
            ceo=self.max,
        )
        Employee.objects.create(firstname='Bob', lastname='Brown', salary=40)
        qs = Employee.objects.annotate(
            is_point_of_contact=Exists(Company.objects.filter(point_of_contact=OuterRef('pk'))),
            is_not_point_of_contact=~Exists(Company.objects.filter(point_of_contact=OuterRef('pk'))),
            is_ceo_of_small_company=Exists(Company.objects.filter(num_employees__lt=200, ceo=OuterRef('pk'))),
            is_ceo_small_2=~~Exists(Company.objects.filter(num_employees__lt=200, ceo=OuterRef('pk'))),
            largest_company=Subquery(Company.objects.order_by('-num_employees').filter(
                Q(ceo=OuterRef('pk')) | Q(point_of_contact=OuterRef('pk'))
            ).values('name')[:1], output_field=CharField())
        ).values(
            'firstname',
            'is_point_of_contact',
            'is_not_point_of_contact',
            'is_ceo_of_small_company',
            'is_ceo_small_2',
            'largest_company',
        ).order_by('firstname')

        results = list(qs)
        # Could use Coalesce(subq, Value('')) instead except for the bug in
        # cx_Oracle mentioned in #23843.
        bob = results[0]
        if bob['largest_company'] == '' and connection.features.interprets_empty_strings_as_nulls:
            bob['largest_company'] = None

        self.assertEqual(results, [
            {
                'firstname': 'Bob',
                'is_point_of_contact': False,
                'is_not_point_of_contact': True,
                'is_ceo_of_small_company': False,
                'is_ceo_small_2': False,
                'largest_company': None,
            },
            {
                'firstname': 'Frank',
                'is_point_of_contact': False,
                'is_not_point_of_contact': True,
                'is_ceo_of_small_company': True,
                'is_ceo_small_2': True,
                'largest_company': 'Foobar Ltd.',
            },
            {
                'firstname': 'Joe',
                'is_point_of_contact': True,
                'is_not_point_of_contact': False,
                'is_ceo_of_small_company': False,
                'is_ceo_small_2': False,
                'largest_company': 'Example Inc.',
            },
            {
                'firstname': 'Max',
                'is_point_of_contact': False,
                'is_not_point_of_contact': True,
                'is_ceo_of_small_company': True,
                'is_ceo_small_2': True,
                'largest_company': 'Example Inc.'
            }
        ])
        # A less elegant way to write the same query: this uses a LEFT OUTER
        # JOIN and an IS NULL, inside a WHERE NOT IN which is probably less
        # efficient than EXISTS.
        self.assertCountEqual(
            qs.filter(is_point_of_contact=True).values('pk'),
            Employee.objects.exclude(company_point_of_contact_set=None).values('pk')
        )

    def test_subquery_eq(self):
        qs = Employee.objects.annotate(
            is_ceo=Exists(Company.objects.filter(ceo=OuterRef('pk'))),
            is_point_of_contact=Exists(
                Company.objects.filter(point_of_contact=OuterRef('pk')),
            ),
            small_company=Exists(
                queryset=Company.objects.filter(num_employees__lt=200),
            ),
        ).filter(is_ceo=True, is_point_of_contact=False, small_company=True)
        self.assertNotEqual(
            qs.query.annotations['is_ceo'],
            qs.query.annotations['is_point_of_contact'],
        )
        self.assertNotEqual(
            qs.query.annotations['is_ceo'],
            qs.query.annotations['small_company'],
        )

    def test_in_subquery(self):
        # This is a contrived test (and you really wouldn't write this query),
        # but it is a succinct way to test the __in=Subquery() construct.
        small_companies = Company.objects.filter(num_employees__lt=200).values('pk')
        subquery_test = Company.objects.filter(pk__in=Subquery(small_companies))
        self.assertCountEqual(subquery_test, [self.foobar_ltd, self.gmbh])
        subquery_test2 = Company.objects.filter(pk=Subquery(small_companies.filter(num_employees=3)))
        self.assertCountEqual(subquery_test2, [self.foobar_ltd])

    def test_uuid_pk_subquery(self):
        u = UUIDPK.objects.create()
        UUID.objects.create(uuid_fk=u)
        qs = UUIDPK.objects.filter(id__in=Subquery(UUID.objects.values('uuid_fk__id')))
        self.assertCountEqual(qs, [u])

    def test_nested_subquery(self):
        inner = Company.objects.filter(point_of_contact=OuterRef('pk'))
        outer = Employee.objects.annotate(is_point_of_contact=Exists(inner))
        contrived = Employee.objects.annotate(
            is_point_of_contact=Subquery(
                outer.filter(pk=OuterRef('pk')).values('is_point_of_contact'),
                output_field=BooleanField(),
            ),
        )
        self.assertCountEqual(contrived.values_list(), outer.values_list())

    def test_nested_subquery_join_outer_ref(self):
        inner = Employee.objects.filter(pk=OuterRef('ceo__pk')).values('pk')
        qs = Employee.objects.annotate(
            ceo_company=Subquery(
                Company.objects.filter(
                    ceo__in=inner,
                    ceo__pk=OuterRef('pk'),
                ).values('pk'),
            ),
        )
        self.assertSequenceEqual(
            qs.values_list('ceo_company', flat=True),
            [self.example_inc.pk, self.foobar_ltd.pk, self.gmbh.pk],
        )

    def test_nested_subquery_outer_ref_2(self):
        first = Time.objects.create(time='09:00')
        second = Time.objects.create(time='17:00')
        third = Time.objects.create(time='21:00')
        SimulationRun.objects.bulk_create([
            SimulationRun(start=first, end=second, midpoint='12:00'),
            SimulationRun(start=first, end=third, midpoint='15:00'),
            SimulationRun(start=second, end=first, midpoint='00:00'),
        ])
        inner = Time.objects.filter(time=OuterRef(OuterRef('time')), pk=OuterRef('start')).values('time')
        middle = SimulationRun.objects.annotate(other=Subquery(inner)).values('other')[:1]
        outer = Time.objects.annotate(other=Subquery(middle, output_field=TimeField()))
        # This is a contrived example. It exercises the double OuterRef form.
        self.assertCountEqual(outer, [first, second, third])

    def test_nested_subquery_outer_ref_with_autofield(self):
        first = Time.objects.create(time='09:00')
        second = Time.objects.create(time='17:00')
        SimulationRun.objects.create(start=first, end=second, midpoint='12:00')
        inner = SimulationRun.objects.filter(start=OuterRef(OuterRef('pk'))).values('start')
        middle = Time.objects.annotate(other=Subquery(inner)).values('other')[:1]
        outer = Time.objects.annotate(other=Subquery(middle, output_field=IntegerField()))
        # This exercises the double OuterRef form with AutoField as pk.
        self.assertCountEqual(outer, [first, second])

    def test_annotations_within_subquery(self):
        Company.objects.filter(num_employees__lt=50).update(ceo=Employee.objects.get(firstname='Frank'))
        inner = Company.objects.filter(
            ceo=OuterRef('pk')
        ).values('ceo').annotate(total_employees=Sum('num_employees')).values('total_employees')
        outer = Employee.objects.annotate(total_employees=Subquery(inner)).filter(salary__lte=Subquery(inner))
        self.assertSequenceEqual(
            outer.order_by('-total_employees').values('salary', 'total_employees'),
            [{'salary': 10, 'total_employees': 2300}, {'salary': 20, 'total_employees': 35}],
        )

    def test_subquery_references_joined_table_twice(self):
        inner = Company.objects.filter(
            num_chairs__gte=OuterRef('ceo__salary'),
            num_employees__gte=OuterRef('point_of_contact__salary'),
        )
        # Another contrived example (there is no need to have a subquery here)
        outer = Company.objects.filter(pk__in=Subquery(inner.values('pk')))
        self.assertFalse(outer.exists())

    def test_subquery_filter_by_aggregate(self):
        Number.objects.create(integer=1000, float=1.2)
        Employee.objects.create(salary=1000)
        qs = Number.objects.annotate(
            min_valuable_count=Subquery(
                Employee.objects.filter(
                    salary=OuterRef('integer'),
                ).annotate(cnt=Count('salary')).filter(cnt__gt=0).values('cnt')[:1]
            ),
        )
        self.assertEqual(qs.get().float, 1.2)

    def test_subquery_filter_by_lazy(self):
        self.max.manager = Manager.objects.create(name='Manager')
        self.max.save()
        max_manager = SimpleLazyObject(
            lambda: Manager.objects.get(pk=self.max.manager.pk)
        )
        qs = Company.objects.annotate(
            ceo_manager=Subquery(
                Employee.objects.filter(
                    lastname=OuterRef('ceo__lastname'),
                ).values('manager'),
            ),
        ).filter(ceo_manager=max_manager)
        self.assertEqual(qs.get(), self.gmbh)

    def test_aggregate_subquery_annotation(self):
        with self.assertNumQueries(1) as ctx:
            aggregate = Company.objects.annotate(
                ceo_salary=Subquery(
                    Employee.objects.filter(
                        id=OuterRef('ceo_id'),
                    ).values('salary')
                ),
            ).aggregate(
                ceo_salary_gt_20=Count('pk', filter=Q(ceo_salary__gt=20)),
            )
        self.assertEqual(aggregate, {'ceo_salary_gt_20': 1})
        # Aggregation over a subquery annotation doesn't annotate the subquery
        # twice in the inner query.
        sql = ctx.captured_queries[0]['sql']
        self.assertLessEqual(sql.count('SELECT'), 3)
        # GROUP BY isn't required to aggregate over a query that doesn't
        # contain nested aggregates.
        self.assertNotIn('GROUP BY', sql)

    @skipUnlessDBFeature('supports_over_clause')
    def test_aggregate_rawsql_annotation(self):
        with self.assertNumQueries(1) as ctx:
            aggregate = Company.objects.annotate(
                salary=RawSQL('SUM(num_chairs) OVER (ORDER BY num_employees)', []),
            ).aggregate(
                count=Count('pk'),
            )
            self.assertEqual(aggregate, {'count': 3})
        sql = ctx.captured_queries[0]['sql']
        self.assertNotIn('GROUP BY', sql)

    def test_explicit_output_field(self):
        class FuncA(Func):
            output_field = CharField()

        class FuncB(Func):
            pass

        expr = FuncB(FuncA())
        self.assertEqual(expr.output_field, FuncA.output_field)

    def test_outerref_mixed_case_table_name(self):
        inner = Result.objects.filter(result_time__gte=OuterRef('experiment__assigned'))
        outer = Result.objects.filter(pk__in=Subquery(inner.values('pk')))
        self.assertFalse(outer.exists())

    def test_outerref_with_operator(self):
        inner = Company.objects.filter(num_employees=OuterRef('ceo__salary') + 2)
        outer = Company.objects.filter(pk__in=Subquery(inner.values('pk')))
        self.assertEqual(outer.get().name, 'Test GmbH')

    def test_nested_outerref_with_function(self):
        self.gmbh.point_of_contact = Employee.objects.get(lastname='Meyer')
        self.gmbh.save()
        inner = Employee.objects.filter(
            lastname__startswith=Left(OuterRef(OuterRef('lastname')), 1),
        )
        qs = Employee.objects.annotate(
            ceo_company=Subquery(
                Company.objects.filter(
                    point_of_contact__in=inner,
                    ceo__pk=OuterRef('pk'),
                ).values('name'),
            ),
        ).filter(ceo_company__isnull=False)
        self.assertEqual(qs.get().ceo_company, 'Test GmbH')

    def test_annotation_with_outerref(self):
        gmbh_salary = Company.objects.annotate(
            max_ceo_salary_raise=Subquery(
                Company.objects.annotate(
                    salary_raise=OuterRef('num_employees') + F('num_employees'),
                ).order_by('-salary_raise').values('salary_raise')[:1],
                output_field=IntegerField(),
            ),
        ).get(pk=self.gmbh.pk)
        self.assertEqual(gmbh_salary.max_ceo_salary_raise, 2332)

    def test_annotation_with_nested_outerref(self):
        self.gmbh.point_of_contact = Employee.objects.get(lastname='Meyer')
        self.gmbh.save()
        inner = Employee.objects.annotate(
            outer_lastname=OuterRef(OuterRef('lastname')),
        ).filter(lastname__startswith=Left('outer_lastname', 1))
        qs = Employee.objects.annotate(
            ceo_company=Subquery(
                Company.objects.filter(
                    point_of_contact__in=inner,
                    ceo__pk=OuterRef('pk'),
                ).values('name'),
            ),
        ).filter(ceo_company__isnull=False)
        self.assertEqual(qs.get().ceo_company, 'Test GmbH')

    def test_pickle_expression(self):
        expr = Value(1)
        expr.convert_value  # populate cached property
        self.assertEqual(pickle.loads(pickle.dumps(expr)), expr)

    def test_incorrect_field_in_F_expression(self):
        with self.assertRaisesMessage(FieldError, ""Cannot resolve keyword 'nope' into field.""):
            list(Employee.objects.filter(firstname=F('nope')))

    def test_incorrect_joined_field_in_F_expression(self):
        with self.assertRaisesMessage(FieldError, ""Cannot resolve keyword 'nope' into field.""):
            list(Company.objects.filter(ceo__pk=F('point_of_contact__nope')))

    def test_exists_in_filter(self):
        inner = Company.objects.filter(ceo=OuterRef('pk')).values('pk')
        qs1 = Employee.objects.filter(Exists(inner))
        qs2 = Employee.objects.annotate(found=Exists(inner)).filter(found=True)
        self.assertCountEqual(qs1, qs2)
        self.assertFalse(Employee.objects.exclude(Exists(inner)).exists())
        self.assertCountEqual(qs2, Employee.objects.exclude(~Exists(inner)))

    def test_subquery_in_filter(self):
        inner = Company.objects.filter(ceo=OuterRef('pk')).values('based_in_eu')
        self.assertSequenceEqual(
            Employee.objects.filter(Subquery(inner)),
            [self.foobar_ltd.ceo],
        )

    def test_subquery_group_by_outerref_in_filter(self):
        inner = Company.objects.annotate(
            employee=OuterRef('pk'),
        ).values('employee').annotate(
            min_num_chairs=Min('num_chairs'),
        ).values('ceo')
        self.assertIs(Employee.objects.filter(pk__in=Subquery(inner)).exists(), True)

    def test_case_in_filter_if_boolean_output_field(self):
        is_ceo = Company.objects.filter(ceo=OuterRef('pk'))
        is_poc = Company.objects.filter(point_of_contact=OuterRef('pk'))
        qs = Employee.objects.filter(
            Case(
                When(Exists(is_ceo), then=True),
                When(Exists(is_poc), then=True),
                default=False,
                output_field=BooleanField(),
            ),
        )
        self.assertCountEqual(qs, [self.example_inc.ceo, self.foobar_ltd.ceo, self.max])

    def test_boolean_expression_combined(self):
        is_ceo = Company.objects.filter(ceo=OuterRef('pk'))
        is_poc = Company.objects.filter(point_of_contact=OuterRef('pk'))
        self.gmbh.point_of_contact = self.max
        self.gmbh.save()
        self.assertCountEqual(
            Employee.objects.filter(Exists(is_ceo) | Exists(is_poc)),
            [self.example_inc.ceo, self.foobar_ltd.ceo, self.max],
        )
        self.assertCountEqual(
            Employee.objects.filter(Exists(is_ceo) & Exists(is_poc)),
            [self.max],
        )
        self.assertCountEqual(
            Employee.objects.filter(Exists(is_ceo) & Q(salary__gte=30)),
            [self.max],
        )
        self.assertCountEqual(
            Employee.objects.filter(Exists(is_poc) | Q(salary__lt=15)),
            [self.example_inc.ceo, self.max],
        )
        self.assertCountEqual(
            Employee.objects.filter(Q(salary__gte=30) & Exists(is_ceo)),
            [self.max],
        )
        self.assertCountEqual(
            Employee.objects.filter(Q(salary__lt=15) | Exists(is_poc)),
            [self.example_inc.ceo, self.max],
        )

    def test_boolean_expression_combined_with_empty_Q(self):
        is_poc = Company.objects.filter(point_of_contact=OuterRef('pk'))
        self.gmbh.point_of_contact = self.max
        self.gmbh.save()
        tests = [
            Exists(is_poc) & Q(),
            Q() & Exists(is_poc),
            Exists(is_poc) | Q(),
            Q() | Exists(is_poc),
            Q(Exists(is_poc)) & Q(),
            Q() & Q(Exists(is_poc)),
            Q(Exists(is_poc)) | Q(),
            Q() | Q(Exists(is_poc)),
        ]
        for conditions in tests:
            with self.subTest(conditions):
                self.assertCountEqual(Employee.objects.filter(conditions), [self.max])

    def test_boolean_expression_in_Q(self):
        is_poc = Company.objects.filter(point_of_contact=OuterRef('pk'))
        self.gmbh.point_of_contact = self.max
        self.gmbh.save()
        self.assertCountEqual(Employee.objects.filter(Q(Exists(is_poc))), [self.max])",1,587 2000 40 2001 41 58 64 588 612 2002 40 2003 41 58 2003 46 2004 61 2005 46 2006 46 2007 40 2008 61 362 44 2009 61 1505 44 2010 61 1502 44 2011 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 362 44 2015 61 1502 41 41 2003 46 2016 61 2005 46 2006 46 2007 40 2008 61 362 44 2009 61 1502 44 2010 61 1502 44 2017 61 515 44 2011 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 362 44 2015 61 1503 41 41 2003 46 733 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 362 44 2015 61 1503 41 2003 46 2018 61 2005 46 2006 46 2007 40 2008 61 362 44 2009 61 1503 44 2010 61 1501 44 2011 61 2003 46 733 41 612 2019 40 2020 41 58 2020 46 2021 61 2005 46 2006 46 2022 40 362 44 362 44 362 41 46 2023 40 362 44 362 44 362 41 612 2024 40 2020 41 58 2025 61 2005 46 2006 46 2026 40 2027 61 2028 40 362 41 44 41 46 2022 40 362 44 362 41 46 2029 40 2030 61 2031 40 2028 40 362 41 43 2028 40 362 41 44 2032 61 2033 40 41 41 44 41 2020 46 2034 40 2025 91 362 93 44 1505 41 612 2035 40 2020 41 58 2025 61 2005 46 2006 46 2026 40 2036 61 2037 40 362 44 91 362 93 41 44 41 46 656 40 2036 61 362 41 46 2023 40 362 41 2020 46 2038 40 2025 44 91 2020 46 2004 44 2020 46 2016 44 2020 46 2018 93 44 41 612 2039 40 2020 41 58 2025 61 2005 46 2006 46 2026 40 2036 61 2037 40 362 44 91 362 93 41 41 2020 46 2034 40 2025 46 2040 40 41 44 1502 41 64 2041 40 362 41 612 2042 40 2020 41 58 2020 46 2034 40 2005 46 2006 46 2026 40 2043 61 2044 40 2045 40 2046 61 1502 41 44 2032 61 2047 40 41 41 41 46 656 40 2043 61 515 41 46 2040 40 41 44 1502 44 41 612 2048 40 2020 41 58 2020 46 2034 40 2005 46 2006 46 656 40 2044 40 2045 40 2046 61 1502 41 44 2032 61 2047 40 41 41 41 46 2040 40 41 44 1502 44 41 612 2049 40 2020 41 58 2020 46 2034 40 2005 46 2006 46 656 40 2037 40 362 44 40 1502 44 41 44 2032 61 2047 40 41 41 44 41 46 2040 40 41 44 1502 44 41 612 2050 40 2020 41 58 330 330 330 2020 46 2038 40 2020 46 2021 46 656 40 2046 61 2028 40 362 41 41 44 91 123 362 58 1502 44 362 58 362 44 362 58 1505 44 125 44 123 362 58 1501 44 362 58 362 44 362 58 1503 125 44 93 44 41 612 2051 40 2020 41 58 330 330 2020 46 2021 46 2052 40 2010 61 2028 40 362 41 41 2020 46 2038 40 2020 46 2021 44 91 123 362 58 1505 44 362 58 362 44 362 58 1505 125 44 123 362 58 1502 44 362 58 362 44 362 58 1502 125 44 123 362 58 1503 44 362 58 362 44 362 58 1503 125 93 44 41 612 2053 40 2020 41 58 330 330 2020 46 2021 46 2052 40 2010 61 2028 40 362 41 43 1502 41 2020 46 2038 40 2020 46 2021 44 91 123 362 58 1505 44 362 58 362 44 362 58 1505 125 44 123 362 58 1502 44 362 58 362 44 362 58 1502 125 44 123 362 58 1503 44 362 58 362 44 362 58 1503 125 93 44 41 612 2054 40 2020 41 58 330 2020 46 2021 46 2052 40 2010 61 2028 40 362 41 43 1502 42 2028 40 362 41 41 2020 46 2038 40 2020 46 2021 44 91 123 362 58 1505 44 362 58 362 44 362 58 1505 125 44 123 362 58 1502 44 362 58 362 44 362 58 1502 125 44 123 362 58 1503 44 362 58 362 44 362 58 1503 125 93 44 41 612 2055 40 2020 41 58 330 2020 46 2021 46 2052 40 2010 61 40 2028 40 362 41 43 1502 41 42 2028 40 362 41 41 2020 46 2038 40 2020 46 2021 44 91 123 362 58 1508 44 362 58 362 44 362 58 1505 125 44 123 362 58 1503 44 362 58 362 44 362 58 1502 125 44 123 362 58 1505 44 362 58 362 44 362 58 1503 125 93 44 41 612 2056 40 2020 41 58 330 2020 46 2034 40 2005 46 2006 46 2052 40 2057 61 2028 40 362 41 41 44 1502 41 2020 46 2058 40 2005 46 2006 46 544 40 41 44 91 362 44 362 44 362 93 44 719 2059 58 813 40 2059 46 2057 41 44 2060 61 443 41 612 2061 40 2020 41 58 2062 46 2006 46 2007 40 2063 61 1501 44 660 61 1501 41 2062 46 2006 46 2007 40 2063 61 1502 41 2062 46 2006 46 656 40 2064 61 443 41 46 2052 40 660 61 2065 40 470 41 41 2020 46 2058 40 2062 46 2006 46 544 40 41 44 91 470 44 470 93 44 719 2066 58 2066 46 660 44 2060 61 443 41 612 2067 40 2020 41 58 330 2005 46 2006 46 2052 40 2057 61 2028 40 362 41 41 2059 61 2005 46 2006 46 2068 40 41 2059 46 2057 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 362 41 2059 46 2069 40 41 2020 46 2058 40 2005 46 2006 46 656 40 2070 61 2028 40 362 41 41 44 91 362 44 362 93 44 719 2059 58 2059 46 2008 44 2060 61 443 41 2005 46 2006 46 2071 40 2070 61 2028 40 362 41 41 46 2052 40 2008 61 362 41 2020 46 2034 40 2005 46 2006 46 2071 40 2070 61 2028 40 362 41 41 46 2072 40 41 46 2008 44 362 44 41 2073 61 362 871 2020 46 2074 40 2075 44 2073 41 58 2005 46 2006 46 2071 40 2070 61 2028 40 362 41 41 46 2052 40 2008 61 2028 40 362 41 41 612 2076 40 2020 41 58 330 2020 46 2018 46 2009 61 2028 40 362 41 43 1502 2020 46 2018 46 2069 40 41 2020 46 2018 46 2077 40 41 2020 46 2034 40 2020 46 2018 46 2009 44 1503 41 612 2078 40 2020 41 58 330 2079 61 2005 40 2008 61 2080 40 2065 40 362 41 41 44 2009 61 1503 44 2010 61 1501 44 2011 61 2020 46 733 41 2079 46 2069 40 41 2079 46 2077 40 41 2020 46 2034 40 2079 46 2008 44 362 41 612 2081 40 2020 41 58 2079 61 2005 46 2006 46 2007 40 2008 61 2080 40 2065 40 362 41 41 44 2009 61 1503 44 2010 61 1501 44 2011 61 2020 46 733 41 2079 46 2077 40 41 2020 46 2034 40 2079 46 2008 44 362 41 612 2082 40 2020 41 58 330 2073 61 362 871 2020 46 2074 40 2075 44 2073 41 58 2005 46 2006 46 2007 40 2008 61 362 44 2009 61 2083 40 2065 40 1501 41 41 44 2010 61 1501 44 2011 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 362 44 2015 61 1503 41 44 41 612 2084 40 2020 41 58 330 330 2085 61 2005 46 2006 46 2072 40 2086 61 2020 46 2018 46 2086 41 2073 61 362 871 2020 46 2074 40 2087 44 2073 41 58 2085 46 2057 61 2028 40 362 41 2085 46 2057 61 2020 46 2018 46 2011 2085 46 2069 40 41 2085 46 2008 61 2028 40 362 41 2073 61 362 871 2020 46 2074 40 2075 44 2073 41 58 2085 46 2069 40 41 612 2088 40 2020 41 58 2073 61 362 871 2020 46 2074 40 2075 44 2073 41 58 2089 46 2006 46 2052 40 2090 61 2028 40 362 41 42 1502 41 612 2091 40 2020 41 58 330 330 2092 61 2005 40 2008 61 362 44 2009 61 1503 44 2010 61 1502 44 2011 61 2020 46 733 41 2092 46 2009 61 2028 40 362 41 43 1503 2073 61 40 362 362 362 362 41 871 2020 46 2074 40 2087 44 2073 41 58 2092 46 2069 40 41 2092 46 2009 61 1503 2092 46 2008 61 2080 40 2028 40 362 41 41 2073 61 40 362 362 362 41 871 2020 46 2074 40 2087 44 2073 41 58 2092 46 2069 40 41 612 2093 40 2020 41 58 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 362 41 2094 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 362 41 2095 61 2012 46 2006 46 656 40 2096 61 2028 40 362 41 41 2020 46 2038 40 2095 44 91 2094 93 41 612 2097 40 2020 41 58 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 362 41 2098 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 362 41 2099 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 362 41 2020 46 2038 40 2012 46 2006 46 656 40 2100 61 2028 40 362 41 41 44 91 2098 44 2099 93 688 2101 46 2102 46 2103 630 91 2098 93 41 2104 61 2012 46 2006 46 656 40 2105 61 2028 40 362 41 41 46 2023 40 362 41 2020 46 2038 40 2104 44 91 2098 44 2099 93 41 612 2106 40 2020 41 58 330 330 330 2104 61 2012 46 2006 46 656 40 2107 61 2028 40 362 41 41 2020 46 2034 40 813 40 2104 46 2108 41 46 2040 40 362 41 44 1501 41 612 2109 40 2020 41 58 330 330 330 330 2104 61 2012 46 2006 46 656 40 2107 61 2028 40 362 41 44 2110 61 1501 44 41 2020 46 2034 40 813 40 2104 46 2108 41 46 2040 40 362 41 44 1501 41 612 2111 40 2020 41 58 330 330 330 330 330 2104 61 2012 46 2006 46 656 40 2112 61 2028 40 362 41 44 2086 61 2028 40 362 41 41 2020 46 2034 40 813 40 2104 46 2108 41 46 2040 40 362 41 44 1501 41 612 2113 40 2020 41 58 330 2104 61 2012 46 2006 46 656 40 2112 61 2028 40 362 41 41 46 656 40 2112 61 2028 40 362 41 41 2020 46 2034 40 813 40 2104 46 2108 41 46 2040 40 362 41 44 1502 41 612 2114 40 2020 41 58 2115 61 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 362 44 2015 61 1503 41 2116 61 2012 46 2006 46 656 40 2014 61 362 41 46 2023 40 330 2117 40 2005 46 2006 46 656 40 2011 61 2118 40 362 41 41 41 46 2119 40 41 41 2020 46 2038 40 2116 44 91 2020 46 733 44 2115 93 41 612 2120 40 2020 41 58 2121 61 40 2037 40 362 44 91 93 41 46 2119 40 41 44 2037 40 362 44 91 93 41 46 2122 40 41 41 664 2104 696 40 2005 46 2006 46 544 40 41 44 2005 46 2006 46 2123 40 41 44 41 58 871 2020 46 2124 40 2104 61 2104 41 58 2020 46 2038 40 2104 46 2023 40 42 2121 41 44 91 2020 46 2004 44 2020 46 2018 44 2020 46 2016 93 44 41 612 2125 40 2020 41 58 2126 61 2005 46 2006 46 656 40 2057 61 2118 40 362 41 41 2073 61 40 362 362 41 871 2020 46 2074 40 2087 44 2073 41 58 2126 46 2127 40 41 2128 61 2012 46 2006 46 2026 40 2129 61 2117 40 2126 41 41 2020 46 2130 40 2128 46 2127 40 41 44 515 41 612 2131 40 2020 41 58 2095 61 2005 46 2006 46 2022 40 362 41 2020 46 2132 40 2117 40 2095 41 46 2032 44 2047 41 612 2133 40 2020 41 58 2005 46 2006 46 656 40 2008 61 362 41 46 2052 40 2057 61 2012 46 2006 46 2072 40 2013 61 362 44 2014 61 362 41 44 2011 61 2020 46 733 44 41 2012 46 2006 46 2007 40 2013 61 362 44 2014 61 362 44 2015 61 1503 41 2104 61 2012 46 2006 46 2026 40 2129 61 2117 40 2005 46 2006 46 656 40 2057 61 2118 40 362 41 41 41 44 2134 61 126 2117 40 2005 46 2006 46 656 40 2057 61 2118 40 362 41 41 41 44 2135 61 2117 40 2005 46 2006 46 656 40 2136 61 1504 44 2011 61 2118 40 362 41 41 41 44 2137 61 126 126 2117 40 2005 46 2006 46 656 40 2136 61 1504 44 2011 61 2118 40 362 41 41 41 44 2138 61 2139 40 2005 46 2006 46 2023 40 362 41 46 656 40 2045 40 2011 61 2118 40 362 41 41 124 2045 40 2057 61 2118 40 362 41 41 41 46 2022 40 362 41 91 58 1501 93 44 2032 61 2140 40 41 41 41 46 2022 40 362 44 362 44 362 44 362 44 362 44 362 44 41 46 2023 40 362 41 2141 61 723 40 2104 41 330 330 2142 61 2141 91 1500 93 688 2142 91 362 93 323 362 545 2101 46 2102 46 2143 58 2142 91 362 93 61 470 2020 46 2034 40 2141 44 91 123 362 58 362 44 362 58 443 44 362 58 515 44 362 58 443 44 362 58 443 44 362 58 470 44 125 44 123 362 58 362 44 362 58 443 44 362 58 515 44 362 58 515 44 362 58 515 44 362 58 362 44 125 44 123 362 58 362 44 362 58 515 44 362 58 443 44 362 58 443 44 362 58 443 44 362 58 362 44 125 44 123 362 58 362 44 362 58 443 44 362 58 515 44 362 58 515 44 362 58 515 44 362 58 362 125 93 41 330 330 330 2020 46 2144 40 2104 46 656 40 2129 61 515 41 46 2022 40 362 41 44 2012 46 2006 46 2071 40 2145 61 470 41 46 2022 40 362 41 41 612 2146 40 2020 41 58 2104 61 2012 46 2006 46 2026 40 2147 61 2117 40 2005 46 2006 46 656 40 2011 61 2118 40 362 41 41 41 44 2129 61 2117 40 2005 46 2006 46 656 40 2057 61 2118 40 362 41 41 44 41 44 2148 61 2117 40 2095 61 2005 46 2006 46 656 40 2136 61 1504 41 44 41 44 41 46 656 40 2147 61 515 44 2129 61 443 44 2148 61 515 41 2020 46 2149 40 2104 46 2108 46 2150 91 362 93 44 2104 46 2108 46 2150 91 362 93 44 41 2020 46 2149 40 2104 46 2108 46 2150 91 362 93 44 2104 46 2108 46 2150 91 362 93 44 41 612 2151 40 2020 41 58 330 330 2152 61 2005 46 2006 46 656 40 2136 61 1504 41 46 2022 40 362 41 2153 61 2005 46 2006 46 656 40 2154 61 2139 40 2152 41 41 2020 46 2144 40 2153 44 91 2020 46 2016 44 2020 46 2018 93 41 2155 61 2005 46 2006 46 656 40 2086 61 2139 40 2152 46 656 40 2009 61 1502 41 41 41 2020 46 2144 40 2155 44 91 2020 46 2016 93 41 612 2156 40 2020 41 58 2157 61 2158 46 2006 46 2007 40 41 2159 46 2006 46 2007 40 2160 61 2157 41 2104 61 2158 46 2006 46 656 40 2161 61 2139 40 2159 46 2006 46 2022 40 362 41 41 41 2020 46 2144 40 2104 44 91 2157 93 41 612 2162 40 2020 41 58 2126 61 2005 46 2006 46 656 40 2057 61 2118 40 362 41 41 2128 61 2012 46 2006 46 2026 40 2129 61 2117 40 2126 41 41 2163 61 2012 46 2006 46 2026 40 2129 61 2139 40 2128 46 656 40 2086 61 2118 40 362 41 41 46 2022 40 362 41 44 2032 61 2047 40 41 44 41 44 41 2020 46 2144 40 2163 46 2164 40 41 44 2128 46 2164 40 41 41 612 2165 40 2020 41 58 2126 61 2012 46 2006 46 656 40 2086 61 2118 40 362 41 41 46 2022 40 362 41 2104 61 2012 46 2006 46 2026 40 2166 61 2139 40 2005 46 2006 46 656 40 2167 61 2126 44 2168 61 2118 40 362 41 44 41 46 2022 40 362 41 44 41 44 41 2020 46 2038 40 2104 46 2164 40 362 44 2169 61 515 41 44 91 2020 46 2004 46 2086 44 2020 46 2016 46 2086 44 2020 46 2018 46 2086 93 44 41 612 2170 40 2020 41 58 2068 61 2171 46 2006 46 2007 40 2172 61 362 41 2173 61 2171 46 2006 46 2007 40 2172 61 362 41 2174 61 2171 46 2006 46 2007 40 2172 61 362 41 2175 46 2006 46 2176 40 91 2175 40 2177 61 2068 44 2178 61 2173 44 2179 61 362 41 44 2175 40 2177 61 2068 44 2178 61 2174 44 2179 61 362 41 44 2175 40 2177 61 2173 44 2178 61 2068 44 2179 61 362 41 44 93 41 2126 61 2171 46 2006 46 656 40 2172 61 2118 40 2118 40 362 41 41 44 2086 61 2118 40 362 41 41 46 2022 40 362 41 2180 61 2175 46 2006 46 2026 40 2181 61 2139 40 2126 41 41 46 2022 40 362 41 91 58 1501 93 2128 61 2171 46 2006 46 2026 40 2181 61 2139 40 2180 44 2032 61 2182 40 41 41 41 330 2020 46 2144 40 2128 44 91 2068 44 2173 44 2174 93 41 612 2183 40 2020 41 58 2068 61 2171 46 2006 46 2007 40 2172 61 362 41 2173 61 2171 46 2006 46 2007 40 2172 61 362 41 2175 46 2006 46 2007 40 2177 61 2068 44 2178 61 2173 44 2179 61 362 41 2126 61 2175 46 2006 46 656 40 2177 61 2118 40 2118 40 362 41 41 41 46 2022 40 362 41 2180 61 2171 46 2006 46 2026 40 2181 61 2139 40 2126 41 41 46 2022 40 362 41 91 58 1501 93 2128 61 2171 46 2006 46 2026 40 2181 61 2139 40 2180 44 2032 61 2033 40 41 41 41 330 2020 46 2144 40 2128 44 91 2068 44 2173 93 41 612 2184 40 2020 41 58 2005 46 2006 46 656 40 2136 61 1503 41 46 2052 40 2011 61 2012 46 2006 46 2072 40 2013 61 362 41 41 2126 61 2005 46 2006 46 656 40 2011 61 2118 40 362 41 41 46 2022 40 362 41 46 2026 40 2185 61 2031 40 362 41 41 46 2022 40 362 41 2128 61 2012 46 2006 46 2026 40 2185 61 2139 40 2126 41 41 46 656 40 2186 61 2139 40 2126 41 41 2020 46 2038 40 2128 46 2023 40 362 41 46 2022 40 362 44 362 41 44 91 123 362 58 1502 44 362 58 1505 125 44 123 362 58 1503 44 362 58 1503 125 93 44 41 612 2187 40 2020 41 58 2126 61 2005 46 2006 46 656 40 2188 61 2118 40 362 41 44 2189 61 2118 40 362 41 44 41 330 2128 61 2005 46 2006 46 656 40 2154 61 2139 40 2126 46 2022 40 362 41 41 41 2020 46 2190 40 2128 46 2127 40 41 41 612 2191 40 2020 41 58 2062 46 2006 46 2007 40 2063 61 1504 44 660 61 1502 41 2012 46 2006 46 2007 40 2015 61 1504 41 2104 61 2062 46 2006 46 2026 40 2192 61 2139 40 2012 46 2006 46 656 40 2015 61 2118 40 362 41 44 41 46 2026 40 2193 61 2194 40 362 41 41 46 656 40 2195 61 1500 41 46 2022 40 362 41 91 58 1501 93 41 44 41 2020 46 2034 40 2104 46 2072 40 41 46 660 44 1502 41 612 2196 40 2020 41 58 2020 46 733 46 2197 61 2198 46 2006 46 2007 40 2008 61 362 41 2020 46 733 46 2069 40 41 2199 61 2200 40 719 58 2198 46 2006 46 2072 40 2086 61 2020 46 733 46 2197 46 2086 41 41 2104 61 2005 46 2006 46 2026 40 2201 61 2139 40 2012 46 2006 46 656 40 2014 61 2118 40 362 41 44 41 46 2022 40 362 41 44 41 44 41 46 656 40 2201 61 2199 41 2020 46 2034 40 2104 46 2072 40 41 44 2020 46 2018 41 612 2202 40 2020 41 58 871 2020 46 2203 40 1501 41 552 2204 58 2029 61 2005 46 2006 46 2026 40 2205 61 2139 40 2012 46 2006 46 656 40 687 61 2118 40 362 41 44 41 46 2022 40 362 41 41 44 41 46 2029 40 2206 61 2194 40 362 44 656 61 2045 40 2207 61 1503 41 41 44 41 2020 46 2034 40 2029 44 123 362 58 1501 125 41 330 330 2208 61 2204 46 2209 91 1500 93 91 362 93 2020 46 2210 40 2208 46 2040 40 362 41 44 1502 41 330 330 2020 46 2211 40 362 44 2208 41 64 2041 40 362 41 612 2212 40 2020 41 58 871 2020 46 2203 40 1501 41 552 2204 58 2029 61 2005 46 2006 46 2026 40 2015 61 2037 40 362 44 91 93 41 44 41 46 2029 40 2040 61 2194 40 362 41 44 41 2020 46 2034 40 2029 44 123 362 58 1502 125 41 2208 61 2204 46 2209 91 1500 93 91 362 93 2020 46 2211 40 362 44 2208 41 612 2213 40 2020 41 58 587 2214 40 2215 41 58 2032 61 2140 40 41 587 2216 40 2215 41 58 767 2217 61 2216 40 2214 40 41 41 2020 46 2034 40 2217 46 2032 44 2214 46 2032 41 612 2218 40 2020 41 58 2126 61 2219 46 2006 46 656 40 2220 61 2118 40 362 41 41 2128 61 2219 46 2006 46 656 40 2154 61 2139 40 2126 46 2022 40 362 41 41 41 2020 46 2190 40 2128 46 2127 40 41 41 612 2221 40 2020 41 58 2126 61 2005 46 2006 46 656 40 2009 61 2118 40 362 41 43 1502 41 2128 61 2005 46 2006 46 656 40 2154 61 2139 40 2126 46 2022 40 362 41 41 41 2020 46 2034 40 2128 46 2072 40 41 46 2008 44 362 41 612 2222 40 2020 41 58 2020 46 2018 46 2057 61 2012 46 2006 46 2072 40 2014 61 362 41 2020 46 2018 46 2069 40 41 2126 61 2012 46 2006 46 656 40 2100 61 2223 40 2118 40 2118 40 362 41 41 44 1501 41 44 41 2104 61 2012 46 2006 46 2026 40 2166 61 2139 40 2005 46 2006 46 656 40 2224 61 2126 44 2168 61 2118 40 362 41 44 41 46 2022 40 362 41 44 41 44 41 46 656 40 2225 61 443 41 2020 46 2034 40 2104 46 2072 40 41 46 2166 44 362 41 612 2226 40 2020 41 58 2227 61 2005 46 2006 46 2026 40 2228 61 2139 40 2005 46 2006 46 2026 40 2229 61 2118 40 362 41 43 2028 40 362 41 44 41 46 2023 40 362 41 46 2022 40 362 41 91 58 1501 93 44 2032 61 2033 40 41 44 41 44 41 46 2072 40 2086 61 2020 46 2018 46 2086 41 2020 46 2034 40 2227 46 2228 44 1505 41 612 2230 40 2020 41 58 2020 46 2018 46 2057 61 2012 46 2006 46 2072 40 2014 61 362 41 2020 46 2018 46 2069 40 41 2126 61 2012 46 2006 46 2026 40 2231 61 2118 40 2118 40 362 41 41 44 41 46 656 40 2100 61 2223 40 362 44 1501 41 41 2104 61 2012 46 2006 46 2026 40 2166 61 2139 40 2005 46 2006 46 656 40 2224 61 2126 44 2168 61 2118 40 362 41 44 41 46 2022 40 362 41 44 41 44 41 46 656 40 2225 61 443 41 2020 46 2034 40 2104 46 2072 40 41 46 2166 44 362 41 612 2232 40 2020 41 58 2217 61 2065 40 1501 41 2217 46 2233 330 2020 46 2034 40 2234 46 2235 40 2234 46 2236 40 2217 41 41 44 2217 41 612 2237 40 2020 41 58 871 2020 46 2074 40 2075 44 362 41 58 723 40 2012 46 2006 46 656 40 2013 61 2028 40 362 41 41 41 612 2238 40 2020 41 58 871 2020 46 2074 40 2075 44 362 41 58 723 40 2005 46 2006 46 656 40 2168 61 2028 40 362 41 41 41 612 2239 40 2020 41 58 2126 61 2005 46 2006 46 656 40 2011 61 2118 40 362 41 41 46 2022 40 362 41 2240 61 2012 46 2006 46 656 40 2117 40 2126 41 41 2241 61 2012 46 2006 46 2026 40 2242 61 2117 40 2126 41 41 46 656 40 2242 61 515 41 2020 46 2144 40 2240 44 2241 41 2020 46 2190 40 2012 46 2006 46 2071 40 2117 40 2126 41 41 46 2127 40 41 41 2020 46 2144 40 2241 44 2012 46 2006 46 2071 40 126 2117 40 2126 41 41 41 612 2243 40 2020 41 58 2126 61 2005 46 2006 46 656 40 2011 61 2118 40 362 41 41 46 2022 40 362 41 2020 46 2038 40 2012 46 2006 46 656 40 2139 40 2126 41 41 44 91 2020 46 2016 46 2011 93 44 41 612 2244 40 2020 41 58 2126 61 2005 46 2006 46 2026 40 2245 61 2118 40 362 41 44 41 46 2022 40 362 41 46 2026 40 2246 61 2247 40 362 41 44 41 46 2022 40 362 41 2020 46 2130 40 2012 46 2006 46 656 40 2154 61 2139 40 2126 41 41 46 2127 40 41 44 515 41 612 2248 40 2020 41 58 2147 61 2005 46 2006 46 656 40 2011 61 2118 40 362 41 41 2249 61 2005 46 2006 46 656 40 2057 61 2118 40 362 41 41 2104 61 2012 46 2006 46 656 40 2250 40 2251 40 2117 40 2147 41 44 2252 61 515 41 44 2251 40 2117 40 2249 41 44 2252 61 515 41 44 2253 61 443 44 2032 61 2047 40 41 44 41 44 41 2020 46 2144 40 2104 44 91 2020 46 2004 46 2011 44 2020 46 2016 46 2011 44 2020 46 733 93 41 612 2254 40 2020 41 58 2147 61 2005 46 2006 46 656 40 2011 61 2118 40 362 41 41 2249 61 2005 46 2006 46 656 40 2057 61 2118 40 362 41 41 2020 46 2018 46 2057 61 2020 46 733 2020 46 2018 46 2069 40 41 2020 46 2144 40 2012 46 2006 46 656 40 2117 40 2147 41 124 2117 40 2249 41 41 44 91 2020 46 2004 46 2011 44 2020 46 2016 46 2011 44 2020 46 733 93 44 41 2020 46 2144 40 2012 46 2006 46 656 40 2117 40 2147 41 38 2117 40 2249 41 41 44 91 2020 46 733 93 44 41 2020 46 2144 40 2012 46 2006 46 656 40 2117 40 2147 41 38 2045 40 2255 61 1503 41 41 44 91 2020 46 733 93 44 41 2020 46 2144 40 2012 46 2006 46 656 40 2117 40 2249 41 124 2045 40 2256 61 1503 41 41 44 91 2020 46 2004 46 2011 44 2020 46 733 93 44 41 2020 46 2144 40 2012 46 2006 46 656 40 2045 40 2255 61 1503 41 38 2117 40 2147 41 41 44 91 2020 46 733 93 44 41 2020 46 2144 40 2012 46 2006 46 656 40 2045 40 2256 61 1503 41 124 2117 40 2249 41 41 44 91 2020 46 2004 46 2011 44 2020 46 733 93 44 41 612 2257 40 2020 41 58 2249 61 2005 46 2006 46 656 40 2057 61 2118 40 362 41 41 2020 46 2018 46 2057 61 2020 46 733 2020 46 2018 46 2069 40 41 2258 61 91 2117 40 2249 41 38 2045 40 41 44 2045 40 41 38 2117 40 2249 41 44 2117 40 2249 41 124 2045 40 41 44 2045 40 41 124 2117 40 2249 41 44 2045 40 2117 40 2249 41 41 38 2045 40 41 44 2045 40 41 38 2045 40 2117 40 2249 41 41 44 2045 40 2117 40 2249 41 41 124 2045 40 41 44 2045 40 41 124 2045 40 2117 40 2249 41 41 44 93 664 2259 696 2258 58 871 2020 46 2124 40 2259 41 58 2020 46 2144 40 2012 46 2006 46 656 40 2259 41 44 91 2020 46 733 93 41 612 2260 40 2020 41 58 2249 61 2005 46 2006 46 656 40 2057 61 2118 40 362 41 41 2020 46 2018 46 2057 61 2020 46 733 2020 46 2018 46 2069 40 41 2020 46 2144 40 2012 46 2006 46 656 40 2045 40 2117 40 2249 41 41 41 44 91 2020 46 733 93 41 ,"{'AvgLine': 11, 'CountLine': 811, 'CountStmt': 309, 'MaxNesting': 2, 'AvgLineCode': 10, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 243, 'MaxEssential': 1, 'SumEssential': 63, 'AvgCyclomatic': 1, 'CountLineCode': 692, 'CountStmtDecl': 159, 'MaxCyclomatic': 2, 'SumCyclomatic': 67, 'AvgLineComment': 0, 'CountClassBase': 0, 'CountLineBlank': 73, 'CountDeclMethod': 63, 'CountLineCodeExe': 623, 'CountLineComment': 47, 'CountClassCoupled': 33, 'CountClassDerived': 0, 'CountLineCodeDecl': 164, 'CountDeclMethodAll': 63, 'MaxInheritanceTree': 0, 'RatioCommentToCode': '0.07', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 3, 'SumCyclomaticStrict': 68, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 2, 'SumCyclomaticModified': 67, 'CountDeclInstanceMethod': 62, 'CountClassCoupledModified': 30, 'CountDeclInstanceVariable': 1}"
126269,Python,"class SparkSqlHook(BaseHook):
    """"""
    This hook is a wrapper around the spark-sql binary. It requires that the
    ""spark-sql"" binary is in the PATH.

    :param sql: The SQL query to execute
    :type sql: str
    :param conf: arbitrary Spark configuration property
    :type conf: str (format: PROP=VALUE)
    :param conn_id: connection_id string
    :type conn_id: str
    :param total_executor_cores: (Standalone & Mesos only) Total cores for all executors
        (Default: all the available cores on the worker)
    :type total_executor_cores: int
    :param executor_cores: (Standalone & YARN only) Number of cores per
        executor (Default: 2)
    :type executor_cores: int
    :param executor_memory: Memory per executor (e.g. 1000M, 2G) (Default: 1G)
    :type executor_memory: str
    :param keytab: Full path to the file that contains the keytab
    :type keytab: str
    :param master: spark://host:port, mesos://host:port, yarn, or local
        (Default: The ``host`` and ``port`` set in the Connection, or ``""yarn""``)
    :type master: str
    :param name: Name of the job.
    :type name: str
    :param num_executors: Number of executors to launch
    :type num_executors: int
    :param verbose: Whether to pass the verbose flag to spark-sql
    :type verbose: bool
    :param yarn_queue: The YARN queue to submit to
        (Default: The ``queue`` value set in the Connection, or ``""default""``)
    :type yarn_queue: str
    """"""

    conn_name_attr = 'conn_id'
    default_conn_name = 'spark_sql_default'
    conn_type = 'spark_sql'
    hook_name = 'Spark SQL'

    def __init__(
        self,
        sql: str,
        conf: Optional[str] = None,
        conn_id: str = default_conn_name,
        total_executor_cores: Optional[int] = None,
        executor_cores: Optional[int] = None,
        executor_memory: Optional[str] = None,
        keytab: Optional[str] = None,
        principal: Optional[str] = None,
        master: Optional[str] = None,
        name: str = 'default-name',
        num_executors: Optional[int] = None,
        verbose: bool = True,
        yarn_queue: Optional[str] = None,
    ) -> None:
        super().__init__()
        options: Dict = {}
        conn: Optional[Connection] = None

        try:
            conn = self.get_connection(conn_id)
        except AirflowNotFoundException:
            conn = None
            options: Dict = {}
        else:
            if conn:
                options = conn.extra_dejson

        # Set arguments to values set in Connection if not explicitly provided.
        if master is None:
            if conn is None:
                master = ""yarn""
            elif conn.port:
                master = f""{conn.host}:{conn.port}""
            else:
                master = conn.host
        if yarn_queue is None:
            yarn_queue = options.get(""queue"", ""default"")

        self._sql = sql
        self._conf = conf
        self._total_executor_cores = total_executor_cores
        self._executor_cores = executor_cores
        self._executor_memory = executor_memory
        self._keytab = keytab
        self._principal = principal
        self._master = master
        self._name = name
        self._num_executors = num_executors
        self._verbose = verbose
        self._yarn_queue = yarn_queue
        self._sp: Any = None

    def get_conn(self) -> Any:
        pass

    def _prepare_command(self, cmd: Union[str, List[str]]) -> List[str]:
        """"""
        Construct the spark-sql command to execute. Verbose output is enabled
        as default.

        :param cmd: command to append to the spark-sql command
        :type cmd: str or list[str]
        :return: full command to be executed
        """"""
        connection_cmd = [""spark-sql""]
        if self._conf:
            for conf_el in self._conf.split("",""):
                connection_cmd += [""--conf"", conf_el]
        if self._total_executor_cores:
            connection_cmd += [""--total-executor-cores"", str(self._total_executor_cores)]
        if self._executor_cores:
            connection_cmd += [""--executor-cores"", str(self._executor_cores)]
        if self._executor_memory:
            connection_cmd += [""--executor-memory"", self._executor_memory]
        if self._keytab:
            connection_cmd += [""--keytab"", self._keytab]
        if self._principal:
            connection_cmd += [""--principal"", self._principal]
        if self._num_executors:
            connection_cmd += [""--num-executors"", str(self._num_executors)]
        if self._sql:
            sql = self._sql.strip()
            if sql.endswith("".sql"") or sql.endswith("".hql""):
                connection_cmd += [""-f"", sql]
            else:
                connection_cmd += [""-e"", sql]
        if self._master:
            connection_cmd += [""--master"", self._master]
        if self._name:
            connection_cmd += [""--name"", self._name]
        if self._verbose:
            connection_cmd += [""--verbose""]
        if self._yarn_queue:
            connection_cmd += [""--queue"", self._yarn_queue]

        if isinstance(cmd, str):
            connection_cmd += cmd.split()
        elif isinstance(cmd, list):
            connection_cmd += cmd
        else:
            raise AirflowException(f""Invalid additional command: {cmd}"")

        self.log.debug(""Spark-Sql cmd: %s"", connection_cmd)

        return connection_cmd

    def run_query(self, cmd: str = """", **kwargs: Any) -> None:
        """"""
        Remote Popen (actually execute the Spark-sql query)

        :param cmd: command to append to the spark-sql command
        :type cmd: str or list[str]
        :param kwargs: extra arguments to Popen (see subprocess.Popen)
        :type kwargs: dict
        """"""
        spark_sql_cmd = self._prepare_command(cmd)

        self._sp = subprocess.Popen(
            spark_sql_cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True, **kwargs
        )

        for line in iter(self._sp.stdout):  # type: ignore
            self.log.info(line)

        returncode = self._sp.wait()

        if returncode:
            raise AirflowException(
                f""Cannot execute '{self._sql}' on {self._master} (additional parameters: '{cmd}'). ""
                f""Process exit code: {returncode}.""
            )

    def kill(self) -> None:
        """"""Kill Spark job""""""
        if self._sp and self._sp.poll() is None:
            self.log.info(""Killing the Spark-Sql job"")
            self._sp.kill()",1,587 2000 40 2001 41 58 362 2002 61 362 2003 61 362 2004 61 362 2005 61 362 612 2006 40 2007 44 2008 58 813 44 2009 58 2010 91 813 93 61 470 44 2011 58 813 61 2003 44 2012 58 2010 91 704 93 61 470 44 2013 58 2010 91 704 93 61 470 44 2014 58 2010 91 813 93 61 470 44 2015 58 2010 91 813 93 61 470 44 2016 58 2010 91 813 93 61 470 44 2017 58 2010 91 813 93 61 470 44 2018 58 813 61 362 44 2019 58 2010 91 704 93 61 470 44 2020 58 569 61 515 44 2021 58 2010 91 813 93 61 470 44 41 354 470 58 818 40 41 46 2006 40 41 2022 58 2023 61 123 125 2024 58 2010 91 2025 93 61 470 830 58 2024 61 2007 46 2026 40 2011 41 645 2027 58 2024 61 470 2022 58 2023 61 123 125 630 58 688 2024 58 2022 61 2024 46 2028 330 688 2017 712 470 58 688 2024 712 470 58 2017 61 362 629 2024 46 2029 58 2017 61 362 630 58 2017 61 2024 46 2030 688 2021 712 470 58 2021 61 2022 46 2031 40 362 44 362 41 2007 46 2032 61 2008 2007 46 2033 61 2009 2007 46 2034 61 2012 2007 46 2035 61 2013 2007 46 2036 61 2014 2007 46 2037 61 2015 2007 46 2038 61 2016 2007 46 2039 61 2017 2007 46 2040 61 2018 2007 46 2041 61 2019 2007 46 2042 61 2020 2007 46 2043 61 2021 2007 46 2044 58 2045 61 470 612 2046 40 2007 41 354 2045 58 767 612 2047 40 2007 44 2048 58 2049 91 813 44 2050 91 813 93 93 41 354 2050 91 813 93 58 362 2051 61 91 362 93 688 2007 46 2033 58 664 2052 696 2007 46 2033 46 2053 40 362 41 58 2051 348 91 362 44 2052 93 688 2007 46 2034 58 2051 348 91 362 44 813 40 2007 46 2034 41 93 688 2007 46 2035 58 2051 348 91 362 44 813 40 2007 46 2035 41 93 688 2007 46 2036 58 2051 348 91 362 44 2007 46 2036 93 688 2007 46 2037 58 2051 348 91 362 44 2007 46 2037 93 688 2007 46 2038 58 2051 348 91 362 44 2007 46 2038 93 688 2007 46 2041 58 2051 348 91 362 44 813 40 2007 46 2041 41 93 688 2007 46 2032 58 2008 61 2007 46 2032 46 2054 40 41 688 2008 46 2055 40 362 41 759 2008 46 2055 40 362 41 58 2051 348 91 362 44 2008 93 630 58 2051 348 91 362 44 2008 93 688 2007 46 2039 58 2051 348 91 362 44 2007 46 2039 93 688 2007 46 2040 58 2051 348 91 362 44 2007 46 2040 93 688 2007 46 2042 58 2051 348 91 362 93 688 2007 46 2043 58 2051 348 91 362 44 2007 46 2043 93 688 713 40 2048 44 813 41 58 2051 348 2048 46 2053 40 41 629 713 40 2048 44 723 41 58 2051 348 2048 630 58 778 2056 40 362 41 2007 46 2057 46 2058 40 362 44 2051 41 792 2051 612 2059 40 2007 44 2048 58 813 61 362 44 350 2060 58 2045 41 354 470 58 362 2061 61 2007 46 2047 40 2048 41 2007 46 2044 61 2062 46 2063 40 2061 44 2064 61 2062 46 2065 44 2066 61 2062 46 2067 44 2068 61 515 44 350 2060 41 664 2069 696 717 40 2007 46 2044 46 2064 41 58 330 2007 46 2057 46 2070 40 2069 41 2071 61 2007 46 2044 46 2072 40 41 688 2071 58 778 2056 40 362 362 41 612 2073 40 2007 41 354 470 58 362 688 2007 46 2044 545 2007 46 2044 46 2074 40 41 712 470 58 2007 46 2057 46 2070 40 362 41 2007 46 2044 46 2073 40 41 ,"{'AvgLine': 27, 'CountLine': 179, 'CountStmt': 87, 'MaxNesting': 2, 'AvgLineCode': 21, 'AvgEssential': 1, 'AvgLineBlank': 2, 'CountStmtExe': 81, 'MaxEssential': 3, 'SumEssential': 7, 'AvgCyclomatic': 6, 'CountLineCode': 112, 'CountStmtDecl': 31, 'MaxCyclomatic': 17, 'SumCyclomatic': 30, 'AvgLineComment': 3, 'CountClassBase': 1, 'CountLineBlank': 19, 'CountDeclMethod': 5, 'CountLineCodeExe': 91, 'CountLineComment': 49, 'CountClassCoupled': 8, 'CountClassDerived': 0, 'CountLineCodeDecl': 46, 'CountDeclMethodAll': 12, 'MaxInheritanceTree': 2, 'RatioCommentToCode': '0.44', 'AvgCyclomaticStrict': 6, 'MaxCyclomaticStrict': 18, 'SumCyclomaticStrict': 32, 'AvgCyclomaticModified': 6, 'MaxCyclomaticModified': 17, 'SumCyclomaticModified': 30, 'CountDeclInstanceMethod': 5, 'CountClassCoupledModified': 3, 'CountDeclInstanceVariable': 13}"
126852,Python,"class WinRMHook(BaseHook):
    """"""
    Hook for winrm remote execution using pywinrm.

    :seealso: https://github.com/diyan/pywinrm/blob/master/winrm/protocol.py

    :param ssh_conn_id: connection id from airflow Connections from where
        all the required parameters can be fetched like username and password.
        Thought the priority is given to the param passed during init
    :type ssh_conn_id: str
    :param endpoint: When not set, endpoint will be constructed like this:
        'http://{remote_host}:{remote_port}/wsman'
    :type endpoint: str
    :param remote_host: Remote host to connect to. Ignored if `endpoint` is set.
    :type remote_host: str
    :param remote_port: Remote port to connect to. Ignored if `endpoint` is set.
    :type remote_port: int
    :param transport: transport type, one of 'plaintext' (default), 'kerberos', 'ssl', 'ntlm', 'credssp'
    :type transport: str
    :param username: username to connect to the remote_host
    :type username: str
    :param password: password of the username to connect to the remote_host
    :type password: str
    :param service: the service name, default is HTTP
    :type service: str
    :param keytab: the path to a keytab file if you are using one
    :type keytab: str
    :param ca_trust_path: Certification Authority trust path
    :type ca_trust_path: str
    :param cert_pem: client authentication certificate file path in PEM format
    :type cert_pem: str
    :param cert_key_pem: client authentication certificate key file path in PEM format
    :type cert_key_pem: str
    :param server_cert_validation: whether server certificate should be validated on
        Python versions that support it; one of 'validate' (default), 'ignore'
    :type server_cert_validation: str
    :param kerberos_delegation: if True, TGT is sent to target server to
        allow multiple hops
    :type kerberos_delegation: bool
    :param read_timeout_sec: maximum seconds to wait before an HTTP connect/read times out (default 30).
        This value should be slightly higher than operation_timeout_sec,
        as the server can block *at least* that long.
    :type read_timeout_sec: int
    :param operation_timeout_sec: maximum allowed time in seconds for any single wsman
        HTTP operation (default 20). Note that operation timeouts while receiving output
        (the only wsman operation that should take any significant time,
        and where these timeouts are expected) will be silently retried indefinitely.
    :type operation_timeout_sec: int
    :param kerberos_hostname_override: the hostname to use for the kerberos exchange
        (defaults to the hostname in the endpoint URL)
    :type kerberos_hostname_override: str
    :param message_encryption: Will encrypt the WinRM messages if set
        and the transport auth supports message encryption. (Default 'auto')
    :type message_encryption: str
    :param credssp_disable_tlsv1_2: Whether to disable TLSv1.2 support and work with older
        protocols like TLSv1.0, default is False
    :type credssp_disable_tlsv1_2: bool
    :param send_cbt: Will send the channel bindings over a HTTPS channel (Default: True)
    :type send_cbt: bool
    """"""

    def __init__(
        self,
        ssh_conn_id: Optional[str] = None,
        endpoint: Optional[str] = None,
        remote_host: Optional[str] = None,
        remote_port: int = 5985,
        transport: str = 'plaintext',
        username: Optional[str] = None,
        password: Optional[str] = None,
        service: str = 'HTTP',
        keytab: Optional[str] = None,
        ca_trust_path: Optional[str] = None,
        cert_pem: Optional[str] = None,
        cert_key_pem: Optional[str] = None,
        server_cert_validation: str = 'validate',
        kerberos_delegation: bool = False,
        read_timeout_sec: int = 30,
        operation_timeout_sec: int = 20,
        kerberos_hostname_override: Optional[str] = None,
        message_encryption: Optional[str] = 'auto',
        credssp_disable_tlsv1_2: bool = False,
        send_cbt: bool = True,
    ) -> None:
        super().__init__()
        self.ssh_conn_id = ssh_conn_id
        self.endpoint = endpoint
        self.remote_host = remote_host
        self.remote_port = remote_port
        self.transport = transport
        self.username = username
        self.password = password
        self.service = service
        self.keytab = keytab
        self.ca_trust_path = ca_trust_path
        self.cert_pem = cert_pem
        self.cert_key_pem = cert_key_pem
        self.server_cert_validation = server_cert_validation
        self.kerberos_delegation = kerberos_delegation
        self.read_timeout_sec = read_timeout_sec
        self.operation_timeout_sec = operation_timeout_sec
        self.kerberos_hostname_override = kerberos_hostname_override
        self.message_encryption = message_encryption
        self.credssp_disable_tlsv1_2 = credssp_disable_tlsv1_2
        self.send_cbt = send_cbt

        self.client = None
        self.winrm_protocol = None

    def get_conn(self):
        if self.client:
            return self.client

        self.log.debug('Creating WinRM client for conn_id: %s', self.ssh_conn_id)
        if self.ssh_conn_id is not None:
            conn = self.get_connection(self.ssh_conn_id)

            if self.username is None:
                self.username = conn.login
            if self.password is None:
                self.password = conn.password
            if self.remote_host is None:
                self.remote_host = conn.host

            if conn.extra is not None:
                extra_options = conn.extra_dejson

                if ""endpoint"" in extra_options:
                    self.endpoint = str(extra_options[""endpoint""])
                if ""remote_port"" in extra_options:
                    self.remote_port = int(extra_options[""remote_port""])
                if ""transport"" in extra_options:
                    self.transport = str(extra_options[""transport""])
                if ""service"" in extra_options:
                    self.service = str(extra_options[""service""])
                if ""keytab"" in extra_options:
                    self.keytab = str(extra_options[""keytab""])
                if ""ca_trust_path"" in extra_options:
                    self.ca_trust_path = str(extra_options[""ca_trust_path""])
                if ""cert_pem"" in extra_options:
                    self.cert_pem = str(extra_options[""cert_pem""])
                if ""cert_key_pem"" in extra_options:
                    self.cert_key_pem = str(extra_options[""cert_key_pem""])
                if ""server_cert_validation"" in extra_options:
                    self.server_cert_validation = str(extra_options[""server_cert_validation""])
                if ""kerberos_delegation"" in extra_options:
                    self.kerberos_delegation = str(extra_options[""kerberos_delegation""]).lower() == 'true'
                if ""read_timeout_sec"" in extra_options:
                    self.read_timeout_sec = int(extra_options[""read_timeout_sec""])
                if ""operation_timeout_sec"" in extra_options:
                    self.operation_timeout_sec = int(extra_options[""operation_timeout_sec""])
                if ""kerberos_hostname_override"" in extra_options:
                    self.kerberos_hostname_override = str(extra_options[""kerberos_hostname_override""])
                if ""message_encryption"" in extra_options:
                    self.message_encryption = str(extra_options[""message_encryption""])
                if ""credssp_disable_tlsv1_2"" in extra_options:
                    self.credssp_disable_tlsv1_2 = (
                        str(extra_options[""credssp_disable_tlsv1_2""]).lower() == 'true'
                    )
                if ""send_cbt"" in extra_options:
                    self.send_cbt = str(extra_options[""send_cbt""]).lower() == 'true'

        if not self.remote_host:
            raise AirflowException(""Missing required param: remote_host"")

        # Auto detecting username values from system
        if not self.username:
            self.log.debug(
                ""username to WinRM to host: %s is not specified for connection id""
                "" %s. Using system's default provided by getpass.getuser()"",
                self.remote_host,
                self.ssh_conn_id,
            )
            self.username = getuser()

        # If endpoint is not set, then build a standard wsman endpoint from host and port.
        if not self.endpoint:
            self.endpoint = f'http://{self.remote_host}:{self.remote_port}/wsman'

        try:
            if self.password and self.password.strip():
                self.winrm_protocol = Protocol(
                    endpoint=self.endpoint,
                    transport=self.transport,
                    username=self.username,
                    password=self.password,
                    service=self.service,
                    keytab=self.keytab,
                    ca_trust_path=self.ca_trust_path,
                    cert_pem=self.cert_pem,
                    cert_key_pem=self.cert_key_pem,
                    server_cert_validation=self.server_cert_validation,
                    kerberos_delegation=self.kerberos_delegation,
                    read_timeout_sec=self.read_timeout_sec,
                    operation_timeout_sec=self.operation_timeout_sec,
                    kerberos_hostname_override=self.kerberos_hostname_override,
                    message_encryption=self.message_encryption,
                    credssp_disable_tlsv1_2=self.credssp_disable_tlsv1_2,
                    send_cbt=self.send_cbt,
                )

            self.log.info(""Establishing WinRM connection to host: %s"", self.remote_host)
            self.client = self.winrm_protocol.open_shell()

        except Exception as error:
            error_msg = f""Error connecting to host: {self.remote_host}, error: {error}""
            self.log.error(error_msg)
            raise AirflowException(error_msg)

        return self.client",1,587 2000 40 2001 41 58 362 612 2002 40 2003 44 2004 58 2005 91 813 93 61 470 44 2006 58 2005 91 813 93 61 470 44 2007 58 2005 91 813 93 61 470 44 2008 58 704 61 1505 44 2009 58 813 61 362 44 2010 58 2005 91 813 93 61 470 44 2011 58 2005 91 813 93 61 470 44 2012 58 813 61 362 44 2013 58 2005 91 813 93 61 470 44 2014 58 2005 91 813 93 61 470 44 2015 58 2005 91 813 93 61 470 44 2016 58 2005 91 813 93 61 470 44 2017 58 813 61 362 44 2018 58 569 61 443 44 2019 58 704 61 1503 44 2020 58 704 61 1503 44 2021 58 2005 91 813 93 61 470 44 2022 58 2005 91 813 93 61 362 44 2023 58 569 61 443 44 2024 58 569 61 515 44 41 354 470 58 818 40 41 46 2002 40 41 2003 46 2004 61 2004 2003 46 2006 61 2006 2003 46 2007 61 2007 2003 46 2008 61 2008 2003 46 2009 61 2009 2003 46 2010 61 2010 2003 46 2011 61 2011 2003 46 2012 61 2012 2003 46 2013 61 2013 2003 46 2014 61 2014 2003 46 2015 61 2015 2003 46 2016 61 2016 2003 46 2017 61 2017 2003 46 2018 61 2018 2003 46 2019 61 2019 2003 46 2020 61 2020 2003 46 2021 61 2021 2003 46 2022 61 2022 2003 46 2023 61 2023 2003 46 2024 61 2024 2003 46 2025 61 470 2003 46 2026 61 470 612 2027 40 2003 41 58 688 2003 46 2025 58 792 2003 46 2025 2003 46 2028 46 2029 40 362 44 2003 46 2004 41 688 2003 46 2004 712 750 470 58 2030 61 2003 46 2031 40 2003 46 2004 41 688 2003 46 2010 712 470 58 2003 46 2010 61 2030 46 2032 688 2003 46 2011 712 470 58 2003 46 2011 61 2030 46 2011 688 2003 46 2007 712 470 58 2003 46 2007 61 2030 46 2033 688 2030 46 2034 712 750 470 58 2035 61 2030 46 2036 688 362 696 2035 58 2003 46 2006 61 813 40 2035 91 362 93 41 688 362 696 2035 58 2003 46 2008 61 704 40 2035 91 362 93 41 688 362 696 2035 58 2003 46 2009 61 813 40 2035 91 362 93 41 688 362 696 2035 58 2003 46 2012 61 813 40 2035 91 362 93 41 688 362 696 2035 58 2003 46 2013 61 813 40 2035 91 362 93 41 688 362 696 2035 58 2003 46 2014 61 813 40 2035 91 362 93 41 688 362 696 2035 58 2003 46 2015 61 813 40 2035 91 362 93 41 688 362 696 2035 58 2003 46 2016 61 813 40 2035 91 362 93 41 688 362 696 2035 58 2003 46 2017 61 813 40 2035 91 362 93 41 688 362 696 2035 58 2003 46 2018 61 813 40 2035 91 362 93 41 46 2037 40 41 323 362 688 362 696 2035 58 2003 46 2019 61 704 40 2035 91 362 93 41 688 362 696 2035 58 2003 46 2020 61 704 40 2035 91 362 93 41 688 362 696 2035 58 2003 46 2021 61 813 40 2035 91 362 93 41 688 362 696 2035 58 2003 46 2022 61 813 40 2035 91 362 93 41 688 362 696 2035 58 2003 46 2023 61 40 813 40 2035 91 362 93 41 46 2037 40 41 323 362 41 688 362 696 2035 58 2003 46 2024 61 813 40 2035 91 362 93 41 46 2037 40 41 323 362 688 750 2003 46 2007 58 778 2038 40 362 41 330 688 750 2003 46 2010 58 2003 46 2028 46 2029 40 362 362 44 2003 46 2007 44 2003 46 2004 44 41 2003 46 2010 61 2039 40 41 330 688 750 2003 46 2006 58 2003 46 2006 61 362 830 58 688 2003 46 2011 545 2003 46 2011 46 2040 40 41 58 2003 46 2026 61 2041 40 2006 61 2003 46 2006 44 2009 61 2003 46 2009 44 2010 61 2003 46 2010 44 2011 61 2003 46 2011 44 2012 61 2003 46 2012 44 2013 61 2003 46 2013 44 2014 61 2003 46 2014 44 2015 61 2003 46 2015 44 2016 61 2003 46 2016 44 2017 61 2003 46 2017 44 2018 61 2003 46 2018 44 2019 61 2003 46 2019 44 2020 61 2003 46 2020 44 2021 61 2003 46 2021 44 2022 61 2003 46 2022 44 2023 61 2003 46 2023 44 2024 61 2003 46 2024 44 41 2003 46 2028 46 2042 40 362 44 2003 46 2007 41 2003 46 2025 61 2003 46 2026 46 2043 40 41 645 2044 552 2045 58 2046 61 362 2003 46 2028 46 2045 40 2046 41 778 2038 40 2046 41 792 2003 46 2025 ,"{'AvgLine': 74, 'CountLine': 210, 'CountStmt': 88, 'MaxNesting': 3, 'AvgLineCode': 67, 'AvgEssential': 2, 'AvgLineBlank': 6, 'CountStmtExe': 85, 'MaxEssential': 4, 'SumEssential': 5, 'AvgCyclomatic': 14, 'CountLineCode': 135, 'CountStmtDecl': 28, 'MaxCyclomatic': 28, 'SumCyclomatic': 29, 'AvgLineComment': 1, 'CountClassBase': 1, 'CountLineBlank': 16, 'CountDeclMethod': 2, 'CountLineCodeExe': 110, 'CountLineComment': 59, 'CountClassCoupled': 5, 'CountClassDerived': 0, 'CountLineCodeDecl': 51, 'CountDeclMethodAll': 9, 'MaxInheritanceTree': 2, 'RatioCommentToCode': '0.44', 'AvgCyclomaticStrict': 15, 'MaxCyclomaticStrict': 29, 'SumCyclomaticStrict': 30, 'AvgCyclomaticModified': 14, 'MaxCyclomaticModified': 28, 'SumCyclomaticModified': 29, 'CountDeclInstanceMethod': 2, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 22}"
131525,Python,"class GEOSTest(SimpleTestCase, TestDataMixin):

    def test_wkt(self):
        ""Testing WKT output.""
        for g in self.geometries.wkt_out:
            geom = fromstr(g.wkt)
            if geom.hasz:
                self.assertEqual(g.ewkt, geom.wkt)

    def test_hex(self):
        ""Testing HEX output.""
        for g in self.geometries.hex_wkt:
            geom = fromstr(g.wkt)
            self.assertEqual(g.hex, geom.hex.decode())

    def test_hexewkb(self):
        ""Testing (HEX)EWKB output.""
        # For testing HEX(EWKB).
        ogc_hex = b'01010000000000000000000000000000000000F03F'
        ogc_hex_3d = b'01010000800000000000000000000000000000F03F0000000000000040'
        # `SELECT ST_AsHEXEWKB(ST_GeomFromText('POINT(0 1)', 4326));`
        hexewkb_2d = b'0101000020E61000000000000000000000000000000000F03F'
        # `SELECT ST_AsHEXEWKB(ST_GeomFromEWKT('SRID=4326;POINT(0 1 2)'));`
        hexewkb_3d = b'01010000A0E61000000000000000000000000000000000F03F0000000000000040'

        pnt_2d = Point(0, 1, srid=4326)
        pnt_3d = Point(0, 1, 2, srid=4326)

        # OGC-compliant HEX will not have SRID value.
        self.assertEqual(ogc_hex, pnt_2d.hex)
        self.assertEqual(ogc_hex_3d, pnt_3d.hex)

        # HEXEWKB should be appropriate for its dimension -- have to use an
        # a WKBWriter w/dimension set accordingly, else GEOS will insert
        # garbage into 3D coordinate if there is none.
        self.assertEqual(hexewkb_2d, pnt_2d.hexewkb)
        self.assertEqual(hexewkb_3d, pnt_3d.hexewkb)
        self.assertIs(GEOSGeometry(hexewkb_3d).hasz, True)

        # Same for EWKB.
        self.assertEqual(memoryview(a2b_hex(hexewkb_2d)), pnt_2d.ewkb)
        self.assertEqual(memoryview(a2b_hex(hexewkb_3d)), pnt_3d.ewkb)

        # Redundant sanity check.
        self.assertEqual(4326, GEOSGeometry(hexewkb_2d).srid)

    def test_kml(self):
        ""Testing KML output.""
        for tg in self.geometries.wkt_out:
            geom = fromstr(tg.wkt)
            kml = getattr(tg, 'kml', False)
            if kml:
                self.assertEqual(kml, geom.kml)

    def test_errors(self):
        ""Testing the Error handlers.""
        # string-based
        for err in self.geometries.errors:
            with self.assertRaises((GEOSException, ValueError)):
                fromstr(err.wkt)

        # Bad WKB
        with self.assertRaises(GEOSException):
            GEOSGeometry(memoryview(b'0'))

        class NotAGeometry:
            pass

        # Some other object
        with self.assertRaises(TypeError):
            GEOSGeometry(NotAGeometry())
        # None
        with self.assertRaises(TypeError):
            GEOSGeometry(None)

    def test_wkb(self):
        ""Testing WKB output.""
        for g in self.geometries.hex_wkt:
            geom = fromstr(g.wkt)
            wkb = geom.wkb
            self.assertEqual(wkb.hex().upper(), g.hex)

    def test_create_hex(self):
        ""Testing creation from HEX.""
        for g in self.geometries.hex_wkt:
            geom_h = GEOSGeometry(g.hex)
            # we need to do this so decimal places get normalized
            geom_t = fromstr(g.wkt)
            self.assertEqual(geom_t.wkt, geom_h.wkt)

    def test_create_wkb(self):
        ""Testing creation from WKB.""
        for g in self.geometries.hex_wkt:
            wkb = memoryview(bytes.fromhex(g.hex))
            geom_h = GEOSGeometry(wkb)
            # we need to do this so decimal places get normalized
            geom_t = fromstr(g.wkt)
            self.assertEqual(geom_t.wkt, geom_h.wkt)

    def test_ewkt(self):
        ""Testing EWKT.""
        srids = (-1, 32140)
        for srid in srids:
            for p in self.geometries.polygons:
                ewkt = 'SRID=%d;%s' % (srid, p.wkt)
                poly = fromstr(ewkt)
                self.assertEqual(srid, poly.srid)
                self.assertEqual(srid, poly.shell.srid)
                self.assertEqual(srid, fromstr(poly.ewkt).srid)  # Checking export

    def test_json(self):
        ""Testing GeoJSON input/output (via GDAL).""
        for g in self.geometries.json_geoms:
            geom = GEOSGeometry(g.wkt)
            if not hasattr(g, 'not_equal'):
                # Loading jsons to prevent decimal differences
                self.assertEqual(json.loads(g.json), json.loads(geom.json))
                self.assertEqual(json.loads(g.json), json.loads(geom.geojson))
            self.assertEqual(GEOSGeometry(g.wkt, 4326), GEOSGeometry(geom.json))

    def test_json_srid(self):
        geojson_data = {
            ""type"": ""Point"",
            ""coordinates"": [2, 49],
            ""crs"": {
                ""type"": ""name"",
                ""properties"": {
                    ""name"": ""urn:ogc:def:crs:EPSG::4322""
                }
            }
        }
        self.assertEqual(GEOSGeometry(json.dumps(geojson_data)), Point(2, 49, srid=4322))

    def test_fromfile(self):
        ""Testing the fromfile() factory.""
        ref_pnt = GEOSGeometry('POINT(5 23)')

        wkt_f = BytesIO()
        wkt_f.write(ref_pnt.wkt.encode())
        wkb_f = BytesIO()
        wkb_f.write(bytes(ref_pnt.wkb))

        # Other tests use `fromfile()` on string filenames so those
        # aren't tested here.
        for fh in (wkt_f, wkb_f):
            fh.seek(0)
            pnt = fromfile(fh)
            self.assertEqual(ref_pnt, pnt)

    def test_eq(self):
        ""Testing equivalence.""
        p = fromstr('POINT(5 23)')
        self.assertEqual(p, p.wkt)
        self.assertNotEqual(p, 'foo')
        ls = fromstr('LINESTRING(0 0, 1 1, 5 5)')
        self.assertEqual(ls, ls.wkt)
        self.assertNotEqual(p, 'bar')
        self.assertEqual(p, 'POINT(5.0 23.0)')
        # Error shouldn't be raise on equivalence testing with
        # an invalid type.
        for g in (p, ls):
            self.assertIsNotNone(g)
            self.assertNotEqual(g, {'foo': 'bar'})
            self.assertIsNot(g, False)

    def test_hash(self):
        point_1 = Point(5, 23)
        point_2 = Point(5, 23, srid=4326)
        point_3 = Point(5, 23, srid=32632)
        multipoint_1 = MultiPoint(point_1, srid=4326)
        multipoint_2 = MultiPoint(point_2)
        multipoint_3 = MultiPoint(point_3)
        self.assertNotEqual(hash(point_1), hash(point_2))
        self.assertNotEqual(hash(point_1), hash(point_3))
        self.assertNotEqual(hash(point_2), hash(point_3))
        self.assertNotEqual(hash(multipoint_1), hash(multipoint_2))
        self.assertEqual(hash(multipoint_2), hash(multipoint_3))
        self.assertNotEqual(hash(multipoint_1), hash(point_1))
        self.assertNotEqual(hash(multipoint_2), hash(point_2))
        self.assertNotEqual(hash(multipoint_3), hash(point_3))

    def test_eq_with_srid(self):
        ""Testing non-equivalence with different srids.""
        p0 = Point(5, 23)
        p1 = Point(5, 23, srid=4326)
        p2 = Point(5, 23, srid=32632)
        # GEOS
        self.assertNotEqual(p0, p1)
        self.assertNotEqual(p1, p2)
        # EWKT
        self.assertNotEqual(p0, p1.ewkt)
        self.assertNotEqual(p1, p0.ewkt)
        self.assertNotEqual(p1, p2.ewkt)
        # Equivalence with matching SRIDs
        self.assertEqual(p2, p2)
        self.assertEqual(p2, p2.ewkt)
        # WKT contains no SRID so will not equal
        self.assertNotEqual(p2, p2.wkt)
        # SRID of 0
        self.assertEqual(p0, 'SRID=0;POINT (5 23)')
        self.assertNotEqual(p1, 'SRID=0;POINT (5 23)')

    def test_points(self):
        ""Testing Point objects.""
        prev = fromstr('POINT(0 0)')
        for p in self.geometries.points:
            # Creating the point from the WKT
            pnt = fromstr(p.wkt)
            self.assertEqual(pnt.geom_type, 'Point')
            self.assertEqual(pnt.geom_typeid, 0)
            self.assertEqual(pnt.dims, 0)
            self.assertEqual(p.x, pnt.x)
            self.assertEqual(p.y, pnt.y)
            self.assertEqual(pnt, fromstr(p.wkt))
            self.assertIs(pnt == prev, False)  # Use assertIs() to test __eq__.

            # Making sure that the point's X, Y components are what we expect
            self.assertAlmostEqual(p.x, pnt.tuple[0], 9)
            self.assertAlmostEqual(p.y, pnt.tuple[1], 9)

            # Testing the third dimension, and getting the tuple arguments
            if hasattr(p, 'z'):
                self.assertIs(pnt.hasz, True)
                self.assertEqual(p.z, pnt.z)
                self.assertEqual(p.z, pnt.tuple[2], 9)
                tup_args = (p.x, p.y, p.z)
                set_tup1 = (2.71, 3.14, 5.23)
                set_tup2 = (5.23, 2.71, 3.14)
            else:
                self.assertIs(pnt.hasz, False)
                self.assertIsNone(pnt.z)
                tup_args = (p.x, p.y)
                set_tup1 = (2.71, 3.14)
                set_tup2 = (3.14, 2.71)

            # Centroid operation on point should be point itself
            self.assertEqual(p.centroid, pnt.centroid.tuple)

            # Now testing the different constructors
            pnt2 = Point(tup_args)  # e.g., Point((1, 2))
            pnt3 = Point(*tup_args)  # e.g., Point(1, 2)
            self.assertEqual(pnt, pnt2)
            self.assertEqual(pnt, pnt3)

            # Now testing setting the x and y
            pnt.y = 3.14
            pnt.x = 2.71
            self.assertEqual(3.14, pnt.y)
            self.assertEqual(2.71, pnt.x)

            # Setting via the tuple/coords property
            pnt.tuple = set_tup1
            self.assertEqual(set_tup1, pnt.tuple)
            pnt.coords = set_tup2
            self.assertEqual(set_tup2, pnt.coords)

            prev = pnt  # setting the previous geometry

    def test_point_reverse(self):
        point = GEOSGeometry('POINT(144.963 -37.8143)', 4326)
        self.assertEqual(point.srid, 4326)
        point.reverse()
        self.assertEqual(point.ewkt, 'SRID=4326;POINT (-37.8143 144.963)')

    def test_multipoints(self):
        ""Testing MultiPoint objects.""
        for mp in self.geometries.multipoints:
            mpnt = fromstr(mp.wkt)
            self.assertEqual(mpnt.geom_type, 'MultiPoint')
            self.assertEqual(mpnt.geom_typeid, 4)
            self.assertEqual(mpnt.dims, 0)

            self.assertAlmostEqual(mp.centroid[0], mpnt.centroid.tuple[0], 9)
            self.assertAlmostEqual(mp.centroid[1], mpnt.centroid.tuple[1], 9)

            with self.assertRaises(IndexError):
                mpnt.__getitem__(len(mpnt))
            self.assertEqual(mp.centroid, mpnt.centroid.tuple)
            self.assertEqual(mp.coords, tuple(m.tuple for m in mpnt))
            for p in mpnt:
                self.assertEqual(p.geom_type, 'Point')
                self.assertEqual(p.geom_typeid, 0)
                self.assertIs(p.empty, False)
                self.assertIs(p.valid, True)

    def test_linestring(self):
        ""Testing LineString objects.""
        prev = fromstr('POINT(0 0)')
        for line in self.geometries.linestrings:
            ls = fromstr(line.wkt)
            self.assertEqual(ls.geom_type, 'LineString')
            self.assertEqual(ls.geom_typeid, 1)
            self.assertEqual(ls.dims, 1)
            self.assertIs(ls.empty, False)
            self.assertIs(ls.ring, False)
            if hasattr(line, 'centroid'):
                self.assertEqual(line.centroid, ls.centroid.tuple)
            if hasattr(line, 'tup'):
                self.assertEqual(line.tup, ls.tuple)

            self.assertEqual(ls, fromstr(line.wkt))
            self.assertIs(ls == prev, False)  # Use assertIs() to test __eq__.
            with self.assertRaises(IndexError):
                ls.__getitem__(len(ls))
            prev = ls

            # Creating a LineString from a tuple, list, and numpy array
            self.assertEqual(ls, LineString(ls.tuple))  # tuple
            self.assertEqual(ls, LineString(*ls.tuple))  # as individual arguments
            self.assertEqual(ls, LineString([list(tup) for tup in ls.tuple]))  # as list
            # Point individual arguments
            self.assertEqual(ls.wkt, LineString(*tuple(Point(tup) for tup in ls.tuple)).wkt)
            if numpy:
                self.assertEqual(ls, LineString(numpy.array(ls.tuple)))  # as numpy array

        with self.assertRaisesMessage(TypeError, 'Each coordinate should be a sequence (list or tuple)'):
            LineString((0, 0))

        with self.assertRaisesMessage(ValueError, 'LineString requires at least 2 points, got 1.'):
            LineString([(0, 0)])

        if numpy:
            with self.assertRaisesMessage(ValueError, 'LineString requires at least 2 points, got 1.'):
                LineString(numpy.array([(0, 0)]))

        with mock.patch('django.contrib.gis.geos.linestring.numpy', False):
            with self.assertRaisesMessage(TypeError, 'Invalid initialization input for LineStrings.'):
                LineString('wrong input')

        # Test __iter__().
        self.assertEqual(list(LineString((0, 0), (1, 1), (2, 2))), [(0, 0), (1, 1), (2, 2)])

    def test_linestring_reverse(self):
        line = GEOSGeometry('LINESTRING(144.963 -37.8143,151.2607 -33.887)', 4326)
        self.assertEqual(line.srid, 4326)
        line.reverse()
        self.assertEqual(line.ewkt, 'SRID=4326;LINESTRING (151.2607 -33.887, 144.963 -37.8143)')

    def _test_is_counterclockwise(self):
        lr = LinearRing((0, 0), (1, 0), (0, 1), (0, 0))
        self.assertIs(lr.is_counterclockwise, True)
        lr.reverse()
        self.assertIs(lr.is_counterclockwise, False)
        msg = 'Orientation of an empty LinearRing cannot be determined.'
        with self.assertRaisesMessage(ValueError, msg):
            LinearRing().is_counterclockwise

    @skipIf(geos_version_tuple() < (3, 7), 'GEOS >= 3.7.0 is required')
    def test_is_counterclockwise(self):
        self._test_is_counterclockwise()

    @skipIf(geos_version_tuple() < (3, 7), 'GEOS >= 3.7.0 is required')
    def test_is_counterclockwise_geos_error(self):
        with mock.patch('django.contrib.gis.geos.prototypes.cs_is_ccw') as mocked:
            mocked.return_value = 0
            mocked.func_name = 'GEOSCoordSeq_isCCW'
            msg = 'Error encountered in GEOS C function ""GEOSCoordSeq_isCCW"".'
            with self.assertRaisesMessage(GEOSException, msg):
                LinearRing((0, 0), (1, 0), (0, 1), (0, 0)).is_counterclockwise

    @mock.patch('django.contrib.gis.geos.libgeos.geos_version', lambda: b'3.6.9')
    def test_is_counterclockwise_fallback(self):
        self._test_is_counterclockwise()

    def test_multilinestring(self):
        ""Testing MultiLineString objects.""
        prev = fromstr('POINT(0 0)')
        for line in self.geometries.multilinestrings:
            ml = fromstr(line.wkt)
            self.assertEqual(ml.geom_type, 'MultiLineString')
            self.assertEqual(ml.geom_typeid, 5)
            self.assertEqual(ml.dims, 1)

            self.assertAlmostEqual(line.centroid[0], ml.centroid.x, 9)
            self.assertAlmostEqual(line.centroid[1], ml.centroid.y, 9)

            self.assertEqual(ml, fromstr(line.wkt))
            self.assertIs(ml == prev, False)  # Use assertIs() to test __eq__.
            prev = ml

            for ls in ml:
                self.assertEqual(ls.geom_type, 'LineString')
                self.assertEqual(ls.geom_typeid, 1)
                self.assertIs(ls.empty, False)

            with self.assertRaises(IndexError):
                ml.__getitem__(len(ml))
            self.assertEqual(ml.wkt, MultiLineString(*tuple(s.clone() for s in ml)).wkt)
            self.assertEqual(ml, MultiLineString(*tuple(LineString(s.tuple) for s in ml)))

    def test_linearring(self):
        ""Testing LinearRing objects.""
        for rr in self.geometries.linearrings:
            lr = fromstr(rr.wkt)
            self.assertEqual(lr.geom_type, 'LinearRing')
            self.assertEqual(lr.geom_typeid, 2)
            self.assertEqual(lr.dims, 1)
            self.assertEqual(rr.n_p, len(lr))
            self.assertIs(lr.valid, True)
            self.assertIs(lr.empty, False)

            # Creating a LinearRing from a tuple, list, and numpy array
            self.assertEqual(lr, LinearRing(lr.tuple))
            self.assertEqual(lr, LinearRing(*lr.tuple))
            self.assertEqual(lr, LinearRing([list(tup) for tup in lr.tuple]))
            if numpy:
                self.assertEqual(lr, LinearRing(numpy.array(lr.tuple)))

        with self.assertRaisesMessage(ValueError, 'LinearRing requires at least 4 points, got 3.'):
            LinearRing((0, 0), (1, 1), (0, 0))

        with self.assertRaisesMessage(ValueError, 'LinearRing requires at least 4 points, got 1.'):
            LinearRing([(0, 0)])

        if numpy:
            with self.assertRaisesMessage(ValueError, 'LinearRing requires at least 4 points, got 1.'):
                LinearRing(numpy.array([(0, 0)]))

    def test_linearring_json(self):
        self.assertJSONEqual(
            LinearRing((0, 0), (0, 1), (1, 1), (0, 0)).json,
            '{""coordinates"": [[0, 0], [0, 1], [1, 1], [0, 0]], ""type"": ""LineString""}',
        )

    def test_polygons_from_bbox(self):
        ""Testing `from_bbox` class method.""
        bbox = (-180, -90, 180, 90)
        p = Polygon.from_bbox(bbox)
        self.assertEqual(bbox, p.extent)

        # Testing numerical precision
        x = 3.14159265358979323
        bbox = (0, 0, 1, x)
        p = Polygon.from_bbox(bbox)
        y = p.extent[-1]
        self.assertEqual(format(x, '.13f'), format(y, '.13f'))

    def test_polygons(self):
        ""Testing Polygon objects.""

        prev = fromstr('POINT(0 0)')
        for p in self.geometries.polygons:
            # Creating the Polygon, testing its properties.
            poly = fromstr(p.wkt)
            self.assertEqual(poly.geom_type, 'Polygon')
            self.assertEqual(poly.geom_typeid, 3)
            self.assertEqual(poly.dims, 2)
            self.assertIs(poly.empty, False)
            self.assertIs(poly.ring, False)
            self.assertEqual(p.n_i, poly.num_interior_rings)
            self.assertEqual(p.n_i + 1, len(poly))  # Testing __len__
            self.assertEqual(p.n_p, poly.num_points)

            # Area & Centroid
            self.assertAlmostEqual(p.area, poly.area, 9)
            self.assertAlmostEqual(p.centroid[0], poly.centroid.tuple[0], 9)
            self.assertAlmostEqual(p.centroid[1], poly.centroid.tuple[1], 9)

            # Testing the geometry equivalence
            self.assertEqual(poly, fromstr(p.wkt))
            # Should not be equal to previous geometry
            self.assertIs(poly == prev, False)  # Use assertIs() to test __eq__.
            self.assertIs(poly != prev, True)  # Use assertIs() to test __ne__.

            # Testing the exterior ring
            ring = poly.exterior_ring
            self.assertEqual(ring.geom_type, 'LinearRing')
            self.assertEqual(ring.geom_typeid, 2)
            if p.ext_ring_cs:
                self.assertEqual(p.ext_ring_cs, ring.tuple)
                self.assertEqual(p.ext_ring_cs, poly[0].tuple)  # Testing __getitem__

            # Testing __getitem__ and __setitem__ on invalid indices
            with self.assertRaises(IndexError):
                poly.__getitem__(len(poly))
            with self.assertRaises(IndexError):
                poly.__setitem__(len(poly), False)
            with self.assertRaises(IndexError):
                poly.__getitem__(-1 * len(poly) - 1)

            # Testing __iter__
            for r in poly:
                self.assertEqual(r.geom_type, 'LinearRing')
                self.assertEqual(r.geom_typeid, 2)

            # Testing polygon construction.
            with self.assertRaises(TypeError):
                Polygon(0, [1, 2, 3])
            with self.assertRaises(TypeError):
                Polygon('foo')

            # Polygon(shell, (hole1, ... holeN))
            ext_ring, *int_rings = poly
            self.assertEqual(poly, Polygon(ext_ring, int_rings))

            # Polygon(shell_tuple, hole_tuple1, ... , hole_tupleN)
            ring_tuples = tuple(r.tuple for r in poly)
            self.assertEqual(poly, Polygon(*ring_tuples))

            # Constructing with tuples of LinearRings.
            self.assertEqual(poly.wkt, Polygon(*tuple(r for r in poly)).wkt)
            self.assertEqual(poly.wkt, Polygon(*tuple(LinearRing(r.tuple) for r in poly)).wkt)

    def test_polygons_templates(self):
        # Accessing Polygon attributes in templates should work.
        engine = Engine()
        template = engine.from_string('{{ polygons.0.wkt }}')
        polygons = [fromstr(p.wkt) for p in self.geometries.multipolygons[:2]]
        content = template.render(Context({'polygons': polygons}))
        self.assertIn('MULTIPOLYGON (((100', content)

    def test_polygon_comparison(self):
        p1 = Polygon(((0, 0), (0, 1), (1, 1), (1, 0), (0, 0)))
        p2 = Polygon(((0, 0), (0, 1), (1, 0), (0, 0)))
        self.assertGreater(p1, p2)
        self.assertLess(p2, p1)

        p3 = Polygon(((0, 0), (0, 1), (1, 1), (2, 0), (0, 0)))
        p4 = Polygon(((0, 0), (0, 1), (2, 2), (1, 0), (0, 0)))
        self.assertGreater(p4, p3)
        self.assertLess(p3, p4)

    def test_multipolygons(self):
        ""Testing MultiPolygon objects.""
        fromstr('POINT (0 0)')
        for mp in self.geometries.multipolygons:
            mpoly = fromstr(mp.wkt)
            self.assertEqual(mpoly.geom_type, 'MultiPolygon')
            self.assertEqual(mpoly.geom_typeid, 6)
            self.assertEqual(mpoly.dims, 2)
            self.assertEqual(mp.valid, mpoly.valid)

            if mp.valid:
                self.assertEqual(mp.num_geom, mpoly.num_geom)
                self.assertEqual(mp.n_p, mpoly.num_coords)
                self.assertEqual(mp.num_geom, len(mpoly))
                with self.assertRaises(IndexError):
                    mpoly.__getitem__(len(mpoly))
                for p in mpoly:
                    self.assertEqual(p.geom_type, 'Polygon')
                    self.assertEqual(p.geom_typeid, 3)
                    self.assertIs(p.valid, True)
                self.assertEqual(mpoly.wkt, MultiPolygon(*tuple(poly.clone() for poly in mpoly)).wkt)

    def test_memory_hijinks(self):
        ""Testing Geometry __del__() on rings and polygons.""
        # #### Memory issues with rings and poly

        # These tests are needed to ensure sanity with writable geometries.

        # Getting a polygon with interior rings, and pulling out the interior rings
        poly = fromstr(self.geometries.polygons[1].wkt)
        ring1 = poly[0]
        ring2 = poly[1]

        # These deletes should be 'harmless' since they are done on child geometries
        del ring1
        del ring2
        ring1 = poly[0]
        ring2 = poly[1]

        # Deleting the polygon
        del poly

        # Access to these rings is OK since they are clones.
        str(ring1)
        str(ring2)

    def test_coord_seq(self):
        ""Testing Coordinate Sequence objects.""
        for p in self.geometries.polygons:
            if p.ext_ring_cs:
                # Constructing the polygon and getting the coordinate sequence
                poly = fromstr(p.wkt)
                cs = poly.exterior_ring.coord_seq

                self.assertEqual(p.ext_ring_cs, cs.tuple)  # done in the Polygon test too.
                self.assertEqual(len(p.ext_ring_cs), len(cs))  # Making sure __len__ works

                # Checks __getitem__ and __setitem__
                for i in range(len(p.ext_ring_cs)):
                    c1 = p.ext_ring_cs[i]  # Expected value
                    c2 = cs[i]  # Value from coordseq
                    self.assertEqual(c1, c2)

                    # Constructing the test value to set the coordinate sequence with
                    if len(c1) == 2:
                        tset = (5, 23)
                    else:
                        tset = (5, 23, 8)
                    cs[i] = tset

                    # Making sure every set point matches what we expect
                    for j in range(len(tset)):
                        cs[i] = tset
                        self.assertEqual(tset[j], cs[i][j])

    def test_relate_pattern(self):
        ""Testing relate() and relate_pattern().""
        g = fromstr('POINT (0 0)')
        with self.assertRaises(GEOSException):
            g.relate_pattern(0, 'invalid pattern, yo')
        for rg in self.geometries.relate_geoms:
            a = fromstr(rg.wkt_a)
            b = fromstr(rg.wkt_b)
            self.assertEqual(rg.result, a.relate_pattern(b, rg.pattern))
            self.assertEqual(rg.pattern, a.relate(b))

    def test_intersection(self):
        ""Testing intersects() and intersection().""
        for i in range(len(self.geometries.topology_geoms)):
            a = fromstr(self.geometries.topology_geoms[i].wkt_a)
            b = fromstr(self.geometries.topology_geoms[i].wkt_b)
            i1 = fromstr(self.geometries.intersect_geoms[i].wkt)
            self.assertIs(a.intersects(b), True)
            i2 = a.intersection(b)
            self.assertTrue(i1.equals(i2))
            self.assertTrue(i1.equals(a & b))  # __and__ is intersection operator
            a &= b  # testing __iand__
            self.assertTrue(i1.equals(a))

    def test_union(self):
        ""Testing union().""
        for i in range(len(self.geometries.topology_geoms)):
            a = fromstr(self.geometries.topology_geoms[i].wkt_a)
            b = fromstr(self.geometries.topology_geoms[i].wkt_b)
            u1 = fromstr(self.geometries.union_geoms[i].wkt)
            u2 = a.union(b)
            self.assertTrue(u1.equals(u2))
            self.assertTrue(u1.equals(a | b))  # __or__ is union operator
            a |= b  # testing __ior__
            self.assertTrue(u1.equals(a))

    def test_unary_union(self):
        ""Testing unary_union.""
        for i in range(len(self.geometries.topology_geoms)):
            a = fromstr(self.geometries.topology_geoms[i].wkt_a)
            b = fromstr(self.geometries.topology_geoms[i].wkt_b)
            u1 = fromstr(self.geometries.union_geoms[i].wkt)
            u2 = GeometryCollection(a, b).unary_union
            self.assertTrue(u1.equals(u2))

    def test_difference(self):
        ""Testing difference().""
        for i in range(len(self.geometries.topology_geoms)):
            a = fromstr(self.geometries.topology_geoms[i].wkt_a)
            b = fromstr(self.geometries.topology_geoms[i].wkt_b)
            d1 = fromstr(self.geometries.diff_geoms[i].wkt)
            d2 = a.difference(b)
            self.assertTrue(d1.equals(d2))
            self.assertTrue(d1.equals(a - b))  # __sub__ is difference operator
            a -= b  # testing __isub__
            self.assertTrue(d1.equals(a))

    def test_symdifference(self):
        ""Testing sym_difference().""
        for i in range(len(self.geometries.topology_geoms)):
            a = fromstr(self.geometries.topology_geoms[i].wkt_a)
            b = fromstr(self.geometries.topology_geoms[i].wkt_b)
            d1 = fromstr(self.geometries.sdiff_geoms[i].wkt)
            d2 = a.sym_difference(b)
            self.assertTrue(d1.equals(d2))
            self.assertTrue(d1.equals(a ^ b))  # __xor__ is symmetric difference operator
            a ^= b  # testing __ixor__
            self.assertTrue(d1.equals(a))

    def test_buffer(self):
        bg = self.geometries.buffer_geoms[0]
        g = fromstr(bg.wkt)

        # Can't use a floating-point for the number of quadsegs.
        with self.assertRaises(ctypes.ArgumentError):
            g.buffer(bg.width, quadsegs=1.1)

        self._test_buffer(self.geometries.buffer_geoms, 'buffer')

    def test_buffer_with_style(self):
        bg = self.geometries.buffer_with_style_geoms[0]
        g = fromstr(bg.wkt)

        # Can't use a floating-point for the number of quadsegs.
        with self.assertRaises(ctypes.ArgumentError):
            g.buffer_with_style(bg.width, quadsegs=1.1)

        # Can't use a floating-point for the end cap style.
        with self.assertRaises(ctypes.ArgumentError):
            g.buffer_with_style(bg.width, end_cap_style=1.2)
        # Can't use a end cap style that is not in the enum.
        with self.assertRaises(GEOSException):
            g.buffer_with_style(bg.width, end_cap_style=55)

        # Can't use a floating-point for the join style.
        with self.assertRaises(ctypes.ArgumentError):
            g.buffer_with_style(bg.width, join_style=1.3)
        # Can't use a join style that is not in the enum.
        with self.assertRaises(GEOSException):
            g.buffer_with_style(bg.width, join_style=66)

        self._test_buffer(
            itertools.chain(self.geometries.buffer_geoms, self.geometries.buffer_with_style_geoms),
            'buffer_with_style',
        )

    def _test_buffer(self, geometries, buffer_method_name):
        for bg in geometries:
            g = fromstr(bg.wkt)

            # The buffer we expect
            exp_buf = fromstr(bg.buffer_wkt)

            # Constructing our buffer
            buf_kwargs = {
                kwarg_name: getattr(bg, kwarg_name)
                for kwarg_name in ('width', 'quadsegs', 'end_cap_style', 'join_style', 'mitre_limit')
                if hasattr(bg, kwarg_name)
            }
            buf = getattr(g, buffer_method_name)(**buf_kwargs)
            self.assertEqual(exp_buf.num_coords, buf.num_coords)
            self.assertEqual(len(exp_buf), len(buf))

            # Now assuring that each point in the buffer is almost equal
            for j in range(len(exp_buf)):
                exp_ring = exp_buf[j]
                buf_ring = buf[j]
                self.assertEqual(len(exp_ring), len(buf_ring))
                for k in range(len(exp_ring)):
                    # Asserting the X, Y of each point are almost equal (due to floating point imprecision)
                    self.assertAlmostEqual(exp_ring[k][0], buf_ring[k][0], 9)
                    self.assertAlmostEqual(exp_ring[k][1], buf_ring[k][1], 9)

    def test_covers(self):
        poly = Polygon(((0, 0), (0, 10), (10, 10), (10, 0), (0, 0)))
        self.assertTrue(poly.covers(Point(5, 5)))
        self.assertFalse(poly.covers(Point(100, 100)))

    def test_closed(self):
        ls_closed = LineString((0, 0), (1, 1), (0, 0))
        ls_not_closed = LineString((0, 0), (1, 1))
        self.assertFalse(ls_not_closed.closed)
        self.assertTrue(ls_closed.closed)

    def test_srid(self):
        ""Testing the SRID property and keyword.""
        # Testing SRID keyword on Point
        pnt = Point(5, 23, srid=4326)
        self.assertEqual(4326, pnt.srid)
        pnt.srid = 3084
        self.assertEqual(3084, pnt.srid)
        with self.assertRaises(ctypes.ArgumentError):
            pnt.srid = '4326'

        # Testing SRID keyword on fromstr(), and on Polygon rings.
        poly = fromstr(self.geometries.polygons[1].wkt, srid=4269)
        self.assertEqual(4269, poly.srid)
        for ring in poly:
            self.assertEqual(4269, ring.srid)
        poly.srid = 4326
        self.assertEqual(4326, poly.shell.srid)

        # Testing SRID keyword on GeometryCollection
        gc = GeometryCollection(Point(5, 23), LineString((0, 0), (1.5, 1.5), (3, 3)), srid=32021)
        self.assertEqual(32021, gc.srid)
        for i in range(len(gc)):
            self.assertEqual(32021, gc[i].srid)

        # GEOS may get the SRID from HEXEWKB
        # 'POINT(5 23)' at SRID=4326 in hex form -- obtained from PostGIS
        # using `SELECT GeomFromText('POINT (5 23)', 4326);`.
        hex = '0101000020E610000000000000000014400000000000003740'
        p1 = fromstr(hex)
        self.assertEqual(4326, p1.srid)

        p2 = fromstr(p1.hex)
        self.assertIsNone(p2.srid)
        p3 = fromstr(p1.hex, srid=-1)  # -1 is intended.
        self.assertEqual(-1, p3.srid)

        # Testing that geometry SRID could be set to its own value
        pnt_wo_srid = Point(1, 1)
        pnt_wo_srid.srid = pnt_wo_srid.srid

        # Input geometries that have an SRID.
        self.assertEqual(GEOSGeometry(pnt.ewkt, srid=pnt.srid).srid, pnt.srid)
        self.assertEqual(GEOSGeometry(pnt.ewkb, srid=pnt.srid).srid, pnt.srid)
        with self.assertRaisesMessage(ValueError, 'Input geometry already has SRID: %d.' % pnt.srid):
            GEOSGeometry(pnt.ewkt, srid=1)
        with self.assertRaisesMessage(ValueError, 'Input geometry already has SRID: %d.' % pnt.srid):
            GEOSGeometry(pnt.ewkb, srid=1)

    def test_custom_srid(self):
        """"""Test with a null srid and a srid unknown to GDAL.""""""
        for srid in [None, 999999]:
            pnt = Point(111200, 220900, srid=srid)
            self.assertTrue(pnt.ewkt.startswith((""SRID=%s;"" % srid if srid else '') + ""POINT (111200""))
            self.assertIsInstance(pnt.ogr, gdal.OGRGeometry)
            self.assertIsNone(pnt.srs)

            # Test conversion from custom to a known srid
            c2w = gdal.CoordTransform(
                gdal.SpatialReference(
                    '+proj=mill +lat_0=0 +lon_0=0 +x_0=0 +y_0=0 +R_A +ellps=WGS84 '
                    '+datum=WGS84 +units=m +no_defs'
                ),
                gdal.SpatialReference(4326))
            new_pnt = pnt.transform(c2w, clone=True)
            self.assertEqual(new_pnt.srid, 4326)
            self.assertAlmostEqual(new_pnt.x, 1, 1)
            self.assertAlmostEqual(new_pnt.y, 2, 1)

    def test_mutable_geometries(self):
        ""Testing the mutability of Polygons and Geometry Collections.""
        # ### Testing the mutability of Polygons ###
        for p in self.geometries.polygons:
            poly = fromstr(p.wkt)

            # Should only be able to use __setitem__ with LinearRing geometries.
            with self.assertRaises(TypeError):
                poly.__setitem__(0, LineString((1, 1), (2, 2)))

            # Constructing the new shell by adding 500 to every point in the old shell.
            shell_tup = poly.shell.tuple
            new_coords = []
            for point in shell_tup:
                new_coords.append((point[0] + 500., point[1] + 500.))
            new_shell = LinearRing(*tuple(new_coords))

            # Assigning polygon's exterior ring w/the new shell
            poly.exterior_ring = new_shell
            str(new_shell)  # new shell is still accessible
            self.assertEqual(poly.exterior_ring, new_shell)
            self.assertEqual(poly[0], new_shell)

        # ### Testing the mutability of Geometry Collections
        for tg in self.geometries.multipoints:
            mp = fromstr(tg.wkt)
            for i in range(len(mp)):
                # Creating a random point.
                pnt = mp[i]
                new = Point(random.randint(21, 100), random.randint(21, 100))
                # Testing the assignment
                mp[i] = new
                str(new)  # what was used for the assignment is still accessible
                self.assertEqual(mp[i], new)
                self.assertEqual(mp[i].wkt, new.wkt)
                self.assertNotEqual(pnt, mp[i])

        # MultiPolygons involve much more memory management because each
        # Polygon w/in the collection has its own rings.
        for tg in self.geometries.multipolygons:
            mpoly = fromstr(tg.wkt)
            for i in range(len(mpoly)):
                poly = mpoly[i]
                old_poly = mpoly[i]
                # Offsetting the each ring in the polygon by 500.
                for j in range(len(poly)):
                    r = poly[j]
                    for k in range(len(r)):
                        r[k] = (r[k][0] + 500., r[k][1] + 500.)
                    poly[j] = r

                self.assertNotEqual(mpoly[i], poly)
                # Testing the assignment
                mpoly[i] = poly
                str(poly)  # Still accessible
                self.assertEqual(mpoly[i], poly)
                self.assertNotEqual(mpoly[i], old_poly)

        # Extreme (!!) __setitem__ -- no longer works, have to detect
        # in the first object that __setitem__ is called in the subsequent
        # objects -- maybe mpoly[0, 0, 0] = (3.14, 2.71)?
        # mpoly[0][0][0] = (3.14, 2.71)
        # self.assertEqual((3.14, 2.71), mpoly[0][0][0])
        # Doing it more slowly..
        # self.assertEqual((3.14, 2.71), mpoly[0].shell[0])
        # del mpoly

    def test_point_list_assignment(self):
        p = Point(0, 0)

        p[:] = (1, 2, 3)
        self.assertEqual(p, Point(1, 2, 3))

        p[:] = ()
        self.assertEqual(p.wkt, Point())

        p[:] = (1, 2)
        self.assertEqual(p.wkt, Point(1, 2))

        with self.assertRaises(ValueError):
            p[:] = (1,)
        with self.assertRaises(ValueError):
            p[:] = (1, 2, 3, 4, 5)

    def test_linestring_list_assignment(self):
        ls = LineString((0, 0), (1, 1))

        ls[:] = ()
        self.assertEqual(ls, LineString())

        ls[:] = ((0, 0), (1, 1), (2, 2))
        self.assertEqual(ls, LineString((0, 0), (1, 1), (2, 2)))

        with self.assertRaises(ValueError):
            ls[:] = (1,)

    def test_linearring_list_assignment(self):
        ls = LinearRing((0, 0), (0, 1), (1, 1), (0, 0))

        ls[:] = ()
        self.assertEqual(ls, LinearRing())

        ls[:] = ((0, 0), (0, 1), (1, 1), (1, 0), (0, 0))
        self.assertEqual(ls, LinearRing((0, 0), (0, 1), (1, 1), (1, 0), (0, 0)))

        with self.assertRaises(ValueError):
            ls[:] = ((0, 0), (1, 1), (2, 2))

    def test_polygon_list_assignment(self):
        pol = Polygon()

        pol[:] = (((0, 0), (0, 1), (1, 1), (1, 0), (0, 0)),)
        self.assertEqual(pol, Polygon(((0, 0), (0, 1), (1, 1), (1, 0), (0, 0)),))

        pol[:] = ()
        self.assertEqual(pol, Polygon())

    def test_geometry_collection_list_assignment(self):
        p = Point()
        gc = GeometryCollection()

        gc[:] = [p]
        self.assertEqual(gc, GeometryCollection(p))

        gc[:] = ()
        self.assertEqual(gc, GeometryCollection())

    def test_threed(self):
        ""Testing three-dimensional geometries.""
        # Testing a 3D Point
        pnt = Point(2, 3, 8)
        self.assertEqual((2., 3., 8.), pnt.coords)
        with self.assertRaises(TypeError):
            pnt.tuple = (1., 2.)
        pnt.coords = (1., 2., 3.)
        self.assertEqual((1., 2., 3.), pnt.coords)

        # Testing a 3D LineString
        ls = LineString((2., 3., 8.), (50., 250., -117.))
        self.assertEqual(((2., 3., 8.), (50., 250., -117.)), ls.tuple)
        with self.assertRaises(TypeError):
            ls.__setitem__(0, (1., 2.))
        ls[0] = (1., 2., 3.)
        self.assertEqual((1., 2., 3.), ls[0])

    def test_distance(self):
        ""Testing the distance() function.""
        # Distance to self should be 0.
        pnt = Point(0, 0)
        self.assertEqual(0.0, pnt.distance(Point(0, 0)))

        # Distance should be 1
        self.assertEqual(1.0, pnt.distance(Point(0, 1)))

        # Distance should be ~ sqrt(2)
        self.assertAlmostEqual(1.41421356237, pnt.distance(Point(1, 1)), 11)

        # Distances are from the closest vertex in each geometry --
        #  should be 3 (distance from (2, 2) to (5, 2)).
        ls1 = LineString((0, 0), (1, 1), (2, 2))
        ls2 = LineString((5, 2), (6, 1), (7, 0))
        self.assertEqual(3, ls1.distance(ls2))

    def test_length(self):
        ""Testing the length property.""
        # Points have 0 length.
        pnt = Point(0, 0)
        self.assertEqual(0.0, pnt.length)

        # Should be ~ sqrt(2)
        ls = LineString((0, 0), (1, 1))
        self.assertAlmostEqual(1.41421356237, ls.length, 11)

        # Should be circumference of Polygon
        poly = Polygon(LinearRing((0, 0), (0, 1), (1, 1), (1, 0), (0, 0)))
        self.assertEqual(4.0, poly.length)

        # Should be sum of each element's length in collection.
        mpoly = MultiPolygon(poly.clone(), poly)
        self.assertEqual(8.0, mpoly.length)

    def test_emptyCollections(self):
        ""Testing empty geometries and collections.""
        geoms = [
            GeometryCollection([]),
            fromstr('GEOMETRYCOLLECTION EMPTY'),
            GeometryCollection(),
            fromstr('POINT EMPTY'),
            Point(),
            fromstr('LINESTRING EMPTY'),
            LineString(),
            fromstr('POLYGON EMPTY'),
            Polygon(),
            fromstr('MULTILINESTRING EMPTY'),
            MultiLineString(),
            fromstr('MULTIPOLYGON EMPTY'),
            MultiPolygon(()),
            MultiPolygon(),
        ]

        if numpy:
            geoms.append(LineString(numpy.array([])))

        for g in geoms:
            self.assertIs(g.empty, True)

            # Testing len() and num_geom.
            if isinstance(g, Polygon):
                self.assertEqual(1, len(g))  # Has one empty linear ring
                self.assertEqual(1, g.num_geom)
                self.assertEqual(0, len(g[0]))
            elif isinstance(g, (Point, LineString)):
                self.assertEqual(1, g.num_geom)
                self.assertEqual(0, len(g))
            else:
                self.assertEqual(0, g.num_geom)
                self.assertEqual(0, len(g))

            # Testing __getitem__ (doesn't work on Point or Polygon)
            if isinstance(g, Point):
                with self.assertRaises(IndexError):
                    g.x
            elif isinstance(g, Polygon):
                lr = g.shell
                self.assertEqual('LINEARRING EMPTY', lr.wkt)
                self.assertEqual(0, len(lr))
                self.assertIs(lr.empty, True)
                with self.assertRaises(IndexError):
                    lr.__getitem__(0)
            else:
                with self.assertRaises(IndexError):
                    g.__getitem__(0)

    def test_collection_dims(self):
        gc = GeometryCollection([])
        self.assertEqual(gc.dims, -1)

        gc = GeometryCollection(Point(0, 0))
        self.assertEqual(gc.dims, 0)

        gc = GeometryCollection(LineString((0, 0), (1, 1)), Point(0, 0))
        self.assertEqual(gc.dims, 1)

        gc = GeometryCollection(LineString((0, 0), (1, 1)), Polygon(((0, 0), (0, 1), (1, 1), (0, 0))), Point(0, 0))
        self.assertEqual(gc.dims, 2)

    def test_collections_of_collections(self):
        ""Testing GeometryCollection handling of other collections.""
        # Creating a GeometryCollection WKT string composed of other
        # collections and polygons.
        coll = [mp.wkt for mp in self.geometries.multipolygons if mp.valid]
        coll.extend(mls.wkt for mls in self.geometries.multilinestrings)
        coll.extend(p.wkt for p in self.geometries.polygons)
        coll.extend(mp.wkt for mp in self.geometries.multipoints)
        gc_wkt = 'GEOMETRYCOLLECTION(%s)' % ','.join(coll)

        # Should construct ok from WKT
        gc1 = GEOSGeometry(gc_wkt)

        # Should also construct ok from individual geometry arguments.
        gc2 = GeometryCollection(*tuple(g for g in gc1))

        # And, they should be equal.
        self.assertEqual(gc1, gc2)

    def test_gdal(self):
        ""Testing `ogr` and `srs` properties.""
        g1 = fromstr('POINT(5 23)')
        self.assertIsInstance(g1.ogr, gdal.OGRGeometry)
        self.assertIsNone(g1.srs)

        g1_3d = fromstr('POINT(5 23 8)')
        self.assertIsInstance(g1_3d.ogr, gdal.OGRGeometry)
        self.assertEqual(g1_3d.ogr.z, 8)

        g2 = fromstr('LINESTRING(0 0, 5 5, 23 23)', srid=4326)
        self.assertIsInstance(g2.ogr, gdal.OGRGeometry)
        self.assertIsInstance(g2.srs, gdal.SpatialReference)
        self.assertEqual(g2.hex, g2.ogr.hex)
        self.assertEqual('WGS 84', g2.srs.name)

    def test_copy(self):
        ""Testing use with the Python `copy` module.""
        import copy
        poly = GEOSGeometry('POLYGON((0 0, 0 23, 23 23, 23 0, 0 0), (5 5, 5 10, 10 10, 10 5, 5 5))')
        cpy1 = copy.copy(poly)
        cpy2 = copy.deepcopy(poly)
        self.assertNotEqual(poly._ptr, cpy1._ptr)
        self.assertNotEqual(poly._ptr, cpy2._ptr)

    def test_transform(self):
        ""Testing `transform` method.""
        orig = GEOSGeometry('POINT (-104.609 38.255)', 4326)
        trans = GEOSGeometry('POINT (992385.4472045 481455.4944650)', 2774)

        # Using a srid, a SpatialReference object, and a CoordTransform object
        # for transformations.
        t1, t2, t3 = orig.clone(), orig.clone(), orig.clone()
        t1.transform(trans.srid)
        t2.transform(gdal.SpatialReference('EPSG:2774'))
        ct = gdal.CoordTransform(gdal.SpatialReference('WGS84'), gdal.SpatialReference(2774))
        t3.transform(ct)

        # Testing use of the `clone` keyword.
        k1 = orig.clone()
        k2 = k1.transform(trans.srid, clone=True)
        self.assertEqual(k1, orig)
        self.assertNotEqual(k1, k2)

        # Different PROJ versions use different transformations, all are
        # correct as having a 1 meter accuracy.
        prec = -1
        for p in (t1, t2, t3, k2):
            self.assertAlmostEqual(trans.x, p.x, prec)
            self.assertAlmostEqual(trans.y, p.y, prec)

    def test_transform_3d(self):
        p3d = GEOSGeometry('POINT (5 23 100)', 4326)
        p3d.transform(2774)
        self.assertAlmostEqual(p3d.z, 100, 3)

    def test_transform_noop(self):
        """""" Testing `transform` method (SRID match) """"""
        # transform() should no-op if source & dest SRIDs match,
        # regardless of whether GDAL is available.
        g = GEOSGeometry('POINT (-104.609 38.255)', 4326)
        gt = g.tuple
        g.transform(4326)
        self.assertEqual(g.tuple, gt)
        self.assertEqual(g.srid, 4326)

        g = GEOSGeometry('POINT (-104.609 38.255)', 4326)
        g1 = g.transform(4326, clone=True)
        self.assertEqual(g1.tuple, g.tuple)
        self.assertEqual(g1.srid, 4326)
        self.assertIsNot(g1, g, ""Clone didn't happen"")

    def test_transform_nosrid(self):
        """""" Testing `transform` method (no SRID or negative SRID) """"""

        g = GEOSGeometry('POINT (-104.609 38.255)', srid=None)
        with self.assertRaises(GEOSException):
            g.transform(2774)

        g = GEOSGeometry('POINT (-104.609 38.255)', srid=None)
        with self.assertRaises(GEOSException):
            g.transform(2774, clone=True)

        g = GEOSGeometry('POINT (-104.609 38.255)', srid=-1)
        with self.assertRaises(GEOSException):
            g.transform(2774)

        g = GEOSGeometry('POINT (-104.609 38.255)', srid=-1)
        with self.assertRaises(GEOSException):
            g.transform(2774, clone=True)

    def test_extent(self):
        ""Testing `extent` method.""
        # The xmin, ymin, xmax, ymax of the MultiPoint should be returned.
        mp = MultiPoint(Point(5, 23), Point(0, 0), Point(10, 50))
        self.assertEqual((0.0, 0.0, 10.0, 50.0), mp.extent)
        pnt = Point(5.23, 17.8)
        # Extent of points is just the point itself repeated.
        self.assertEqual((5.23, 17.8, 5.23, 17.8), pnt.extent)
        # Testing on the 'real world' Polygon.
        poly = fromstr(self.geometries.polygons[3].wkt)
        ring = poly.shell
        x, y = ring.x, ring.y
        xmin, ymin = min(x), min(y)
        xmax, ymax = max(x), max(y)
        self.assertEqual((xmin, ymin, xmax, ymax), poly.extent)

    def test_pickle(self):
        ""Testing pickling and unpickling support.""
        # Creating a list of test geometries for pickling,
        # and setting the SRID on some of them.
        def get_geoms(lst, srid=None):
            return [GEOSGeometry(tg.wkt, srid) for tg in lst]
        tgeoms = get_geoms(self.geometries.points)
        tgeoms.extend(get_geoms(self.geometries.multilinestrings, 4326))
        tgeoms.extend(get_geoms(self.geometries.polygons, 3084))
        tgeoms.extend(get_geoms(self.geometries.multipolygons, 3857))
        tgeoms.append(Point(srid=4326))
        tgeoms.append(Point())
        for geom in tgeoms:
            s1 = pickle.dumps(geom)
            g1 = pickle.loads(s1)
            self.assertEqual(geom, g1)
            self.assertEqual(geom.srid, g1.srid)

    def test_prepared(self):
        ""Testing PreparedGeometry support.""
        # Creating a simple multipolygon and getting a prepared version.
        mpoly = GEOSGeometry('MULTIPOLYGON(((0 0,0 5,5 5,5 0,0 0)),((5 5,5 10,10 10,10 5,5 5)))')
        prep = mpoly.prepared

        # A set of test points.
        pnts = [Point(5, 5), Point(7.5, 7.5), Point(2.5, 7.5)]
        for pnt in pnts:
            # Results should be the same (but faster)
            self.assertEqual(mpoly.contains(pnt), prep.contains(pnt))
            self.assertEqual(mpoly.intersects(pnt), prep.intersects(pnt))
            self.assertEqual(mpoly.covers(pnt), prep.covers(pnt))

        self.assertTrue(prep.crosses(fromstr('LINESTRING(1 1, 15 15)')))
        self.assertTrue(prep.disjoint(Point(-5, -5)))
        poly = Polygon(((-1, -1), (1, 1), (1, 0), (-1, -1)))
        self.assertTrue(prep.overlaps(poly))
        poly = Polygon(((-5, 0), (-5, 5), (0, 5), (-5, 0)))
        self.assertTrue(prep.touches(poly))
        poly = Polygon(((-1, -1), (-1, 11), (11, 11), (11, -1), (-1, -1)))
        self.assertTrue(prep.within(poly))

        # Original geometry deletion should not crash the prepared one (#21662)
        del mpoly
        self.assertTrue(prep.covers(Point(5, 5)))

    def test_line_merge(self):
        ""Testing line merge support""
        ref_geoms = (fromstr('LINESTRING(1 1, 1 1, 3 3)'),
                     fromstr('MULTILINESTRING((1 1, 3 3), (3 3, 4 2))'),
                     )
        ref_merged = (fromstr('LINESTRING(1 1, 3 3)'),
                      fromstr('LINESTRING (1 1, 3 3, 4 2)'),
                      )
        for geom, merged in zip(ref_geoms, ref_merged):
            self.assertEqual(merged, geom.merged)

    def test_valid_reason(self):
        ""Testing IsValidReason support""

        g = GEOSGeometry(""POINT(0 0)"")
        self.assertTrue(g.valid)
        self.assertIsInstance(g.valid_reason, str)
        self.assertEqual(g.valid_reason, ""Valid Geometry"")

        g = GEOSGeometry(""LINESTRING(0 0, 0 0)"")

        self.assertFalse(g.valid)
        self.assertIsInstance(g.valid_reason, str)
        self.assertTrue(g.valid_reason.startswith(""Too few points in geometry component""))

    def test_linearref(self):
        ""Testing linear referencing""

        ls = fromstr('LINESTRING(0 0, 0 10, 10 10, 10 0)')
        mls = fromstr('MULTILINESTRING((0 0, 0 10), (10 0, 10 10))')

        self.assertEqual(ls.project(Point(0, 20)), 10.0)
        self.assertEqual(ls.project(Point(7, 6)), 24)
        self.assertEqual(ls.project_normalized(Point(0, 20)), 1.0 / 3)

        self.assertEqual(ls.interpolate(10), Point(0, 10))
        self.assertEqual(ls.interpolate(24), Point(10, 6))
        self.assertEqual(ls.interpolate_normalized(1.0 / 3), Point(0, 10))

        self.assertEqual(mls.project(Point(0, 20)), 10)
        self.assertEqual(mls.project(Point(7, 6)), 16)

        self.assertEqual(mls.interpolate(9), Point(0, 9))
        self.assertEqual(mls.interpolate(17), Point(10, 7))

    def test_deconstructible(self):
        """"""
        Geometry classes should be deconstructible.
        """"""
        point = Point(4.337844, 50.827537, srid=4326)
        path, args, kwargs = point.deconstruct()
        self.assertEqual(path, 'django.contrib.gis.geos.point.Point')
        self.assertEqual(args, (4.337844, 50.827537))
        self.assertEqual(kwargs, {'srid': 4326})

        ls = LineString(((0, 0), (1, 1)))
        path, args, kwargs = ls.deconstruct()
        self.assertEqual(path, 'django.contrib.gis.geos.linestring.LineString')
        self.assertEqual(args, (((0, 0), (1, 1)),))
        self.assertEqual(kwargs, {})

        ls2 = LineString([Point(0, 0), Point(1, 1)], srid=4326)
        path, args, kwargs = ls2.deconstruct()
        self.assertEqual(path, 'django.contrib.gis.geos.linestring.LineString')
        self.assertEqual(args, ([Point(0, 0), Point(1, 1)],))
        self.assertEqual(kwargs, {'srid': 4326})

        ext_coords = ((0, 0), (0, 1), (1, 1), (1, 0), (0, 0))
        int_coords = ((0.4, 0.4), (0.4, 0.6), (0.6, 0.6), (0.6, 0.4), (0.4, 0.4))
        poly = Polygon(ext_coords, int_coords)
        path, args, kwargs = poly.deconstruct()
        self.assertEqual(path, 'django.contrib.gis.geos.polygon.Polygon')
        self.assertEqual(args, (ext_coords, int_coords))
        self.assertEqual(kwargs, {})

        lr = LinearRing((0, 0), (0, 1), (1, 1), (0, 0))
        path, args, kwargs = lr.deconstruct()
        self.assertEqual(path, 'django.contrib.gis.geos.linestring.LinearRing')
        self.assertEqual(args, ((0, 0), (0, 1), (1, 1), (0, 0)))
        self.assertEqual(kwargs, {})

        mp = MultiPoint(Point(0, 0), Point(1, 1))
        path, args, kwargs = mp.deconstruct()
        self.assertEqual(path, 'django.contrib.gis.geos.collections.MultiPoint')
        self.assertEqual(args, (Point(0, 0), Point(1, 1)))
        self.assertEqual(kwargs, {})

        ls1 = LineString((0, 0), (1, 1))
        ls2 = LineString((2, 2), (3, 3))
        mls = MultiLineString(ls1, ls2)
        path, args, kwargs = mls.deconstruct()
        self.assertEqual(path, 'django.contrib.gis.geos.collections.MultiLineString')
        self.assertEqual(args, (ls1, ls2))
        self.assertEqual(kwargs, {})

        p1 = Polygon(((0, 0), (0, 1), (1, 1), (0, 0)))
        p2 = Polygon(((1, 1), (1, 2), (2, 2), (1, 1)))
        mp = MultiPolygon(p1, p2)
        path, args, kwargs = mp.deconstruct()
        self.assertEqual(path, 'django.contrib.gis.geos.collections.MultiPolygon')
        self.assertEqual(args, (p1, p2))
        self.assertEqual(kwargs, {})

        poly = Polygon(((0, 0), (0, 1), (1, 1), (0, 0)))
        gc = GeometryCollection(Point(0, 0), MultiPoint(Point(0, 0), Point(1, 1)), poly)
        path, args, kwargs = gc.deconstruct()
        self.assertEqual(path, 'django.contrib.gis.geos.collections.GeometryCollection')
        self.assertEqual(args, (Point(0, 0), MultiPoint(Point(0, 0), Point(1, 1)), poly))
        self.assertEqual(kwargs, {})

    def test_subclassing(self):
        """"""
        GEOSGeometry subclass may itself be subclassed without being forced-cast
        to the parent class during `__init__`.
        """"""
        class ExtendedPolygon(Polygon):
            def __init__(self, *args, data=0, **kwargs):
                super().__init__(*args, **kwargs)
                self._data = data

            def __str__(self):
                return ""EXT_POLYGON - data: %d - %s"" % (self._data, self.wkt)

        ext_poly = ExtendedPolygon(((0, 0), (0, 1), (1, 1), (0, 0)), data=3)
        self.assertEqual(type(ext_poly), ExtendedPolygon)
        # ExtendedPolygon.__str__ should be called (instead of Polygon.__str__).
        self.assertEqual(str(ext_poly), ""EXT_POLYGON - data: 3 - POLYGON ((0 0, 0 1, 1 1, 0 0))"")
        self.assertJSONEqual(
            ext_poly.json,
            '{""coordinates"": [[[0, 0], [0, 1], [1, 1], [0, 0]]], ""type"": ""Polygon""}',
        )

    def test_geos_version_tuple(self):
        versions = (
            (b'3.0.0rc4-CAPI-1.3.3', (3, 0, 0)),
            (b'3.0.0-CAPI-1.4.1', (3, 0, 0)),
            (b'3.4.0dev-CAPI-1.8.0', (3, 4, 0)),
            (b'3.4.0dev-CAPI-1.8.0 r0', (3, 4, 0)),
            (b'3.6.2-CAPI-1.10.2 4d2925d6', (3, 6, 2)),
        )
        for version_string, version_tuple in versions:
            with self.subTest(version_string=version_string):
                with mock.patch('django.contrib.gis.geos.libgeos.geos_version', lambda: version_string):
                    self.assertEqual(geos_version_tuple(), version_tuple)

    def test_from_gml(self):
        self.assertEqual(
            GEOSGeometry('POINT(0 0)'),
            GEOSGeometry.from_gml(
                '<gml:Point gml:id=""p21"" srsName=""http://www.opengis.net/def/crs/EPSG/0/4326"">'
                '    <gml:pos srsDimension=""2"">0 0</gml:pos>'
                '</gml:Point>'
            ),
        )

    def test_from_ewkt(self):
        self.assertEqual(GEOSGeometry.from_ewkt('SRID=1;POINT(1 1)'), Point(1, 1, srid=1))
        self.assertEqual(GEOSGeometry.from_ewkt('POINT(1 1)'), Point(1, 1))

    def test_from_ewkt_empty_string(self):
        msg = 'Expected WKT but got an empty string.'
        with self.assertRaisesMessage(ValueError, msg):
            GEOSGeometry.from_ewkt('')
        with self.assertRaisesMessage(ValueError, msg):
            GEOSGeometry.from_ewkt('SRID=1;')

    def test_from_ewkt_invalid_srid(self):
        msg = 'EWKT has invalid SRID part.'
        with self.assertRaisesMessage(ValueError, msg):
            GEOSGeometry.from_ewkt('SRUD=1;POINT(1 1)')
        with self.assertRaisesMessage(ValueError, msg):
            GEOSGeometry.from_ewkt('SRID=WGS84;POINT(1 1)')

    def test_fromstr_scientific_wkt(self):
        self.assertEqual(GEOSGeometry('POINT(1.0e-1 1.0e+1)'), Point(.1, 10))

    def test_normalize(self):
        g = MultiPoint(Point(0, 0), Point(2, 2), Point(1, 1))
        self.assertIsNone(g.normalize())
        self.assertTrue(g.equals_exact(MultiPoint(Point(2, 2), Point(1, 1), Point(0, 0))))

    @skipIf(geos_version_tuple() < (3, 8), 'GEOS >= 3.8.0 is required')
    def test_make_valid(self):
        poly = GEOSGeometry('POLYGON((0 0, 0 23, 23 0, 23 23, 0 0))')
        self.assertIs(poly.valid, False)
        valid_poly = poly.make_valid()
        self.assertIs(valid_poly.valid, True)
        self.assertNotEqual(valid_poly, poly)

        valid_poly2 = valid_poly.make_valid()
        self.assertIs(valid_poly2.valid, True)
        self.assertEqual(valid_poly, valid_poly2)

    @mock.patch('django.contrib.gis.geos.libgeos.geos_version', lambda: b'3.7.3')
    def test_make_valid_geos_version(self):
        msg = 'GEOSGeometry.make_valid() requires GEOS >= 3.8.0.'
        poly = GEOSGeometry('POLYGON((0 0, 0 23, 23 0, 23 23, 0 0))')
        with self.assertRaisesMessage(GEOSException, msg):
            poly.make_valid()

    def test_empty_point(self):
        p = Point(srid=4326)
        self.assertEqual(p.ogr.ewkt, p.ewkt)

        self.assertEqual(p.transform(2774, clone=True), Point(srid=2774))
        p.transform(2774)
        self.assertEqual(p, Point(srid=2774))

    def test_linestring_iter(self):
        ls = LineString((0, 0), (1, 1))
        it = iter(ls)
        # Step into CoordSeq iterator.
        next(it)
        ls[:] = []
        with self.assertRaises(IndexError):
            next(it)",1,587 2000 40 2001 44 2002 41 58 612 2003 40 2004 41 58 362 664 2005 696 2004 46 2006 46 2007 58 2008 61 2009 40 2005 46 2010 41 688 2008 46 2011 58 2004 46 2012 40 2005 46 2013 44 2008 46 2010 41 612 2014 40 2004 41 58 362 664 2005 696 2004 46 2006 46 2015 58 2008 61 2009 40 2005 46 2010 41 2004 46 2012 40 2005 46 681 44 2008 46 681 46 2016 40 41 41 612 2017 40 2004 41 58 362 330 2018 61 362 2019 61 362 330 2020 61 362 330 2021 61 362 2022 61 2023 40 1500 44 1501 44 2024 61 1505 41 2025 61 2023 40 1500 44 1501 44 1502 44 2024 61 1505 41 330 2004 46 2012 40 2018 44 2022 46 681 41 2004 46 2012 40 2019 44 2025 46 681 41 330 330 330 2004 46 2012 40 2020 44 2022 46 2026 41 2004 46 2012 40 2021 44 2025 46 2026 41 2004 46 2027 40 2028 40 2021 41 46 2011 44 515 41 330 2004 46 2012 40 734 40 2029 40 2020 41 41 44 2022 46 2030 41 2004 46 2012 40 734 40 2029 40 2021 41 41 44 2025 46 2030 41 330 2004 46 2012 40 1505 44 2028 40 2020 41 46 2024 41 612 2031 40 2004 41 58 362 664 2032 696 2004 46 2006 46 2007 58 2008 61 2009 40 2032 46 2010 41 2033 61 673 40 2032 44 362 44 443 41 688 2033 58 2004 46 2012 40 2033 44 2008 46 2033 41 612 2034 40 2004 41 58 362 330 664 2035 696 2004 46 2006 46 2036 58 871 2004 46 2037 40 40 2038 44 2039 41 41 58 2009 40 2035 46 2010 41 330 871 2004 46 2037 40 2038 41 58 2028 40 734 40 362 41 41 587 2040 58 767 330 871 2004 46 2037 40 2041 41 58 2028 40 2040 40 41 41 330 871 2004 46 2037 40 2041 41 58 2028 40 470 41 612 2042 40 2004 41 58 362 664 2005 696 2004 46 2006 46 2015 58 2008 61 2009 40 2005 46 2010 41 2043 61 2008 46 2043 2004 46 2012 40 2043 46 681 40 41 46 2044 40 41 44 2005 46 681 41 612 2045 40 2004 41 58 362 664 2005 696 2004 46 2006 46 2015 58 2046 61 2028 40 2005 46 681 41 330 2047 61 2009 40 2005 46 2010 41 2004 46 2012 40 2047 46 2010 44 2046 46 2010 41 612 2048 40 2004 41 58 362 664 2005 696 2004 46 2006 46 2015 58 2043 61 734 40 576 46 2049 40 2005 46 681 41 41 2046 61 2028 40 2043 41 330 2047 61 2009 40 2005 46 2010 41 2004 46 2012 40 2047 46 2010 44 2046 46 2010 41 612 2050 40 2004 41 58 362 2051 61 40 45 1501 44 1506 41 664 2024 696 2051 58 664 2052 696 2004 46 2006 46 2053 58 2013 61 362 37 40 2024 44 2052 46 2010 41 2054 61 2009 40 2013 41 2004 46 2012 40 2024 44 2054 46 2024 41 2004 46 2012 40 2024 44 2054 46 2055 46 2024 41 2004 46 2012 40 2024 44 2009 40 2054 46 2013 41 46 2024 41 330 612 2056 40 2004 41 58 362 664 2005 696 2004 46 2006 46 2057 58 2008 61 2028 40 2005 46 2010 41 688 750 678 40 2005 44 362 41 58 330 2004 46 2012 40 2058 46 2059 40 2005 46 2058 41 44 2058 46 2059 40 2008 46 2058 41 41 2004 46 2012 40 2058 46 2059 40 2005 46 2058 41 44 2058 46 2059 40 2008 46 2060 41 41 2004 46 2012 40 2028 40 2005 46 2010 44 1505 41 44 2028 40 2008 46 2058 41 41 612 2061 40 2004 41 58 2062 61 123 362 58 362 44 362 58 91 1502 44 1503 93 44 362 58 123 362 58 362 44 362 58 123 362 58 362 125 125 125 2004 46 2012 40 2028 40 2058 46 2063 40 2062 41 41 44 2023 40 1502 44 1503 44 2024 61 1505 41 41 612 2064 40 2004 41 58 362 2065 61 2028 40 362 41 2066 61 2067 40 41 2066 46 2068 40 2065 46 2010 46 2069 40 41 41 2070 61 2067 40 41 2070 46 2068 40 576 40 2065 46 2043 41 41 330 330 664 2071 696 40 2066 44 2070 41 58 2071 46 2072 40 1500 41 2073 61 2074 40 2071 41 2004 46 2012 40 2065 44 2073 41 612 2075 40 2004 41 58 362 2052 61 2009 40 362 41 2004 46 2012 40 2052 44 2052 46 2010 41 2004 46 2076 40 2052 44 362 41 2077 61 2009 40 362 41 2004 46 2012 40 2077 44 2077 46 2010 41 2004 46 2076 40 2052 44 362 41 2004 46 2012 40 2052 44 362 41 330 330 664 2005 696 40 2052 44 2077 41 58 2004 46 2078 40 2005 41 2004 46 2076 40 2005 44 123 362 58 362 125 41 2004 46 2079 40 2005 44 443 41 612 2080 40 2004 41 58 2081 61 2023 40 1502 44 1503 41 2082 61 2023 40 1502 44 1503 44 2024 61 1505 41 2083 61 2023 40 1502 44 1503 44 2024 61 1506 41 2084 61 2085 40 2081 44 2024 61 1505 41 2086 61 2085 40 2082 41 2087 61 2085 40 2083 41 2004 46 2076 40 679 40 2081 41 44 679 40 2082 41 41 2004 46 2076 40 679 40 2081 41 44 679 40 2083 41 41 2004 46 2076 40 679 40 2082 41 44 679 40 2083 41 41 2004 46 2076 40 679 40 2084 41 44 679 40 2086 41 41 2004 46 2012 40 679 40 2086 41 44 679 40 2087 41 41 2004 46 2076 40 679 40 2084 41 44 679 40 2081 41 41 2004 46 2076 40 679 40 2086 41 44 679 40 2082 41 41 2004 46 2076 40 679 40 2087 41 44 679 40 2083 41 41 612 2088 40 2004 41 58 362 2089 61 2023 40 1502 44 1503 41 2090 61 2023 40 1502 44 1503 44 2024 61 1505 41 2091 61 2023 40 1502 44 1503 44 2024 61 1506 41 330 2004 46 2076 40 2089 44 2090 41 2004 46 2076 40 2090 44 2091 41 330 2004 46 2076 40 2089 44 2090 46 2013 41 2004 46 2076 40 2090 44 2089 46 2013 41 2004 46 2076 40 2090 44 2091 46 2013 41 330 2004 46 2012 40 2091 44 2091 41 2004 46 2012 40 2091 44 2091 46 2013 41 330 2004 46 2076 40 2091 44 2091 46 2010 41 330 2004 46 2012 40 2089 44 362 41 2004 46 2076 40 2090 44 362 41 612 2092 40 2004 41 58 362 2093 61 2009 40 362 41 664 2052 696 2004 46 2006 46 2094 58 330 2073 61 2009 40 2052 46 2010 41 2004 46 2012 40 2073 46 2095 44 362 41 2004 46 2012 40 2073 46 2096 44 1500 41 2004 46 2012 40 2073 46 2097 44 1500 41 2004 46 2012 40 2052 46 2098 44 2073 46 2098 41 2004 46 2012 40 2052 46 2099 44 2073 46 2099 41 2004 46 2012 40 2073 44 2009 40 2052 46 2010 41 41 2004 46 2027 40 2073 323 2093 44 443 41 330 330 2004 46 2100 40 2052 46 2098 44 2073 46 831 91 1500 93 44 1502 41 2004 46 2100 40 2052 46 2099 44 2073 46 831 91 1501 93 44 1502 41 330 688 678 40 2052 44 362 41 58 2004 46 2027 40 2073 46 2011 44 515 41 2004 46 2012 40 2052 46 2101 44 2073 46 2101 41 2004 46 2012 40 2052 46 2101 44 2073 46 831 91 1502 93 44 1502 41 2102 61 40 2052 46 2098 44 2052 46 2099 44 2052 46 2101 41 2103 61 40 1502 44 1502 44 1502 41 2104 61 40 1502 44 1502 44 1502 41 630 58 2004 46 2027 40 2073 46 2011 44 443 41 2004 46 2105 40 2073 46 2101 41 2102 61 40 2052 46 2098 44 2052 46 2099 41 2103 61 40 1502 44 1502 41 2104 61 40 1502 44 1502 41 330 2004 46 2012 40 2052 46 2106 44 2073 46 2106 46 831 41 330 2107 61 2023 40 2102 41 330 2108 61 2023 40 42 2102 41 330 2004 46 2012 40 2073 44 2107 41 2004 46 2012 40 2073 44 2108 41 330 2073 46 2099 61 1502 2073 46 2098 61 1502 2004 46 2012 40 1502 44 2073 46 2099 41 2004 46 2012 40 1502 44 2073 46 2098 41 330 2073 46 831 61 2103 2004 46 2012 40 2103 44 2073 46 831 41 2073 46 2109 61 2104 2004 46 2012 40 2104 44 2073 46 2109 41 2093 61 2073 330 612 2110 40 2004 41 58 2111 61 2028 40 362 44 1505 41 2004 46 2012 40 2111 46 2024 44 1505 41 2111 46 2112 40 41 2004 46 2012 40 2111 46 2013 44 362 41 612 2113 40 2004 41 58 362 664 2114 696 2004 46 2006 46 2115 58 2116 61 2009 40 2114 46 2010 41 2004 46 2012 40 2116 46 2095 44 362 41 2004 46 2012 40 2116 46 2096 44 1502 41 2004 46 2012 40 2116 46 2097 44 1500 41 2004 46 2100 40 2114 46 2106 91 1500 93 44 2116 46 2106 46 831 91 1500 93 44 1502 41 2004 46 2100 40 2114 46 2106 91 1501 93 44 2116 46 2106 46 831 91 1501 93 44 1502 41 871 2004 46 2037 40 2117 41 58 2116 46 2118 40 720 40 2116 41 41 2004 46 2012 40 2114 46 2106 44 2116 46 2106 46 831 41 2004 46 2012 40 2114 46 2109 44 831 40 2119 46 831 664 2119 696 2116 41 41 664 2052 696 2116 58 2004 46 2012 40 2052 46 2095 44 362 41 2004 46 2012 40 2052 46 2096 44 1500 41 2004 46 2027 40 2052 46 2120 44 443 41 2004 46 2027 40 2052 46 2121 44 515 41 612 2122 40 2004 41 58 362 2093 61 2009 40 362 41 664 2123 696 2004 46 2006 46 2124 58 2077 61 2009 40 2123 46 2010 41 2004 46 2012 40 2077 46 2095 44 362 41 2004 46 2012 40 2077 46 2096 44 1501 41 2004 46 2012 40 2077 46 2097 44 1501 41 2004 46 2027 40 2077 46 2120 44 443 41 2004 46 2027 40 2077 46 2125 44 443 41 688 678 40 2123 44 362 41 58 2004 46 2012 40 2123 46 2106 44 2077 46 2106 46 831 41 688 678 40 2123 44 362 41 58 2004 46 2012 40 2123 46 2126 44 2077 46 831 41 2004 46 2012 40 2077 44 2009 40 2123 46 2010 41 41 2004 46 2027 40 2077 323 2093 44 443 41 330 871 2004 46 2037 40 2117 41 58 2077 46 2118 40 720 40 2077 41 41 2093 61 2077 330 2004 46 2012 40 2077 44 2127 40 2077 46 831 41 41 330 2004 46 2012 40 2077 44 2127 40 42 2077 46 831 41 41 330 2004 46 2012 40 2077 44 2127 40 91 723 40 2126 41 664 2126 696 2077 46 831 93 41 41 330 330 2004 46 2012 40 2077 46 2010 44 2127 40 42 831 40 2023 40 2126 41 664 2126 696 2077 46 831 41 41 46 2010 41 688 2128 58 2004 46 2012 40 2077 44 2127 40 2128 46 2129 40 2077 46 831 41 41 41 330 871 2004 46 2130 40 2041 44 362 41 58 2127 40 40 1500 44 1500 41 41 871 2004 46 2130 40 2039 44 362 41 58 2127 40 91 40 1500 44 1500 41 93 41 688 2128 58 871 2004 46 2130 40 2039 44 362 41 58 2127 40 2128 46 2129 40 91 40 1500 44 1500 41 93 41 41 871 2131 46 2132 40 362 44 443 41 58 871 2004 46 2130 40 2041 44 362 41 58 2127 40 362 41 330 2004 46 2012 40 723 40 2127 40 40 1500 44 1500 41 44 40 1501 44 1501 41 44 40 1502 44 1502 41 41 41 44 91 40 1500 44 1500 41 44 40 1501 44 1501 41 44 40 1502 44 1502 41 93 41 612 2133 40 2004 41 58 2123 61 2028 40 362 44 1505 41 2004 46 2012 40 2123 46 2024 44 1505 41 2123 46 2112 40 41 2004 46 2012 40 2123 46 2013 44 362 41 612 2134 40 2004 41 58 2135 61 2136 40 40 1500 44 1500 41 44 40 1501 44 1500 41 44 40 1500 44 1501 41 44 40 1500 44 1500 41 41 2004 46 2027 40 2135 46 2137 44 515 41 2135 46 2112 40 41 2004 46 2027 40 2135 46 2137 44 443 41 2138 61 362 871 2004 46 2130 40 2039 44 2138 41 58 2136 40 41 46 2137 64 2139 40 2140 40 41 60 40 1502 44 1502 41 44 362 41 612 2141 40 2004 41 58 2004 46 2134 40 41 64 2139 40 2140 40 41 60 40 1502 44 1502 41 44 362 41 612 2142 40 2004 41 58 871 2131 46 2132 40 362 41 552 2143 58 2143 46 2144 61 1500 2143 46 2145 61 362 2138 61 362 871 2004 46 2130 40 2038 44 2138 41 58 2136 40 40 1500 44 1500 41 44 40 1501 44 1500 41 44 40 1500 44 1501 41 44 40 1500 44 1500 41 41 46 2137 64 2131 46 2132 40 362 44 719 58 362 41 612 2146 40 2004 41 58 2004 46 2134 40 41 612 2147 40 2004 41 58 362 2093 61 2009 40 362 41 664 2123 696 2004 46 2006 46 2148 58 2149 61 2009 40 2123 46 2010 41 2004 46 2012 40 2149 46 2095 44 362 41 2004 46 2012 40 2149 46 2096 44 1502 41 2004 46 2012 40 2149 46 2097 44 1501 41 2004 46 2100 40 2123 46 2106 91 1500 93 44 2149 46 2106 46 2098 44 1502 41 2004 46 2100 40 2123 46 2106 91 1501 93 44 2149 46 2106 46 2099 44 1502 41 2004 46 2012 40 2149 44 2009 40 2123 46 2010 41 41 2004 46 2027 40 2149 323 2093 44 443 41 330 2093 61 2149 664 2077 696 2149 58 2004 46 2012 40 2077 46 2095 44 362 41 2004 46 2012 40 2077 46 2096 44 1501 41 2004 46 2027 40 2077 46 2120 44 443 41 871 2004 46 2037 40 2117 41 58 2149 46 2118 40 720 40 2149 41 41 2004 46 2012 40 2149 46 2010 44 2150 40 42 831 40 2151 46 2152 40 41 664 2151 696 2149 41 41 46 2010 41 2004 46 2012 40 2149 44 2150 40 42 831 40 2127 40 2151 46 831 41 664 2151 696 2149 41 41 41 612 2153 40 2004 41 58 362 664 2154 696 2004 46 2006 46 2155 58 2135 61 2009 40 2154 46 2010 41 2004 46 2012 40 2135 46 2095 44 362 41 2004 46 2012 40 2135 46 2096 44 1502 41 2004 46 2012 40 2135 46 2097 44 1501 41 2004 46 2012 40 2154 46 2156 44 720 40 2135 41 41 2004 46 2027 40 2135 46 2121 44 515 41 2004 46 2027 40 2135 46 2120 44 443 41 330 2004 46 2012 40 2135 44 2136 40 2135 46 831 41 41 2004 46 2012 40 2135 44 2136 40 42 2135 46 831 41 41 2004 46 2012 40 2135 44 2136 40 91 723 40 2126 41 664 2126 696 2135 46 831 93 41 41 688 2128 58 2004 46 2012 40 2135 44 2136 40 2128 46 2129 40 2135 46 831 41 41 41 871 2004 46 2130 40 2039 44 362 41 58 2136 40 40 1500 44 1500 41 44 40 1501 44 1501 41 44 40 1500 44 1500 41 41 871 2004 46 2130 40 2039 44 362 41 58 2136 40 91 40 1500 44 1500 41 93 41 688 2128 58 871 2004 46 2130 40 2039 44 362 41 58 2136 40 2128 46 2129 40 91 40 1500 44 1500 41 93 41 41 612 2157 40 2004 41 58 2004 46 2158 40 2136 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1501 41 44 40 1500 44 1500 41 41 46 2058 44 362 44 41 612 2159 40 2004 41 58 362 2160 61 40 45 1504 44 45 1503 44 1504 44 1503 41 2052 61 2161 46 2162 40 2160 41 2004 46 2012 40 2160 44 2052 46 2163 41 330 2098 61 1502 2160 61 40 1500 44 1500 44 1501 44 2098 41 2052 61 2161 46 2162 40 2160 41 2099 61 2052 46 2163 91 45 1501 93 2004 46 2012 40 666 40 2098 44 362 41 44 666 40 2099 44 362 41 41 612 2164 40 2004 41 58 362 2093 61 2009 40 362 41 664 2052 696 2004 46 2006 46 2053 58 330 2054 61 2009 40 2052 46 2010 41 2004 46 2012 40 2054 46 2095 44 362 41 2004 46 2012 40 2054 46 2096 44 1502 41 2004 46 2012 40 2054 46 2097 44 1502 41 2004 46 2027 40 2054 46 2120 44 443 41 2004 46 2027 40 2054 46 2125 44 443 41 2004 46 2012 40 2052 46 2165 44 2054 46 2166 41 2004 46 2012 40 2052 46 2165 43 1501 44 720 40 2054 41 41 330 2004 46 2012 40 2052 46 2156 44 2054 46 2167 41 330 2004 46 2100 40 2052 46 2168 44 2054 46 2168 44 1502 41 2004 46 2100 40 2052 46 2106 91 1500 93 44 2054 46 2106 46 831 91 1500 93 44 1502 41 2004 46 2100 40 2052 46 2106 91 1501 93 44 2054 46 2106 46 831 91 1501 93 44 1502 41 330 2004 46 2012 40 2054 44 2009 40 2052 46 2010 41 41 330 2004 46 2027 40 2054 323 2093 44 443 41 330 2004 46 2027 40 2054 340 2093 44 515 41 330 330 2125 61 2054 46 2169 2004 46 2012 40 2125 46 2095 44 362 41 2004 46 2012 40 2125 46 2096 44 1502 41 688 2052 46 2170 58 2004 46 2012 40 2052 46 2170 44 2125 46 831 41 2004 46 2012 40 2052 46 2170 44 2054 91 1500 93 46 831 41 330 330 871 2004 46 2037 40 2117 41 58 2054 46 2118 40 720 40 2054 41 41 871 2004 46 2037 40 2117 41 58 2054 46 2171 40 720 40 2054 41 44 443 41 871 2004 46 2037 40 2117 41 58 2054 46 2118 40 45 1501 42 720 40 2054 41 45 1501 41 330 664 2172 696 2054 58 2004 46 2012 40 2172 46 2095 44 362 41 2004 46 2012 40 2172 46 2096 44 1502 41 330 871 2004 46 2037 40 2041 41 58 2161 40 1500 44 91 1501 44 1502 44 1502 93 41 871 2004 46 2037 40 2041 41 58 2161 40 362 41 330 2173 44 42 2174 61 2054 2004 46 2012 40 2054 44 2161 40 2173 44 2174 41 41 330 2175 61 831 40 2172 46 831 664 2172 696 2054 41 2004 46 2012 40 2054 44 2161 40 42 2175 41 41 330 2004 46 2012 40 2054 46 2010 44 2161 40 42 831 40 2172 664 2172 696 2054 41 41 46 2010 41 2004 46 2012 40 2054 46 2010 44 2161 40 42 831 40 2136 40 2172 46 831 41 664 2172 696 2054 41 41 46 2010 41 612 2176 40 2004 41 58 330 2177 61 2178 40 41 2179 61 2177 46 2180 40 362 41 2053 61 91 2009 40 2052 46 2010 41 664 2052 696 2004 46 2006 46 2181 91 58 1502 93 93 2182 61 2179 46 2183 40 2184 40 123 362 58 2053 125 41 41 2004 46 2185 40 362 44 2182 41 612 2186 40 2004 41 58 2090 61 2161 40 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1501 41 44 40 1501 44 1500 41 44 40 1500 44 1500 41 41 41 2091 61 2161 40 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1500 41 44 40 1500 44 1500 41 41 41 2004 46 2187 40 2090 44 2091 41 2004 46 2188 40 2091 44 2090 41 2189 61 2161 40 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1501 41 44 40 1502 44 1500 41 44 40 1500 44 1500 41 41 41 2190 61 2161 40 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1502 44 1502 41 44 40 1501 44 1500 41 44 40 1500 44 1500 41 41 41 2004 46 2187 40 2190 44 2189 41 2004 46 2188 40 2189 44 2190 41 612 2191 40 2004 41 58 362 2009 40 362 41 664 2114 696 2004 46 2006 46 2181 58 2192 61 2009 40 2114 46 2010 41 2004 46 2012 40 2192 46 2095 44 362 41 2004 46 2012 40 2192 46 2096 44 1502 41 2004 46 2012 40 2192 46 2097 44 1502 41 2004 46 2012 40 2114 46 2121 44 2192 46 2121 41 688 2114 46 2121 58 2004 46 2012 40 2114 46 2193 44 2192 46 2193 41 2004 46 2012 40 2114 46 2156 44 2192 46 2194 41 2004 46 2012 40 2114 46 2193 44 720 40 2192 41 41 871 2004 46 2037 40 2117 41 58 2192 46 2118 40 720 40 2192 41 41 664 2052 696 2192 58 2004 46 2012 40 2052 46 2095 44 362 41 2004 46 2012 40 2052 46 2096 44 1502 41 2004 46 2027 40 2052 46 2121 44 515 41 2004 46 2012 40 2192 46 2010 44 2195 40 42 831 40 2054 46 2152 40 41 664 2054 696 2192 41 41 46 2010 41 612 2196 40 2004 41 58 362 330 330 330 2054 61 2009 40 2004 46 2006 46 2053 91 1501 93 46 2010 41 2197 61 2054 91 1500 93 2198 61 2054 91 1501 93 330 616 2197 616 2198 2197 61 2054 91 1500 93 2198 61 2054 91 1501 93 330 616 2054 330 813 40 2197 41 813 40 2198 41 612 2199 40 2004 41 58 362 664 2052 696 2004 46 2006 46 2053 58 688 2052 46 2170 58 330 2054 61 2009 40 2052 46 2010 41 2200 61 2054 46 2169 46 2201 2004 46 2012 40 2052 46 2170 44 2200 46 831 41 330 2004 46 2012 40 720 40 2052 46 2170 41 44 720 40 2200 41 41 330 330 664 2202 696 779 40 720 40 2052 46 2170 41 41 58 2203 61 2052 46 2170 91 2202 93 330 2204 61 2200 91 2202 93 330 2004 46 2012 40 2203 44 2204 41 330 688 720 40 2203 41 323 1502 58 2205 61 40 1502 44 1503 41 630 58 2205 61 40 1502 44 1503 44 1502 41 2200 91 2202 93 61 2205 330 664 2206 696 779 40 720 40 2205 41 41 58 2200 91 2202 93 61 2205 2004 46 2012 40 2205 91 2206 93 44 2200 91 2202 93 91 2206 93 41 612 2207 40 2004 41 58 362 2005 61 2009 40 362 41 871 2004 46 2037 40 2038 41 58 2005 46 2208 40 1500 44 362 41 664 2209 696 2004 46 2006 46 2210 58 2211 61 2009 40 2209 46 2212 41 2213 61 2009 40 2209 46 2214 41 2004 46 2012 40 2209 46 2215 44 2211 46 2208 40 2213 44 2209 46 2216 41 41 2004 46 2012 40 2209 46 2216 44 2211 46 2217 40 2213 41 41 612 2218 40 2004 41 58 362 664 2202 696 779 40 720 40 2004 46 2006 46 2219 41 41 58 2211 61 2009 40 2004 46 2006 46 2219 91 2202 93 46 2212 41 2213 61 2009 40 2004 46 2006 46 2219 91 2202 93 46 2214 41 2220 61 2009 40 2004 46 2006 46 2221 91 2202 93 46 2010 41 2004 46 2027 40 2211 46 2222 40 2213 41 44 515 41 2223 61 2211 46 2224 40 2213 41 2004 46 2225 40 2220 46 2226 40 2223 41 41 2004 46 2225 40 2220 46 2226 40 2211 38 2213 41 41 330 2211 301 2213 330 2004 46 2225 40 2220 46 2226 40 2211 41 41 612 2227 40 2004 41 58 362 664 2202 696 779 40 720 40 2004 46 2006 46 2219 41 41 58 2211 61 2009 40 2004 46 2006 46 2219 91 2202 93 46 2212 41 2213 61 2009 40 2004 46 2006 46 2219 91 2202 93 46 2214 41 2228 61 2009 40 2004 46 2006 46 2229 91 2202 93 46 2010 41 2230 61 2211 46 2231 40 2213 41 2004 46 2225 40 2228 46 2226 40 2230 41 41 2004 46 2225 40 2228 46 2226 40 2211 124 2213 41 41 330 2211 347 2213 330 2004 46 2225 40 2228 46 2226 40 2211 41 41 612 2232 40 2004 41 58 362 664 2202 696 779 40 720 40 2004 46 2006 46 2219 41 41 58 2211 61 2009 40 2004 46 2006 46 2219 91 2202 93 46 2212 41 2213 61 2009 40 2004 46 2006 46 2219 91 2202 93 46 2214 41 2228 61 2009 40 2004 46 2006 46 2229 91 2202 93 46 2010 41 2230 61 2233 40 2211 44 2213 41 46 2234 2004 46 2225 40 2228 46 2226 40 2230 41 41 612 2235 40 2004 41 58 362 664 2202 696 779 40 720 40 2004 46 2006 46 2219 41 41 58 2211 61 2009 40 2004 46 2006 46 2219 91 2202 93 46 2212 41 2213 61 2009 40 2004 46 2006 46 2219 91 2202 93 46 2214 41 2236 61 2009 40 2004 46 2006 46 2237 91 2202 93 46 2010 41 2238 61 2211 46 2239 40 2213 41 2004 46 2225 40 2236 46 2226 40 2238 41 41 2004 46 2225 40 2236 46 2226 40 2211 45 2213 41 41 330 2211 337 2213 330 2004 46 2225 40 2236 46 2226 40 2211 41 41 612 2240 40 2004 41 58 362 664 2202 696 779 40 720 40 2004 46 2006 46 2219 41 41 58 2211 61 2009 40 2004 46 2006 46 2219 91 2202 93 46 2212 41 2213 61 2009 40 2004 46 2006 46 2219 91 2202 93 46 2214 41 2236 61 2009 40 2004 46 2006 46 2241 91 2202 93 46 2010 41 2238 61 2211 46 2242 40 2213 41 2004 46 2225 40 2236 46 2226 40 2238 41 41 2004 46 2225 40 2236 46 2226 40 2211 94 2213 41 41 330 2211 366 2213 330 2004 46 2225 40 2236 46 2226 40 2211 41 41 612 2243 40 2004 41 58 2244 61 2004 46 2006 46 2245 91 1500 93 2005 61 2009 40 2244 46 2010 41 330 871 2004 46 2037 40 2246 46 2247 41 58 2005 46 2248 40 2244 46 2249 44 2250 61 1502 41 2004 46 2251 40 2004 46 2006 46 2245 44 362 41 612 2252 40 2004 41 58 2244 61 2004 46 2006 46 2253 91 1500 93 2005 61 2009 40 2244 46 2010 41 330 871 2004 46 2037 40 2246 46 2247 41 58 2005 46 2254 40 2244 46 2249 44 2250 61 1502 41 330 871 2004 46 2037 40 2246 46 2247 41 58 2005 46 2254 40 2244 46 2249 44 2255 61 1502 41 330 871 2004 46 2037 40 2038 41 58 2005 46 2254 40 2244 46 2249 44 2255 61 1503 41 330 871 2004 46 2037 40 2246 46 2247 41 58 2005 46 2254 40 2244 46 2249 44 2256 61 1502 41 330 871 2004 46 2037 40 2038 41 58 2005 46 2254 40 2244 46 2249 44 2256 61 1503 41 2004 46 2251 40 2257 46 2258 40 2004 46 2006 46 2245 44 2004 46 2006 46 2253 41 44 362 44 41 612 2251 40 2004 44 2006 44 2259 41 58 664 2244 696 2006 58 2005 61 2009 40 2244 46 2010 41 330 2260 61 2009 40 2244 46 2261 41 330 2262 61 123 2263 58 673 40 2244 44 2263 41 664 2263 696 40 362 44 362 44 362 44 362 44 362 41 688 678 40 2244 44 2263 41 125 2264 61 673 40 2005 44 2259 41 40 350 2262 41 2004 46 2012 40 2260 46 2194 44 2264 46 2194 41 2004 46 2012 40 720 40 2260 41 44 720 40 2264 41 41 330 664 2206 696 779 40 720 40 2260 41 41 58 2265 61 2260 91 2206 93 2266 61 2264 91 2206 93 2004 46 2012 40 720 40 2265 41 44 720 40 2266 41 41 664 2267 696 779 40 720 40 2265 41 41 58 330 2004 46 2100 40 2265 91 2267 93 91 1500 93 44 2266 91 2267 93 91 1500 93 44 1502 41 2004 46 2100 40 2265 91 2267 93 91 1501 93 44 2266 91 2267 93 91 1501 93 44 1502 41 612 2268 40 2004 41 58 2054 61 2161 40 40 40 1500 44 1500 41 44 40 1500 44 1502 41 44 40 1502 44 1502 41 44 40 1502 44 1500 41 44 40 1500 44 1500 41 41 41 2004 46 2225 40 2054 46 2269 40 2023 40 1502 44 1502 41 41 41 2004 46 2270 40 2054 46 2269 40 2023 40 1503 44 1503 41 41 41 612 2271 40 2004 41 58 2272 61 2127 40 40 1500 44 1500 41 44 40 1501 44 1501 41 44 40 1500 44 1500 41 41 2273 61 2127 40 40 1500 44 1500 41 44 40 1501 44 1501 41 41 2004 46 2270 40 2273 46 2274 41 2004 46 2225 40 2272 46 2274 41 612 2275 40 2004 41 58 362 330 2073 61 2023 40 1502 44 1503 44 2024 61 1505 41 2004 46 2012 40 1505 44 2073 46 2024 41 2073 46 2024 61 1505 2004 46 2012 40 1505 44 2073 46 2024 41 871 2004 46 2037 40 2246 46 2247 41 58 2073 46 2024 61 362 330 2054 61 2009 40 2004 46 2006 46 2053 91 1501 93 46 2010 44 2024 61 1505 41 2004 46 2012 40 1505 44 2054 46 2024 41 664 2125 696 2054 58 2004 46 2012 40 1505 44 2125 46 2024 41 2054 46 2024 61 1505 2004 46 2012 40 1505 44 2054 46 2055 46 2024 41 330 2276 61 2233 40 2023 40 1502 44 1503 41 44 2127 40 40 1500 44 1500 41 44 40 1502 44 1502 41 44 40 1502 44 1502 41 41 44 2024 61 1506 41 2004 46 2012 40 1506 44 2276 46 2024 41 664 2202 696 779 40 720 40 2276 41 41 58 2004 46 2012 40 1506 44 2276 91 2202 93 46 2024 41 330 330 330 681 61 362 2090 61 2009 40 681 41 2004 46 2012 40 1505 44 2090 46 2024 41 2091 61 2009 40 2090 46 681 41 2004 46 2105 40 2091 46 2024 41 2189 61 2009 40 2090 46 681 44 2024 61 45 1501 41 330 2004 46 2012 40 45 1501 44 2189 46 2024 41 330 2277 61 2023 40 1501 44 1501 41 2277 46 2024 61 2277 46 2024 330 2004 46 2012 40 2028 40 2073 46 2013 44 2024 61 2073 46 2024 41 46 2024 44 2073 46 2024 41 2004 46 2012 40 2028 40 2073 46 2030 44 2024 61 2073 46 2024 41 46 2024 44 2073 46 2024 41 871 2004 46 2130 40 2039 44 362 37 2073 46 2024 41 58 2028 40 2073 46 2013 44 2024 61 1501 41 871 2004 46 2130 40 2039 44 362 37 2073 46 2024 41 58 2028 40 2073 46 2030 44 2024 61 1501 41 612 2278 40 2004 41 58 362 664 2024 696 91 470 44 1507 93 58 2073 61 2023 40 1507 44 1507 44 2024 61 2024 41 2004 46 2225 40 2073 46 2013 46 2279 40 40 362 37 2024 688 2024 630 362 41 43 362 41 41 2004 46 2280 40 2073 46 2281 44 2282 46 2283 41 2004 46 2105 40 2073 46 2284 41 330 2285 61 2282 46 2286 40 2282 46 2287 40 362 362 41 44 2282 46 2287 40 1505 41 41 2288 61 2073 46 2289 40 2285 44 2152 61 515 41 2004 46 2012 40 2288 46 2024 44 1505 41 2004 46 2100 40 2288 46 2098 44 1501 44 1501 41 2004 46 2100 40 2288 46 2099 44 1502 44 1501 41 612 2290 40 2004 41 58 362 330 664 2052 696 2004 46 2006 46 2053 58 2054 61 2009 40 2052 46 2010 41 330 871 2004 46 2037 40 2041 41 58 2054 46 2171 40 1500 44 2127 40 40 1501 44 1501 41 44 40 1502 44 1502 41 41 41 330 2291 61 2054 46 2055 46 831 2292 61 91 93 664 2111 696 2291 58 2292 46 2293 40 40 2111 91 1500 93 43 1504 44 2111 91 1501 93 43 1504 41 41 2294 61 2136 40 42 831 40 2292 41 41 330 2054 46 2169 61 2294 813 40 2294 41 330 2004 46 2012 40 2054 46 2169 44 2294 41 2004 46 2012 40 2054 91 1500 93 44 2294 41 330 664 2032 696 2004 46 2006 46 2115 58 2114 61 2009 40 2032 46 2010 41 664 2202 696 779 40 720 40 2114 41 41 58 330 2073 61 2114 91 2202 93 2295 61 2023 40 2296 46 2297 40 1503 44 1503 41 44 2296 46 2297 40 1503 44 1503 41 41 330 2114 91 2202 93 61 2295 813 40 2295 41 330 2004 46 2012 40 2114 91 2202 93 44 2295 41 2004 46 2012 40 2114 91 2202 93 46 2010 44 2295 46 2010 41 2004 46 2076 40 2073 44 2114 91 2202 93 41 330 330 664 2032 696 2004 46 2006 46 2181 58 2192 61 2009 40 2032 46 2010 41 664 2202 696 779 40 720 40 2192 41 41 58 2054 61 2192 91 2202 93 2298 61 2192 91 2202 93 330 664 2206 696 779 40 720 40 2054 41 41 58 2172 61 2054 91 2206 93 664 2267 696 779 40 720 40 2172 41 41 58 2172 91 2267 93 61 40 2172 91 2267 93 91 1500 93 43 1504 44 2172 91 2267 93 91 1501 93 43 1504 41 2054 91 2206 93 61 2172 2004 46 2076 40 2192 91 2202 93 44 2054 41 330 2192 91 2202 93 61 2054 813 40 2054 41 330 2004 46 2012 40 2192 91 2202 93 44 2054 41 2004 46 2076 40 2192 91 2202 93 44 2298 41 330 330 330 330 330 330 330 330 612 2299 40 2004 41 58 2052 61 2023 40 1500 44 1500 41 2052 91 58 93 61 40 1501 44 1502 44 1502 41 2004 46 2012 40 2052 44 2023 40 1501 44 1502 44 1502 41 41 2052 91 58 93 61 40 41 2004 46 2012 40 2052 46 2010 44 2023 40 41 41 2052 91 58 93 61 40 1501 44 1502 41 2004 46 2012 40 2052 46 2010 44 2023 40 1501 44 1502 41 41 871 2004 46 2037 40 2039 41 58 2052 91 58 93 61 40 1501 44 41 871 2004 46 2037 40 2039 41 58 2052 91 58 93 61 40 1501 44 1502 44 1502 44 1502 44 1502 41 612 2300 40 2004 41 58 2077 61 2127 40 40 1500 44 1500 41 44 40 1501 44 1501 41 41 2077 91 58 93 61 40 41 2004 46 2012 40 2077 44 2127 40 41 41 2077 91 58 93 61 40 40 1500 44 1500 41 44 40 1501 44 1501 41 44 40 1502 44 1502 41 41 2004 46 2012 40 2077 44 2127 40 40 1500 44 1500 41 44 40 1501 44 1501 41 44 40 1502 44 1502 41 41 41 871 2004 46 2037 40 2039 41 58 2077 91 58 93 61 40 1501 44 41 612 2301 40 2004 41 58 2077 61 2136 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1501 41 44 40 1500 44 1500 41 41 2077 91 58 93 61 40 41 2004 46 2012 40 2077 44 2136 40 41 41 2077 91 58 93 61 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1501 41 44 40 1501 44 1500 41 44 40 1500 44 1500 41 41 2004 46 2012 40 2077 44 2136 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1501 41 44 40 1501 44 1500 41 44 40 1500 44 1500 41 41 41 871 2004 46 2037 40 2039 41 58 2077 91 58 93 61 40 40 1500 44 1500 41 44 40 1501 44 1501 41 44 40 1502 44 1502 41 41 612 2302 40 2004 41 58 2303 61 2161 40 41 2303 91 58 93 61 40 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1501 41 44 40 1501 44 1500 41 44 40 1500 44 1500 41 41 44 41 2004 46 2012 40 2303 44 2161 40 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1501 41 44 40 1501 44 1500 41 44 40 1500 44 1500 41 41 44 41 41 2303 91 58 93 61 40 41 2004 46 2012 40 2303 44 2161 40 41 41 612 2304 40 2004 41 58 2052 61 2023 40 41 2276 61 2233 40 41 2276 91 58 93 61 91 2052 93 2004 46 2012 40 2276 44 2233 40 2052 41 41 2276 91 58 93 61 40 41 2004 46 2012 40 2276 44 2233 40 41 41 612 2305 40 2004 41 58 362 330 2073 61 2023 40 1502 44 1502 44 1502 41 2004 46 2012 40 40 1502 44 1502 44 1502 41 44 2073 46 2109 41 871 2004 46 2037 40 2041 41 58 2073 46 831 61 40 1501 44 1502 41 2073 46 2109 61 40 1501 44 1502 44 1502 41 2004 46 2012 40 40 1501 44 1502 44 1502 41 44 2073 46 2109 41 330 2077 61 2127 40 40 1502 44 1502 44 1502 41 44 40 1503 44 1504 44 45 1504 41 41 2004 46 2012 40 40 40 1502 44 1502 44 1502 41 44 40 1503 44 1504 44 45 1504 41 41 44 2077 46 831 41 871 2004 46 2037 40 2041 41 58 2077 46 2171 40 1500 44 40 1501 44 1502 41 41 2077 91 1500 93 61 40 1501 44 1502 44 1502 41 2004 46 2012 40 40 1501 44 1502 44 1502 41 44 2077 91 1500 93 41 612 2306 40 2004 41 58 362 330 2073 61 2023 40 1500 44 1500 41 2004 46 2012 40 1500 44 2073 46 2307 40 2023 40 1500 44 1500 41 41 41 330 2004 46 2012 40 1501 44 2073 46 2307 40 2023 40 1500 44 1501 41 41 41 330 2004 46 2100 40 1502 44 2073 46 2307 40 2023 40 1501 44 1501 41 41 44 1503 41 330 330 2308 61 2127 40 40 1500 44 1500 41 44 40 1501 44 1501 41 44 40 1502 44 1502 41 41 2309 61 2127 40 40 1502 44 1502 41 44 40 1502 44 1501 41 44 40 1502 44 1500 41 41 2004 46 2012 40 1502 44 2308 46 2307 40 2309 41 41 612 2310 40 2004 41 58 362 330 2073 61 2023 40 1500 44 1500 41 2004 46 2012 40 1500 44 2073 46 2311 41 330 2077 61 2127 40 40 1500 44 1500 41 44 40 1501 44 1501 41 41 2004 46 2100 40 1502 44 2077 46 2311 44 1503 41 330 2054 61 2161 40 2136 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1501 41 44 40 1501 44 1500 41 44 40 1500 44 1500 41 41 41 2004 46 2012 40 1502 44 2054 46 2311 41 330 2192 61 2195 40 2054 46 2152 40 41 44 2054 41 2004 46 2012 40 1502 44 2192 46 2311 41 612 2312 40 2004 41 58 362 2313 61 91 2233 40 91 93 41 44 2009 40 362 41 44 2233 40 41 44 2009 40 362 41 44 2023 40 41 44 2009 40 362 41 44 2127 40 41 44 2009 40 362 41 44 2161 40 41 44 2009 40 362 41 44 2150 40 41 44 2009 40 362 41 44 2195 40 40 41 41 44 2195 40 41 44 93 688 2128 58 2313 46 2293 40 2127 40 2128 46 2129 40 91 93 41 41 41 664 2005 696 2313 58 2004 46 2027 40 2005 46 2120 44 515 41 330 688 713 40 2005 44 2161 41 58 2004 46 2012 40 1501 44 720 40 2005 41 41 330 2004 46 2012 40 1501 44 2005 46 2193 41 2004 46 2012 40 1500 44 720 40 2005 91 1500 93 41 41 629 713 40 2005 44 40 2023 44 2127 41 41 58 2004 46 2012 40 1501 44 2005 46 2193 41 2004 46 2012 40 1500 44 720 40 2005 41 41 630 58 2004 46 2012 40 1500 44 2005 46 2193 41 2004 46 2012 40 1500 44 720 40 2005 41 41 330 688 713 40 2005 44 2023 41 58 871 2004 46 2037 40 2117 41 58 2005 46 2098 629 713 40 2005 44 2161 41 58 2135 61 2005 46 2055 2004 46 2012 40 362 44 2135 46 2010 41 2004 46 2012 40 1500 44 720 40 2135 41 41 2004 46 2027 40 2135 46 2120 44 515 41 871 2004 46 2037 40 2117 41 58 2135 46 2118 40 1500 41 630 58 871 2004 46 2037 40 2117 41 58 2005 46 2118 40 1500 41 612 2314 40 2004 41 58 2276 61 2233 40 91 93 41 2004 46 2012 40 2276 46 2097 44 45 1501 41 2276 61 2233 40 2023 40 1500 44 1500 41 41 2004 46 2012 40 2276 46 2097 44 1500 41 2276 61 2233 40 2127 40 40 1500 44 1500 41 44 40 1501 44 1501 41 41 44 2023 40 1500 44 1500 41 41 2004 46 2012 40 2276 46 2097 44 1501 41 2276 61 2233 40 2127 40 40 1500 44 1500 41 44 40 1501 44 1501 41 41 44 2161 40 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1501 41 44 40 1500 44 1500 41 41 41 44 2023 40 1500 44 1500 41 41 2004 46 2012 40 2276 46 2097 44 1502 41 612 2315 40 2004 41 58 362 330 330 2316 61 91 2114 46 2010 664 2114 696 2004 46 2006 46 2181 688 2114 46 2121 93 2316 46 2317 40 2318 46 2010 664 2318 696 2004 46 2006 46 2148 41 2316 46 2317 40 2052 46 2010 664 2052 696 2004 46 2006 46 2053 41 2316 46 2317 40 2114 46 2010 664 2114 696 2004 46 2006 46 2115 41 2319 61 362 37 362 46 2320 40 2316 41 330 2321 61 2028 40 2319 41 330 2322 61 2233 40 42 831 40 2005 664 2005 696 2321 41 41 330 2004 46 2012 40 2321 44 2322 41 612 2323 40 2004 41 58 362 2324 61 2009 40 362 41 2004 46 2280 40 2324 46 2281 44 2282 46 2283 41 2004 46 2105 40 2324 46 2284 41 2325 61 2009 40 362 41 2004 46 2280 40 2325 46 2281 44 2282 46 2283 41 2004 46 2012 40 2325 46 2281 46 2101 44 1502 41 2326 61 2009 40 362 44 2024 61 1505 41 2004 46 2280 40 2326 46 2281 44 2282 46 2283 41 2004 46 2280 40 2326 46 2284 44 2282 46 2287 41 2004 46 2012 40 2326 46 681 44 2326 46 2281 46 681 41 2004 46 2012 40 362 44 2326 46 2284 46 2327 41 612 2328 40 2004 41 58 362 695 2329 2054 61 2028 40 362 41 2330 61 2329 46 2329 40 2054 41 2331 61 2329 46 2332 40 2054 41 2004 46 2076 40 2054 46 2333 44 2330 46 2333 41 2004 46 2076 40 2054 46 2333 44 2331 46 2333 41 612 2334 40 2004 41 58 362 2335 61 2028 40 362 44 1505 41 2336 61 2028 40 362 44 1505 41 330 330 2337 44 2338 44 2339 61 2335 46 2152 40 41 44 2335 46 2152 40 41 44 2335 46 2152 40 41 2337 46 2289 40 2336 46 2024 41 2338 46 2289 40 2282 46 2287 40 362 41 41 2340 61 2282 46 2286 40 2282 46 2287 40 362 41 44 2282 46 2287 40 1505 41 41 2339 46 2289 40 2340 41 330 2341 61 2335 46 2152 40 41 2342 61 2341 46 2289 40 2336 46 2024 44 2152 61 515 41 2004 46 2012 40 2341 44 2335 41 2004 46 2076 40 2341 44 2342 41 330 330 2343 61 45 1501 664 2052 696 40 2337 44 2338 44 2339 44 2342 41 58 2004 46 2100 40 2336 46 2098 44 2052 46 2098 44 2343 41 2004 46 2100 40 2336 46 2099 44 2052 46 2099 44 2343 41 612 2344 40 2004 41 58 2345 61 2028 40 362 44 1505 41 2345 46 2289 40 1505 41 2004 46 2100 40 2345 46 2101 44 1503 44 1502 41 612 2346 40 2004 41 58 362 330 330 2005 61 2028 40 362 44 1505 41 2347 61 2005 46 831 2005 46 2289 40 1505 41 2004 46 2012 40 2005 46 831 44 2347 41 2004 46 2012 40 2005 46 2024 44 1505 41 2005 61 2028 40 362 44 1505 41 2324 61 2005 46 2289 40 1505 44 2152 61 515 41 2004 46 2012 40 2324 46 831 44 2005 46 831 41 2004 46 2012 40 2324 46 2024 44 1505 41 2004 46 2079 40 2324 44 2005 44 362 41 612 2348 40 2004 41 58 362 2005 61 2028 40 362 44 2024 61 470 41 871 2004 46 2037 40 2038 41 58 2005 46 2289 40 1505 41 2005 61 2028 40 362 44 2024 61 470 41 871 2004 46 2037 40 2038 41 58 2005 46 2289 40 1505 44 2152 61 515 41 2005 61 2028 40 362 44 2024 61 45 1501 41 871 2004 46 2037 40 2038 41 58 2005 46 2289 40 1505 41 2005 61 2028 40 362 44 2024 61 45 1501 41 871 2004 46 2037 40 2038 41 58 2005 46 2289 40 1505 44 2152 61 515 41 612 2349 40 2004 41 58 362 330 2114 61 2085 40 2023 40 1502 44 1503 41 44 2023 40 1500 44 1500 41 44 2023 40 1502 44 1503 41 41 2004 46 2012 40 40 1500 44 1500 44 1502 44 1503 41 44 2114 46 2163 41 2073 61 2023 40 1502 44 1503 41 330 2004 46 2012 40 40 1502 44 1503 44 1502 44 1503 41 44 2073 46 2163 41 330 2054 61 2009 40 2004 46 2006 46 2053 91 1502 93 46 2010 41 2125 61 2054 46 2055 2098 44 2099 61 2125 46 2098 44 2125 46 2099 2350 44 2351 61 735 40 2098 41 44 735 40 2099 41 2352 44 2353 61 733 40 2098 41 44 733 40 2099 41 2004 46 2012 40 40 2350 44 2351 44 2352 44 2353 41 44 2054 46 2163 41 612 2354 40 2004 41 58 362 330 330 612 2355 40 2356 44 2024 61 470 41 58 792 91 2028 40 2032 46 2010 44 2024 41 664 2032 696 2356 93 2357 61 2355 40 2004 46 2006 46 2094 41 2357 46 2317 40 2355 40 2004 46 2006 46 2148 44 1505 41 41 2357 46 2317 40 2355 40 2004 46 2006 46 2053 44 1505 41 41 2357 46 2317 40 2355 40 2004 46 2006 46 2181 44 1505 41 41 2357 46 2293 40 2023 40 2024 61 1505 41 41 2357 46 2293 40 2023 40 41 41 664 2008 696 2357 58 2358 61 2359 46 2063 40 2008 41 2324 61 2359 46 2059 40 2358 41 2004 46 2012 40 2008 44 2324 41 2004 46 2012 40 2008 46 2024 44 2324 46 2024 41 612 2360 40 2004 41 58 362 330 2192 61 2028 40 362 41 2361 61 2192 46 2362 330 2363 61 91 2023 40 1502 44 1502 41 44 2023 40 1502 44 1502 41 44 2023 40 1502 44 1502 41 93 664 2073 696 2363 58 330 2004 46 2012 40 2192 46 2364 40 2073 41 44 2361 46 2364 40 2073 41 41 2004 46 2012 40 2192 46 2222 40 2073 41 44 2361 46 2222 40 2073 41 41 2004 46 2012 40 2192 46 2269 40 2073 41 44 2361 46 2269 40 2073 41 41 2004 46 2225 40 2361 46 2365 40 2009 40 362 41 41 41 2004 46 2225 40 2361 46 2366 40 2023 40 45 1502 44 45 1502 41 41 41 2054 61 2161 40 40 40 45 1501 44 45 1501 41 44 40 1501 44 1501 41 44 40 1501 44 1500 41 44 40 45 1501 44 45 1501 41 41 41 2004 46 2225 40 2361 46 2367 40 2054 41 41 2054 61 2161 40 40 40 45 1502 44 1500 41 44 40 45 1502 44 1502 41 44 40 1500 44 1502 41 44 40 45 1502 44 1500 41 41 41 2004 46 2225 40 2361 46 2368 40 2054 41 41 2054 61 2161 40 40 40 45 1501 44 45 1501 41 44 40 45 1501 44 1503 41 44 40 1503 44 1503 41 44 40 1503 44 45 1501 41 44 40 45 1501 44 45 1501 41 41 41 2004 46 2225 40 2361 46 2369 40 2054 41 41 330 616 2192 2004 46 2225 40 2361 46 2269 40 2023 40 1502 44 1502 41 41 41 612 2370 40 2004 41 58 362 2371 61 40 2009 40 362 41 44 2009 40 362 41 44 41 2372 61 40 2009 40 362 41 44 2009 40 362 41 44 41 664 2008 44 2373 696 875 40 2371 44 2372 41 58 2004 46 2012 40 2373 44 2008 46 2373 41 612 2374 40 2004 41 58 362 2005 61 2028 40 362 41 2004 46 2225 40 2005 46 2121 41 2004 46 2280 40 2005 46 2375 44 813 41 2004 46 2012 40 2005 46 2375 44 362 41 2005 61 2028 40 362 41 2004 46 2270 40 2005 46 2121 41 2004 46 2280 40 2005 46 2375 44 813 41 2004 46 2225 40 2005 46 2375 46 2279 40 362 41 41 612 2376 40 2004 41 58 362 2077 61 2009 40 362 41 2318 61 2009 40 362 41 2004 46 2012 40 2077 46 2377 40 2023 40 1500 44 1503 41 41 44 1502 41 2004 46 2012 40 2077 46 2377 40 2023 40 1502 44 1502 41 41 44 1503 41 2004 46 2012 40 2077 46 2378 40 2023 40 1500 44 1503 41 41 44 1501 47 1502 41 2004 46 2012 40 2077 46 2379 40 1502 41 44 2023 40 1500 44 1502 41 41 2004 46 2012 40 2077 46 2379 40 1503 41 44 2023 40 1502 44 1502 41 41 2004 46 2012 40 2077 46 2380 40 1501 47 1502 41 44 2023 40 1500 44 1502 41 41 2004 46 2012 40 2318 46 2377 40 2023 40 1500 44 1503 41 41 44 1502 41 2004 46 2012 40 2318 46 2377 40 2023 40 1502 44 1502 41 41 44 1503 41 2004 46 2012 40 2318 46 2379 40 1502 41 44 2023 40 1500 44 1502 41 41 2004 46 2012 40 2318 46 2379 40 1503 41 44 2023 40 1502 44 1502 41 41 612 2381 40 2004 41 58 362 2111 61 2023 40 1502 44 1503 44 2024 61 1505 41 2382 44 2383 44 2384 61 2111 46 2385 40 41 2004 46 2012 40 2382 44 362 41 2004 46 2012 40 2383 44 40 1502 44 1503 41 41 2004 46 2012 40 2384 44 123 362 58 1505 125 41 2077 61 2127 40 40 40 1500 44 1500 41 44 40 1501 44 1501 41 41 41 2382 44 2383 44 2384 61 2077 46 2385 40 41 2004 46 2012 40 2382 44 362 41 2004 46 2012 40 2383 44 40 40 40 1500 44 1500 41 44 40 1501 44 1501 41 41 44 41 41 2004 46 2012 40 2384 44 123 125 41 2309 61 2127 40 91 2023 40 1500 44 1500 41 44 2023 40 1501 44 1501 41 93 44 2024 61 1505 41 2382 44 2383 44 2384 61 2309 46 2385 40 41 2004 46 2012 40 2382 44 362 41 2004 46 2012 40 2383 44 40 91 2023 40 1500 44 1500 41 44 2023 40 1501 44 1501 41 93 44 41 41 2004 46 2012 40 2384 44 123 362 58 1505 125 41 2386 61 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1501 41 44 40 1501 44 1500 41 44 40 1500 44 1500 41 41 2387 61 40 40 1500 44 1500 41 44 40 1500 44 1500 41 44 40 1500 44 1500 41 44 40 1500 44 1500 41 44 40 1500 44 1500 41 41 2054 61 2161 40 2386 44 2387 41 2382 44 2383 44 2384 61 2054 46 2385 40 41 2004 46 2012 40 2382 44 362 41 2004 46 2012 40 2383 44 40 2386 44 2387 41 41 2004 46 2012 40 2384 44 123 125 41 2135 61 2136 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1501 41 44 40 1500 44 1500 41 41 2382 44 2383 44 2384 61 2135 46 2385 40 41 2004 46 2012 40 2382 44 362 41 2004 46 2012 40 2383 44 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1501 41 44 40 1500 44 1500 41 41 41 2004 46 2012 40 2384 44 123 125 41 2114 61 2085 40 2023 40 1500 44 1500 41 44 2023 40 1501 44 1501 41 41 2382 44 2383 44 2384 61 2114 46 2385 40 41 2004 46 2012 40 2382 44 362 41 2004 46 2012 40 2383 44 40 2023 40 1500 44 1500 41 44 2023 40 1501 44 1501 41 41 41 2004 46 2012 40 2384 44 123 125 41 2308 61 2127 40 40 1500 44 1500 41 44 40 1501 44 1501 41 41 2309 61 2127 40 40 1502 44 1502 41 44 40 1502 44 1502 41 41 2318 61 2150 40 2308 44 2309 41 2382 44 2383 44 2384 61 2318 46 2385 40 41 2004 46 2012 40 2382 44 362 41 2004 46 2012 40 2383 44 40 2308 44 2309 41 41 2004 46 2012 40 2384 44 123 125 41 2090 61 2161 40 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1501 41 44 40 1500 44 1500 41 41 41 2091 61 2161 40 40 40 1501 44 1501 41 44 40 1501 44 1502 41 44 40 1502 44 1502 41 44 40 1501 44 1501 41 41 41 2114 61 2195 40 2090 44 2091 41 2382 44 2383 44 2384 61 2114 46 2385 40 41 2004 46 2012 40 2382 44 362 41 2004 46 2012 40 2383 44 40 2090 44 2091 41 41 2004 46 2012 40 2384 44 123 125 41 2054 61 2161 40 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1501 41 44 40 1500 44 1500 41 41 41 2276 61 2233 40 2023 40 1500 44 1500 41 44 2085 40 2023 40 1500 44 1500 41 44 2023 40 1501 44 1501 41 41 44 2054 41 2382 44 2383 44 2384 61 2276 46 2385 40 41 2004 46 2012 40 2382 44 362 41 2004 46 2012 40 2383 44 40 2023 40 1500 44 1500 41 44 2085 40 2023 40 1500 44 1500 41 44 2023 40 1501 44 1501 41 41 44 2054 41 41 2004 46 2012 40 2384 44 123 125 41 612 2388 40 2004 41 58 362 587 2389 40 2161 41 58 612 2390 40 2004 44 42 2383 44 2391 61 1500 44 350 2384 41 58 818 40 41 46 2390 40 42 2383 44 350 2384 41 2004 46 2392 61 2391 612 2393 40 2004 41 58 792 362 37 40 2004 46 2392 44 2004 46 2010 41 2394 61 2389 40 40 40 1500 44 1500 41 44 40 1500 44 1501 41 44 40 1501 44 1501 41 44 40 1500 44 1500 41 41 44 2391 61 1502 41 2004 46 2012 40 832 40 2394 41 44 2389 41 330 2004 46 2012 40 813 40 2394 41 44 362 41 2004 46 2158 40 2394 46 2058 44 362 44 41 612 2395 40 2004 41 58 2396 61 40 40 362 44 40 1502 44 1500 44 1500 41 41 44 40 362 44 40 1502 44 1500 44 1500 41 41 44 40 362 44 40 1502 44 1502 44 1500 41 41 44 40 362 44 40 1502 44 1502 44 1500 41 41 44 40 362 44 40 1502 44 1502 44 1502 41 41 44 41 664 2397 44 2398 696 2396 58 871 2004 46 2399 40 2397 61 2397 41 58 871 2131 46 2132 40 362 44 719 58 2397 41 58 2004 46 2012 40 2140 40 41 44 2398 41 612 2400 40 2004 41 58 2004 46 2012 40 2028 40 362 41 44 2028 46 2401 40 362 362 362 41 44 41 612 2402 40 2004 41 58 2004 46 2012 40 2028 46 2403 40 362 41 44 2023 40 1501 44 1501 44 2024 61 1501 41 41 2004 46 2012 40 2028 46 2403 40 362 41 44 2023 40 1501 44 1501 41 41 612 2404 40 2004 41 58 2138 61 362 871 2004 46 2130 40 2039 44 2138 41 58 2028 46 2403 40 362 41 871 2004 46 2130 40 2039 44 2138 41 58 2028 46 2403 40 362 41 612 2405 40 2004 41 58 2138 61 362 871 2004 46 2130 40 2039 44 2138 41 58 2028 46 2403 40 362 41 871 2004 46 2130 40 2039 44 2138 41 58 2028 46 2403 40 362 41 612 2406 40 2004 41 58 2004 46 2012 40 2028 40 362 41 44 2023 40 1500 44 1502 41 41 612 2407 40 2004 41 58 2005 61 2085 40 2023 40 1500 44 1500 41 44 2023 40 1502 44 1502 41 44 2023 40 1501 44 1501 41 41 2004 46 2105 40 2005 46 2408 40 41 41 2004 46 2225 40 2005 46 2409 40 2085 40 2023 40 1502 44 1502 41 44 2023 40 1501 44 1501 41 44 2023 40 1500 44 1500 41 41 41 41 64 2139 40 2140 40 41 60 40 1502 44 1502 41 44 362 41 612 2410 40 2004 41 58 2054 61 2028 40 362 41 2004 46 2027 40 2054 46 2121 44 443 41 2411 61 2054 46 2412 40 41 2004 46 2027 40 2411 46 2121 44 515 41 2004 46 2076 40 2411 44 2054 41 2413 61 2411 46 2412 40 41 2004 46 2027 40 2413 46 2121 44 515 41 2004 46 2012 40 2411 44 2413 41 64 2131 46 2132 40 362 44 719 58 362 41 612 2414 40 2004 41 58 2138 61 362 2054 61 2028 40 362 41 871 2004 46 2130 40 2038 44 2138 41 58 2054 46 2412 40 41 612 2415 40 2004 41 58 2052 61 2023 40 2024 61 1505 41 2004 46 2012 40 2052 46 2281 46 2013 44 2052 46 2013 41 2004 46 2012 40 2052 46 2289 40 1505 44 2152 61 515 41 44 2023 40 2024 61 1505 41 41 2052 46 2289 40 1505 41 2004 46 2012 40 2052 44 2023 40 2024 61 1505 41 41 612 2416 40 2004 41 58 2077 61 2127 40 40 1500 44 1500 41 44 40 1501 44 1501 41 41 2417 61 717 40 2077 41 330 745 40 2417 41 2077 91 58 93 61 91 93 871 2004 46 2037 40 2117 41 58 745 40 2417 41 ,"{'AvgLine': 15, 'CountLine': 1442, 'CountStmt': 957, 'MaxNesting': 4, 'AvgLineCode': 11, 'AvgEssential': 1, 'AvgLineBlank': 1, 'CountStmtExe': 866, 'MaxEssential': 1, 'SumEssential': 87, 'AvgCyclomatic': 1, 'CountLineCode': 1027, 'CountStmtDecl': 365, 'MaxCyclomatic': 9, 'SumCyclomatic': 159, 'AvgLineComment': 2, 'CountClassBase': 2, 'CountLineBlank': 227, 'CountDeclMethod': 84, 'CountLineCodeExe': 931, 'CountLineComment': 220, 'CountClassCoupled': 21, 'CountClassDerived': 0, 'CountLineCodeDecl': 371, 'CountDeclMethodAll': 120, 'MaxInheritanceTree': 2, 'RatioCommentToCode': '0.21', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 9, 'SumCyclomaticStrict': 159, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 9, 'SumCyclomaticModified': 159, 'CountDeclInstanceMethod': 84, 'CountClassCoupledModified': 13, 'CountDeclInstanceVariable': 0}"
125341,Python,"class AirbyteHook(HttpHook):
    """"""
    Hook for Airbyte API

    :param airbyte_conn_id: Required. The name of the Airflow connection to get
        connection information for Airbyte.
    :type airbyte_conn_id: str
    :param api_version: Optional. Airbyte API version.
    :type api_version: str
    """"""

    conn_name_attr = 'airbyte_conn_id'
    default_conn_name = 'airbyte_default'
    conn_type = 'airbyte'
    hook_name = 'Airbyte'

    RUNNING = ""running""
    SUCCEEDED = ""succeeded""
    CANCELLED = ""cancelled""
    PENDING = ""pending""
    FAILED = ""failed""
    ERROR = ""error""
    INCOMPLETE = ""incomplete""

    def __init__(self, airbyte_conn_id: str = ""airbyte_default"", api_version: str = ""v1"") -> None:
        super().__init__(http_conn_id=airbyte_conn_id)
        self.api_version: str = api_version

    def wait_for_job(
        self, job_id: Union[str, int], wait_seconds: float = 3, timeout: Optional[float] = 3600
    ) -> None:
        """"""
        Helper method which polls a job to check if it finishes.

        :param job_id: Required. Id of the Airbyte job
        :type job_id: str
        :param wait_seconds: Optional. Number of seconds between checks.
        :type wait_seconds: float
        :param timeout: Optional. How many seconds wait for job to be ready.
            Used only if ``asynchronous`` is False.
        :type timeout: float
        """"""
        state = None
        start = time.monotonic()
        while True:
            if timeout and start + timeout < time.monotonic():
                raise AirflowException(f""Timeout: Airbyte job {job_id} is not ready after {timeout}s"")
            time.sleep(wait_seconds)
            try:
                job = self.get_job(job_id=(int(job_id)))
                state = job.json()[""job""][""status""]
            except AirflowException as err:
                self.log.info(""Retrying. Airbyte API returned server error when waiting for job: %s"", err)
                continue

            if state in (self.RUNNING, self.PENDING, self.INCOMPLETE):
                continue
            if state == self.SUCCEEDED:
                break
            if state == self.ERROR:
                raise AirflowException(f""Job failed:\n{job}"")
            elif state == self.CANCELLED:
                raise AirflowException(f""Job was cancelled:\n{job}"")
            else:
                raise Exception(f""Encountered unexpected state `{state}` for job_id `{job_id}`"")

    def submit_sync_connection(self, connection_id: str) -> Any:
        """"""
        Submits a job to a Airbyte server.

        :param connection_id: Required. The ConnectionId of the Airbyte Connection.
        :type connection_id: str
        """"""
        return self.run(
            endpoint=f""api/{self.api_version}/connections/sync"",
            json={""connectionId"": connection_id},
            headers={""accept"": ""application/json""},
        )

    def get_job(self, job_id: int) -> Any:
        """"""
        Gets the resource representation for a job in Airbyte.

        :param job_id: Required. Id of the Airbyte job
        :type job_id: int
        """"""
        return self.run(
            endpoint=f""api/{self.api_version}/jobs/get"",
            json={""id"": job_id},
            headers={""accept"": ""application/json""},
        )

    def test_connection(self):
        """"""Tests the Airbyte connection by hitting the health API""""""
        self.method = 'GET'
        try:
            res = self.run(
                endpoint=f""api/{self.api_version}/health"",
                headers={""accept"": ""application/json""},
                extra_options={'check_response': False},
            )

            if res.status_code == 200:
                return True, 'Connection successfully tested'
            else:
                return False, res.text
        except Exception as e:
            return False, str(e)
        finally:
            self.method = 'POST'",1,587 2000 40 2001 41 58 362 2002 61 362 2003 61 362 2004 61 362 2005 61 362 2006 61 362 2007 61 362 2008 61 362 2009 61 362 2010 61 362 2011 61 362 2012 61 362 612 2013 40 2014 44 2015 58 813 61 362 44 2016 58 813 61 362 41 354 470 58 818 40 41 46 2013 40 2017 61 2015 41 2014 46 2016 58 813 61 2016 612 2018 40 2014 44 2019 58 2020 91 813 44 704 93 44 2021 58 660 61 1502 44 2022 58 2023 91 660 93 61 1505 41 354 470 58 362 2024 61 470 2025 61 2026 46 2027 40 41 870 515 58 688 2022 545 2025 43 2022 60 2026 46 2027 40 41 58 778 2028 40 362 41 2026 46 2029 40 2021 41 830 58 2030 61 2014 46 2031 40 2019 61 40 704 40 2019 41 41 41 2024 61 2030 46 2032 40 41 91 362 93 91 362 93 645 2028 552 2033 58 2014 46 2034 46 2035 40 362 44 2033 41 605 688 2024 696 40 2014 46 2006 44 2014 46 2009 44 2014 46 2012 41 58 605 688 2024 323 2014 46 2007 58 572 688 2024 323 2014 46 2011 58 778 2028 40 362 41 629 2024 323 2014 46 2008 58 778 2028 40 362 41 630 58 778 2036 40 362 41 612 2037 40 2014 44 2038 58 813 41 354 2039 58 362 792 2014 46 2040 40 2041 61 362 44 2032 61 123 362 58 2038 125 44 2042 61 123 362 58 362 125 44 41 612 2031 40 2014 44 2019 58 704 41 354 2039 58 362 792 2014 46 2040 40 2041 61 362 44 2032 61 123 362 58 2019 125 44 2042 61 123 362 58 362 125 44 41 612 2043 40 2014 41 58 362 2014 46 2044 61 362 830 58 2045 61 2014 46 2040 40 2041 61 362 44 2042 61 123 362 58 362 125 44 2046 61 123 362 58 443 125 44 41 688 2045 46 2047 323 1504 58 792 515 44 362 630 58 792 443 44 2045 46 2048 645 2036 552 2049 58 792 443 44 813 40 2049 41 658 58 2014 46 2044 61 362 ,"{'AvgLine': 16, 'CountLine': 110, 'CountStmt': 50, 'MaxNesting': 2, 'AvgLineCode': 11, 'AvgEssential': 2, 'AvgLineBlank': 1, 'CountStmtExe': 44, 'MaxEssential': 8, 'SumEssential': 14, 'AvgCyclomatic': 2, 'CountLineCode': 68, 'CountStmtDecl': 22, 'MaxCyclomatic': 8, 'SumCyclomatic': 14, 'AvgLineComment': 4, 'CountClassBase': 1, 'CountLineBlank': 13, 'CountDeclMethod': 5, 'CountLineCodeExe': 60, 'CountLineComment': 29, 'CountClassCoupled': 5, 'CountClassDerived': 0, 'CountLineCodeDecl': 26, 'CountDeclMethodAll': 19, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '0.43', 'AvgCyclomaticStrict': 3, 'MaxCyclomaticStrict': 9, 'SumCyclomaticStrict': 15, 'AvgCyclomaticModified': 2, 'MaxCyclomaticModified': 8, 'SumCyclomaticModified': 14, 'CountDeclInstanceMethod': 5, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 1}"
130810,Python,"class Client(ClientMixin, RequestFactory):
    """"""
    A class that can act as a client for testing purposes.

    It allows the user to compose GET and POST requests, and
    obtain the response that the server gave to those requests.
    The server Response objects are annotated with the details
    of the contexts and templates that were rendered during the
    process of serving the request.

    Client objects are stateful - they will retain cookie (and
    thus session) details for the lifetime of the Client instance.

    This is not intended as a replacement for Twill/Selenium or
    the like - it is here to allow testing against the
    contexts and templates produced by a view, rather than the
    HTML rendered to the end-user.
    """"""
    def __init__(self, enforce_csrf_checks=False, raise_request_exception=True, **defaults):
        super().__init__(**defaults)
        self.handler = ClientHandler(enforce_csrf_checks)
        self.raise_request_exception = raise_request_exception
        self.exc_info = None
        self.extra = None

    def request(self, **request):
        """"""
        The master request method. Compose the environment dictionary and pass
        to the handler, return the result of the handler. Assume defaults for
        the query environment, which can be overridden using the arguments to
        the request.
        """"""
        environ = self._base_environ(**request)

        # Curry a data dictionary into an instance of the template renderer
        # callback function.
        data = {}
        on_template_render = partial(store_rendered_templates, data)
        signal_uid = ""template-render-%s"" % id(request)
        signals.template_rendered.connect(on_template_render, dispatch_uid=signal_uid)
        # Capture exceptions created by the handler.
        exception_uid = ""request-exception-%s"" % id(request)
        got_request_exception.connect(self.store_exc_info, dispatch_uid=exception_uid)
        try:
            response = self.handler(environ)
        finally:
            signals.template_rendered.disconnect(dispatch_uid=signal_uid)
            got_request_exception.disconnect(dispatch_uid=exception_uid)
        # Check for signaled exceptions.
        self.check_exception(response)
        # Save the client and request that stimulated the response.
        response.client = self
        response.request = request
        # Add any rendered template detail to the response.
        response.templates = data.get('templates', [])
        response.context = data.get('context')
        response.json = partial(self._parse_json, response)
        # Attach the ResolverMatch instance to the response.
        urlconf = getattr(response.wsgi_request, 'urlconf', None)
        response.resolver_match = SimpleLazyObject(
            lambda: resolve(request['PATH_INFO'], urlconf=urlconf),
        )
        # Flatten a single context. Not really necessary anymore thanks to the
        # __getattr__ flattening in ContextList, but has some edge case
        # backwards compatibility implications.
        if response.context and len(response.context) == 1:
            response.context = response.context[0]
        # Update persistent cookie data.
        if response.cookies:
            self.cookies.update(response.cookies)
        return response

    def get(self, path, data=None, follow=False, secure=False, **extra):
        """"""Request a response from the server using GET.""""""
        self.extra = extra
        response = super().get(path, data=data, secure=secure, **extra)
        if follow:
            response = self._handle_redirects(response, data=data, **extra)
        return response

    def post(self, path, data=None, content_type=MULTIPART_CONTENT,
             follow=False, secure=False, **extra):
        """"""Request a response from the server using POST.""""""
        self.extra = extra
        response = super().post(path, data=data, content_type=content_type, secure=secure, **extra)
        if follow:
            response = self._handle_redirects(response, data=data, content_type=content_type, **extra)
        return response

    def head(self, path, data=None, follow=False, secure=False, **extra):
        """"""Request a response from the server using HEAD.""""""
        self.extra = extra
        response = super().head(path, data=data, secure=secure, **extra)
        if follow:
            response = self._handle_redirects(response, data=data, **extra)
        return response

    def options(self, path, data='', content_type='application/octet-stream',
                follow=False, secure=False, **extra):
        """"""Request a response from the server using OPTIONS.""""""
        self.extra = extra
        response = super().options(path, data=data, content_type=content_type, secure=secure, **extra)
        if follow:
            response = self._handle_redirects(response, data=data, content_type=content_type, **extra)
        return response

    def put(self, path, data='', content_type='application/octet-stream',
            follow=False, secure=False, **extra):
        """"""Send a resource to the server using PUT.""""""
        self.extra = extra
        response = super().put(path, data=data, content_type=content_type, secure=secure, **extra)
        if follow:
            response = self._handle_redirects(response, data=data, content_type=content_type, **extra)
        return response

    def patch(self, path, data='', content_type='application/octet-stream',
              follow=False, secure=False, **extra):
        """"""Send a resource to the server using PATCH.""""""
        self.extra = extra
        response = super().patch(path, data=data, content_type=content_type, secure=secure, **extra)
        if follow:
            response = self._handle_redirects(response, data=data, content_type=content_type, **extra)
        return response

    def delete(self, path, data='', content_type='application/octet-stream',
               follow=False, secure=False, **extra):
        """"""Send a DELETE request to the server.""""""
        self.extra = extra
        response = super().delete(path, data=data, content_type=content_type, secure=secure, **extra)
        if follow:
            response = self._handle_redirects(response, data=data, content_type=content_type, **extra)
        return response

    def trace(self, path, data='', follow=False, secure=False, **extra):
        """"""Send a TRACE request to the server.""""""
        self.extra = extra
        response = super().trace(path, data=data, secure=secure, **extra)
        if follow:
            response = self._handle_redirects(response, data=data, **extra)
        return response

    def _handle_redirects(self, response, data='', content_type='', **extra):
        """"""
        Follow any redirects by requesting responses from the server using GET.
        """"""
        response.redirect_chain = []
        redirect_status_codes = (
            HTTPStatus.MOVED_PERMANENTLY,
            HTTPStatus.FOUND,
            HTTPStatus.SEE_OTHER,
            HTTPStatus.TEMPORARY_REDIRECT,
            HTTPStatus.PERMANENT_REDIRECT,
        )
        while response.status_code in redirect_status_codes:
            response_url = response.url
            redirect_chain = response.redirect_chain
            redirect_chain.append((response_url, response.status_code))

            url = urlsplit(response_url)
            if url.scheme:
                extra['wsgi.url_scheme'] = url.scheme
            if url.hostname:
                extra['SERVER_NAME'] = url.hostname
            if url.port:
                extra['SERVER_PORT'] = str(url.port)

            path = url.path
            # RFC 2616: bare domains without path are treated as the root.
            if not path and url.netloc:
                path = '/'
            # Prepend the request path to handle relative path redirects
            if not path.startswith('/'):
                path = urljoin(response.request['PATH_INFO'], path)

            if response.status_code in (HTTPStatus.TEMPORARY_REDIRECT, HTTPStatus.PERMANENT_REDIRECT):
                # Preserve request method and query string (if needed)
                # post-redirect for 307/308 responses.
                request_method = response.request['REQUEST_METHOD'].lower()
                if request_method not in ('get', 'head'):
                    extra['QUERY_STRING'] = url.query
                request_method = getattr(self, request_method)
            else:
                request_method = self.get
                data = QueryDict(url.query)
                content_type = None

            response = request_method(path, data=data, content_type=content_type, follow=False, **extra)
            response.redirect_chain = redirect_chain

            if redirect_chain[-1] in redirect_chain[:-1]:
                # Check that we're not redirecting to somewhere we've already
                # been to, to prevent loops.
                raise RedirectCycleError(""Redirect loop detected."", last_response=response)
            if len(redirect_chain) > 20:
                # Such a lengthy chain likely also means a loop, but one with
                # a growing path, changing view, or changing query argument;
                # 20 is the value of ""network.http.redirection-limit"" from Firefox.
                raise RedirectCycleError(""Too many redirects."", last_response=response)

        return response",1,587 2000 40 2001 44 2002 41 58 362 612 2003 40 2004 44 2005 61 443 44 2006 61 515 44 350 2007 41 58 818 40 41 46 2003 40 350 2007 41 2004 46 2008 61 2009 40 2005 41 2004 46 2006 61 2006 2004 46 2010 61 470 2004 46 2011 61 470 612 2012 40 2004 44 350 2012 41 58 362 2013 61 2004 46 2014 40 350 2012 41 330 330 2015 61 123 125 2016 61 2017 40 2018 44 2015 41 2019 61 362 37 687 40 2012 41 2020 46 2021 46 2022 40 2016 44 2023 61 2019 41 330 2024 61 362 37 687 40 2012 41 2025 46 2022 40 2004 46 2026 44 2023 61 2024 41 830 58 2027 61 2004 46 2008 40 2013 41 658 58 2020 46 2021 46 2028 40 2023 61 2019 41 2025 46 2028 40 2023 61 2024 41 330 2004 46 2029 40 2027 41 330 2027 46 2030 61 2004 2027 46 2012 61 2012 330 2027 46 2031 61 2015 46 2032 40 362 44 91 93 41 2027 46 2033 61 2015 46 2032 40 362 41 2027 46 2034 61 2017 40 2004 46 2035 44 2027 41 330 2036 61 673 40 2027 46 2037 44 362 44 470 41 2027 46 2038 61 2039 40 719 58 2040 40 2012 91 362 93 44 2036 61 2036 41 44 41 330 330 330 688 2027 46 2033 545 720 40 2027 46 2033 41 323 1501 58 2027 46 2033 61 2027 46 2033 91 1500 93 330 688 2027 46 2041 58 2004 46 2041 46 2042 40 2027 46 2041 41 792 2027 612 2032 40 2004 44 2043 44 2015 61 470 44 2044 61 443 44 2045 61 443 44 350 2011 41 58 362 2004 46 2011 61 2011 2027 61 818 40 41 46 2032 40 2043 44 2015 61 2015 44 2045 61 2045 44 350 2011 41 688 2044 58 2027 61 2004 46 2046 40 2027 44 2015 61 2015 44 350 2011 41 792 2027 612 2047 40 2004 44 2043 44 2015 61 470 44 2048 61 2049 44 2044 61 443 44 2045 61 443 44 350 2011 41 58 362 2004 46 2011 61 2011 2027 61 818 40 41 46 2047 40 2043 44 2015 61 2015 44 2048 61 2048 44 2045 61 2045 44 350 2011 41 688 2044 58 2027 61 2004 46 2046 40 2027 44 2015 61 2015 44 2048 61 2048 44 350 2011 41 792 2027 612 2050 40 2004 44 2043 44 2015 61 470 44 2044 61 443 44 2045 61 443 44 350 2011 41 58 362 2004 46 2011 61 2011 2027 61 818 40 41 46 2050 40 2043 44 2015 61 2015 44 2045 61 2045 44 350 2011 41 688 2044 58 2027 61 2004 46 2046 40 2027 44 2015 61 2015 44 350 2011 41 792 2027 612 2051 40 2004 44 2043 44 2015 61 362 44 2048 61 362 44 2044 61 443 44 2045 61 443 44 350 2011 41 58 362 2004 46 2011 61 2011 2027 61 818 40 41 46 2051 40 2043 44 2015 61 2015 44 2048 61 2048 44 2045 61 2045 44 350 2011 41 688 2044 58 2027 61 2004 46 2046 40 2027 44 2015 61 2015 44 2048 61 2048 44 350 2011 41 792 2027 612 2052 40 2004 44 2043 44 2015 61 362 44 2048 61 362 44 2044 61 443 44 2045 61 443 44 350 2011 41 58 362 2004 46 2011 61 2011 2027 61 818 40 41 46 2052 40 2043 44 2015 61 2015 44 2048 61 2048 44 2045 61 2045 44 350 2011 41 688 2044 58 2027 61 2004 46 2046 40 2027 44 2015 61 2015 44 2048 61 2048 44 350 2011 41 792 2027 612 2053 40 2004 44 2043 44 2015 61 362 44 2048 61 362 44 2044 61 443 44 2045 61 443 44 350 2011 41 58 362 2004 46 2011 61 2011 2027 61 818 40 41 46 2053 40 2043 44 2015 61 2015 44 2048 61 2048 44 2045 61 2045 44 350 2011 41 688 2044 58 2027 61 2004 46 2046 40 2027 44 2015 61 2015 44 2048 61 2048 44 350 2011 41 792 2027 612 2054 40 2004 44 2043 44 2015 61 362 44 2048 61 362 44 2044 61 443 44 2045 61 443 44 350 2011 41 58 362 2004 46 2011 61 2011 2027 61 818 40 41 46 2054 40 2043 44 2015 61 2015 44 2048 61 2048 44 2045 61 2045 44 350 2011 41 688 2044 58 2027 61 2004 46 2046 40 2027 44 2015 61 2015 44 2048 61 2048 44 350 2011 41 792 2027 612 2055 40 2004 44 2043 44 2015 61 362 44 2044 61 443 44 2045 61 443 44 350 2011 41 58 362 2004 46 2011 61 2011 2027 61 818 40 41 46 2055 40 2043 44 2015 61 2015 44 2045 61 2045 44 350 2011 41 688 2044 58 2027 61 2004 46 2046 40 2027 44 2015 61 2015 44 350 2011 41 792 2027 612 2046 40 2004 44 2027 44 2015 61 362 44 2048 61 362 44 350 2011 41 58 362 2027 46 2056 61 91 93 2057 61 40 2058 46 2059 44 2058 46 2060 44 2058 46 2061 44 2058 46 2062 44 2058 46 2063 44 41 870 2027 46 2064 696 2057 58 2065 61 2027 46 2066 2056 61 2027 46 2056 2056 46 2067 40 40 2065 44 2027 46 2064 41 41 2066 61 2068 40 2065 41 688 2066 46 2069 58 2011 91 362 93 61 2066 46 2069 688 2066 46 2070 58 2011 91 362 93 61 2066 46 2070 688 2066 46 2071 58 2011 91 362 93 61 813 40 2066 46 2071 41 2043 61 2066 46 2043 330 688 750 2043 545 2066 46 2072 58 2043 61 362 330 688 750 2043 46 2073 40 362 41 58 2043 61 2074 40 2027 46 2012 91 362 93 44 2043 41 688 2027 46 2064 696 40 2058 46 2062 44 2058 46 2063 41 58 330 330 2075 61 2027 46 2012 91 362 93 46 2076 40 41 688 2075 750 696 40 362 44 362 41 58 2011 91 362 93 61 2066 46 2077 2075 61 673 40 2004 44 2075 41 630 58 2075 61 2004 46 2032 2015 61 2078 40 2066 46 2077 41 2048 61 470 2027 61 2075 40 2043 44 2015 61 2015 44 2048 61 2048 44 2044 61 443 44 350 2011 41 2027 46 2056 61 2056 688 2056 91 45 1501 93 696 2056 91 58 45 1501 93 58 330 330 778 2079 40 362 44 2080 61 2027 41 688 720 40 2056 41 62 1503 58 330 330 330 778 2079 40 362 44 2080 61 2027 41 792 2027 ,"{'AvgLine': 15, 'CountLine': 200, 'CountStmt': 114, 'MaxNesting': 3, 'AvgLineCode': 11, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 102, 'MaxEssential': 4, 'SumEssential': 14, 'AvgCyclomatic': 2, 'CountLineCode': 129, 'CountStmtDecl': 37, 'MaxCyclomatic': 11, 'SumCyclomatic': 31, 'AvgLineComment': 3, 'CountClassBase': 2, 'CountLineBlank': 20, 'CountDeclMethod': 11, 'CountLineCodeExe': 112, 'CountLineComment': 51, 'CountClassCoupled': 6, 'CountClassDerived': 2, 'CountLineCodeDecl': 43, 'CountDeclMethodAll': 34, 'MaxInheritanceTree': 1, 'RatioCommentToCode': '0.40', 'AvgCyclomaticStrict': 3, 'MaxCyclomaticStrict': 12, 'SumCyclomaticStrict': 33, 'AvgCyclomaticModified': 2, 'MaxCyclomaticModified': 11, 'SumCyclomaticModified': 31, 'CountDeclInstanceMethod': 11, 'CountClassCoupledModified': 4, 'CountDeclInstanceVariable': 5}"
125734,Python,"class JenkinsJobTriggerOperator(BaseOperator):
    """"""
    Trigger a Jenkins Job and monitor it's execution.
    This operator depend on python-jenkins library,
    version >= 0.4.15 to communicate with jenkins server.
    You'll also need to configure a Jenkins connection in the connections screen.

    :param jenkins_connection_id: The jenkins connection to use for this job
    :type jenkins_connection_id: str
    :param job_name: The name of the job to trigger
    :type job_name: str
    :param parameters: The parameters block provided to jenkins for use in
        the API call when triggering a build. (templated)
    :type parameters: str, Dict, or List
    :param sleep_time: How long will the operator sleep between each status
        request for the job (min 1, default 10)
    :type sleep_time: int
    :param max_try_before_job_appears: The maximum number of requests to make
        while waiting for the job to appears on jenkins server (default 10)
    :type max_try_before_job_appears: int
    :param allowed_jenkins_states: Iterable of allowed result jenkins states, default is ``['SUCCESS']``
    :type allowed_jenkins_states: Optional[Iterable[str]]
    """"""

    template_fields = ('parameters',)
    template_ext = ('.json',)
    ui_color = '#f9ec86'

    def __init__(
        self,
        *,
        jenkins_connection_id: str,
        job_name: str,
        parameters: ParamType = None,
        sleep_time: int = 10,
        max_try_before_job_appears: int = 10,
        allowed_jenkins_states: Optional[Iterable[str]] = None,
        **kwargs,
    ):
        super().__init__(**kwargs)
        self.job_name = job_name
        self.parameters = parameters
        self.sleep_time = max(sleep_time, 1)
        self.jenkins_connection_id = jenkins_connection_id
        self.max_try_before_job_appears = max_try_before_job_appears
        self.allowed_jenkins_states = list(allowed_jenkins_states) if allowed_jenkins_states else ['SUCCESS']

    def build_job(self, jenkins_server: Jenkins, params: ParamType = None) -> Optional[JenkinsRequest]:
        """"""
        This function makes an API call to Jenkins to trigger a build for 'job_name'
        It returned a dict with 2 keys : body and headers.
        headers contains also a dict-like object which can be queried to get
        the location to poll in the queue.

        :param jenkins_server: The jenkins server where the job should be triggered
        :param params: The parameters block to provide to jenkins API call.
        :return: Dict containing the response body (key body)
            and the headers coming along (headers)
        """"""
        # Since params can be either JSON string, dictionary, or list,
        # check type and pass to build_job_url
        if params and isinstance(params, str):
            params = ast.literal_eval(params)

        request = Request(method='POST', url=jenkins_server.build_job_url(self.job_name, params, None))
        return jenkins_request_with_headers(jenkins_server, request)

    def poll_job_in_queue(self, location: str, jenkins_server: Jenkins) -> int:
        """"""
        This method poll the jenkins queue until the job is executed.
        When we trigger a job through an API call,
        the job is first put in the queue without having a build number assigned.
        Thus we have to wait the job exit the queue to know its build number.
        To do so, we have to add /api/json (or /api/xml) to the location
        returned by the build_job call and poll this file.
        When a 'executable' block appears in the json, it means the job execution started
        and the field 'number' then contains the build number.

        :param location: Location to poll, returned in the header of the build_job call
        :param jenkins_server: The jenkins server to poll
        :return: The build_number corresponding to the triggered job
        """"""
        try_count = 0
        location += '/api/json'
        # TODO Use get_queue_info instead
        # once it will be available in python-jenkins (v > 0.4.15)
        self.log.info('Polling jenkins queue at the url %s', location)
        while try_count < self.max_try_before_job_appears:
            location_answer = jenkins_request_with_headers(
                jenkins_server, Request(method='POST', url=location)
            )
            if location_answer is not None:
                json_response = json.loads(location_answer['body'])
                if 'executable' in json_response and 'number' in json_response['executable']:
                    build_number = json_response['executable']['number']
                    self.log.info('Job executed on Jenkins side with the build number %s', build_number)
                    return build_number
            try_count += 1
            time.sleep(self.sleep_time)
        raise AirflowException(
            ""The job hasn't been executed after polling "" f""the queue {self.max_try_before_job_appears} times""
        )

    def get_hook(self) -> JenkinsHook:
        """"""Instantiate jenkins hook""""""
        return JenkinsHook(self.jenkins_connection_id)

    def execute(self, context: Mapping[Any, Any]) -> Optional[str]:
        self.log.info(
            'Triggering the job %s on the jenkins : %s with the parameters : %s',
            self.job_name,
            self.jenkins_connection_id,
            self.parameters,
        )
        jenkins_server = self.get_hook().get_jenkins_server()
        jenkins_response = self.build_job(jenkins_server, self.parameters)
        if jenkins_response:
            build_number = self.poll_job_in_queue(jenkins_response['headers']['Location'], jenkins_server)

        time.sleep(self.sleep_time)
        keep_polling_job = True
        build_info = None

        while keep_polling_job:
            try:
                build_info = jenkins_server.get_build_info(name=self.job_name, number=build_number)
                if build_info['result'] is not None:
                    keep_polling_job = False
                    # Check if job ended with not allowed state.
                    if build_info['result'] not in self.allowed_jenkins_states:
                        raise AirflowException(
                            f""Jenkins job failed, final state : {build_info['result']}. ""
                            f""Find more information on job url : {build_info['url']}""
                        )
                else:
                    self.log.info('Waiting for job to complete : %s , build %s', self.job_name, build_number)
                    time.sleep(self.sleep_time)
            except jenkins.NotFoundException as err:

                raise AirflowException(f'Jenkins job status check failed. Final error was: {err.resp.status}')
            except jenkins.JenkinsException as err:
                raise AirflowException(
                    f'Jenkins call failed with error : {err}, if you have parameters '
                    'double check them, jenkins sends back '
                    'this exception for unknown parameters'
                    'You can also check logs for more details on this exception '
                    '(jenkins_url/log/rss)'
                )
        if build_info:
            # If we can we return the url of the job
            # for later use (like retrieving an artifact)
            return build_info['url']
        return None",1,587 2000 40 2001 41 58 362 2002 61 40 362 44 41 2003 61 40 362 44 41 2004 61 362 612 2005 40 2006 44 42 44 2007 58 813 44 2008 58 813 44 2009 58 2010 61 470 44 2011 58 704 61 1502 44 2012 58 704 61 1502 44 2013 58 2014 91 2015 91 813 93 93 61 470 44 350 2016 44 41 58 818 40 41 46 2005 40 350 2016 41 2006 46 2008 61 2008 2006 46 2009 61 2009 2006 46 2011 61 733 40 2011 44 1501 41 2006 46 2007 61 2007 2006 46 2012 61 2012 2006 46 2013 61 723 40 2013 41 688 2013 630 91 362 93 612 2017 40 2006 44 2018 58 2019 44 2020 58 2010 61 470 41 354 2014 91 2021 93 58 362 330 330 688 2020 545 713 40 2020 44 813 41 58 2020 61 2022 46 2023 40 2020 41 2024 61 2025 40 2026 61 362 44 2027 61 2018 46 2028 40 2006 46 2008 44 2020 44 470 41 41 792 2029 40 2018 44 2024 41 612 2030 40 2006 44 2031 58 813 44 2018 58 2019 41 354 704 58 362 2032 61 1500 2031 348 362 330 330 2006 46 2033 46 2034 40 362 44 2031 41 870 2032 60 2006 46 2012 58 2035 61 2029 40 2018 44 2025 40 2026 61 362 44 2027 61 2031 41 41 688 2035 712 750 470 58 2036 61 2037 46 2038 40 2035 91 362 93 41 688 362 696 2036 545 362 696 2036 91 362 93 58 2039 61 2036 91 362 93 91 362 93 2006 46 2033 46 2034 40 362 44 2039 41 792 2039 2032 348 1501 2040 46 2041 40 2006 46 2011 41 778 2042 40 362 362 41 612 2043 40 2006 41 354 2044 58 362 792 2044 40 2006 46 2007 41 612 2045 40 2006 44 2046 58 2047 91 2048 44 2048 93 41 354 2014 91 813 93 58 2006 46 2033 46 2034 40 362 44 2006 46 2008 44 2006 46 2007 44 2006 46 2009 44 41 2018 61 2006 46 2043 40 41 46 2049 40 41 2050 61 2006 46 2017 40 2018 44 2006 46 2009 41 688 2050 58 2039 61 2006 46 2030 40 2050 91 362 93 91 362 93 44 2018 41 2040 46 2041 40 2006 46 2011 41 2051 61 515 2052 61 470 870 2051 58 830 58 2052 61 2018 46 2053 40 2054 61 2006 46 2008 44 2055 61 2039 41 688 2052 91 362 93 712 750 470 58 2051 61 443 330 688 2052 91 362 93 750 696 2006 46 2013 58 778 2042 40 362 362 41 630 58 2006 46 2033 46 2034 40 362 44 2006 46 2008 44 2039 41 2040 46 2041 40 2006 46 2011 41 645 2056 46 2057 552 2058 58 778 2042 40 362 41 645 2056 46 2059 552 2058 58 778 2042 40 362 362 362 362 362 41 688 2052 58 330 330 792 2052 91 362 93 792 470 ,"{'AvgLine': 24, 'CountLine': 153, 'CountStmt': 59, 'MaxNesting': 4, 'AvgLineCode': 16, 'AvgEssential': 2, 'AvgLineBlank': 1, 'CountStmtExe': 53, 'MaxEssential': 7, 'SumEssential': 14, 'AvgCyclomatic': 3, 'CountLineCode': 88, 'CountStmtDecl': 25, 'MaxCyclomatic': 8, 'SumCyclomatic': 17, 'AvgLineComment': 6, 'CountClassBase': 1, 'CountLineBlank': 13, 'CountDeclMethod': 5, 'CountLineCodeExe': 72, 'CountLineComment': 53, 'CountClassCoupled': 6, 'CountClassDerived': 0, 'CountLineCodeDecl': 36, 'CountDeclMethodAll': 83, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '0.60', 'AvgCyclomaticStrict': 3, 'MaxCyclomaticStrict': 8, 'SumCyclomaticStrict': 19, 'AvgCyclomaticModified': 3, 'MaxCyclomaticModified': 8, 'SumCyclomaticModified': 17, 'CountDeclInstanceMethod': 5, 'CountClassCoupledModified': 2, 'CountDeclInstanceVariable': 6}"
125021,Python,"class S3ToGCSOperator(S3ListOperator):
    """"""
    Synchronizes an S3 key, possibly a prefix, with a Google Cloud Storage
    destination path.

    .. seealso::
        For more information on how to use this operator, take a look at the guide:
        :ref:`howto/operator:S3ToGCSOperator`

    :param bucket: The S3 bucket where to find the objects. (templated)
    :type bucket: str
    :param prefix: Prefix string which filters objects whose name begin with
        such prefix. (templated)
    :type prefix: str
    :param delimiter: the delimiter marks key hierarchy. (templated)
    :type delimiter: str
    :param aws_conn_id: The source S3 connection
    :type aws_conn_id: str
    :param verify: Whether or not to verify SSL certificates for S3 connection.
        By default SSL certificates are verified.
        You can provide the following values:

        - ``False``: do not validate SSL certificates. SSL will still be used
                 (unless use_ssl is False), but SSL certificates will not be
                 verified.
        - ``path/to/cert/bundle.pem``: A filename of the CA cert bundle to uses.
                 You can specify this argument if you want to use a different
                 CA cert bundle than the one used by botocore.
    :type verify: bool or str
    :param gcp_conn_id: (Optional) The connection ID used to connect to Google Cloud.
    :type gcp_conn_id: str
    :param dest_gcs_conn_id: (Deprecated) The connection ID used to connect to Google Cloud.
        This parameter has been deprecated. You should pass the gcp_conn_id parameter instead.
    :type dest_gcs_conn_id: str
    :param dest_gcs: The destination Google Cloud Storage bucket and prefix
        where you want to store the files. (templated)
    :type dest_gcs: str
    :param delegate_to: Google account to impersonate using domain-wide delegation of authority,
        if any. For this to work, the service account making the request must have
        domain-wide delegation enabled.
    :type delegate_to: str
    :param replace: Whether you want to replace existing destination files
        or not.
    :type replace: bool
    :param gzip: Option to compress file for upload
    :type gzip: bool
    :param google_impersonation_chain: Optional Google service account to impersonate using
        short-term credentials, or chained list of accounts required to get the access_token
        of the last account in the list, which will be impersonated in the request.
        If set as a string, the account must grant the originating account
        the Service Account Token Creator IAM role.
        If set as a sequence, the identities from the list must grant
        Service Account Token Creator IAM role to the directly preceding identity, with first
        account from the list granting this role to the originating account (templated).
    :type google_impersonation_chain: Union[str, Sequence[str]]


    **Example**:

    .. code-block:: python

       s3_to_gcs_op = S3ToGCSOperator(
           task_id=""s3_to_gcs_example"",
           bucket=""my-s3-bucket"",
           prefix=""data/customers-201804"",
           dest_gcs_conn_id=""google_cloud_default"",
           dest_gcs=""gs://my.gcs.bucket/some/customers/"",
           replace=False,
           gzip=True,
           dag=my - dag,
       )

    Note that ``bucket``, ``prefix``, ``delimiter`` and ``dest_gcs`` are
    templated, so you can use variables in them if you wish.
    """"""

    template_fields: Iterable[str] = (
        'bucket',
        'prefix',
        'delimiter',
        'dest_gcs',
        'google_impersonation_chain',
    )
    ui_color = '#e09411'

    def __init__(
        self,
        *,
        bucket,
        prefix='',
        delimiter='',
        aws_conn_id='aws_default',
        verify=None,
        gcp_conn_id='google_cloud_default',
        dest_gcs_conn_id=None,
        dest_gcs=None,
        delegate_to=None,
        replace=False,
        gzip=False,
        google_impersonation_chain: Optional[Union[str, Sequence[str]]] = None,
        **kwargs,
    ):

        super().__init__(bucket=bucket, prefix=prefix, delimiter=delimiter, aws_conn_id=aws_conn_id, **kwargs)

        if dest_gcs_conn_id:
            warnings.warn(
                ""The dest_gcs_conn_id parameter has been deprecated. You should pass ""
                ""the gcp_conn_id parameter."",
                DeprecationWarning,
                stacklevel=3,
            )
            gcp_conn_id = dest_gcs_conn_id

        self.gcp_conn_id = gcp_conn_id
        self.dest_gcs = dest_gcs
        self.delegate_to = delegate_to
        self.replace = replace
        self.verify = verify
        self.gzip = gzip
        self.google_impersonation_chain = google_impersonation_chain

    def _check_inputs(self) -> None:
        if self.dest_gcs and not gcs_object_is_directory(self.dest_gcs):
            self.log.info(
                'Destination Google Cloud Storage path is not a valid '
                '""directory"", define a path that ends with a slash ""/"" or '
                'leave it empty for the root of the bucket.'
            )
            raise AirflowException(
                'The destination Google Cloud Storage path must end with a slash ""/"" or be empty.'
            )

    def execute(self, context):
        self._check_inputs()
        # use the super method to list all the files in an S3 bucket/key
        files = super().execute(context)

        gcs_hook = GCSHook(
            gcp_conn_id=self.gcp_conn_id,
            delegate_to=self.delegate_to,
            impersonation_chain=self.google_impersonation_chain,
        )

        if not self.replace:
            # if we are not replacing -> list all files in the GCS bucket
            # and only keep those files which are present in
            # S3 and not in Google Cloud Storage
            bucket_name, object_prefix = _parse_gcs_url(self.dest_gcs)
            existing_files_prefixed = gcs_hook.list(bucket_name, prefix=object_prefix)

            existing_files = []

            if existing_files_prefixed:
                # Remove the object prefix itself, an empty directory was found
                if object_prefix in existing_files_prefixed:
                    existing_files_prefixed.remove(object_prefix)

                # Remove the object prefix from all object string paths
                for f in existing_files_prefixed:
                    if f.startswith(object_prefix):
                        existing_files.append(f[len(object_prefix) :])
                    else:
                        existing_files.append(f)

            files = list(set(files) - set(existing_files))
            if len(files) > 0:
                self.log.info('%s files are going to be synced: %s.', len(files), files)
            else:
                self.log.info('There are no new files to sync. Have a nice day!')

        if files:
            hook = S3Hook(aws_conn_id=self.aws_conn_id, verify=self.verify)

            for file in files:
                # GCS hook builds its own in-memory file so we have to create
                # and pass the path
                file_object = hook.get_key(file, self.bucket)
                with NamedTemporaryFile(mode='wb', delete=True) as f:
                    file_object.download_fileobj(f)
                    f.flush()

                    dest_gcs_bucket, dest_gcs_object_prefix = _parse_gcs_url(self.dest_gcs)
                    # There will always be a '/' before file because it is
                    # enforced at instantiation time
                    dest_gcs_object = dest_gcs_object_prefix + file

                    # Sync is sequential and the hook already logs too much
                    # so skip this for now
                    # self.log.info(
                    #     'Saving file {0} from S3 bucket {1} in GCS bucket {2}'
                    #     ' as object {3}'.format(file, self.bucket,
                    #                             dest_gcs_bucket,
                    #                             dest_gcs_object))

                    gcs_hook.upload(dest_gcs_bucket, dest_gcs_object, f.name, gzip=self.gzip)

            self.log.info(""All done, uploaded %d files to Google Cloud Storage"", len(files))
        else:
            self.log.info('In sync, no files needed to be uploaded to Google Cloud Storage')

        return files",1,587 2000 40 2001 41 58 362 2002 58 2003 91 813 93 61 40 362 44 362 44 362 44 362 44 362 44 41 2004 61 362 612 2005 40 2006 44 42 44 2007 44 2008 61 362 44 2009 61 362 44 2010 61 362 44 2011 61 470 44 2012 61 362 44 2013 61 470 44 2014 61 470 44 2015 61 470 44 2016 61 443 44 2017 61 443 44 2018 58 2019 91 2020 91 813 44 2021 91 813 93 93 93 61 470 44 350 2022 44 41 58 818 40 41 46 2005 40 2007 61 2007 44 2008 61 2008 44 2009 61 2009 44 2010 61 2010 44 350 2022 41 688 2013 58 2023 46 2024 40 362 362 44 2025 44 2026 61 1502 44 41 2012 61 2013 2006 46 2012 61 2012 2006 46 2014 61 2014 2006 46 2015 61 2015 2006 46 2016 61 2016 2006 46 2011 61 2011 2006 46 2017 61 2017 2006 46 2018 61 2018 612 2027 40 2006 41 354 470 58 688 2006 46 2014 545 750 2028 40 2006 46 2014 41 58 2006 46 2029 46 2030 40 362 362 362 41 778 2031 40 362 41 612 2032 40 2006 44 2033 41 58 2006 46 2027 40 41 330 2034 61 818 40 41 46 2032 40 2033 41 2035 61 2036 40 2012 61 2006 46 2012 44 2015 61 2006 46 2015 44 2037 61 2006 46 2018 44 41 688 750 2006 46 2016 58 330 330 330 2038 44 2039 61 2040 40 2006 46 2014 41 2041 61 2035 46 723 40 2038 44 2008 61 2039 41 2042 61 91 93 688 2041 58 330 688 2039 696 2041 58 2041 46 2043 40 2039 41 330 664 2044 696 2041 58 688 2044 46 2045 40 2039 41 58 2042 46 2046 40 2044 91 720 40 2039 41 58 93 41 630 58 2042 46 2046 40 2044 41 2034 61 723 40 801 40 2034 41 45 801 40 2042 41 41 688 720 40 2034 41 62 1500 58 2006 46 2029 46 2030 40 362 44 720 40 2034 41 44 2034 41 630 58 2006 46 2029 46 2030 40 362 41 688 2034 58 2047 61 2048 40 2010 61 2006 46 2010 44 2011 61 2006 46 2011 41 664 2049 696 2034 58 330 330 2050 61 2047 46 2051 40 2049 44 2006 46 2007 41 871 2052 40 2053 61 362 44 2054 61 515 41 552 2044 58 2050 46 2055 40 2044 41 2044 46 2056 40 41 2057 44 2058 61 2040 40 2006 46 2014 41 330 330 2059 61 2058 43 2049 330 330 330 330 330 330 330 2035 46 2060 40 2057 44 2059 44 2044 46 2061 44 2017 61 2006 46 2017 41 2006 46 2029 46 2030 40 362 44 720 40 2034 41 41 630 58 2006 46 2029 46 2030 40 362 41 792 2034 ,"{'AvgLine': 38, 'CountLine': 202, 'CountStmt': 51, 'MaxNesting': 4, 'AvgLineCode': 27, 'AvgEssential': 1, 'AvgLineBlank': 5, 'CountStmtExe': 47, 'MaxEssential': 1, 'SumEssential': 3, 'AvgCyclomatic': 4, 'CountLineCode': 90, 'CountStmtDecl': 24, 'MaxCyclomatic': 9, 'SumCyclomatic': 13, 'AvgLineComment': 5, 'CountClassBase': 1, 'CountLineBlank': 29, 'CountDeclMethod': 3, 'CountLineCodeExe': 70, 'CountLineComment': 84, 'CountClassCoupled': 7, 'CountClassDerived': 0, 'CountLineCodeDecl': 40, 'CountDeclMethodAll': 3, 'MaxInheritanceTree': 1, 'RatioCommentToCode': '0.93', 'AvgCyclomaticStrict': 4, 'MaxCyclomaticStrict': 9, 'SumCyclomaticStrict': 14, 'AvgCyclomaticModified': 4, 'MaxCyclomaticModified': 9, 'SumCyclomaticModified': 13, 'CountDeclInstanceMethod': 3, 'CountClassCoupledModified': 3, 'CountDeclInstanceVariable': 8}"
135207,Python,"class ExtraRegressTests(TestCase):

    @classmethod
    def setUpTestData(cls):
        cls.u = User.objects.create_user(
            username=""fred"",
            password=""secret"",
            email=""fred@example.com""
        )

    def test_regression_7314_7372(self):
        """"""
        Regression tests for #7314 and #7372
        """"""
        rm = RevisionableModel.objects.create(
            title='First Revision',
            when=datetime.datetime(2008, 9, 28, 10, 30, 0)
        )
        self.assertEqual(rm.pk, rm.base.pk)

        rm2 = rm.new_revision()
        rm2.title = ""Second Revision""
        rm.when = datetime.datetime(2008, 9, 28, 14, 25, 0)
        rm2.save()

        self.assertEqual(rm2.title, 'Second Revision')
        self.assertEqual(rm2.base.title, 'First Revision')

        self.assertNotEqual(rm2.pk, rm.pk)
        self.assertEqual(rm2.base.pk, rm.pk)

        # Queryset to match most recent revision:
        qs = RevisionableModel.objects.extra(
            where=[""%(table)s.id IN (SELECT MAX(rev.id) FROM %(table)s rev GROUP BY rev.base_id)"" % {
                'table': RevisionableModel._meta.db_table,
            }]
        )

        self.assertQuerysetEqual(
            qs, [('Second Revision', 'First Revision')],
            transform=lambda r: (r.title, r.base.title)
        )

        # Queryset to search for string in title:
        qs2 = RevisionableModel.objects.filter(title__contains=""Revision"")
        self.assertQuerysetEqual(
            qs2, [
                ('First Revision', 'First Revision'),
                ('Second Revision', 'First Revision'),
            ],
            transform=lambda r: (r.title, r.base.title),
            ordered=False
        )

        # Following queryset should return the most recent revision:
        self.assertQuerysetEqual(
            qs & qs2,
            [('Second Revision', 'First Revision')],
            transform=lambda r: (r.title, r.base.title),
            ordered=False
        )

    def test_extra_stay_tied(self):
        # Extra select parameters should stay tied to their corresponding
        # select portions. Applies when portions are updated or otherwise
        # moved around.
        qs = User.objects.extra(select={'alpha': '%s', 'beta': ""2"", 'gamma': '%s'}, select_params=(1, 3))
        qs = qs.extra(select={""beta"": 4})
        qs = qs.extra(select={""alpha"": ""%s""}, select_params=[5])
        self.assertEqual(
            list(qs.filter(id=self.u.id).values('alpha', 'beta', 'gamma')),
            [{'alpha': 5, 'beta': 4, 'gamma': 3}]
        )

    def test_regression_7957(self):
        """"""
        Regression test for #7957: Combining extra() calls should leave the
        corresponding parameters associated with the right extra() bit. I.e.
        internal dictionary must remain sorted.
        """"""
        self.assertEqual(
            (User.objects
                .extra(select={""alpha"": ""%s""}, select_params=(1,))
                .extra(select={""beta"": ""%s""}, select_params=(2,))[0].alpha),
            1
        )

        self.assertEqual(
            (User.objects
                .extra(select={""beta"": ""%s""}, select_params=(1,))
                .extra(select={""alpha"": ""%s""}, select_params=(2,))[0].alpha),
            2
        )

    def test_regression_7961(self):
        """"""
        Regression test for #7961: When not using a portion of an
        extra(...) in a query, remove any corresponding parameters from the
        query as well.
        """"""
        self.assertEqual(
            list(User.objects.extra(select={""alpha"": ""%s""}, select_params=(-6,))
                 .filter(id=self.u.id).values_list('id', flat=True)),
            [self.u.id]
        )

    def test_regression_8063(self):
        """"""
        Regression test for #8063: limiting a query shouldn't discard any
        extra() bits.
        """"""
        qs = User.objects.all().extra(where=['id=%s'], params=[self.u.id])
        self.assertSequenceEqual(qs, [self.u])
        self.assertSequenceEqual(qs[:1], [self.u])

    def test_regression_8039(self):
        """"""
        Regression test for #8039: Ordering sometimes removed relevant tables
        from extra(). This test is the critical case: ordering uses a table,
        but then removes the reference because of an optimization. The table
        should still be present because of the extra() call.
        """"""
        self.assertQuerysetEqual(
            (Order.objects
                .extra(where=[""username=%s""], params=[""fred""], tables=[""auth_user""])
                .order_by('created_by')),
            []
        )

    def test_regression_8819(self):
        """"""
        Regression test for #8819: Fields in the extra(select=...) list
        should be available to extra(order_by=...).
        """"""
        self.assertSequenceEqual(
            User.objects.filter(pk=self.u.id).extra(select={'extra_field': 1}).distinct(),
            [self.u],
        )
        self.assertSequenceEqual(
            User.objects.filter(pk=self.u.id).extra(select={'extra_field': 1}, order_by=['extra_field']),
            [self.u],
        )
        self.assertSequenceEqual(
            User.objects.filter(pk=self.u.id).extra(select={'extra_field': 1}, order_by=['extra_field']).distinct(),
            [self.u],
        )

    def test_dates_query(self):
        """"""
        When calling the dates() method on a queryset with extra selection
        columns, we can (and should) ignore those columns. They don't change
        the result and cause incorrect SQL to be produced otherwise.
        """"""
        RevisionableModel.objects.create(
            title='First Revision',
            when=datetime.datetime(2008, 9, 28, 10, 30, 0)
        )

        self.assertSequenceEqual(
            RevisionableModel.objects.extra(select={""the_answer"": 'id'}).datetimes('when', 'month'),
            [datetime.datetime(2008, 9, 1, 0, 0)],
        )

    def test_values_with_extra(self):
        """"""
        Regression test for #10256... If there is a values() clause, Extra
        columns are only returned if they are explicitly mentioned.
        """"""
        obj = TestObject(first='first', second='second', third='third')
        obj.save()

        self.assertEqual(
            list(
                TestObject.objects
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
                .values()
            ),
            [{
                'bar': 'second', 'third': 'third', 'second': 'second', 'whiz': 'third', 'foo': 'first',
                'id': obj.pk, 'first': 'first'
            }]
        )

        # Extra clauses after an empty values clause are still included
        self.assertEqual(
            list(
                TestObject.objects
                .values()
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
            ),
            [{
                'bar': 'second', 'third': 'third', 'second': 'second', 'whiz': 'third', 'foo': 'first',
                'id': obj.pk, 'first': 'first'
            }]
        )

        # Extra columns are ignored if not mentioned in the values() clause
        self.assertEqual(
            list(
                TestObject.objects
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
                .values('first', 'second')
            ),
            [{'second': 'second', 'first': 'first'}]
        )

        # Extra columns after a non-empty values() clause are ignored
        self.assertEqual(
            list(
                TestObject.objects
                .values('first', 'second')
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
            ),
            [{'second': 'second', 'first': 'first'}]
        )

        # Extra columns can be partially returned
        self.assertEqual(
            list(
                TestObject.objects
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
                .values('first', 'second', 'foo')
            ),
            [{'second': 'second', 'foo': 'first', 'first': 'first'}]
        )

        # Also works if only extra columns are included
        self.assertEqual(
            list(
                TestObject.objects
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
                .values('foo', 'whiz')
            ),
            [{'foo': 'first', 'whiz': 'third'}]
        )

        # Values list works the same way
        # All columns are returned for an empty values_list()
        self.assertEqual(
            list(
                TestObject.objects
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
                .values_list()
            ),
            [('first', 'second', 'third', obj.pk, 'first', 'second', 'third')]
        )

        # Extra columns after an empty values_list() are still included
        self.assertEqual(
            list(
                TestObject.objects
                .values_list()
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
            ),
            [('first', 'second', 'third', obj.pk, 'first', 'second', 'third')]
        )

        # Extra columns ignored completely if not mentioned in values_list()
        self.assertEqual(
            list(
                TestObject.objects
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
                .values_list('first', 'second')
            ),
            [('first', 'second')]
        )

        # Extra columns after a non-empty values_list() clause are ignored completely
        self.assertEqual(
            list(
                TestObject.objects
                .values_list('first', 'second')
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
            ),
            [('first', 'second')]
        )

        self.assertEqual(
            list(
                TestObject.objects
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
                .values_list('second', flat=True)
            ),
            ['second']
        )

        # Only the extra columns specified in the values_list() are returned
        self.assertEqual(
            list(
                TestObject.objects
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
                .values_list('first', 'second', 'whiz')
            ),
            [('first', 'second', 'third')]
        )

        # ...also works if only extra columns are included
        self.assertEqual(
            list(
                TestObject.objects
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
                .values_list('foo', 'whiz')
            ),
            [('first', 'third')]
        )

        self.assertEqual(
            list(
                TestObject.objects
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
                .values_list('whiz', flat=True)
            ),
            ['third']
        )

        # ... and values are returned in the order they are specified
        self.assertEqual(
            list(
                TestObject.objects
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
                .values_list('whiz', 'foo')
            ),
            [('third', 'first')]
        )

        self.assertEqual(
            list(
                TestObject.objects
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
                .values_list('first', 'id')
            ),
            [('first', obj.pk)]
        )

        self.assertEqual(
            list(
                TestObject.objects
                .extra(select={'foo': 'first', 'bar': 'second', 'whiz': 'third'})
                .values_list('whiz', 'first', 'bar', 'id')
            ),
            [('third', 'first', 'second', obj.pk)]
        )

    def test_regression_10847(self):
        """"""
        Regression for #10847: the list of extra columns can always be
        accurately evaluated. Using an inner query ensures that as_sql() is
        producing correct output without requiring full evaluation and
        execution of the inner query.
        """"""
        obj = TestObject(first='first', second='second', third='third')
        obj.save()

        self.assertEqual(
            list(TestObject.objects.extra(select={'extra': 1}).values('pk')),
            [{'pk': obj.pk}]
        )

        self.assertSequenceEqual(
            TestObject.objects.filter(
                pk__in=TestObject.objects.extra(select={'extra': 1}).values('pk')
            ),
            [obj],
        )

        self.assertEqual(
            list(TestObject.objects.values('pk').extra(select={'extra': 1})),
            [{'pk': obj.pk}]
        )

        self.assertSequenceEqual(
            TestObject.objects.filter(
                pk__in=TestObject.objects.values('pk').extra(select={'extra': 1})
            ),
            [obj],
        )

        self.assertSequenceEqual(
            TestObject.objects.filter(pk=obj.pk) | TestObject.objects.extra(where=[""id > %s""], params=[obj.pk]),
            [obj],
        )

    def test_regression_17877(self):
        """"""
        Extra WHERE clauses get correctly ANDed, even when they
        contain OR operations.
        """"""
        # Test Case 1: should appear in queryset.
        t1 = TestObject.objects.create(first='a', second='a', third='a')
        # Test Case 2: should appear in queryset.
        t2 = TestObject.objects.create(first='b', second='a', third='a')
        # Test Case 3: should not appear in queryset, bug case.
        t = TestObject(first='a', second='a', third='b')
        t.save()
        # Test Case 4: should not appear in queryset.
        t = TestObject(first='b', second='a', third='b')
        t.save()
        # Test Case 5: should not appear in queryset.
        t = TestObject(first='b', second='b', third='a')
        t.save()
        # Test Case 6: should not appear in queryset, bug case.
        t = TestObject(first='a', second='b', third='b')
        t.save()

        self.assertCountEqual(
            TestObject.objects.extra(
                where=[""first = 'a' OR second = 'a'"", ""third = 'a'""],
            ),
            [t1, t2],
        )

    def test_extra_values_distinct_ordering(self):
        t1 = TestObject.objects.create(first='a', second='a', third='a')
        t2 = TestObject.objects.create(first='a', second='b', third='b')
        qs = TestObject.objects.extra(
            select={'second_extra': 'second'}
        ).values_list('id', flat=True).distinct()
        self.assertSequenceEqual(qs.order_by('second_extra'), [t1.pk, t2.pk])
        self.assertSequenceEqual(qs.order_by('-second_extra'), [t2.pk, t1.pk])
        # Note: the extra ordering must appear in select clause, so we get two
        # non-distinct results here (this is on purpose, see #7070).
        # Extra select doesn't appear in result values.
        self.assertSequenceEqual(qs.order_by('-second_extra').values_list('first'), [('a',), ('a',)])",1,587 2000 40 2001 41 58 64 588 612 2002 40 2003 41 58 2003 46 2004 61 2005 46 2006 46 2007 40 2008 61 362 44 2009 61 362 44 2010 61 362 41 612 2011 40 2012 41 58 362 2013 61 2014 46 2006 46 2015 40 2016 61 362 44 2017 61 2018 46 2018 40 1505 44 1502 44 1503 44 1502 44 1503 44 1500 41 41 2012 46 2019 40 2013 46 2020 44 2013 46 2021 46 2020 41 2022 61 2013 46 2023 40 41 2022 46 2016 61 362 2013 46 2017 61 2018 46 2018 40 1505 44 1502 44 1503 44 1503 44 1503 44 1500 41 2022 46 2024 40 41 2012 46 2019 40 2022 46 2016 44 362 41 2012 46 2019 40 2022 46 2021 46 2016 44 362 41 2012 46 2025 40 2022 46 2020 44 2013 46 2020 41 2012 46 2019 40 2022 46 2021 46 2020 44 2013 46 2020 41 330 2026 61 2014 46 2006 46 2027 40 2028 61 91 362 37 123 362 58 2014 46 2029 46 2030 44 125 93 41 2012 46 2031 40 2026 44 91 40 362 44 362 41 93 44 2032 61 719 2033 58 40 2033 46 2016 44 2033 46 2021 46 2016 41 41 330 2034 61 2014 46 2006 46 656 40 2035 61 362 41 2012 46 2031 40 2034 44 91 40 362 44 362 41 44 40 362 44 362 41 44 93 44 2032 61 719 2033 58 40 2033 46 2016 44 2033 46 2021 46 2016 41 44 2036 61 443 41 330 2012 46 2031 40 2026 38 2034 44 91 40 362 44 362 41 93 44 2032 61 719 2033 58 40 2033 46 2016 44 2033 46 2021 46 2016 41 44 2036 61 443 41 612 2037 40 2012 41 58 330 330 330 2026 61 2005 46 2006 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 44 2039 61 40 1501 44 1502 41 41 2026 61 2026 46 2027 40 2038 61 123 362 58 1502 125 41 2026 61 2026 46 2027 40 2038 61 123 362 58 362 125 44 2039 61 91 1502 93 41 2012 46 2019 40 723 40 2026 46 656 40 687 61 2012 46 2004 46 687 41 46 2040 40 362 44 362 44 362 41 41 44 91 123 362 58 1502 44 362 58 1502 44 362 58 1502 125 93 41 612 2041 40 2012 41 58 362 2012 46 2019 40 40 2005 46 2006 46 2027 40 2038 61 123 362 58 362 125 44 2039 61 40 1501 44 41 41 46 2027 40 2038 61 123 362 58 362 125 44 2039 61 40 1502 44 41 41 91 1500 93 46 2042 41 44 1501 41 2012 46 2019 40 40 2005 46 2006 46 2027 40 2038 61 123 362 58 362 125 44 2039 61 40 1501 44 41 41 46 2027 40 2038 61 123 362 58 362 125 44 2039 61 40 1502 44 41 41 91 1500 93 46 2042 41 44 1502 41 612 2043 40 2012 41 58 362 2012 46 2019 40 723 40 2005 46 2006 46 2027 40 2038 61 123 362 58 362 125 44 2039 61 40 45 1502 44 41 41 46 656 40 687 61 2012 46 2004 46 687 41 46 2044 40 362 44 2045 61 515 41 41 44 91 2012 46 2004 46 687 93 41 612 2046 40 2012 41 58 362 2026 61 2005 46 2006 46 544 40 41 46 2027 40 2028 61 91 362 93 44 2047 61 91 2012 46 2004 46 687 93 41 2012 46 2048 40 2026 44 91 2012 46 2004 93 41 2012 46 2048 40 2026 91 58 1501 93 44 91 2012 46 2004 93 41 612 2049 40 2012 41 58 362 2012 46 2031 40 40 2050 46 2006 46 2027 40 2028 61 91 362 93 44 2047 61 91 362 93 44 2051 61 91 362 93 41 46 2052 40 362 41 41 44 91 93 41 612 2053 40 2012 41 58 362 2012 46 2048 40 2005 46 2006 46 656 40 2020 61 2012 46 2004 46 687 41 46 2027 40 2038 61 123 362 58 1501 125 41 46 2054 40 41 44 91 2012 46 2004 93 44 41 2012 46 2048 40 2005 46 2006 46 656 40 2020 61 2012 46 2004 46 687 41 46 2027 40 2038 61 123 362 58 1501 125 44 2052 61 91 362 93 41 44 91 2012 46 2004 93 44 41 2012 46 2048 40 2005 46 2006 46 656 40 2020 61 2012 46 2004 46 687 41 46 2027 40 2038 61 123 362 58 1501 125 44 2052 61 91 362 93 41 46 2054 40 41 44 91 2012 46 2004 93 44 41 612 2055 40 2012 41 58 362 2014 46 2006 46 2015 40 2016 61 362 44 2017 61 2018 46 2018 40 1505 44 1502 44 1503 44 1502 44 1503 44 1500 41 41 2012 46 2048 40 2014 46 2006 46 2027 40 2038 61 123 362 58 362 125 41 46 2056 40 362 44 362 41 44 91 2018 46 2018 40 1505 44 1502 44 1501 44 1500 44 1500 41 93 44 41 612 2057 40 2012 41 58 362 2058 61 2059 40 2060 61 362 44 2061 61 362 44 2062 61 362 41 2058 46 2024 40 41 2012 46 2019 40 723 40 2059 46 2006 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 46 2040 40 41 41 44 91 123 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 2058 46 2020 44 362 58 362 125 93 41 330 2012 46 2019 40 723 40 2059 46 2006 46 2040 40 41 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 41 44 91 123 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 362 44 362 58 2058 46 2020 44 362 58 362 125 93 41 330 2012 46 2019 40 723 40 2059 46 2006 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 46 2040 40 362 44 362 41 41 44 91 123 362 58 362 44 362 58 362 125 93 41 330 2012 46 2019 40 723 40 2059 46 2006 46 2040 40 362 44 362 41 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 41 44 91 123 362 58 362 44 362 58 362 125 93 41 330 2012 46 2019 40 723 40 2059 46 2006 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 46 2040 40 362 44 362 44 362 41 41 44 91 123 362 58 362 44 362 58 362 44 362 58 362 125 93 41 330 2012 46 2019 40 723 40 2059 46 2006 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 46 2040 40 362 44 362 41 41 44 91 123 362 58 362 44 362 58 362 125 93 41 330 330 2012 46 2019 40 723 40 2059 46 2006 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 46 2044 40 41 41 44 91 40 362 44 362 44 362 44 2058 46 2020 44 362 44 362 44 362 41 93 41 330 2012 46 2019 40 723 40 2059 46 2006 46 2044 40 41 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 41 44 91 40 362 44 362 44 362 44 2058 46 2020 44 362 44 362 44 362 41 93 41 330 2012 46 2019 40 723 40 2059 46 2006 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 46 2044 40 362 44 362 41 41 44 91 40 362 44 362 41 93 41 330 2012 46 2019 40 723 40 2059 46 2006 46 2044 40 362 44 362 41 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 41 44 91 40 362 44 362 41 93 41 2012 46 2019 40 723 40 2059 46 2006 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 46 2044 40 362 44 2045 61 515 41 41 44 91 362 93 41 330 2012 46 2019 40 723 40 2059 46 2006 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 46 2044 40 362 44 362 44 362 41 41 44 91 40 362 44 362 44 362 41 93 41 330 2012 46 2019 40 723 40 2059 46 2006 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 46 2044 40 362 44 362 41 41 44 91 40 362 44 362 41 93 41 2012 46 2019 40 723 40 2059 46 2006 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 46 2044 40 362 44 2045 61 515 41 41 44 91 362 93 41 330 2012 46 2019 40 723 40 2059 46 2006 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 46 2044 40 362 44 362 41 41 44 91 40 362 44 362 41 93 41 2012 46 2019 40 723 40 2059 46 2006 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 46 2044 40 362 44 362 41 41 44 91 40 362 44 2058 46 2020 41 93 41 2012 46 2019 40 723 40 2059 46 2006 46 2027 40 2038 61 123 362 58 362 44 362 58 362 44 362 58 362 125 41 46 2044 40 362 44 362 44 362 44 362 41 41 44 91 40 362 44 362 44 362 44 2058 46 2020 41 93 41 612 2063 40 2012 41 58 362 2058 61 2059 40 2060 61 362 44 2061 61 362 44 2062 61 362 41 2058 46 2024 40 41 2012 46 2019 40 723 40 2059 46 2006 46 2027 40 2038 61 123 362 58 1501 125 41 46 2040 40 362 41 41 44 91 123 362 58 2058 46 2020 125 93 41 2012 46 2048 40 2059 46 2006 46 656 40 2064 61 2059 46 2006 46 2027 40 2038 61 123 362 58 1501 125 41 46 2040 40 362 41 41 44 91 2058 93 44 41 2012 46 2019 40 723 40 2059 46 2006 46 2040 40 362 41 46 2027 40 2038 61 123 362 58 1501 125 41 41 44 91 123 362 58 2058 46 2020 125 93 41 2012 46 2048 40 2059 46 2006 46 656 40 2064 61 2059 46 2006 46 2040 40 362 41 46 2027 40 2038 61 123 362 58 1501 125 41 41 44 91 2058 93 44 41 2012 46 2048 40 2059 46 2006 46 656 40 2020 61 2058 46 2020 41 124 2059 46 2006 46 2027 40 2028 61 91 362 93 44 2047 61 91 2058 46 2020 93 41 44 91 2058 93 44 41 612 2065 40 2012 41 58 362 330 2066 61 2059 46 2006 46 2015 40 2060 61 362 44 2061 61 362 44 2062 61 362 41 330 2067 61 2059 46 2006 46 2015 40 2060 61 362 44 2061 61 362 44 2062 61 362 41 330 2068 61 2059 40 2060 61 362 44 2061 61 362 44 2062 61 362 41 2068 46 2024 40 41 330 2068 61 2059 40 2060 61 362 44 2061 61 362 44 2062 61 362 41 2068 46 2024 40 41 330 2068 61 2059 40 2060 61 362 44 2061 61 362 44 2062 61 362 41 2068 46 2024 40 41 330 2068 61 2059 40 2060 61 362 44 2061 61 362 44 2062 61 362 41 2068 46 2024 40 41 2012 46 2069 40 2059 46 2006 46 2027 40 2028 61 91 362 44 362 93 44 41 44 91 2066 44 2067 93 44 41 612 2070 40 2012 41 58 2066 61 2059 46 2006 46 2015 40 2060 61 362 44 2061 61 362 44 2062 61 362 41 2067 61 2059 46 2006 46 2015 40 2060 61 362 44 2061 61 362 44 2062 61 362 41 2026 61 2059 46 2006 46 2027 40 2038 61 123 362 58 362 125 41 46 2044 40 362 44 2045 61 515 41 46 2054 40 41 2012 46 2048 40 2026 46 2052 40 362 41 44 91 2066 46 2020 44 2067 46 2020 93 41 2012 46 2048 40 2026 46 2052 40 362 41 44 91 2067 46 2020 44 2066 46 2020 93 41 330 330 330 2012 46 2048 40 2026 46 2052 40 362 41 46 2044 40 362 41 44 91 40 362 44 41 44 40 362 44 41 93 41 ,"{'AvgLine': 31, 'CountLine': 423, 'CountStmt': 89, 'MaxNesting': 0, 'AvgLineCode': 23, 'AvgEssential': 1, 'AvgLineBlank': 2, 'CountStmtExe': 75, 'MaxEssential': 1, 'SumEssential': 13, 'AvgCyclomatic': 1, 'CountLineCode': 304, 'CountStmtDecl': 28, 'MaxCyclomatic': 1, 'SumCyclomatic': 13, 'AvgLineComment': 5, 'CountClassBase': 0, 'CountLineBlank': 45, 'CountDeclMethod': 13, 'CountLineCodeExe': 289, 'CountLineComment': 74, 'CountClassCoupled': 6, 'CountClassDerived': 0, 'CountLineCodeDecl': 29, 'CountDeclMethodAll': 13, 'MaxInheritanceTree': 0, 'RatioCommentToCode': '0.24', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 1, 'SumCyclomaticStrict': 13, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 1, 'SumCyclomaticModified': 13, 'CountDeclInstanceMethod': 12, 'CountClassCoupledModified': 4, 'CountDeclInstanceVariable': 0}"
131345,Python,"class OtherModelTests(SimpleTestCase):

    def test_unique_primary_key(self):
        invalid_id = models.IntegerField(primary_key=False)

        class Model(models.Model):
            id = invalid_id

        self.assertEqual(Model.check(), [
            Error(
                ""'id' can only be used as a field name if the field also sets ""
                ""'primary_key=True'."",
                obj=Model,
                id='models.E004',
            ),
        ])

    def test_ordering_non_iterable(self):
        class Model(models.Model):
            class Meta:
                ordering = 'missing_field'

        self.assertEqual(Model.check(), [
            Error(
                ""'ordering' must be a tuple or list ""
                ""(even if you want to order by only one field)."",
                obj=Model,
                id='models.E014',
            ),
        ])

    def test_just_ordering_no_errors(self):
        class Model(models.Model):
            order = models.PositiveIntegerField()

            class Meta:
                ordering = ['order']

        self.assertEqual(Model.check(), [])

    def test_just_order_with_respect_to_no_errors(self):
        class Question(models.Model):
            pass

        class Answer(models.Model):
            question = models.ForeignKey(Question, models.CASCADE)

            class Meta:
                order_with_respect_to = 'question'

        self.assertEqual(Answer.check(), [])

    def test_ordering_with_order_with_respect_to(self):
        class Question(models.Model):
            pass

        class Answer(models.Model):
            question = models.ForeignKey(Question, models.CASCADE)
            order = models.IntegerField()

            class Meta:
                order_with_respect_to = 'question'
                ordering = ['order']

        self.assertEqual(Answer.check(), [
            Error(
                ""'ordering' and 'order_with_respect_to' cannot be used together."",
                obj=Answer,
                id='models.E021',
            ),
        ])

    def test_non_valid(self):
        class RelationModel(models.Model):
            pass

        class Model(models.Model):
            relation = models.ManyToManyField(RelationModel)

            class Meta:
                ordering = ['relation']

        self.assertEqual(Model.check(), [
            Error(
                ""'ordering' refers to the nonexistent field, related field, ""
                ""or lookup 'relation'."",
                obj=Model,
                id='models.E015',
            ),
        ])

    def test_ordering_pointing_to_missing_field(self):
        class Model(models.Model):
            class Meta:
                ordering = ('missing_field',)

        self.assertEqual(Model.check(), [
            Error(
                ""'ordering' refers to the nonexistent field, related field, ""
                ""or lookup 'missing_field'."",
                obj=Model,
                id='models.E015',
            )
        ])

    def test_ordering_pointing_to_missing_foreignkey_field(self):
        class Model(models.Model):
            missing_fk_field = models.IntegerField()

            class Meta:
                ordering = ('missing_fk_field_id',)

        self.assertEqual(Model.check(), [
            Error(
                ""'ordering' refers to the nonexistent field, related field, ""
                ""or lookup 'missing_fk_field_id'."",
                obj=Model,
                id='models.E015',
            )
        ])

    def test_ordering_pointing_to_missing_related_field(self):
        class Model(models.Model):
            test = models.IntegerField()

            class Meta:
                ordering = ('missing_related__id',)

        self.assertEqual(Model.check(), [
            Error(
                ""'ordering' refers to the nonexistent field, related field, ""
                ""or lookup 'missing_related__id'."",
                obj=Model,
                id='models.E015',
            )
        ])

    def test_ordering_pointing_to_missing_related_model_field(self):
        class Parent(models.Model):
            pass

        class Child(models.Model):
            parent = models.ForeignKey(Parent, models.CASCADE)

            class Meta:
                ordering = ('parent__missing_field',)

        self.assertEqual(Child.check(), [
            Error(
                ""'ordering' refers to the nonexistent field, related field, ""
                ""or lookup 'parent__missing_field'."",
                obj=Child,
                id='models.E015',
            )
        ])

    def test_ordering_pointing_to_non_related_field(self):
        class Child(models.Model):
            parent = models.IntegerField()

            class Meta:
                ordering = ('parent__missing_field',)

        self.assertEqual(Child.check(), [
            Error(
                ""'ordering' refers to the nonexistent field, related field, ""
                ""or lookup 'parent__missing_field'."",
                obj=Child,
                id='models.E015',
            )
        ])

    def test_ordering_pointing_to_two_related_model_field(self):
        class Parent2(models.Model):
            pass

        class Parent1(models.Model):
            parent2 = models.ForeignKey(Parent2, models.CASCADE)

        class Child(models.Model):
            parent1 = models.ForeignKey(Parent1, models.CASCADE)

            class Meta:
                ordering = ('parent1__parent2__missing_field',)

        self.assertEqual(Child.check(), [
            Error(
                ""'ordering' refers to the nonexistent field, related field, ""
                ""or lookup 'parent1__parent2__missing_field'."",
                obj=Child,
                id='models.E015',
            )
        ])

    def test_ordering_pointing_multiple_times_to_model_fields(self):
        class Parent(models.Model):
            field1 = models.CharField(max_length=100)
            field2 = models.CharField(max_length=100)

        class Child(models.Model):
            parent = models.ForeignKey(Parent, models.CASCADE)

            class Meta:
                ordering = ('parent__field1__field2',)

        self.assertEqual(Child.check(), [
            Error(
                ""'ordering' refers to the nonexistent field, related field, ""
                ""or lookup 'parent__field1__field2'."",
                obj=Child,
                id='models.E015',
            )
        ])

    def test_ordering_allows_registered_lookups(self):
        class Model(models.Model):
            test = models.CharField(max_length=100)

            class Meta:
                ordering = ('test__lower',)

        with register_lookup(models.CharField, Lower):
            self.assertEqual(Model.check(), [])

    def test_ordering_pointing_to_lookup_not_transform(self):
        class Model(models.Model):
            test = models.CharField(max_length=100)

            class Meta:
                ordering = ('test__isnull',)

        self.assertEqual(Model.check(), [])

    def test_ordering_pointing_to_related_model_pk(self):
        class Parent(models.Model):
            pass

        class Child(models.Model):
            parent = models.ForeignKey(Parent, models.CASCADE)

            class Meta:
                ordering = ('parent__pk',)

        self.assertEqual(Child.check(), [])

    def test_ordering_pointing_to_foreignkey_field(self):
        class Parent(models.Model):
            pass

        class Child(models.Model):
            parent = models.ForeignKey(Parent, models.CASCADE)

            class Meta:
                ordering = ('parent_id',)

        self.assertFalse(Child.check())

    def test_name_beginning_with_underscore(self):
        class _Model(models.Model):
            pass

        self.assertEqual(_Model.check(), [
            Error(
                ""The model name '_Model' cannot start or end with an underscore ""
                ""as it collides with the query lookup syntax."",
                obj=_Model,
                id='models.E023',
            )
        ])

    def test_name_ending_with_underscore(self):
        class Model_(models.Model):
            pass

        self.assertEqual(Model_.check(), [
            Error(
                ""The model name 'Model_' cannot start or end with an underscore ""
                ""as it collides with the query lookup syntax."",
                obj=Model_,
                id='models.E023',
            )
        ])

    def test_name_contains_double_underscores(self):
        class Test__Model(models.Model):
            pass

        self.assertEqual(Test__Model.check(), [
            Error(
                ""The model name 'Test__Model' cannot contain double underscores ""
                ""as it collides with the query lookup syntax."",
                obj=Test__Model,
                id='models.E024',
            )
        ])

    def test_property_and_related_field_accessor_clash(self):
        class Model(models.Model):
            fk = models.ForeignKey('self', models.CASCADE)

        # Override related field accessor.
        Model.fk_id = property(lambda self: 'ERROR')

        self.assertEqual(Model.check(), [
            Error(
                ""The property 'fk_id' clashes with a related field accessor."",
                obj=Model,
                id='models.E025',
            )
        ])

    def test_single_primary_key(self):
        class Model(models.Model):
            foo = models.IntegerField(primary_key=True)
            bar = models.IntegerField(primary_key=True)

        self.assertEqual(Model.check(), [
            Error(
                ""The model cannot have more than one field with 'primary_key=True'."",
                obj=Model,
                id='models.E026',
            )
        ])

    @override_settings(TEST_SWAPPED_MODEL_BAD_VALUE='not-a-model')
    def test_swappable_missing_app_name(self):
        class Model(models.Model):
            class Meta:
                swappable = 'TEST_SWAPPED_MODEL_BAD_VALUE'

        self.assertEqual(Model.check(), [
            Error(
                ""'TEST_SWAPPED_MODEL_BAD_VALUE' is not of the form 'app_label.app_name'."",
                id='models.E001',
            ),
        ])

    @override_settings(TEST_SWAPPED_MODEL_BAD_MODEL='not_an_app.Target')
    def test_swappable_missing_app(self):
        class Model(models.Model):
            class Meta:
                swappable = 'TEST_SWAPPED_MODEL_BAD_MODEL'

        self.assertEqual(Model.check(), [
            Error(
                ""'TEST_SWAPPED_MODEL_BAD_MODEL' references 'not_an_app.Target', ""
                'which has not been installed, or is abstract.',
                id='models.E002',
            ),
        ])

    def test_two_m2m_through_same_relationship(self):
        class Person(models.Model):
            pass

        class Group(models.Model):
            primary = models.ManyToManyField(Person, through='Membership', related_name='primary')
            secondary = models.ManyToManyField(Person, through='Membership', related_name='secondary')

        class Membership(models.Model):
            person = models.ForeignKey(Person, models.CASCADE)
            group = models.ForeignKey(Group, models.CASCADE)

        self.assertEqual(Group.check(), [
            Error(
                ""The model has two identical many-to-many relations through ""
                ""the intermediate model 'invalid_models_tests.Membership'."",
                obj=Group,
                id='models.E003',
            )
        ])

    def test_two_m2m_through_same_model_with_different_through_fields(self):
        class Country(models.Model):
            pass

        class ShippingMethod(models.Model):
            to_countries = models.ManyToManyField(
                Country, through='ShippingMethodPrice',
                through_fields=('method', 'to_country'),
            )
            from_countries = models.ManyToManyField(
                Country, through='ShippingMethodPrice',
                through_fields=('method', 'from_country'),
                related_name='+',
            )

        class ShippingMethodPrice(models.Model):
            method = models.ForeignKey(ShippingMethod, models.CASCADE)
            to_country = models.ForeignKey(Country, models.CASCADE)
            from_country = models.ForeignKey(Country, models.CASCADE)

        self.assertEqual(ShippingMethod.check(), [])

    def test_onetoone_with_parent_model(self):
        class Place(models.Model):
            pass

        class ParkingLot(Place):
            other_place = models.OneToOneField(Place, models.CASCADE, related_name='other_parking')

        self.assertEqual(ParkingLot.check(), [])

    def test_onetoone_with_explicit_parent_link_parent_model(self):
        class Place(models.Model):
            pass

        class ParkingLot(Place):
            place = models.OneToOneField(Place, models.CASCADE, parent_link=True, primary_key=True)
            other_place = models.OneToOneField(Place, models.CASCADE, related_name='other_parking')

        self.assertEqual(ParkingLot.check(), [])

    def test_m2m_table_name_clash(self):
        class Foo(models.Model):
            bar = models.ManyToManyField('Bar', db_table='myapp_bar')

            class Meta:
                db_table = 'myapp_foo'

        class Bar(models.Model):
            class Meta:
                db_table = 'myapp_bar'

        self.assertEqual(Foo.check(), [
            Error(
                ""The field's intermediary table 'myapp_bar' clashes with the ""
                ""table name of 'invalid_models_tests.Bar'."",
                obj=Foo._meta.get_field('bar'),
                id='fields.E340',
            )
        ])

    @override_settings(DATABASE_ROUTERS=['invalid_models_tests.test_models.EmptyRouter'])
    def test_m2m_table_name_clash_database_routers_installed(self):
        class Foo(models.Model):
            bar = models.ManyToManyField('Bar', db_table='myapp_bar')

            class Meta:
                db_table = 'myapp_foo'

        class Bar(models.Model):
            class Meta:
                db_table = 'myapp_bar'

        self.assertEqual(Foo.check(), [
            Warning(
                ""The field's intermediary table 'myapp_bar' clashes with the ""
                ""table name of 'invalid_models_tests.Bar'."",
                obj=Foo._meta.get_field('bar'),
                hint=(
                    ""You have configured settings.DATABASE_ROUTERS. Verify ""
                    ""that the table of 'invalid_models_tests.Bar' is ""
                    ""correctly routed to a separate database.""
                ),
                id='fields.W344',
            ),
        ])

    def test_m2m_field_table_name_clash(self):
        class Foo(models.Model):
            pass

        class Bar(models.Model):
            foos = models.ManyToManyField(Foo, db_table='clash')

        class Baz(models.Model):
            foos = models.ManyToManyField(Foo, db_table='clash')

        self.assertEqual(Bar.check() + Baz.check(), [
            Error(
                ""The field's intermediary table 'clash' clashes with the ""
                ""table name of 'invalid_models_tests.Baz.foos'."",
                obj=Bar._meta.get_field('foos'),
                id='fields.E340',
            ),
            Error(
                ""The field's intermediary table 'clash' clashes with the ""
                ""table name of 'invalid_models_tests.Bar.foos'."",
                obj=Baz._meta.get_field('foos'),
                id='fields.E340',
            )
        ])

    @override_settings(DATABASE_ROUTERS=['invalid_models_tests.test_models.EmptyRouter'])
    def test_m2m_field_table_name_clash_database_routers_installed(self):
        class Foo(models.Model):
            pass

        class Bar(models.Model):
            foos = models.ManyToManyField(Foo, db_table='clash')

        class Baz(models.Model):
            foos = models.ManyToManyField(Foo, db_table='clash')

        self.assertEqual(Bar.check() + Baz.check(), [
            Warning(
                ""The field's intermediary table 'clash' clashes with the ""
                ""table name of 'invalid_models_tests.%s.foos'.""
                % clashing_model,
                obj=model_cls._meta.get_field('foos'),
                hint=(
                    ""You have configured settings.DATABASE_ROUTERS. Verify ""
                    ""that the table of 'invalid_models_tests.%s.foos' is ""
                    ""correctly routed to a separate database."" % clashing_model
                ),
                id='fields.W344',
            ) for model_cls, clashing_model in [(Bar, 'Baz'), (Baz, 'Bar')]
        ])

    def test_m2m_autogenerated_table_name_clash(self):
        class Foo(models.Model):
            class Meta:
                db_table = 'bar_foos'

        class Bar(models.Model):
            # The autogenerated `db_table` will be bar_foos.
            foos = models.ManyToManyField(Foo)

            class Meta:
                db_table = 'bar'

        self.assertEqual(Bar.check(), [
            Error(
                ""The field's intermediary table 'bar_foos' clashes with the ""
                ""table name of 'invalid_models_tests.Foo'."",
                obj=Bar._meta.get_field('foos'),
                id='fields.E340',
            )
        ])

    @override_settings(DATABASE_ROUTERS=['invalid_models_tests.test_models.EmptyRouter'])
    def test_m2m_autogenerated_table_name_clash_database_routers_installed(self):
        class Foo(models.Model):
            class Meta:
                db_table = 'bar_foos'

        class Bar(models.Model):
            # The autogenerated db_table is bar_foos.
            foos = models.ManyToManyField(Foo)

            class Meta:
                db_table = 'bar'

        self.assertEqual(Bar.check(), [
            Warning(
                ""The field's intermediary table 'bar_foos' clashes with the ""
                ""table name of 'invalid_models_tests.Foo'."",
                obj=Bar._meta.get_field('foos'),
                hint=(
                    ""You have configured settings.DATABASE_ROUTERS. Verify ""
                    ""that the table of 'invalid_models_tests.Foo' is ""
                    ""correctly routed to a separate database.""
                ),
                id='fields.W344',
            ),
        ])

    def test_m2m_unmanaged_shadow_models_not_checked(self):
        class A1(models.Model):
            pass

        class C1(models.Model):
            mm_a = models.ManyToManyField(A1, db_table='d1')

        # Unmanaged models that shadow the above models. Reused table names
        # shouldn't be flagged by any checks.
        class A2(models.Model):
            class Meta:
                managed = False

        class C2(models.Model):
            mm_a = models.ManyToManyField(A2, through='Intermediate')

            class Meta:
                managed = False

        class Intermediate(models.Model):
            a2 = models.ForeignKey(A2, models.CASCADE, db_column='a1_id')
            c2 = models.ForeignKey(C2, models.CASCADE, db_column='c1_id')

            class Meta:
                db_table = 'd1'
                managed = False

        self.assertEqual(C1.check(), [])
        self.assertEqual(C2.check(), [])

    def test_m2m_to_concrete_and_proxy_allowed(self):
        class A(models.Model):
            pass

        class Through(models.Model):
            a = models.ForeignKey('A', models.CASCADE)
            c = models.ForeignKey('C', models.CASCADE)

        class ThroughProxy(Through):
            class Meta:
                proxy = True

        class C(models.Model):
            mm_a = models.ManyToManyField(A, through=Through)
            mm_aproxy = models.ManyToManyField(A, through=ThroughProxy, related_name='proxied_m2m')

        self.assertEqual(C.check(), [])

    @isolate_apps('django.contrib.auth', kwarg_name='apps')
    def test_lazy_reference_checks(self, apps):
        class DummyModel(models.Model):
            author = models.ForeignKey('Author', models.CASCADE)

            class Meta:
                app_label = 'invalid_models_tests'

        class DummyClass:
            def __call__(self, **kwargs):
                pass

            def dummy_method(self):
                pass

        def dummy_function(*args, **kwargs):
            pass

        apps.lazy_model_operation(dummy_function, ('auth', 'imaginarymodel'))
        apps.lazy_model_operation(dummy_function, ('fanciful_app', 'imaginarymodel'))

        post_init.connect(dummy_function, sender='missing-app.Model', apps=apps)
        post_init.connect(DummyClass(), sender='missing-app.Model', apps=apps)
        post_init.connect(DummyClass().dummy_method, sender='missing-app.Model', apps=apps)

        self.assertEqual(_check_lazy_references(apps), [
            Error(
                ""%r contains a lazy reference to auth.imaginarymodel, ""
                ""but app 'auth' doesn't provide model 'imaginarymodel'."" % dummy_function,
                obj=dummy_function,
                id='models.E022',
            ),
            Error(
                ""%r contains a lazy reference to fanciful_app.imaginarymodel, ""
                ""but app 'fanciful_app' isn't installed."" % dummy_function,
                obj=dummy_function,
                id='models.E022',
            ),
            Error(
                ""An instance of class 'DummyClass' was connected to ""
                ""the 'post_init' signal with a lazy reference to the sender ""
                ""'missing-app.model', but app 'missing-app' isn't installed."",
                hint=None,
                obj='invalid_models_tests.test_models',
                id='signals.E001',
            ),
            Error(
                ""Bound method 'DummyClass.dummy_method' was connected to the ""
                ""'post_init' signal with a lazy reference to the sender ""
                ""'missing-app.model', but app 'missing-app' isn't installed."",
                hint=None,
                obj='invalid_models_tests.test_models',
                id='signals.E001',
            ),
            Error(
                ""The field invalid_models_tests.DummyModel.author was declared ""
                ""with a lazy reference to 'invalid_models_tests.author', but app ""
                ""'invalid_models_tests' isn't installed."",
                hint=None,
                obj=DummyModel.author.field,
                id='fields.E307',
            ),
            Error(
                ""The function 'dummy_function' was connected to the 'post_init' ""
                ""signal with a lazy reference to the sender ""
                ""'missing-app.model', but app 'missing-app' isn't installed."",
                hint=None,
                obj='invalid_models_tests.test_models',
                id='signals.E001',
            ),
        ])",1,587 2000 40 2001 41 58 612 2002 40 2003 41 58 2004 61 2005 46 2006 40 2007 61 443 41 587 2008 40 2005 46 2008 41 58 687 61 2004 2003 46 2009 40 2008 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2008 44 687 61 362 44 41 44 93 41 612 2013 40 2003 41 58 587 2008 40 2005 46 2008 41 58 587 2014 58 2015 61 362 2003 46 2009 40 2008 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2008 44 687 61 362 44 41 44 93 41 612 2016 40 2003 41 58 587 2008 40 2005 46 2008 41 58 2017 61 2005 46 2018 40 41 587 2014 58 2015 61 91 362 93 2003 46 2009 40 2008 46 2010 40 41 44 91 93 41 612 2019 40 2003 41 58 587 2020 40 2005 46 2008 41 58 767 587 2021 40 2005 46 2008 41 58 2022 61 2005 46 2023 40 2020 44 2005 46 2024 41 587 2014 58 2025 61 362 2003 46 2009 40 2021 46 2010 40 41 44 91 93 41 612 2026 40 2003 41 58 587 2020 40 2005 46 2008 41 58 767 587 2021 40 2005 46 2008 41 58 2022 61 2005 46 2023 40 2020 44 2005 46 2024 41 2017 61 2005 46 2006 40 41 587 2014 58 2025 61 362 2015 61 91 362 93 2003 46 2009 40 2021 46 2010 40 41 44 91 2011 40 362 44 2012 61 2021 44 687 61 362 44 41 44 93 41 612 2027 40 2003 41 58 587 2028 40 2005 46 2008 41 58 767 587 2008 40 2005 46 2008 41 58 2029 61 2005 46 2030 40 2028 41 587 2014 58 2015 61 91 362 93 2003 46 2009 40 2008 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2008 44 687 61 362 44 41 44 93 41 612 2031 40 2003 41 58 587 2008 40 2005 46 2008 41 58 587 2014 58 2015 61 40 362 44 41 2003 46 2009 40 2008 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2008 44 687 61 362 44 41 93 41 612 2032 40 2003 41 58 587 2008 40 2005 46 2008 41 58 2033 61 2005 46 2006 40 41 587 2014 58 2015 61 40 362 44 41 2003 46 2009 40 2008 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2008 44 687 61 362 44 41 93 41 612 2034 40 2003 41 58 587 2008 40 2005 46 2008 41 58 2035 61 2005 46 2006 40 41 587 2014 58 2015 61 40 362 44 41 2003 46 2009 40 2008 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2008 44 687 61 362 44 41 93 41 612 2036 40 2003 41 58 587 2037 40 2005 46 2008 41 58 767 587 2038 40 2005 46 2008 41 58 2039 61 2005 46 2023 40 2037 44 2005 46 2024 41 587 2014 58 2015 61 40 362 44 41 2003 46 2009 40 2038 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2038 44 687 61 362 44 41 93 41 612 2040 40 2003 41 58 587 2038 40 2005 46 2008 41 58 2039 61 2005 46 2006 40 41 587 2014 58 2015 61 40 362 44 41 2003 46 2009 40 2038 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2038 44 687 61 362 44 41 93 41 612 2041 40 2003 41 58 587 2042 40 2005 46 2008 41 58 767 587 2043 40 2005 46 2008 41 58 2044 61 2005 46 2023 40 2042 44 2005 46 2024 41 587 2038 40 2005 46 2008 41 58 2045 61 2005 46 2023 40 2043 44 2005 46 2024 41 587 2014 58 2015 61 40 362 44 41 2003 46 2009 40 2038 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2038 44 687 61 362 44 41 93 41 612 2046 40 2003 41 58 587 2037 40 2005 46 2008 41 58 2047 61 2005 46 2048 40 2049 61 1503 41 2050 61 2005 46 2048 40 2049 61 1503 41 587 2038 40 2005 46 2008 41 58 2039 61 2005 46 2023 40 2037 44 2005 46 2024 41 587 2014 58 2015 61 40 362 44 41 2003 46 2009 40 2038 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2038 44 687 61 362 44 41 93 41 612 2051 40 2003 41 58 587 2008 40 2005 46 2008 41 58 2035 61 2005 46 2048 40 2049 61 1503 41 587 2014 58 2015 61 40 362 44 41 871 2052 40 2005 46 2048 44 2053 41 58 2003 46 2009 40 2008 46 2010 40 41 44 91 93 41 612 2054 40 2003 41 58 587 2008 40 2005 46 2008 41 58 2035 61 2005 46 2048 40 2049 61 1503 41 587 2014 58 2015 61 40 362 44 41 2003 46 2009 40 2008 46 2010 40 41 44 91 93 41 612 2055 40 2003 41 58 587 2037 40 2005 46 2008 41 58 767 587 2038 40 2005 46 2008 41 58 2039 61 2005 46 2023 40 2037 44 2005 46 2024 41 587 2014 58 2015 61 40 362 44 41 2003 46 2009 40 2038 46 2010 40 41 44 91 93 41 612 2056 40 2003 41 58 587 2037 40 2005 46 2008 41 58 767 587 2038 40 2005 46 2008 41 58 2039 61 2005 46 2023 40 2037 44 2005 46 2024 41 587 2014 58 2015 61 40 362 44 41 2003 46 2057 40 2038 46 2010 40 41 41 612 2058 40 2003 41 58 587 2059 40 2005 46 2008 41 58 767 2003 46 2009 40 2059 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2059 44 687 61 362 44 41 93 41 612 2060 40 2003 41 58 587 2061 40 2005 46 2008 41 58 767 2003 46 2009 40 2061 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2061 44 687 61 362 44 41 93 41 612 2062 40 2003 41 58 587 2063 40 2005 46 2008 41 58 767 2003 46 2009 40 2063 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2063 44 687 61 362 44 41 93 41 612 2064 40 2003 41 58 587 2008 40 2005 46 2008 41 58 2065 61 2005 46 2023 40 362 44 2005 46 2024 41 330 2008 46 2066 61 774 40 719 2003 58 362 41 2003 46 2009 40 2008 46 2010 40 41 44 91 2011 40 362 44 2012 61 2008 44 687 61 362 44 41 93 41 612 2067 40 2003 41 58 587 2008 40 2005 46 2008 41 58 2068 61 2005 46 2006 40 2007 61 515 41 2069 61 2005 46 2006 40 2007 61 515 41 2003 46 2009 40 2008 46 2010 40 41 44 91 2011 40 362 44 2012 61 2008 44 687 61 362 44 41 93 41 64 2070 40 2071 61 362 41 612 2072 40 2003 41 58 587 2008 40 2005 46 2008 41 58 587 2014 58 2073 61 362 2003 46 2009 40 2008 46 2010 40 41 44 91 2011 40 362 44 687 61 362 44 41 44 93 41 64 2070 40 2074 61 362 41 612 2075 40 2003 41 58 587 2008 40 2005 46 2008 41 58 587 2014 58 2073 61 362 2003 46 2009 40 2008 46 2010 40 41 44 91 2011 40 362 362 44 687 61 362 44 41 44 93 41 612 2076 40 2003 41 58 587 2077 40 2005 46 2008 41 58 767 587 2078 40 2005 46 2008 41 58 2079 61 2005 46 2030 40 2077 44 2080 61 362 44 2081 61 362 41 2082 61 2005 46 2030 40 2077 44 2080 61 362 44 2081 61 362 41 587 2083 40 2005 46 2008 41 58 2084 61 2005 46 2023 40 2077 44 2005 46 2024 41 2085 61 2005 46 2023 40 2078 44 2005 46 2024 41 2003 46 2009 40 2078 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2078 44 687 61 362 44 41 93 41 612 2086 40 2003 41 58 587 2087 40 2005 46 2008 41 58 767 587 2088 40 2005 46 2008 41 58 2089 61 2005 46 2030 40 2087 44 2080 61 362 44 2090 61 40 362 44 362 41 44 41 2091 61 2005 46 2030 40 2087 44 2080 61 362 44 2090 61 40 362 44 362 41 44 2081 61 362 44 41 587 2092 40 2005 46 2008 41 58 2093 61 2005 46 2023 40 2088 44 2005 46 2024 41 2094 61 2005 46 2023 40 2087 44 2005 46 2024 41 2095 61 2005 46 2023 40 2087 44 2005 46 2024 41 2003 46 2009 40 2088 46 2010 40 41 44 91 93 41 612 2096 40 2003 41 58 587 2097 40 2005 46 2008 41 58 767 587 2098 40 2097 41 58 2099 61 2005 46 2100 40 2097 44 2005 46 2024 44 2081 61 362 41 2003 46 2009 40 2098 46 2010 40 41 44 91 93 41 612 2101 40 2003 41 58 587 2097 40 2005 46 2008 41 58 767 587 2098 40 2097 41 58 2102 61 2005 46 2100 40 2097 44 2005 46 2024 44 2103 61 515 44 2007 61 515 41 2099 61 2005 46 2100 40 2097 44 2005 46 2024 44 2081 61 362 41 2003 46 2009 40 2098 46 2010 40 41 44 91 93 41 612 2104 40 2003 41 58 587 2105 40 2005 46 2008 41 58 2069 61 2005 46 2030 40 362 44 2106 61 362 41 587 2014 58 2106 61 362 587 2107 40 2005 46 2008 41 58 587 2014 58 2106 61 362 2003 46 2009 40 2105 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2105 46 2108 46 2109 40 362 41 44 687 61 362 44 41 93 41 64 2070 40 2110 61 91 362 93 41 612 2111 40 2003 41 58 587 2105 40 2005 46 2008 41 58 2069 61 2005 46 2030 40 362 44 2106 61 362 41 587 2014 58 2106 61 362 587 2107 40 2005 46 2008 41 58 587 2014 58 2106 61 362 2003 46 2009 40 2105 46 2010 40 41 44 91 2112 40 362 362 44 2012 61 2105 46 2108 46 2109 40 362 41 44 2113 61 40 362 362 362 41 44 687 61 362 44 41 44 93 41 612 2114 40 2003 41 58 587 2105 40 2005 46 2008 41 58 767 587 2107 40 2005 46 2008 41 58 2115 61 2005 46 2030 40 2105 44 2106 61 362 41 587 2116 40 2005 46 2008 41 58 2115 61 2005 46 2030 40 2105 44 2106 61 362 41 2003 46 2009 40 2107 46 2010 40 41 43 2116 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2107 46 2108 46 2109 40 362 41 44 687 61 362 44 41 44 2011 40 362 362 44 2012 61 2116 46 2108 46 2109 40 362 41 44 687 61 362 44 41 93 41 64 2070 40 2110 61 91 362 93 41 612 2117 40 2003 41 58 587 2105 40 2005 46 2008 41 58 767 587 2107 40 2005 46 2008 41 58 2115 61 2005 46 2030 40 2105 44 2106 61 362 41 587 2116 40 2005 46 2008 41 58 2115 61 2005 46 2030 40 2105 44 2106 61 362 41 2003 46 2009 40 2107 46 2010 40 41 43 2116 46 2010 40 41 44 91 2112 40 362 362 37 2118 44 2012 61 2119 46 2108 46 2109 40 362 41 44 2113 61 40 362 362 362 37 2118 41 44 687 61 362 44 41 664 2119 44 2118 696 91 40 2107 44 362 41 44 40 2116 44 362 41 93 93 41 612 2120 40 2003 41 58 587 2105 40 2005 46 2008 41 58 587 2014 58 2106 61 362 587 2107 40 2005 46 2008 41 58 330 2115 61 2005 46 2030 40 2105 41 587 2014 58 2106 61 362 2003 46 2009 40 2107 46 2010 40 41 44 91 2011 40 362 362 44 2012 61 2107 46 2108 46 2109 40 362 41 44 687 61 362 44 41 93 41 64 2070 40 2110 61 91 362 93 41 612 2121 40 2003 41 58 587 2105 40 2005 46 2008 41 58 587 2014 58 2106 61 362 587 2107 40 2005 46 2008 41 58 330 2115 61 2005 46 2030 40 2105 41 587 2014 58 2106 61 362 2003 46 2009 40 2107 46 2010 40 41 44 91 2112 40 362 362 44 2012 61 2107 46 2108 46 2109 40 362 41 44 2113 61 40 362 362 362 41 44 687 61 362 44 41 44 93 41 612 2122 40 2003 41 58 587 2123 40 2005 46 2008 41 58 767 587 2124 40 2005 46 2008 41 58 2125 61 2005 46 2030 40 2123 44 2106 61 362 41 330 330 587 2126 40 2005 46 2008 41 58 587 2014 58 2127 61 443 587 2128 40 2005 46 2008 41 58 2125 61 2005 46 2030 40 2126 44 2080 61 362 41 587 2014 58 2127 61 443 587 2129 40 2005 46 2008 41 58 2130 61 2005 46 2023 40 2126 44 2005 46 2024 44 2131 61 362 41 2132 61 2005 46 2023 40 2128 44 2005 46 2024 44 2131 61 362 41 587 2014 58 2106 61 362 2127 61 443 2003 46 2009 40 2124 46 2010 40 41 44 91 93 41 2003 46 2009 40 2128 46 2010 40 41 44 91 93 41 612 2133 40 2003 41 58 587 2134 40 2005 46 2008 41 58 767 587 2135 40 2005 46 2008 41 58 2136 61 2005 46 2023 40 362 44 2005 46 2024 41 2137 61 2005 46 2023 40 362 44 2005 46 2024 41 587 2138 40 2135 41 58 587 2014 58 2139 61 515 587 2140 40 2005 46 2008 41 58 2125 61 2005 46 2030 40 2134 44 2080 61 2135 41 2141 61 2005 46 2030 40 2134 44 2080 61 2138 44 2081 61 362 41 2003 46 2009 40 2140 46 2010 40 41 44 91 93 41 64 2142 40 362 44 2143 61 362 41 612 2144 40 2003 44 2145 41 58 587 2146 40 2005 46 2008 41 58 2147 61 2005 46 2023 40 362 44 2005 46 2024 41 587 2014 58 2148 61 362 587 2149 58 612 2150 40 2003 44 350 2151 41 58 767 612 2152 40 2003 41 58 767 612 2153 40 42 2154 44 350 2151 41 58 767 2145 46 2155 40 2153 44 40 362 44 362 41 41 2145 46 2155 40 2153 44 40 362 44 362 41 41 2156 46 2157 40 2153 44 2158 61 362 44 2145 61 2145 41 2156 46 2157 40 2149 40 41 44 2158 61 362 44 2145 61 2145 41 2156 46 2157 40 2149 40 41 46 2152 44 2158 61 362 44 2145 61 2145 41 2003 46 2009 40 2159 40 2145 41 44 91 2011 40 362 362 37 2153 44 2012 61 2153 44 687 61 362 44 41 44 2011 40 362 362 37 2153 44 2012 61 2153 44 687 61 362 44 41 44 2011 40 362 362 362 44 2113 61 470 44 2012 61 362 44 687 61 362 44 41 44 2011 40 362 362 362 44 2113 61 470 44 2012 61 362 44 687 61 362 44 41 44 2011 40 362 362 362 44 2113 61 470 44 2012 61 2146 46 2147 46 2160 44 687 61 362 44 41 44 2011 40 362 362 362 44 2113 61 470 44 2012 61 362 44 687 61 362 44 41 44 93 41 ,"{'AvgLine': 15, 'CountLine': 677, 'CountStmt': 291, 'MaxNesting': 1, 'AvgLineCode': 13, 'AvgEssential': 1, 'AvgLineBlank': 2, 'CountStmtExe': 151, 'MaxEssential': 1, 'SumEssential': 40, 'AvgCyclomatic': 1, 'CountLineCode': 540, 'CountStmtDecl': 224, 'MaxCyclomatic': 1, 'SumCyclomatic': 40, 'AvgLineComment': 0, 'CountClassBase': 1, 'CountLineBlank': 132, 'CountDeclMethod': 37, 'CountLineCodeExe': 394, 'CountLineComment': 5, 'CountClassCoupled': 45, 'CountClassDerived': 0, 'CountLineCodeDecl': 230, 'CountDeclMethodAll': 72, 'MaxInheritanceTree': 2, 'RatioCommentToCode': '0.01', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 1, 'SumCyclomaticStrict': 40, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 1, 'SumCyclomaticModified': 40, 'CountDeclInstanceMethod': 37, 'CountClassCoupledModified': 43, 'CountDeclInstanceVariable': 0}"
132988,Python,"class ManyToManyTests(TestCase):

    @classmethod
    def setUpTestData(cls):
        # Create a couple of Publications.
        cls.p1 = Publication.objects.create(title='The Python Journal')
        cls.p2 = Publication.objects.create(title='Science News')
        cls.p3 = Publication.objects.create(title='Science Weekly')
        cls.p4 = Publication.objects.create(title='Highlights for Children')

        cls.a1 = Article.objects.create(headline='Django lets you build web apps easily')
        cls.a1.publications.add(cls.p1)

        cls.a2 = Article.objects.create(headline='NASA uses Python')
        cls.a2.publications.add(cls.p1, cls.p2, cls.p3, cls.p4)

        cls.a3 = Article.objects.create(headline='NASA finds intelligent life on Earth')
        cls.a3.publications.add(cls.p2)

        cls.a4 = Article.objects.create(headline='Oxygen-free diet works wonders')
        cls.a4.publications.add(cls.p2)

    def test_add(self):
        # Create an Article.
        a5 = Article(headline='Django lets you create web apps easily')
        # You can't associate it with a Publication until it's been saved.
        msg = (
            '""<Article: Django lets you create web apps easily>"" needs to have '
            'a value for field ""id"" before this many-to-many relationship can be used.'
        )
        with self.assertRaisesMessage(ValueError, msg):
            getattr(a5, 'publications')
        # Save it!
        a5.save()
        # Associate the Article with a Publication.
        a5.publications.add(self.p1)
        self.assertSequenceEqual(a5.publications.all(), [self.p1])
        # Create another Article, and set it to appear in both Publications.
        a6 = Article(headline='ESA uses Python')
        a6.save()
        a6.publications.add(self.p1, self.p2)
        a6.publications.add(self.p3)
        # Adding a second time is OK
        a6.publications.add(self.p3)
        self.assertSequenceEqual(
            a6.publications.all(),
            [self.p2, self.p3, self.p1],
        )

        # Adding an object of the wrong type raises TypeError
        msg = ""'Publication' instance expected, got <Article: Django lets you create web apps easily>""
        with self.assertRaisesMessage(TypeError, msg):
            with transaction.atomic():
                a6.publications.add(a5)

        # Add a Publication directly via publications.add by using keyword arguments.
        p5 = a6.publications.create(title='Highlights for Adults')
        self.assertSequenceEqual(
            a6.publications.all(),
            [p5, self.p2, self.p3, self.p1],
        )

    def test_add_remove_set_by_pk(self):
        a5 = Article.objects.create(headline='Django lets you create web apps easily')
        a5.publications.add(self.p1.pk)
        self.assertSequenceEqual(a5.publications.all(), [self.p1])
        a5.publications.set([self.p2.pk])
        self.assertSequenceEqual(a5.publications.all(), [self.p2])
        a5.publications.remove(self.p2.pk)
        self.assertSequenceEqual(a5.publications.all(), [])

    def test_add_remove_set_by_to_field(self):
        user_1 = User.objects.create(username='Jean')
        user_2 = User.objects.create(username='Joe')
        a5 = Article.objects.create(headline='Django lets you create web apps easily')
        a5.authors.add(user_1.username)
        self.assertSequenceEqual(a5.authors.all(), [user_1])
        a5.authors.set([user_2.username])
        self.assertSequenceEqual(a5.authors.all(), [user_2])
        a5.authors.remove(user_2.username)
        self.assertSequenceEqual(a5.authors.all(), [])

    def test_add_remove_invalid_type(self):
        msg = ""Field 'id' expected a number but got 'invalid'.""
        for method in ['add', 'remove']:
            with self.subTest(method), self.assertRaisesMessage(ValueError, msg):
                getattr(self.a1.publications, method)('invalid')

    def test_reverse_add(self):
        # Adding via the 'other' end of an m2m
        a5 = Article(headline='NASA finds intelligent life on Mars')
        a5.save()
        self.p2.article_set.add(a5)
        self.assertSequenceEqual(
            self.p2.article_set.all(),
            [self.a3, a5, self.a2, self.a4],
        )
        self.assertSequenceEqual(a5.publications.all(), [self.p2])

        # Adding via the other end using keywords
        a6 = self.p2.article_set.create(headline='Carbon-free diet works wonders')
        self.assertSequenceEqual(
            self.p2.article_set.all(),
            [a6, self.a3, a5, self.a2, self.a4],
        )
        a6 = self.p2.article_set.all()[3]
        self.assertSequenceEqual(
            a6.publications.all(),
            [self.p4, self.p2, self.p3, self.p1],
        )

    @skipUnlessDBFeature('supports_ignore_conflicts')
    def test_fast_add_ignore_conflicts(self):
        """"""
        A single query is necessary to add auto-created through instances if
        the database backend supports bulk_create(ignore_conflicts) and no
        m2m_changed signals receivers are connected.
        """"""
        with self.assertNumQueries(1):
            self.a1.publications.add(self.p1, self.p2)

    @skipIfDBFeature('supports_ignore_conflicts')
    def test_add_existing_different_type(self):
        # A single SELECT query is necessary to compare existing values to the
        # provided one; no INSERT should be attempted.
        with self.assertNumQueries(1):
            self.a1.publications.add(str(self.p1.pk))
        self.assertEqual(self.a1.publications.get(), self.p1)

    @skipUnlessDBFeature('supports_ignore_conflicts')
    def test_slow_add_ignore_conflicts(self):
        manager_cls = self.a1.publications.__class__
        # Simulate a race condition between the missing ids retrieval and
        # the bulk insertion attempt.
        missing_target_ids = {self.p1.id}
        # Disable fast-add to test the case where the slow add path is taken.
        add_plan = (True, False, False)
        with mock.patch.object(manager_cls, '_get_missing_target_ids', return_value=missing_target_ids) as mocked:
            with mock.patch.object(manager_cls, '_get_add_plan', return_value=add_plan):
                self.a1.publications.add(self.p1)
        mocked.assert_called_once()

    def test_related_sets(self):
        # Article objects have access to their related Publication objects.
        self.assertSequenceEqual(self.a1.publications.all(), [self.p1])
        self.assertSequenceEqual(
            self.a2.publications.all(),
            [self.p4, self.p2, self.p3, self.p1],
        )
        # Publication objects have access to their related Article objects.
        self.assertSequenceEqual(
            self.p2.article_set.all(),
            [self.a3, self.a2, self.a4],
        )
        self.assertSequenceEqual(
            self.p1.article_set.all(),
            [self.a1, self.a2],
        )
        self.assertSequenceEqual(
            Publication.objects.get(id=self.p4.id).article_set.all(),
            [self.a2],
        )

    def test_selects(self):
        # We can perform kwarg queries across m2m relationships
        self.assertSequenceEqual(
            Article.objects.filter(publications__id__exact=self.p1.id),
            [self.a1, self.a2],
        )
        self.assertSequenceEqual(
            Article.objects.filter(publications__pk=self.p1.id),
            [self.a1, self.a2],
        )
        self.assertSequenceEqual(
            Article.objects.filter(publications=self.p1.id),
            [self.a1, self.a2],
        )
        self.assertSequenceEqual(
            Article.objects.filter(publications=self.p1),
            [self.a1, self.a2],
        )
        self.assertSequenceEqual(
            Article.objects.filter(publications__title__startswith=""Science""),
            [self.a3, self.a2, self.a2, self.a4]
        )
        self.assertSequenceEqual(
            Article.objects.filter(publications__title__startswith=""Science"").distinct(),
            [self.a3, self.a2, self.a4],
        )

        # The count() function respects distinct() as well.
        self.assertEqual(Article.objects.filter(publications__title__startswith=""Science"").count(), 4)
        self.assertEqual(Article.objects.filter(publications__title__startswith=""Science"").distinct().count(), 3)
        self.assertSequenceEqual(
            Article.objects.filter(publications__in=[self.p1.id, self.p2.id]).distinct(),
            [self.a1, self.a3, self.a2, self.a4],
        )
        self.assertSequenceEqual(
            Article.objects.filter(publications__in=[self.p1.id, self.p2]).distinct(),
            [self.a1, self.a3, self.a2, self.a4],
        )
        self.assertSequenceEqual(
            Article.objects.filter(publications__in=[self.p1, self.p2]).distinct(),
            [self.a1, self.a3, self.a2, self.a4],
        )

        # Excluding a related item works as you would expect, too (although the SQL
        # involved is a little complex).
        self.assertSequenceEqual(
            Article.objects.exclude(publications=self.p2),
            [self.a1],
        )

    def test_reverse_selects(self):
        # Reverse m2m queries are supported (i.e., starting at the table that
        # doesn't have a ManyToManyField).
        python_journal = [self.p1]
        self.assertSequenceEqual(Publication.objects.filter(id__exact=self.p1.id), python_journal)
        self.assertSequenceEqual(Publication.objects.filter(pk=self.p1.id), python_journal)
        self.assertSequenceEqual(
            Publication.objects.filter(article__headline__startswith=""NASA""),
            [self.p4, self.p2, self.p2, self.p3, self.p1],
        )

        self.assertSequenceEqual(Publication.objects.filter(article__id__exact=self.a1.id), python_journal)
        self.assertSequenceEqual(Publication.objects.filter(article__pk=self.a1.id), python_journal)
        self.assertSequenceEqual(Publication.objects.filter(article=self.a1.id), python_journal)
        self.assertSequenceEqual(Publication.objects.filter(article=self.a1), python_journal)

        self.assertSequenceEqual(
            Publication.objects.filter(article__in=[self.a1.id, self.a2.id]).distinct(),
            [self.p4, self.p2, self.p3, self.p1],
        )
        self.assertSequenceEqual(
            Publication.objects.filter(article__in=[self.a1.id, self.a2]).distinct(),
            [self.p4, self.p2, self.p3, self.p1],
        )
        self.assertSequenceEqual(
            Publication.objects.filter(article__in=[self.a1, self.a2]).distinct(),
            [self.p4, self.p2, self.p3, self.p1],
        )

    def test_delete(self):
        # If we delete a Publication, its Articles won't be able to access it.
        self.p1.delete()
        self.assertSequenceEqual(
            Publication.objects.all(),
            [self.p4, self.p2, self.p3],
        )
        self.assertSequenceEqual(self.a1.publications.all(), [])
        # If we delete an Article, its Publications won't be able to access it.
        self.a2.delete()
        self.assertSequenceEqual(
            Article.objects.all(),
            [self.a1, self.a3, self.a4],
        )
        self.assertSequenceEqual(
            self.p2.article_set.all(),
            [self.a3, self.a4],
        )

    def test_bulk_delete(self):
        # Bulk delete some Publications - references to deleted publications should go
        Publication.objects.filter(title__startswith='Science').delete()
        self.assertSequenceEqual(
            Publication.objects.all(),
            [self.p4, self.p1],
        )
        self.assertSequenceEqual(
            Article.objects.all(),
            [self.a1, self.a3, self.a2, self.a4],
        )
        self.assertSequenceEqual(
            self.a2.publications.all(),
            [self.p4, self.p1],
        )

        # Bulk delete some articles - references to deleted objects should go
        q = Article.objects.filter(headline__startswith='Django')
        self.assertSequenceEqual(q, [self.a1])
        q.delete()
        # After the delete, the QuerySet cache needs to be cleared,
        # and the referenced objects should be gone
        self.assertSequenceEqual(q, [])
        self.assertSequenceEqual(self.p1.article_set.all(), [self.a2])

    def test_remove(self):
        # Removing publication from an article:
        self.assertSequenceEqual(
            self.p2.article_set.all(),
            [self.a3, self.a2, self.a4],
        )
        self.a4.publications.remove(self.p2)
        self.assertSequenceEqual(
            self.p2.article_set.all(),
            [self.a3, self.a2],
        )
        self.assertSequenceEqual(self.a4.publications.all(), [])
        # And from the other end
        self.p2.article_set.remove(self.a3)
        self.assertSequenceEqual(self.p2.article_set.all(), [self.a2])
        self.assertSequenceEqual(self.a3.publications.all(), [])

    def test_set(self):
        self.p2.article_set.set([self.a4, self.a3])
        self.assertSequenceEqual(
            self.p2.article_set.all(),
            [self.a3, self.a4],
        )
        self.assertSequenceEqual(self.a4.publications.all(), [self.p2])
        self.a4.publications.set([self.p3.id])
        self.assertSequenceEqual(self.p2.article_set.all(), [self.a3])
        self.assertSequenceEqual(self.a4.publications.all(), [self.p3])

        self.p2.article_set.set([])
        self.assertSequenceEqual(self.p2.article_set.all(), [])
        self.a4.publications.set([])
        self.assertSequenceEqual(self.a4.publications.all(), [])

        self.p2.article_set.set([self.a4, self.a3], clear=True)
        self.assertSequenceEqual(
            self.p2.article_set.all(),
            [self.a3, self.a4],
        )
        self.assertSequenceEqual(self.a4.publications.all(), [self.p2])
        self.a4.publications.set([self.p3.id], clear=True)
        self.assertSequenceEqual(self.p2.article_set.all(), [self.a3])
        self.assertSequenceEqual(self.a4.publications.all(), [self.p3])

        self.p2.article_set.set([], clear=True)
        self.assertSequenceEqual(self.p2.article_set.all(), [])
        self.a4.publications.set([], clear=True)
        self.assertSequenceEqual(self.a4.publications.all(), [])

    def test_set_existing_different_type(self):
        # Existing many-to-many relations remain the same for values provided
        # with a different type.
        ids = set(Publication.article_set.through.objects.filter(
            article__in=[self.a4, self.a3],
            publication=self.p2,
        ).values_list('id', flat=True))
        self.p2.article_set.set([str(self.a4.pk), str(self.a3.pk)])
        new_ids = set(Publication.article_set.through.objects.filter(
            publication=self.p2,
        ).values_list('id', flat=True))
        self.assertEqual(ids, new_ids)

    def test_assign_forward(self):
        msg = (
            ""Direct assignment to the reverse side of a many-to-many set is ""
            ""prohibited. Use article_set.set() instead.""
        )
        with self.assertRaisesMessage(TypeError, msg):
            self.p2.article_set = [self.a4, self.a3]

    def test_assign_reverse(self):
        msg = (
            ""Direct assignment to the forward side of a many-to-many ""
            ""set is prohibited. Use publications.set() instead.""
        )
        with self.assertRaisesMessage(TypeError, msg):
            self.a1.publications = [self.p1, self.p2]

    def test_assign(self):
        # Relation sets can be assigned using set().
        self.p2.article_set.set([self.a4, self.a3])
        self.assertSequenceEqual(
            self.p2.article_set.all(),
            [self.a3, self.a4],
        )
        self.assertSequenceEqual(self.a4.publications.all(), [self.p2])
        self.a4.publications.set([self.p3.id])
        self.assertSequenceEqual(self.p2.article_set.all(), [self.a3])
        self.assertSequenceEqual(self.a4.publications.all(), [self.p3])

        # An alternate to calling clear() is to set an empty set.
        self.p2.article_set.set([])
        self.assertSequenceEqual(self.p2.article_set.all(), [])
        self.a4.publications.set([])
        self.assertSequenceEqual(self.a4.publications.all(), [])

    def test_assign_ids(self):
        # Relation sets can also be set using primary key values
        self.p2.article_set.set([self.a4.id, self.a3.id])
        self.assertSequenceEqual(
            self.p2.article_set.all(),
            [self.a3, self.a4],
        )
        self.assertSequenceEqual(self.a4.publications.all(), [self.p2])
        self.a4.publications.set([self.p3.id])
        self.assertSequenceEqual(self.p2.article_set.all(), [self.a3])
        self.assertSequenceEqual(self.a4.publications.all(), [self.p3])

    def test_forward_assign_with_queryset(self):
        # Querysets used in m2m assignments are pre-evaluated so their value
        # isn't affected by the clearing operation in ManyRelatedManager.set()
        # (#19816).
        self.a1.publications.set([self.p1, self.p2])

        qs = self.a1.publications.filter(title='The Python Journal')
        self.a1.publications.set(qs)

        self.assertEqual(1, self.a1.publications.count())
        self.assertEqual(1, qs.count())

    def test_reverse_assign_with_queryset(self):
        # Querysets used in M2M assignments are pre-evaluated so their value
        # isn't affected by the clearing operation in ManyRelatedManager.set()
        # (#19816).
        self.p1.article_set.set([self.a1, self.a2])

        qs = self.p1.article_set.filter(headline='Django lets you build web apps easily')
        self.p1.article_set.set(qs)

        self.assertEqual(1, self.p1.article_set.count())
        self.assertEqual(1, qs.count())

    def test_clear(self):
        # Relation sets can be cleared:
        self.p2.article_set.clear()
        self.assertSequenceEqual(self.p2.article_set.all(), [])
        self.assertSequenceEqual(self.a4.publications.all(), [])

        # And you can clear from the other end
        self.p2.article_set.add(self.a3, self.a4)
        self.assertSequenceEqual(
            self.p2.article_set.all(),
            [self.a3, self.a4],
        )
        self.assertSequenceEqual(self.a4.publications.all(), [self.p2])
        self.a4.publications.clear()
        self.assertSequenceEqual(self.a4.publications.all(), [])
        self.assertSequenceEqual(self.p2.article_set.all(), [self.a3])

    def test_clear_after_prefetch(self):
        a4 = Article.objects.prefetch_related('publications').get(id=self.a4.id)
        self.assertSequenceEqual(a4.publications.all(), [self.p2])
        a4.publications.clear()
        self.assertSequenceEqual(a4.publications.all(), [])

    def test_remove_after_prefetch(self):
        a4 = Article.objects.prefetch_related('publications').get(id=self.a4.id)
        self.assertSequenceEqual(a4.publications.all(), [self.p2])
        a4.publications.remove(self.p2)
        self.assertSequenceEqual(a4.publications.all(), [])

    def test_add_after_prefetch(self):
        a4 = Article.objects.prefetch_related('publications').get(id=self.a4.id)
        self.assertEqual(a4.publications.count(), 1)
        a4.publications.add(self.p1)
        self.assertEqual(a4.publications.count(), 2)

    def test_set_after_prefetch(self):
        a4 = Article.objects.prefetch_related('publications').get(id=self.a4.id)
        self.assertEqual(a4.publications.count(), 1)
        a4.publications.set([self.p2, self.p1])
        self.assertEqual(a4.publications.count(), 2)
        a4.publications.set([self.p1])
        self.assertEqual(a4.publications.count(), 1)

    def test_add_then_remove_after_prefetch(self):
        a4 = Article.objects.prefetch_related('publications').get(id=self.a4.id)
        self.assertEqual(a4.publications.count(), 1)
        a4.publications.add(self.p1)
        self.assertEqual(a4.publications.count(), 2)
        a4.publications.remove(self.p1)
        self.assertSequenceEqual(a4.publications.all(), [self.p2])

    def test_inherited_models_selects(self):
        """"""
        #24156 - Objects from child models where the parent's m2m field uses
        related_name='+' should be retrieved correctly.
        """"""
        a = InheritedArticleA.objects.create()
        b = InheritedArticleB.objects.create()
        a.publications.add(self.p1, self.p2)
        self.assertSequenceEqual(
            a.publications.all(),
            [self.p2, self.p1],
        )
        self.assertSequenceEqual(b.publications.all(), [])
        b.publications.add(self.p3)
        self.assertSequenceEqual(
            a.publications.all(),
            [self.p2, self.p1],
        )
        self.assertSequenceEqual(b.publications.all(), [self.p3])

    def test_custom_default_manager_exists_count(self):
        a5 = Article.objects.create(headline='deleted')
        a5.publications.add(self.p2)
        self.assertEqual(self.p2.article_set.count(), self.p2.article_set.all().count())
        self.assertEqual(self.p3.article_set.exists(), self.p3.article_set.all().exists())",1,587 2000 40 2001 41 58 64 588 612 2002 40 2003 41 58 330 2003 46 2004 61 2005 46 2006 46 2007 40 2008 61 362 41 2003 46 2009 61 2005 46 2006 46 2007 40 2008 61 362 41 2003 46 2010 61 2005 46 2006 46 2007 40 2008 61 362 41 2003 46 2011 61 2005 46 2006 46 2007 40 2008 61 362 41 2003 46 2012 61 2013 46 2006 46 2007 40 2014 61 362 41 2003 46 2012 46 2015 46 2016 40 2003 46 2004 41 2003 46 2017 61 2013 46 2006 46 2007 40 2014 61 362 41 2003 46 2017 46 2015 46 2016 40 2003 46 2004 44 2003 46 2009 44 2003 46 2010 44 2003 46 2011 41 2003 46 2018 61 2013 46 2006 46 2007 40 2014 61 362 41 2003 46 2018 46 2015 46 2016 40 2003 46 2009 41 2003 46 2019 61 2013 46 2006 46 2007 40 2014 61 362 41 2003 46 2019 46 2015 46 2016 40 2003 46 2009 41 612 2020 40 2021 41 58 330 2022 61 2013 40 2014 61 362 41 330 2023 61 40 362 362 41 871 2021 46 2024 40 2025 44 2023 41 58 673 40 2022 44 362 41 330 2022 46 2026 40 41 330 2022 46 2015 46 2016 40 2021 46 2004 41 2021 46 2027 40 2022 46 2015 46 544 40 41 44 91 2021 46 2004 93 41 330 2028 61 2013 40 2014 61 362 41 2028 46 2026 40 41 2028 46 2015 46 2016 40 2021 46 2004 44 2021 46 2009 41 2028 46 2015 46 2016 40 2021 46 2010 41 330 2028 46 2015 46 2016 40 2021 46 2010 41 2021 46 2027 40 2028 46 2015 46 544 40 41 44 91 2021 46 2009 44 2021 46 2010 44 2021 46 2004 93 44 41 330 2023 61 362 871 2021 46 2024 40 2029 44 2023 41 58 871 2030 46 2031 40 41 58 2028 46 2015 46 2016 40 2022 41 330 2032 61 2028 46 2015 46 2007 40 2008 61 362 41 2021 46 2027 40 2028 46 2015 46 544 40 41 44 91 2032 44 2021 46 2009 44 2021 46 2010 44 2021 46 2004 93 44 41 612 2033 40 2021 41 58 2022 61 2013 46 2006 46 2007 40 2014 61 362 41 2022 46 2015 46 2016 40 2021 46 2004 46 2034 41 2021 46 2027 40 2022 46 2015 46 544 40 41 44 91 2021 46 2004 93 41 2022 46 2015 46 801 40 91 2021 46 2009 46 2034 93 41 2021 46 2027 40 2022 46 2015 46 544 40 41 44 91 2021 46 2009 93 41 2022 46 2015 46 2035 40 2021 46 2009 46 2034 41 2021 46 2027 40 2022 46 2015 46 544 40 41 44 91 93 41 612 2036 40 2021 41 58 2037 61 2038 46 2006 46 2007 40 2039 61 362 41 2040 61 2038 46 2006 46 2007 40 2039 61 362 41 2022 61 2013 46 2006 46 2007 40 2014 61 362 41 2022 46 2041 46 2016 40 2037 46 2039 41 2021 46 2027 40 2022 46 2041 46 544 40 41 44 91 2037 93 41 2022 46 2041 46 801 40 91 2040 46 2039 93 41 2021 46 2027 40 2022 46 2041 46 544 40 41 44 91 2040 93 41 2022 46 2041 46 2035 40 2040 46 2039 41 2021 46 2027 40 2022 46 2041 46 544 40 41 44 91 93 41 612 2042 40 2021 41 58 2023 61 362 664 2043 696 91 362 44 362 93 58 871 2021 46 2044 40 2043 41 44 2021 46 2024 40 2025 44 2023 41 58 673 40 2021 46 2012 46 2015 44 2043 41 40 362 41 612 2045 40 2021 41 58 330 2022 61 2013 40 2014 61 362 41 2022 46 2026 40 41 2021 46 2009 46 2046 46 2016 40 2022 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2021 46 2018 44 2022 44 2021 46 2017 44 2021 46 2019 93 44 41 2021 46 2027 40 2022 46 2015 46 544 40 41 44 91 2021 46 2009 93 41 330 2028 61 2021 46 2009 46 2046 46 2007 40 2014 61 362 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2028 44 2021 46 2018 44 2022 44 2021 46 2017 44 2021 46 2019 93 44 41 2028 61 2021 46 2009 46 2046 46 544 40 41 91 1502 93 2021 46 2027 40 2028 46 2015 46 544 40 41 44 91 2021 46 2011 44 2021 46 2009 44 2021 46 2010 44 2021 46 2004 93 44 41 64 2047 40 362 41 612 2048 40 2021 41 58 362 871 2021 46 2049 40 1501 41 58 2021 46 2012 46 2015 46 2016 40 2021 46 2004 44 2021 46 2009 41 64 2050 40 362 41 612 2051 40 2021 41 58 330 330 871 2021 46 2049 40 1501 41 58 2021 46 2012 46 2015 46 2016 40 813 40 2021 46 2004 46 2034 41 41 2021 46 2052 40 2021 46 2012 46 2015 46 2053 40 41 44 2021 46 2004 41 64 2047 40 362 41 612 2054 40 2021 41 58 2055 61 2021 46 2012 46 2015 46 2056 330 330 2057 61 123 2021 46 2004 46 687 125 330 2058 61 40 515 44 443 44 443 41 871 2059 46 2060 46 755 40 2055 44 362 44 2061 61 2057 41 552 2062 58 871 2059 46 2060 46 755 40 2055 44 362 44 2061 61 2058 41 58 2021 46 2012 46 2015 46 2016 40 2021 46 2004 41 2062 46 2063 40 41 612 2064 40 2021 41 58 330 2021 46 2027 40 2021 46 2012 46 2015 46 544 40 41 44 91 2021 46 2004 93 41 2021 46 2027 40 2021 46 2017 46 2015 46 544 40 41 44 91 2021 46 2011 44 2021 46 2009 44 2021 46 2010 44 2021 46 2004 93 44 41 330 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2021 46 2018 44 2021 46 2017 44 2021 46 2019 93 44 41 2021 46 2027 40 2021 46 2004 46 2046 46 544 40 41 44 91 2021 46 2012 44 2021 46 2017 93 44 41 2021 46 2027 40 2005 46 2006 46 2053 40 687 61 2021 46 2011 46 687 41 46 2046 46 544 40 41 44 91 2021 46 2017 93 44 41 612 2065 40 2021 41 58 330 2021 46 2027 40 2013 46 2006 46 656 40 2066 61 2021 46 2004 46 687 41 44 91 2021 46 2012 44 2021 46 2017 93 44 41 2021 46 2027 40 2013 46 2006 46 656 40 2067 61 2021 46 2004 46 687 41 44 91 2021 46 2012 44 2021 46 2017 93 44 41 2021 46 2027 40 2013 46 2006 46 656 40 2015 61 2021 46 2004 46 687 41 44 91 2021 46 2012 44 2021 46 2017 93 44 41 2021 46 2027 40 2013 46 2006 46 656 40 2015 61 2021 46 2004 41 44 91 2021 46 2012 44 2021 46 2017 93 44 41 2021 46 2027 40 2013 46 2006 46 656 40 2068 61 362 41 44 91 2021 46 2018 44 2021 46 2017 44 2021 46 2017 44 2021 46 2019 93 41 2021 46 2027 40 2013 46 2006 46 656 40 2068 61 362 41 46 2069 40 41 44 91 2021 46 2018 44 2021 46 2017 44 2021 46 2019 93 44 41 330 2021 46 2052 40 2013 46 2006 46 656 40 2068 61 362 41 46 2070 40 41 44 1502 41 2021 46 2052 40 2013 46 2006 46 656 40 2068 61 362 41 46 2069 40 41 46 2070 40 41 44 1502 41 2021 46 2027 40 2013 46 2006 46 656 40 2071 61 91 2021 46 2004 46 687 44 2021 46 2009 46 687 93 41 46 2069 40 41 44 91 2021 46 2012 44 2021 46 2018 44 2021 46 2017 44 2021 46 2019 93 44 41 2021 46 2027 40 2013 46 2006 46 656 40 2071 61 91 2021 46 2004 46 687 44 2021 46 2009 93 41 46 2069 40 41 44 91 2021 46 2012 44 2021 46 2018 44 2021 46 2017 44 2021 46 2019 93 44 41 2021 46 2027 40 2013 46 2006 46 656 40 2071 61 91 2021 46 2004 44 2021 46 2009 93 41 46 2069 40 41 44 91 2021 46 2012 44 2021 46 2018 44 2021 46 2017 44 2021 46 2019 93 44 41 330 330 2021 46 2027 40 2013 46 2006 46 2072 40 2015 61 2021 46 2009 41 44 91 2021 46 2012 93 44 41 612 2073 40 2021 41 58 330 330 2074 61 91 2021 46 2004 93 2021 46 2027 40 2005 46 2006 46 656 40 2075 61 2021 46 2004 46 687 41 44 2074 41 2021 46 2027 40 2005 46 2006 46 656 40 2034 61 2021 46 2004 46 687 41 44 2074 41 2021 46 2027 40 2005 46 2006 46 656 40 2076 61 362 41 44 91 2021 46 2011 44 2021 46 2009 44 2021 46 2009 44 2021 46 2010 44 2021 46 2004 93 44 41 2021 46 2027 40 2005 46 2006 46 656 40 2077 61 2021 46 2012 46 687 41 44 2074 41 2021 46 2027 40 2005 46 2006 46 656 40 2078 61 2021 46 2012 46 687 41 44 2074 41 2021 46 2027 40 2005 46 2006 46 656 40 2079 61 2021 46 2012 46 687 41 44 2074 41 2021 46 2027 40 2005 46 2006 46 656 40 2079 61 2021 46 2012 41 44 2074 41 2021 46 2027 40 2005 46 2006 46 656 40 2080 61 91 2021 46 2012 46 687 44 2021 46 2017 46 687 93 41 46 2069 40 41 44 91 2021 46 2011 44 2021 46 2009 44 2021 46 2010 44 2021 46 2004 93 44 41 2021 46 2027 40 2005 46 2006 46 656 40 2080 61 91 2021 46 2012 46 687 44 2021 46 2017 93 41 46 2069 40 41 44 91 2021 46 2011 44 2021 46 2009 44 2021 46 2010 44 2021 46 2004 93 44 41 2021 46 2027 40 2005 46 2006 46 656 40 2080 61 91 2021 46 2012 44 2021 46 2017 93 41 46 2069 40 41 44 91 2021 46 2011 44 2021 46 2009 44 2021 46 2010 44 2021 46 2004 93 44 41 612 2081 40 2021 41 58 330 2021 46 2004 46 2082 40 41 2021 46 2027 40 2005 46 2006 46 544 40 41 44 91 2021 46 2011 44 2021 46 2009 44 2021 46 2010 93 44 41 2021 46 2027 40 2021 46 2012 46 2015 46 544 40 41 44 91 93 41 330 2021 46 2017 46 2082 40 41 2021 46 2027 40 2013 46 2006 46 544 40 41 44 91 2021 46 2012 44 2021 46 2018 44 2021 46 2019 93 44 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2021 46 2018 44 2021 46 2019 93 44 41 612 2083 40 2021 41 58 330 2005 46 2006 46 656 40 2084 61 362 41 46 2082 40 41 2021 46 2027 40 2005 46 2006 46 544 40 41 44 91 2021 46 2011 44 2021 46 2004 93 44 41 2021 46 2027 40 2013 46 2006 46 544 40 41 44 91 2021 46 2012 44 2021 46 2018 44 2021 46 2017 44 2021 46 2019 93 44 41 2021 46 2027 40 2021 46 2017 46 2015 46 544 40 41 44 91 2021 46 2011 44 2021 46 2004 93 44 41 330 2085 61 2013 46 2006 46 656 40 2086 61 362 41 2021 46 2027 40 2085 44 91 2021 46 2012 93 41 2085 46 2082 40 41 330 330 2021 46 2027 40 2085 44 91 93 41 2021 46 2027 40 2021 46 2004 46 2046 46 544 40 41 44 91 2021 46 2017 93 41 612 2087 40 2021 41 58 330 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2021 46 2018 44 2021 46 2017 44 2021 46 2019 93 44 41 2021 46 2019 46 2015 46 2035 40 2021 46 2009 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2021 46 2018 44 2021 46 2017 93 44 41 2021 46 2027 40 2021 46 2019 46 2015 46 544 40 41 44 91 93 41 330 2021 46 2009 46 2046 46 2035 40 2021 46 2018 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2021 46 2017 93 41 2021 46 2027 40 2021 46 2018 46 2015 46 544 40 41 44 91 93 41 612 2088 40 2021 41 58 2021 46 2009 46 2046 46 801 40 91 2021 46 2019 44 2021 46 2018 93 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2021 46 2018 44 2021 46 2019 93 44 41 2021 46 2027 40 2021 46 2019 46 2015 46 544 40 41 44 91 2021 46 2009 93 41 2021 46 2019 46 2015 46 801 40 91 2021 46 2010 46 687 93 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2021 46 2018 93 41 2021 46 2027 40 2021 46 2019 46 2015 46 544 40 41 44 91 2021 46 2010 93 41 2021 46 2009 46 2046 46 801 40 91 93 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 93 41 2021 46 2019 46 2015 46 801 40 91 93 41 2021 46 2027 40 2021 46 2019 46 2015 46 544 40 41 44 91 93 41 2021 46 2009 46 2046 46 801 40 91 2021 46 2019 44 2021 46 2018 93 44 2089 61 515 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2021 46 2018 44 2021 46 2019 93 44 41 2021 46 2027 40 2021 46 2019 46 2015 46 544 40 41 44 91 2021 46 2009 93 41 2021 46 2019 46 2015 46 801 40 91 2021 46 2010 46 687 93 44 2089 61 515 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2021 46 2018 93 41 2021 46 2027 40 2021 46 2019 46 2015 46 544 40 41 44 91 2021 46 2010 93 41 2021 46 2009 46 2046 46 801 40 91 93 44 2089 61 515 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 93 41 2021 46 2019 46 2015 46 801 40 91 93 44 2089 61 515 41 2021 46 2027 40 2021 46 2019 46 2015 46 544 40 41 44 91 93 41 612 2090 40 2021 41 58 330 330 2091 61 801 40 2005 46 2046 46 2092 46 2006 46 656 40 2080 61 91 2021 46 2019 44 2021 46 2018 93 44 2093 61 2021 46 2009 44 41 46 2094 40 362 44 2095 61 515 41 41 2021 46 2009 46 2046 46 801 40 91 813 40 2021 46 2019 46 2034 41 44 813 40 2021 46 2018 46 2034 41 93 41 2096 61 801 40 2005 46 2046 46 2092 46 2006 46 656 40 2093 61 2021 46 2009 44 41 46 2094 40 362 44 2095 61 515 41 41 2021 46 2052 40 2091 44 2096 41 612 2097 40 2021 41 58 2023 61 40 362 362 41 871 2021 46 2024 40 2029 44 2023 41 58 2021 46 2009 46 2046 61 91 2021 46 2019 44 2021 46 2018 93 612 2098 40 2021 41 58 2023 61 40 362 362 41 871 2021 46 2024 40 2029 44 2023 41 58 2021 46 2012 46 2015 61 91 2021 46 2004 44 2021 46 2009 93 612 2099 40 2021 41 58 330 2021 46 2009 46 2046 46 801 40 91 2021 46 2019 44 2021 46 2018 93 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2021 46 2018 44 2021 46 2019 93 44 41 2021 46 2027 40 2021 46 2019 46 2015 46 544 40 41 44 91 2021 46 2009 93 41 2021 46 2019 46 2015 46 801 40 91 2021 46 2010 46 687 93 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2021 46 2018 93 41 2021 46 2027 40 2021 46 2019 46 2015 46 544 40 41 44 91 2021 46 2010 93 41 330 2021 46 2009 46 2046 46 801 40 91 93 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 93 41 2021 46 2019 46 2015 46 801 40 91 93 41 2021 46 2027 40 2021 46 2019 46 2015 46 544 40 41 44 91 93 41 612 2100 40 2021 41 58 330 2021 46 2009 46 2046 46 801 40 91 2021 46 2019 46 687 44 2021 46 2018 46 687 93 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2021 46 2018 44 2021 46 2019 93 44 41 2021 46 2027 40 2021 46 2019 46 2015 46 544 40 41 44 91 2021 46 2009 93 41 2021 46 2019 46 2015 46 801 40 91 2021 46 2010 46 687 93 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2021 46 2018 93 41 2021 46 2027 40 2021 46 2019 46 2015 46 544 40 41 44 91 2021 46 2010 93 41 612 2101 40 2021 41 58 330 330 330 2021 46 2012 46 2015 46 801 40 91 2021 46 2004 44 2021 46 2009 93 41 2102 61 2021 46 2012 46 2015 46 656 40 2008 61 362 41 2021 46 2012 46 2015 46 801 40 2102 41 2021 46 2052 40 1501 44 2021 46 2012 46 2015 46 2070 40 41 41 2021 46 2052 40 1501 44 2102 46 2070 40 41 41 612 2103 40 2021 41 58 330 330 330 2021 46 2004 46 2046 46 801 40 91 2021 46 2012 44 2021 46 2017 93 41 2102 61 2021 46 2004 46 2046 46 656 40 2014 61 362 41 2021 46 2004 46 2046 46 801 40 2102 41 2021 46 2052 40 1501 44 2021 46 2004 46 2046 46 2070 40 41 41 2021 46 2052 40 1501 44 2102 46 2070 40 41 41 612 2104 40 2021 41 58 330 2021 46 2009 46 2046 46 2089 40 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 93 41 2021 46 2027 40 2021 46 2019 46 2015 46 544 40 41 44 91 93 41 330 2021 46 2009 46 2046 46 2016 40 2021 46 2018 44 2021 46 2019 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2021 46 2018 44 2021 46 2019 93 44 41 2021 46 2027 40 2021 46 2019 46 2015 46 544 40 41 44 91 2021 46 2009 93 41 2021 46 2019 46 2015 46 2089 40 41 2021 46 2027 40 2021 46 2019 46 2015 46 544 40 41 44 91 93 41 2021 46 2027 40 2021 46 2009 46 2046 46 544 40 41 44 91 2021 46 2018 93 41 612 2105 40 2021 41 58 2019 61 2013 46 2006 46 2106 40 362 41 46 2053 40 687 61 2021 46 2019 46 687 41 2021 46 2027 40 2019 46 2015 46 544 40 41 44 91 2021 46 2009 93 41 2019 46 2015 46 2089 40 41 2021 46 2027 40 2019 46 2015 46 544 40 41 44 91 93 41 612 2107 40 2021 41 58 2019 61 2013 46 2006 46 2106 40 362 41 46 2053 40 687 61 2021 46 2019 46 687 41 2021 46 2027 40 2019 46 2015 46 544 40 41 44 91 2021 46 2009 93 41 2019 46 2015 46 2035 40 2021 46 2009 41 2021 46 2027 40 2019 46 2015 46 544 40 41 44 91 93 41 612 2108 40 2021 41 58 2019 61 2013 46 2006 46 2106 40 362 41 46 2053 40 687 61 2021 46 2019 46 687 41 2021 46 2052 40 2019 46 2015 46 2070 40 41 44 1501 41 2019 46 2015 46 2016 40 2021 46 2004 41 2021 46 2052 40 2019 46 2015 46 2070 40 41 44 1502 41 612 2109 40 2021 41 58 2019 61 2013 46 2006 46 2106 40 362 41 46 2053 40 687 61 2021 46 2019 46 687 41 2021 46 2052 40 2019 46 2015 46 2070 40 41 44 1501 41 2019 46 2015 46 801 40 91 2021 46 2009 44 2021 46 2004 93 41 2021 46 2052 40 2019 46 2015 46 2070 40 41 44 1502 41 2019 46 2015 46 801 40 91 2021 46 2004 93 41 2021 46 2052 40 2019 46 2015 46 2070 40 41 44 1501 41 612 2110 40 2021 41 58 2019 61 2013 46 2006 46 2106 40 362 41 46 2053 40 687 61 2021 46 2019 46 687 41 2021 46 2052 40 2019 46 2015 46 2070 40 41 44 1501 41 2019 46 2015 46 2016 40 2021 46 2004 41 2021 46 2052 40 2019 46 2015 46 2070 40 41 44 1502 41 2019 46 2015 46 2035 40 2021 46 2004 41 2021 46 2027 40 2019 46 2015 46 544 40 41 44 91 2021 46 2009 93 41 612 2111 40 2021 41 58 362 2112 61 2113 46 2006 46 2007 40 41 2114 61 2115 46 2006 46 2007 40 41 2112 46 2015 46 2016 40 2021 46 2004 44 2021 46 2009 41 2021 46 2027 40 2112 46 2015 46 544 40 41 44 91 2021 46 2009 44 2021 46 2004 93 44 41 2021 46 2027 40 2114 46 2015 46 544 40 41 44 91 93 41 2114 46 2015 46 2016 40 2021 46 2010 41 2021 46 2027 40 2112 46 2015 46 544 40 41 44 91 2021 46 2009 44 2021 46 2004 93 44 41 2021 46 2027 40 2114 46 2015 46 544 40 41 44 91 2021 46 2010 93 41 612 2116 40 2021 41 58 2022 61 2013 46 2006 46 2007 40 2014 61 362 41 2022 46 2015 46 2016 40 2021 46 2009 41 2021 46 2052 40 2021 46 2009 46 2046 46 2070 40 41 44 2021 46 2009 46 2046 46 544 40 41 46 2070 40 41 41 2021 46 2052 40 2021 46 2010 46 2046 46 2117 40 41 44 2021 46 2010 46 2046 46 544 40 41 46 2117 40 41 41 ,"{'AvgLine': 14, 'CountLine': 493, 'CountStmt': 255, 'MaxNesting': 2, 'AvgLineCode': 12, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 223, 'MaxEssential': 1, 'SumEssential': 31, 'AvgCyclomatic': 1, 'CountLineCode': 386, 'CountStmtDecl': 63, 'MaxCyclomatic': 2, 'SumCyclomatic': 32, 'AvgLineComment': 1, 'CountClassBase': 0, 'CountLineBlank': 53, 'CountDeclMethod': 31, 'CountLineCodeExe': 350, 'CountLineComment': 54, 'CountClassCoupled': 9, 'CountClassDerived': 0, 'CountLineCodeDecl': 70, 'CountDeclMethodAll': 31, 'MaxInheritanceTree': 0, 'RatioCommentToCode': '0.14', 'AvgCyclomaticStrict': 1, 'MaxCyclomaticStrict': 2, 'SumCyclomaticStrict': 32, 'AvgCyclomaticModified': 1, 'MaxCyclomaticModified': 2, 'SumCyclomaticModified': 32, 'CountDeclInstanceMethod': 30, 'CountClassCoupledModified': 5, 'CountDeclInstanceVariable': 2}"
127047,Python,"class SageMakerBaseOperator(BaseOperator):
    """"""This is the base operator for all SageMaker operators.

    :param config: The configuration necessary to start a training job (templated)
    :type config: dict
    :param aws_conn_id: The AWS connection ID to use.
    :type aws_conn_id: str
    """"""

    template_fields = ['config']
    template_ext = ()
    template_fields_renderers = {'config': 'json'}
    ui_color = '#ededed'
    integer_fields = []

    def __init__(self, *, config: dict, aws_conn_id: str = 'aws_default', **kwargs):
        super().__init__(**kwargs)
        self.aws_conn_id = aws_conn_id
        self.config = config

    def parse_integer(self, config, field):
        """"""Recursive method for parsing string fields holding integer values to integers.""""""
        if len(field) == 1:
            if isinstance(config, list):
                for sub_config in config:
                    self.parse_integer(sub_config, field)
                return
            head = field[0]
            if head in config:
                config[head] = int(config[head])
            return
        if isinstance(config, list):
            for sub_config in config:
                self.parse_integer(sub_config, field)
            return
        (head, tail) = (field[0], field[1:])
        if head in config:
            self.parse_integer(config[head], tail)
        return

    def parse_config_integers(self):
        """"""
        Parse the integer fields of training config to integers in case the config is rendered by Jinja and
        all fields are str
        """"""
        for field in self.integer_fields:
            self.parse_integer(self.config, field)

    def expand_role(self):
        """"""Placeholder for calling boto3's `expand_role`, which expands an IAM role name into an ARN.""""""

    def preprocess_config(self):
        """"""Process the config into a usable form.""""""
        self.log.info('Preprocessing the config and doing required s3_operations')
        self.hook.configure_s3_resources(self.config)
        self.parse_config_integers()
        self.expand_role()
        self.log.info(
            'After preprocessing the config is:\n %s',
            json.dumps(self.config, sort_keys=True, indent=4, separators=(',', ': ')),
        )

    def execute(self, context):
        raise NotImplementedError('Please implement execute() in sub class!')

    @cached_property
    def hook(self):
        """"""Return SageMakerHook""""""
        return SageMakerHook(aws_conn_id=self.aws_conn_id)",1,587 2000 40 2001 41 58 362 2002 61 91 362 93 2003 61 40 41 2004 61 123 362 58 362 125 2005 61 362 2006 61 91 93 612 2007 40 2008 44 42 44 2009 58 620 44 2010 58 813 61 362 44 350 2011 41 58 818 40 41 46 2007 40 350 2011 41 2008 46 2010 61 2010 2008 46 2009 61 2009 612 2012 40 2008 44 2009 44 2013 41 58 362 688 720 40 2013 41 323 1501 58 688 713 40 2009 44 723 41 58 664 2014 696 2009 58 2008 46 2012 40 2014 44 2013 41 792 2015 61 2013 91 1500 93 688 2015 696 2009 58 2009 91 2015 93 61 704 40 2009 91 2015 93 41 792 688 713 40 2009 44 723 41 58 664 2014 696 2009 58 2008 46 2012 40 2014 44 2013 41 792 40 2015 44 2016 41 61 40 2013 91 1500 93 44 2013 91 1501 58 93 41 688 2015 696 2009 58 2008 46 2012 40 2009 91 2015 93 44 2016 41 792 612 2017 40 2008 41 58 362 664 2013 696 2008 46 2006 58 2008 46 2012 40 2008 46 2009 44 2013 41 612 2018 40 2008 41 58 362 612 2019 40 2008 41 58 362 2008 46 2020 46 2021 40 362 41 2008 46 2022 46 2023 40 2008 46 2009 41 2008 46 2017 40 41 2008 46 2018 40 41 2008 46 2020 46 2021 40 362 44 2024 46 2025 40 2008 46 2009 44 2026 61 515 44 2027 61 1502 44 2028 61 40 362 44 362 41 41 44 41 612 2029 40 2008 44 2030 41 58 778 2031 40 362 41 64 2032 612 2022 40 2008 41 58 362 792 2033 40 2010 61 2008 46 2010 41 ,"{'AvgLine': 6, 'CountLine': 69, 'CountStmt': 42, 'MaxNesting': 3, 'AvgLineCode': 5, 'AvgEssential': 1, 'AvgLineBlank': 0, 'CountStmtExe': 34, 'MaxEssential': 4, 'SumEssential': 10, 'AvgCyclomatic': 2, 'CountLineCode': 46, 'CountStmtDecl': 19, 'MaxCyclomatic': 8, 'SumCyclomatic': 15, 'AvgLineComment': 1, 'CountClassBase': 1, 'CountLineBlank': 9, 'CountDeclMethod': 7, 'CountLineCodeExe': 37, 'CountLineComment': 15, 'CountClassCoupled': 6, 'CountClassDerived': 7, 'CountLineCodeDecl': 20, 'CountDeclMethodAll': 85, 'MaxInheritanceTree': 3, 'RatioCommentToCode': '0.33', 'AvgCyclomaticStrict': 2, 'MaxCyclomaticStrict': 8, 'SumCyclomaticStrict': 15, 'AvgCyclomaticModified': 2, 'MaxCyclomaticModified': 8, 'SumCyclomaticModified': 15, 'CountDeclInstanceMethod': 7, 'CountClassCoupledModified': 1, 'CountDeclInstanceVariable': 2}"
